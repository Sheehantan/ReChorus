INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-04 19:33:07 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5163 [22.0 s]    dev=(HR@5:0.2509,NDCG@5:0.1667) [0.9 s] *
INFO:root:Epoch 2     loss=0.4331 [20.1 s]    dev=(HR@5:0.3203,NDCG@5:0.2167) [0.9 s] *
INFO:root:Epoch 3     loss=0.4002 [20.0 s]    dev=(HR@5:0.3376,NDCG@5:0.2280) [0.9 s] *
INFO:root:Epoch 4     loss=0.3841 [20.0 s]    dev=(HR@5:0.3552,NDCG@5:0.2450) [0.9 s] *
INFO:root:Epoch 5     loss=0.3621 [20.0 s]    dev=(HR@5:0.3727,NDCG@5:0.2595) [0.9 s] *
INFO:root:Epoch 6     loss=0.3374 [20.1 s]    dev=(HR@5:0.3893,NDCG@5:0.2754) [0.9 s] *
INFO:root:Epoch 7     loss=0.3185 [20.0 s]    dev=(HR@5:0.3958,NDCG@5:0.2816) [0.9 s] *
INFO:root:Epoch 8     loss=0.2998 [20.1 s]    dev=(HR@5:0.4057,NDCG@5:0.2896) [0.9 s] *
INFO:root:Epoch 9     loss=0.2840 [20.1 s]    dev=(HR@5:0.4096,NDCG@5:0.2950) [0.9 s] *
INFO:root:Epoch 10    loss=0.2731 [20.1 s]    dev=(HR@5:0.4126,NDCG@5:0.2986) [0.9 s] *
INFO:root:Epoch 11    loss=0.2614 [20.0 s]    dev=(HR@5:0.4151,NDCG@5:0.3001) [0.9 s] *
INFO:root:Epoch 12    loss=0.2528 [20.0 s]    dev=(HR@5:0.4186,NDCG@5:0.3048) [0.9 s] *
INFO:root:Epoch 13    loss=0.2479 [20.0 s]    dev=(HR@5:0.4235,NDCG@5:0.3085) [0.9 s] *
INFO:root:Epoch 14    loss=0.2412 [20.1 s]    dev=(HR@5:0.4203,NDCG@5:0.3061) [0.9 s]
INFO:root:Epoch 15    loss=0.2382 [20.1 s]    dev=(HR@5:0.4183,NDCG@5:0.3038) [0.9 s]
INFO:root:Epoch 16    loss=0.2342 [20.0 s]    dev=(HR@5:0.4239,NDCG@5:0.3101) [0.9 s] *
INFO:root:Epoch 17    loss=0.2300 [20.1 s]    dev=(HR@5:0.4199,NDCG@5:0.3075) [0.9 s]
INFO:root:Epoch 18    loss=0.2262 [20.0 s]    dev=(HR@5:0.4250,NDCG@5:0.3100) [0.9 s]
INFO:root:Epoch 19    loss=0.2227 [20.1 s]    dev=(HR@5:0.4275,NDCG@5:0.3141) [0.9 s] *
INFO:root:Epoch 20    loss=0.2207 [20.1 s]    dev=(HR@5:0.4299,NDCG@5:0.3152) [0.9 s] *
INFO:root:Epoch 21    loss=0.2161 [20.0 s]    dev=(HR@5:0.4296,NDCG@5:0.3170) [0.9 s] *
INFO:root:Epoch 22    loss=0.2139 [20.0 s]    dev=(HR@5:0.4282,NDCG@5:0.3142) [0.9 s]
INFO:root:Epoch 23    loss=0.2138 [20.1 s]    dev=(HR@5:0.4259,NDCG@5:0.3131) [0.9 s]
INFO:root:Epoch 24    loss=0.2131 [19.9 s]    dev=(HR@5:0.4304,NDCG@5:0.3165) [0.9 s]
INFO:root:Epoch 25    loss=0.2092 [20.0 s]    dev=(HR@5:0.4325,NDCG@5:0.3172) [0.9 s] *
INFO:root:Epoch 26    loss=0.2100 [20.1 s]    dev=(HR@5:0.4328,NDCG@5:0.3195) [0.9 s] *
INFO:root:Epoch 27    loss=0.2081 [20.0 s]    dev=(HR@5:0.4323,NDCG@5:0.3188) [0.9 s]
INFO:root:Epoch 28    loss=0.2067 [20.0 s]    dev=(HR@5:0.4369,NDCG@5:0.3223) [0.9 s] *
INFO:root:Epoch 29    loss=0.2052 [20.1 s]    dev=(HR@5:0.4312,NDCG@5:0.3174) [0.9 s]
INFO:root:Epoch 30    loss=0.2045 [20.0 s]    dev=(HR@5:0.4334,NDCG@5:0.3193) [0.9 s]
INFO:root:Epoch 31    loss=0.2028 [20.1 s]    dev=(HR@5:0.4340,NDCG@5:0.3193) [0.9 s]
INFO:root:Epoch 32    loss=0.2031 [20.1 s]    dev=(HR@5:0.4344,NDCG@5:0.3201) [0.9 s]
INFO:root:Epoch 33    loss=0.2025 [20.0 s]    dev=(HR@5:0.4381,NDCG@5:0.3217) [0.9 s]
INFO:root:Epoch 34    loss=0.2008 [20.1 s]    dev=(HR@5:0.4361,NDCG@5:0.3201) [0.9 s]
INFO:root:Epoch 35    loss=0.2022 [20.0 s]    dev=(HR@5:0.4329,NDCG@5:0.3181) [0.9 s]
INFO:root:Epoch 36    loss=0.1992 [20.0 s]    dev=(HR@5:0.4376,NDCG@5:0.3214) [0.9 s]
INFO:root:Epoch 37    loss=0.1999 [20.0 s]    dev=(HR@5:0.4377,NDCG@5:0.3218) [0.9 s]
INFO:root:Epoch 38    loss=0.1997 [20.0 s]    dev=(HR@5:0.4353,NDCG@5:0.3189) [0.9 s]
INFO:root:Epoch 39    loss=0.1991 [20.0 s]    dev=(HR@5:0.4372,NDCG@5:0.3190) [0.9 s]
INFO:root:Epoch 40    loss=0.1989 [20.1 s]    dev=(HR@5:0.4349,NDCG@5:0.3191) [0.9 s]
INFO:root:Epoch 41    loss=0.1990 [20.1 s]    dev=(HR@5:0.4346,NDCG@5:0.3189) [0.9 s]
INFO:root:Epoch 42    loss=0.1990 [20.0 s]    dev=(HR@5:0.4387,NDCG@5:0.3213) [0.9 s]
INFO:root:Epoch 43    loss=0.1981 [20.1 s]    dev=(HR@5:0.4432,NDCG@5:0.3264) [0.9 s] *
INFO:root:Epoch 44    loss=0.2004 [20.1 s]    dev=(HR@5:0.4400,NDCG@5:0.3215) [0.9 s]
INFO:root:Epoch 45    loss=0.1954 [20.2 s]    dev=(HR@5:0.4423,NDCG@5:0.3259) [0.9 s]
INFO:root:Epoch 46    loss=0.1970 [20.1 s]    dev=(HR@5:0.4394,NDCG@5:0.3230) [0.9 s]
INFO:root:Epoch 47    loss=0.1983 [20.1 s]    dev=(HR@5:0.4361,NDCG@5:0.3219) [0.9 s]
INFO:root:Epoch 48    loss=0.1965 [20.1 s]    dev=(HR@5:0.4339,NDCG@5:0.3199) [0.9 s]
INFO:root:Epoch 49    loss=0.1957 [20.0 s]    dev=(HR@5:0.4430,NDCG@5:0.3240) [0.9 s]
INFO:root:Epoch 50    loss=0.1976 [20.1 s]    dev=(HR@5:0.4369,NDCG@5:0.3223) [0.9 s]
INFO:root:Epoch 51    loss=0.1964 [20.1 s]    dev=(HR@5:0.4378,NDCG@5:0.3225) [0.9 s]
INFO:root:Epoch 52    loss=0.1964 [20.0 s]    dev=(HR@5:0.4368,NDCG@5:0.3199) [0.9 s]
INFO:root:Epoch 53    loss=0.1961 [20.0 s]    dev=(HR@5:0.4385,NDCG@5:0.3214) [0.9 s]
INFO:root:Epoch 54    loss=0.1938 [20.1 s]    dev=(HR@5:0.4399,NDCG@5:0.3223) [0.9 s]
INFO:root:Epoch 55    loss=0.1943 [20.0 s]    dev=(HR@5:0.4390,NDCG@5:0.3225) [0.9 s]
INFO:root:Epoch 56    loss=0.1936 [20.0 s]    dev=(HR@5:0.4414,NDCG@5:0.3233) [0.9 s]
INFO:root:Epoch 57    loss=0.1942 [20.1 s]    dev=(HR@5:0.4415,NDCG@5:0.3263) [0.9 s]
INFO:root:Epoch 58    loss=0.1948 [20.0 s]    dev=(HR@5:0.4439,NDCG@5:0.3264) [0.9 s]
INFO:root:Epoch 59    loss=0.1941 [20.0 s]    dev=(HR@5:0.4406,NDCG@5:0.3238) [0.9 s]
INFO:root:Epoch 60    loss=0.1953 [20.1 s]    dev=(HR@5:0.4408,NDCG@5:0.3238) [0.9 s]
INFO:root:Epoch 61    loss=0.1935 [20.1 s]    dev=(HR@5:0.4448,NDCG@5:0.3266) [0.9 s] *
INFO:root:Epoch 62    loss=0.1930 [20.1 s]    dev=(HR@5:0.4379,NDCG@5:0.3236) [0.9 s]
INFO:root:Epoch 63    loss=0.1941 [20.1 s]    dev=(HR@5:0.4419,NDCG@5:0.3261) [0.9 s]
INFO:root:Epoch 64    loss=0.1933 [20.2 s]    dev=(HR@5:0.4410,NDCG@5:0.3237) [0.9 s]
INFO:root:Epoch 65    loss=0.1940 [20.0 s]    dev=(HR@5:0.4394,NDCG@5:0.3234) [0.9 s]
INFO:root:Epoch 66    loss=0.1921 [20.2 s]    dev=(HR@5:0.4398,NDCG@5:0.3223) [0.9 s]
INFO:root:Epoch 67    loss=0.1929 [20.1 s]    dev=(HR@5:0.4431,NDCG@5:0.3258) [0.9 s]
INFO:root:Epoch 68    loss=0.1909 [20.1 s]    dev=(HR@5:0.4393,NDCG@5:0.3234) [0.9 s]
INFO:root:Epoch 69    loss=0.1917 [20.0 s]    dev=(HR@5:0.4390,NDCG@5:0.3225) [0.9 s]
INFO:root:Epoch 70    loss=0.1914 [20.0 s]    dev=(HR@5:0.4385,NDCG@5:0.3236) [0.9 s]
INFO:root:Epoch 71    loss=0.1912 [20.1 s]    dev=(HR@5:0.4378,NDCG@5:0.3233) [0.9 s]
INFO:root:Epoch 72    loss=0.1903 [20.1 s]    dev=(HR@5:0.4357,NDCG@5:0.3204) [0.9 s]
INFO:root:Epoch 73    loss=0.1914 [20.0 s]    dev=(HR@5:0.4387,NDCG@5:0.3226) [0.9 s]
INFO:root:Epoch 74    loss=0.1915 [20.1 s]    dev=(HR@5:0.4342,NDCG@5:0.3179) [0.9 s]
INFO:root:Epoch 75    loss=0.1926 [20.1 s]    dev=(HR@5:0.4376,NDCG@5:0.3235) [0.9 s]
INFO:root:Epoch 76    loss=0.1924 [20.1 s]    dev=(HR@5:0.4389,NDCG@5:0.3222) [0.9 s]
INFO:root:Epoch 77    loss=0.1906 [20.2 s]    dev=(HR@5:0.4400,NDCG@5:0.3227) [0.9 s]
INFO:root:Epoch 78    loss=0.1907 [20.1 s]    dev=(HR@5:0.4383,NDCG@5:0.3230) [0.9 s]
INFO:root:Epoch 79    loss=0.1917 [20.1 s]    dev=(HR@5:0.4399,NDCG@5:0.3246) [0.9 s]
INFO:root:Epoch 80    loss=0.1896 [20.1 s]    dev=(HR@5:0.4395,NDCG@5:0.3226) [0.9 s]
INFO:root:Epoch 81    loss=0.1895 [20.1 s]    dev=(HR@5:0.4371,NDCG@5:0.3186) [0.9 s]
INFO:root:Early stop at 81 based on dev result.
INFO:root:
Best Iter(dev)=   61	 dev=(HR@5:0.4448,NDCG@5:0.3266) [1700.2 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.3923,NDCG@5:0.2798,HR@10:0.5006,NDCG@10:0.3149,HR@20:0.6168,NDCG@20:0.3443,HR@50:0.8247,NDCG@50:0.3853)
INFO:root:
--------------------------------------------- END: 2024-12-04 20:01:29 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-05 19:59:00 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5163 [23.6 s]    dev=(HR@5:0.2509,NDCG@5:0.1667) [0.9 s] *
INFO:root:Epoch 2     loss=0.4331 [20.5 s]    dev=(HR@5:0.3203,NDCG@5:0.2167) [0.9 s] *
INFO:root:Epoch 3     loss=0.4002 [20.2 s]    dev=(HR@5:0.3376,NDCG@5:0.2280) [0.9 s] *
INFO:root:Epoch 4     loss=0.3841 [20.7 s]    dev=(HR@5:0.3552,NDCG@5:0.2450) [0.9 s] *
INFO:root:Epoch 5     loss=0.3621 [20.6 s]    dev=(HR@5:0.3727,NDCG@5:0.2595) [0.9 s] *
INFO:root:Epoch 6     loss=0.3374 [20.7 s]    dev=(HR@5:0.3893,NDCG@5:0.2754) [0.9 s] *
INFO:root:Epoch 7     loss=0.3185 [20.7 s]    dev=(HR@5:0.3958,NDCG@5:0.2816) [0.9 s] *
INFO:root:Epoch 8     loss=0.2998 [20.7 s]    dev=(HR@5:0.4057,NDCG@5:0.2896) [0.9 s] *
INFO:root:Epoch 9     loss=0.2840 [20.5 s]    dev=(HR@5:0.4096,NDCG@5:0.2950) [0.9 s] *
INFO:root:Epoch 10    loss=0.2731 [20.8 s]    dev=(HR@5:0.4126,NDCG@5:0.2986) [0.9 s] *
INFO:root:Epoch 11    loss=0.2614 [20.7 s]    dev=(HR@5:0.4151,NDCG@5:0.3001) [0.9 s] *
INFO:root:Epoch 12    loss=0.2528 [20.8 s]    dev=(HR@5:0.4186,NDCG@5:0.3048) [0.9 s] *
INFO:root:Epoch 13    loss=0.2479 [20.8 s]    dev=(HR@5:0.4235,NDCG@5:0.3085) [0.9 s] *
INFO:root:Epoch 14    loss=0.2412 [20.8 s]    dev=(HR@5:0.4203,NDCG@5:0.3061) [0.9 s]
INFO:root:Epoch 15    loss=0.2382 [20.8 s]    dev=(HR@5:0.4183,NDCG@5:0.3038) [0.9 s]
INFO:root:Epoch 16    loss=0.2342 [20.9 s]    dev=(HR@5:0.4239,NDCG@5:0.3101) [0.9 s] *
INFO:root:Epoch 17    loss=0.2300 [20.9 s]    dev=(HR@5:0.4199,NDCG@5:0.3075) [0.9 s]
INFO:root:Epoch 18    loss=0.2262 [20.9 s]    dev=(HR@5:0.4250,NDCG@5:0.3100) [0.9 s]
INFO:root:Epoch 19    loss=0.2227 [20.7 s]    dev=(HR@5:0.4275,NDCG@5:0.3141) [0.9 s] *
INFO:root:Epoch 20    loss=0.2207 [20.8 s]    dev=(HR@5:0.4299,NDCG@5:0.3152) [0.9 s] *
INFO:root:Epoch 21    loss=0.2161 [20.8 s]    dev=(HR@5:0.4296,NDCG@5:0.3170) [0.9 s] *
INFO:root:Epoch 22    loss=0.2139 [20.8 s]    dev=(HR@5:0.4282,NDCG@5:0.3142) [0.9 s]
INFO:root:Epoch 23    loss=0.2138 [20.7 s]    dev=(HR@5:0.4259,NDCG@5:0.3131) [0.9 s]
INFO:root:Epoch 24    loss=0.2131 [20.8 s]    dev=(HR@5:0.4304,NDCG@5:0.3165) [0.9 s]
INFO:root:Epoch 25    loss=0.2092 [20.7 s]    dev=(HR@5:0.4325,NDCG@5:0.3172) [1.0 s] *
INFO:root:Epoch 26    loss=0.2100 [20.8 s]    dev=(HR@5:0.4328,NDCG@5:0.3195) [0.9 s] *
INFO:root:Epoch 27    loss=0.2081 [20.5 s]    dev=(HR@5:0.4323,NDCG@5:0.3188) [0.9 s]
INFO:root:Epoch 28    loss=0.2067 [20.6 s]    dev=(HR@5:0.4369,NDCG@5:0.3223) [0.9 s] *
INFO:root:Epoch 29    loss=0.2052 [20.4 s]    dev=(HR@5:0.4312,NDCG@5:0.3174) [0.9 s]
INFO:root:Epoch 30    loss=0.2045 [20.3 s]    dev=(HR@5:0.4334,NDCG@5:0.3193) [0.9 s]
INFO:root:Epoch 31    loss=0.2028 [20.5 s]    dev=(HR@5:0.4340,NDCG@5:0.3193) [0.9 s]
INFO:root:Epoch 32    loss=0.2031 [20.3 s]    dev=(HR@5:0.4344,NDCG@5:0.3201) [0.9 s]
INFO:root:Epoch 33    loss=0.2025 [20.5 s]    dev=(HR@5:0.4381,NDCG@5:0.3217) [0.9 s]
INFO:root:Epoch 34    loss=0.2008 [20.3 s]    dev=(HR@5:0.4361,NDCG@5:0.3201) [0.9 s]
INFO:root:Epoch 35    loss=0.2022 [20.8 s]    dev=(HR@5:0.4329,NDCG@5:0.3181) [0.9 s]
INFO:root:Epoch 36    loss=0.1992 [20.7 s]    dev=(HR@5:0.4376,NDCG@5:0.3214) [0.9 s]
INFO:root:Epoch 37    loss=0.1999 [20.9 s]    dev=(HR@5:0.4377,NDCG@5:0.3218) [0.9 s]
INFO:root:Epoch 38    loss=0.1997 [21.5 s]    dev=(HR@5:0.4353,NDCG@5:0.3189) [0.9 s]
INFO:root:Epoch 39    loss=0.1991 [20.8 s]    dev=(HR@5:0.4372,NDCG@5:0.3190) [0.9 s]
INFO:root:Epoch 40    loss=0.1989 [20.8 s]    dev=(HR@5:0.4349,NDCG@5:0.3191) [1.0 s]
INFO:root:Epoch 41    loss=0.1990 [20.6 s]    dev=(HR@5:0.4346,NDCG@5:0.3189) [0.9 s]
INFO:root:Epoch 42    loss=0.1990 [20.9 s]    dev=(HR@5:0.4387,NDCG@5:0.3213) [0.9 s]
INFO:root:Epoch 43    loss=0.1981 [20.8 s]    dev=(HR@5:0.4432,NDCG@5:0.3264) [0.9 s] *
INFO:root:Epoch 44    loss=0.2004 [20.6 s]    dev=(HR@5:0.4400,NDCG@5:0.3215) [0.9 s]
INFO:root:Epoch 45    loss=0.1954 [22.3 s]    dev=(HR@5:0.4423,NDCG@5:0.3259) [1.3 s]
INFO:root:Epoch 46    loss=0.1970 [22.4 s]    dev=(HR@5:0.4394,NDCG@5:0.3230) [0.9 s]
INFO:root:Epoch 47    loss=0.1983 [20.7 s]    dev=(HR@5:0.4361,NDCG@5:0.3219) [0.9 s]
INFO:root:Epoch 48    loss=0.1965 [20.8 s]    dev=(HR@5:0.4339,NDCG@5:0.3199) [0.9 s]
INFO:root:Epoch 49    loss=0.1957 [21.5 s]    dev=(HR@5:0.4430,NDCG@5:0.3240) [1.0 s]
INFO:root:Epoch 50    loss=0.1976 [21.4 s]    dev=(HR@5:0.4369,NDCG@5:0.3223) [0.9 s]
INFO:root:Epoch 51    loss=0.1964 [21.4 s]    dev=(HR@5:0.4378,NDCG@5:0.3225) [0.9 s]
INFO:root:Epoch 52    loss=0.1964 [21.4 s]    dev=(HR@5:0.4368,NDCG@5:0.3199) [0.9 s]
INFO:root:Epoch 53    loss=0.1961 [21.3 s]    dev=(HR@5:0.4385,NDCG@5:0.3214) [0.9 s]
INFO:root:Epoch 54    loss=0.1938 [21.0 s]    dev=(HR@5:0.4399,NDCG@5:0.3223) [1.0 s]
INFO:root:Epoch 55    loss=0.1943 [21.1 s]    dev=(HR@5:0.4390,NDCG@5:0.3225) [1.0 s]
INFO:root:Epoch 56    loss=0.1936 [21.3 s]    dev=(HR@5:0.4414,NDCG@5:0.3233) [0.9 s]
INFO:root:Epoch 57    loss=0.1942 [20.6 s]    dev=(HR@5:0.4415,NDCG@5:0.3263) [0.9 s]
INFO:root:Epoch 58    loss=0.1948 [20.5 s]    dev=(HR@5:0.4439,NDCG@5:0.3264) [0.9 s]
INFO:root:Epoch 59    loss=0.1941 [20.6 s]    dev=(HR@5:0.4406,NDCG@5:0.3238) [0.9 s]
INFO:root:Epoch 60    loss=0.1953 [20.7 s]    dev=(HR@5:0.4408,NDCG@5:0.3238) [0.9 s]
INFO:root:Epoch 61    loss=0.1935 [20.9 s]    dev=(HR@5:0.4448,NDCG@5:0.3266) [0.9 s] *
INFO:root:Epoch 62    loss=0.1930 [20.9 s]    dev=(HR@5:0.4379,NDCG@5:0.3236) [0.9 s]
INFO:root:Epoch 63    loss=0.1941 [20.6 s]    dev=(HR@5:0.4419,NDCG@5:0.3261) [0.9 s]
INFO:root:Epoch 64    loss=0.1933 [22.4 s]    dev=(HR@5:0.4410,NDCG@5:0.3237) [0.9 s]
INFO:root:Epoch 65    loss=0.1940 [21.1 s]    dev=(HR@5:0.4394,NDCG@5:0.3234) [0.9 s]
INFO:root:Epoch 66    loss=0.1921 [20.9 s]    dev=(HR@5:0.4398,NDCG@5:0.3223) [0.9 s]
INFO:root:Epoch 67    loss=0.1929 [20.9 s]    dev=(HR@5:0.4431,NDCG@5:0.3258) [0.9 s]
INFO:root:Epoch 68    loss=0.1909 [20.9 s]    dev=(HR@5:0.4393,NDCG@5:0.3234) [0.9 s]
INFO:root:Epoch 69    loss=0.1917 [20.7 s]    dev=(HR@5:0.4390,NDCG@5:0.3225) [0.9 s]
INFO:root:Epoch 70    loss=0.1914 [20.7 s]    dev=(HR@5:0.4385,NDCG@5:0.3236) [0.9 s]
INFO:root:Epoch 71    loss=0.1912 [20.6 s]    dev=(HR@5:0.4378,NDCG@5:0.3233) [1.0 s]
INFO:root:Epoch 72    loss=0.1903 [20.6 s]    dev=(HR@5:0.4357,NDCG@5:0.3204) [0.9 s]
INFO:root:Epoch 73    loss=0.1914 [20.6 s]    dev=(HR@5:0.4387,NDCG@5:0.3226) [0.9 s]
INFO:root:Epoch 74    loss=0.1915 [32.2 s]    dev=(HR@5:0.4342,NDCG@5:0.3179) [0.9 s]
INFO:root:Epoch 75    loss=0.1926 [20.7 s]    dev=(HR@5:0.4376,NDCG@5:0.3235) [0.9 s]
INFO:root:Epoch 76    loss=0.1924 [20.8 s]    dev=(HR@5:0.4389,NDCG@5:0.3222) [0.9 s]
INFO:root:Epoch 77    loss=0.1906 [20.6 s]    dev=(HR@5:0.4400,NDCG@5:0.3227) [0.9 s]
INFO:root:Epoch 78    loss=0.1907 [20.5 s]    dev=(HR@5:0.4383,NDCG@5:0.3230) [0.9 s]
INFO:root:Epoch 79    loss=0.1917 [20.6 s]    dev=(HR@5:0.4399,NDCG@5:0.3246) [0.9 s]
INFO:root:Epoch 80    loss=0.1896 [20.4 s]    dev=(HR@5:0.4395,NDCG@5:0.3226) [0.9 s]
INFO:root:Epoch 81    loss=0.1895 [21.0 s]    dev=(HR@5:0.4371,NDCG@5:0.3186) [0.9 s]
INFO:root:Early stop at 81 based on dev result.
INFO:root:
Best Iter(dev)=   61	 dev=(HR@5:0.4448,NDCG@5:0.3266) [1775.8 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.3923,NDCG@5:0.2798,HR@10:0.5006,NDCG@10:0.3149,HR@20:0.6168,NDCG@20:0.3443,HR@50:0.8247,NDCG@50:0.3853)
INFO:root:
--------------------------------------------- END: 2024-12-05 20:28:38 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-05 21:00:34 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [35.2 s]    dev=(HR@5:0.2513,NDCG@5:0.1670) [1.4 s] *
INFO:root:Epoch 2     loss=0.4327 [30.5 s]    dev=(HR@5:0.3208,NDCG@5:0.2171) [1.4 s] *
INFO:root:Epoch 3     loss=0.4001 [30.6 s]    dev=(HR@5:0.3373,NDCG@5:0.2273) [1.3 s] *
INFO:root:Epoch 4     loss=0.3850 [21.1 s]    dev=(HR@5:0.3529,NDCG@5:0.2426) [0.9 s] *
INFO:root:Epoch 5     loss=0.3638 [20.7 s]    dev=(HR@5:0.3697,NDCG@5:0.2560) [0.9 s] *
INFO:root:Epoch 6     loss=0.3401 [20.6 s]    dev=(HR@5:0.3845,NDCG@5:0.2707) [0.9 s] *
INFO:root:Epoch 7     loss=0.3215 [20.6 s]    dev=(HR@5:0.3941,NDCG@5:0.2779) [0.9 s] *
INFO:root:Epoch 8     loss=0.3034 [20.7 s]    dev=(HR@5:0.3994,NDCG@5:0.2838) [0.9 s] *
INFO:root:Epoch 9     loss=0.2876 [20.8 s]    dev=(HR@5:0.4021,NDCG@5:0.2881) [0.9 s] *
INFO:root:Epoch 10    loss=0.2768 [20.6 s]    dev=(HR@5:0.4085,NDCG@5:0.2936) [0.9 s] *
INFO:root:Epoch 11    loss=0.2650 [20.7 s]    dev=(HR@5:0.4141,NDCG@5:0.2985) [0.9 s] *
INFO:root:Epoch 12    loss=0.2566 [20.6 s]    dev=(HR@5:0.4173,NDCG@5:0.3019) [0.9 s] *
INFO:root:Epoch 13    loss=0.2512 [20.8 s]    dev=(HR@5:0.4241,NDCG@5:0.3083) [0.9 s] *
INFO:root:Epoch 14    loss=0.2444 [20.6 s]    dev=(HR@5:0.4190,NDCG@5:0.3043) [1.0 s]
INFO:root:Epoch 15    loss=0.2416 [20.6 s]    dev=(HR@5:0.4229,NDCG@5:0.3058) [0.9 s]
INFO:root:Epoch 16    loss=0.2383 [21.0 s]    dev=(HR@5:0.4248,NDCG@5:0.3101) [1.0 s] *
INFO:root:Epoch 17    loss=0.2342 [21.8 s]    dev=(HR@5:0.4239,NDCG@5:0.3094) [0.9 s]
INFO:root:Epoch 18    loss=0.2295 [21.4 s]    dev=(HR@5:0.4254,NDCG@5:0.3113) [0.9 s] *
INFO:root:Epoch 19    loss=0.2268 [21.2 s]    dev=(HR@5:0.4300,NDCG@5:0.3156) [1.0 s] *
INFO:root:Epoch 20    loss=0.2240 [21.2 s]    dev=(HR@5:0.4293,NDCG@5:0.3156) [0.9 s]
INFO:root:Epoch 21    loss=0.2197 [20.6 s]    dev=(HR@5:0.4320,NDCG@5:0.3176) [0.9 s] *
INFO:root:Epoch 22    loss=0.2180 [20.7 s]    dev=(HR@5:0.4257,NDCG@5:0.3134) [0.9 s]
INFO:root:Epoch 23    loss=0.2178 [20.8 s]    dev=(HR@5:0.4267,NDCG@5:0.3146) [0.9 s]
INFO:root:Epoch 24    loss=0.2161 [20.7 s]    dev=(HR@5:0.4374,NDCG@5:0.3209) [0.9 s] *
INFO:root:Epoch 25    loss=0.2129 [20.5 s]    dev=(HR@5:0.4299,NDCG@5:0.3162) [0.9 s]
INFO:root:Epoch 26    loss=0.2129 [20.7 s]    dev=(HR@5:0.4338,NDCG@5:0.3206) [0.9 s]
INFO:root:Epoch 27    loss=0.2120 [20.7 s]    dev=(HR@5:0.4348,NDCG@5:0.3205) [0.9 s]
INFO:root:Epoch 28    loss=0.2096 [22.0 s]    dev=(HR@5:0.4379,NDCG@5:0.3226) [0.9 s] *
INFO:root:Epoch 29    loss=0.2081 [20.6 s]    dev=(HR@5:0.4297,NDCG@5:0.3178) [0.9 s]
INFO:root:Epoch 30    loss=0.2076 [20.6 s]    dev=(HR@5:0.4316,NDCG@5:0.3182) [0.9 s]
INFO:root:Epoch 31    loss=0.2066 [20.6 s]    dev=(HR@5:0.4363,NDCG@5:0.3216) [0.9 s]
INFO:root:Epoch 32    loss=0.2063 [20.6 s]    dev=(HR@5:0.4367,NDCG@5:0.3216) [0.9 s]
INFO:root:Epoch 33    loss=0.2057 [20.6 s]    dev=(HR@5:0.4385,NDCG@5:0.3230) [0.9 s] *
INFO:root:Epoch 34    loss=0.2042 [21.0 s]    dev=(HR@5:0.4365,NDCG@5:0.3207) [0.9 s]
INFO:root:Epoch 35    loss=0.2054 [20.6 s]    dev=(HR@5:0.4349,NDCG@5:0.3200) [0.9 s]
INFO:root:Epoch 36    loss=0.2019 [20.6 s]    dev=(HR@5:0.4369,NDCG@5:0.3216) [0.9 s]
INFO:root:Epoch 37    loss=0.2028 [20.7 s]    dev=(HR@5:0.4346,NDCG@5:0.3212) [0.9 s]
INFO:root:Epoch 38    loss=0.2027 [20.7 s]    dev=(HR@5:0.4368,NDCG@5:0.3203) [0.9 s]
INFO:root:Epoch 39    loss=0.2025 [20.6 s]    dev=(HR@5:0.4357,NDCG@5:0.3194) [0.9 s]
INFO:root:Epoch 40    loss=0.2012 [20.6 s]    dev=(HR@5:0.4319,NDCG@5:0.3196) [0.9 s]
INFO:root:Epoch 41    loss=0.2012 [20.6 s]    dev=(HR@5:0.4323,NDCG@5:0.3177) [0.9 s]
INFO:root:Epoch 42    loss=0.2009 [20.6 s]    dev=(HR@5:0.4389,NDCG@5:0.3223) [0.9 s]
INFO:root:Epoch 43    loss=0.2006 [20.7 s]    dev=(HR@5:0.4420,NDCG@5:0.3256) [0.9 s] *
INFO:root:Epoch 44    loss=0.2014 [20.6 s]    dev=(HR@5:0.4381,NDCG@5:0.3232) [0.9 s]
INFO:root:Epoch 45    loss=0.1967 [20.6 s]    dev=(HR@5:0.4432,NDCG@5:0.3270) [0.9 s] *
INFO:root:Epoch 46    loss=0.1984 [20.7 s]    dev=(HR@5:0.4390,NDCG@5:0.3218) [0.9 s]
INFO:root:Epoch 47    loss=0.1991 [20.7 s]    dev=(HR@5:0.4361,NDCG@5:0.3214) [0.9 s]
INFO:root:Epoch 48    loss=0.1974 [20.6 s]    dev=(HR@5:0.4377,NDCG@5:0.3225) [0.9 s]
INFO:root:Epoch 49    loss=0.1962 [21.1 s]    dev=(HR@5:0.4427,NDCG@5:0.3249) [0.9 s]
INFO:root:Epoch 50    loss=0.1978 [20.7 s]    dev=(HR@5:0.4370,NDCG@5:0.3222) [0.9 s]
INFO:root:Epoch 51    loss=0.1960 [20.7 s]    dev=(HR@5:0.4406,NDCG@5:0.3246) [0.9 s]
INFO:root:Epoch 52    loss=0.1961 [20.7 s]    dev=(HR@5:0.4372,NDCG@5:0.3215) [0.9 s]
INFO:root:Epoch 53    loss=0.1950 [20.7 s]    dev=(HR@5:0.4392,NDCG@5:0.3224) [0.9 s]
INFO:root:Epoch 54    loss=0.1929 [20.8 s]    dev=(HR@5:0.4439,NDCG@5:0.3262) [0.9 s]
INFO:root:Epoch 55    loss=0.1932 [20.6 s]    dev=(HR@5:0.4400,NDCG@5:0.3223) [0.9 s]
INFO:root:Epoch 56    loss=0.1928 [20.6 s]    dev=(HR@5:0.4449,NDCG@5:0.3263) [0.9 s]
INFO:root:Epoch 57    loss=0.1926 [20.6 s]    dev=(HR@5:0.4432,NDCG@5:0.3267) [0.9 s]
INFO:root:Epoch 58    loss=0.1939 [20.6 s]    dev=(HR@5:0.4470,NDCG@5:0.3290) [0.9 s] *
INFO:root:Epoch 59    loss=0.1926 [20.7 s]    dev=(HR@5:0.4409,NDCG@5:0.3254) [0.9 s]
INFO:root:Epoch 60    loss=0.1928 [20.6 s]    dev=(HR@5:0.4392,NDCG@5:0.3240) [0.9 s]
INFO:root:Epoch 61    loss=0.1922 [20.7 s]    dev=(HR@5:0.4453,NDCG@5:0.3282) [0.9 s]
INFO:root:Epoch 62    loss=0.1924 [20.6 s]    dev=(HR@5:0.4433,NDCG@5:0.3269) [0.9 s]
INFO:root:Epoch 63    loss=0.1922 [20.7 s]    dev=(HR@5:0.4430,NDCG@5:0.3272) [0.9 s]
INFO:root:Epoch 64    loss=0.1909 [20.6 s]    dev=(HR@5:0.4447,NDCG@5:0.3259) [0.9 s]
INFO:root:Epoch 65    loss=0.1923 [20.7 s]    dev=(HR@5:0.4419,NDCG@5:0.3259) [0.9 s]
INFO:root:Epoch 66    loss=0.1897 [20.6 s]    dev=(HR@5:0.4403,NDCG@5:0.3229) [0.9 s]
INFO:root:Epoch 67    loss=0.1908 [20.6 s]    dev=(HR@5:0.4433,NDCG@5:0.3261) [0.9 s]
INFO:root:Epoch 68    loss=0.1890 [20.7 s]    dev=(HR@5:0.4428,NDCG@5:0.3263) [0.9 s]
INFO:root:Epoch 69    loss=0.1896 [20.7 s]    dev=(HR@5:0.4453,NDCG@5:0.3269) [0.9 s]
INFO:root:Epoch 70    loss=0.1896 [20.6 s]    dev=(HR@5:0.4434,NDCG@5:0.3262) [0.9 s]
INFO:root:Epoch 71    loss=0.1895 [20.6 s]    dev=(HR@5:0.4429,NDCG@5:0.3272) [0.9 s]
INFO:root:Epoch 72    loss=0.1888 [20.6 s]    dev=(HR@5:0.4384,NDCG@5:0.3228) [0.9 s]
INFO:root:Epoch 73    loss=0.1887 [20.7 s]    dev=(HR@5:0.4345,NDCG@5:0.3195) [0.9 s]
INFO:root:Epoch 74    loss=0.1898 [20.6 s]    dev=(HR@5:0.4339,NDCG@5:0.3176) [0.9 s]
INFO:root:Epoch 75    loss=0.1910 [20.8 s]    dev=(HR@5:0.4409,NDCG@5:0.3244) [0.9 s]
INFO:root:Epoch 76    loss=0.1892 [20.8 s]    dev=(HR@5:0.4379,NDCG@5:0.3223) [0.9 s]
INFO:root:Epoch 77    loss=0.1888 [20.6 s]    dev=(HR@5:0.4374,NDCG@5:0.3213) [0.9 s]
INFO:root:Epoch 78    loss=0.1883 [20.7 s]    dev=(HR@5:0.4411,NDCG@5:0.3246) [0.9 s]
INFO:root:Early stop at 78 based on dev result.
INFO:root:
Best Iter(dev)=   58	 dev=(HR@5:0.4470,NDCG@5:0.3290) [1724.6 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.3976,NDCG@5:0.2837,HR@10:0.4998,NDCG@10:0.3168,HR@20:0.6235,NDCG@20:0.3478,HR@50:0.8318,NDCG@50:0.3891)
INFO:root:
--------------------------------------------- END: 2024-12-05 21:29:21 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-05 22:33:23 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [22.2 s]    dev=(HR@5:0.2513,NDCG@5:0.1670) [0.9 s] *
INFO:root:Epoch 2     loss=0.4326 [20.5 s]    dev=(HR@5:0.3210,NDCG@5:0.2172) [0.9 s] *
INFO:root:Epoch 3     loss=0.4003 [20.4 s]    dev=(HR@5:0.3370,NDCG@5:0.2271) [0.9 s] *
INFO:root:Epoch 4     loss=0.3862 [20.3 s]    dev=(HR@5:0.3494,NDCG@5:0.2397) [0.9 s] *
INFO:root:Epoch 5     loss=0.3667 [20.3 s]    dev=(HR@5:0.3643,NDCG@5:0.2513) [0.9 s] *
INFO:root:Epoch 6     loss=0.3437 [20.2 s]    dev=(HR@5:0.3834,NDCG@5:0.2695) [0.9 s] *
INFO:root:Epoch 7     loss=0.3247 [20.3 s]    dev=(HR@5:0.3927,NDCG@5:0.2759) [0.9 s] *
INFO:root:Epoch 8     loss=0.3062 [20.2 s]    dev=(HR@5:0.3983,NDCG@5:0.2830) [0.9 s] *
INFO:root:Epoch 9     loss=0.2899 [20.3 s]    dev=(HR@5:0.4041,NDCG@5:0.2892) [0.9 s] *
INFO:root:Epoch 10    loss=0.2789 [20.3 s]    dev=(HR@5:0.4099,NDCG@5:0.2947) [0.9 s] *
INFO:root:Epoch 11    loss=0.2675 [20.2 s]    dev=(HR@5:0.4142,NDCG@5:0.2980) [0.9 s] *
INFO:root:Epoch 12    loss=0.2582 [20.3 s]    dev=(HR@5:0.4194,NDCG@5:0.3033) [0.9 s] *
INFO:root:Epoch 13    loss=0.2526 [20.2 s]    dev=(HR@5:0.4267,NDCG@5:0.3093) [0.9 s] *
INFO:root:Epoch 14    loss=0.2461 [20.1 s]    dev=(HR@5:0.4219,NDCG@5:0.3072) [0.9 s]
INFO:root:Epoch 15    loss=0.2426 [20.3 s]    dev=(HR@5:0.4229,NDCG@5:0.3065) [0.9 s]
INFO:root:Epoch 16    loss=0.2392 [20.3 s]    dev=(HR@5:0.4276,NDCG@5:0.3118) [0.9 s] *
INFO:root:Epoch 17    loss=0.2350 [20.3 s]    dev=(HR@5:0.4259,NDCG@5:0.3109) [0.9 s]
INFO:root:Epoch 18    loss=0.2298 [20.2 s]    dev=(HR@5:0.4252,NDCG@5:0.3133) [0.9 s] *
INFO:root:Epoch 19    loss=0.2276 [20.2 s]    dev=(HR@5:0.4293,NDCG@5:0.3155) [0.9 s] *
INFO:root:Epoch 20    loss=0.2244 [20.2 s]    dev=(HR@5:0.4319,NDCG@5:0.3167) [0.9 s] *
INFO:root:Epoch 21    loss=0.2199 [20.3 s]    dev=(HR@5:0.4326,NDCG@5:0.3173) [0.9 s] *
INFO:root:Epoch 22    loss=0.2179 [20.3 s]    dev=(HR@5:0.4306,NDCG@5:0.3175) [0.9 s] *
INFO:root:Epoch 23    loss=0.2179 [20.5 s]    dev=(HR@5:0.4267,NDCG@5:0.3145) [0.9 s]
INFO:root:Epoch 24    loss=0.2168 [20.3 s]    dev=(HR@5:0.4311,NDCG@5:0.3172) [0.9 s]
INFO:root:Epoch 25    loss=0.2131 [20.3 s]    dev=(HR@5:0.4289,NDCG@5:0.3164) [0.9 s]
INFO:root:Epoch 26    loss=0.2131 [20.5 s]    dev=(HR@5:0.4329,NDCG@5:0.3205) [0.9 s] *
INFO:root:Epoch 27    loss=0.2125 [21.1 s]    dev=(HR@5:0.4318,NDCG@5:0.3180) [0.9 s]
INFO:root:Epoch 28    loss=0.2103 [20.1 s]    dev=(HR@5:0.4363,NDCG@5:0.3222) [0.9 s] *
INFO:root:Epoch 29    loss=0.2084 [19.9 s]    dev=(HR@5:0.4307,NDCG@5:0.3177) [0.9 s]
INFO:root:Epoch 30    loss=0.2077 [20.8 s]    dev=(HR@5:0.4308,NDCG@5:0.3178) [0.9 s]
INFO:root:Epoch 31    loss=0.2069 [20.6 s]    dev=(HR@5:0.4352,NDCG@5:0.3217) [1.0 s]
INFO:root:Epoch 32    loss=0.2067 [23.4 s]    dev=(HR@5:0.4366,NDCG@5:0.3210) [1.0 s]
INFO:root:Epoch 33    loss=0.2054 [22.0 s]    dev=(HR@5:0.4372,NDCG@5:0.3236) [1.1 s] *
INFO:root:Epoch 34    loss=0.2044 [22.2 s]    dev=(HR@5:0.4331,NDCG@5:0.3181) [0.9 s]
INFO:root:Epoch 35    loss=0.2052 [21.3 s]    dev=(HR@5:0.4333,NDCG@5:0.3174) [1.0 s]
INFO:root:Epoch 36    loss=0.2015 [20.3 s]    dev=(HR@5:0.4359,NDCG@5:0.3216) [0.9 s]
INFO:root:Epoch 37    loss=0.2026 [20.5 s]    dev=(HR@5:0.4362,NDCG@5:0.3212) [0.9 s]
INFO:root:Epoch 38    loss=0.2021 [21.2 s]    dev=(HR@5:0.4374,NDCG@5:0.3221) [1.0 s]
INFO:root:Epoch 39    loss=0.2019 [21.7 s]    dev=(HR@5:0.4352,NDCG@5:0.3201) [1.0 s]
INFO:root:Epoch 40    loss=0.2000 [21.4 s]    dev=(HR@5:0.4340,NDCG@5:0.3212) [0.9 s]
INFO:root:Epoch 41    loss=0.2005 [21.0 s]    dev=(HR@5:0.4353,NDCG@5:0.3200) [0.9 s]
INFO:root:Epoch 42    loss=0.2003 [20.5 s]    dev=(HR@5:0.4387,NDCG@5:0.3223) [0.9 s]
INFO:root:Epoch 43    loss=0.1999 [20.4 s]    dev=(HR@5:0.4407,NDCG@5:0.3257) [0.9 s] *
INFO:root:Epoch 44    loss=0.2000 [21.0 s]    dev=(HR@5:0.4388,NDCG@5:0.3231) [1.0 s]
INFO:root:Epoch 45    loss=0.1963 [21.4 s]    dev=(HR@5:0.4423,NDCG@5:0.3259) [1.0 s] *
INFO:root:Epoch 46    loss=0.1973 [21.6 s]    dev=(HR@5:0.4341,NDCG@5:0.3210) [1.1 s]
INFO:root:Epoch 47    loss=0.1980 [21.5 s]    dev=(HR@5:0.4338,NDCG@5:0.3188) [0.9 s]
INFO:root:Epoch 48    loss=0.1974 [21.9 s]    dev=(HR@5:0.4376,NDCG@5:0.3213) [1.1 s]
INFO:root:Epoch 49    loss=0.1957 [20.8 s]    dev=(HR@5:0.4393,NDCG@5:0.3230) [0.9 s]
INFO:root:Epoch 50    loss=0.1965 [20.3 s]    dev=(HR@5:0.4340,NDCG@5:0.3209) [0.9 s]
INFO:root:Epoch 51    loss=0.1953 [19.8 s]    dev=(HR@5:0.4366,NDCG@5:0.3230) [0.9 s]
INFO:root:Epoch 52    loss=0.1963 [20.0 s]    dev=(HR@5:0.4384,NDCG@5:0.3224) [0.9 s]
INFO:root:Epoch 53    loss=0.1949 [19.9 s]    dev=(HR@5:0.4383,NDCG@5:0.3217) [0.9 s]
INFO:root:Epoch 54    loss=0.1925 [19.8 s]    dev=(HR@5:0.4382,NDCG@5:0.3222) [0.9 s]
INFO:root:Epoch 55    loss=0.1933 [19.9 s]    dev=(HR@5:0.4428,NDCG@5:0.3248) [0.9 s]
INFO:root:Epoch 56    loss=0.1929 [19.9 s]    dev=(HR@5:0.4407,NDCG@5:0.3244) [0.9 s]
INFO:root:Epoch 57    loss=0.1927 [20.6 s]    dev=(HR@5:0.4419,NDCG@5:0.3255) [0.9 s]
INFO:root:Epoch 58    loss=0.1938 [20.7 s]    dev=(HR@5:0.4447,NDCG@5:0.3286) [0.9 s] *
INFO:root:Epoch 59    loss=0.1934 [20.4 s]    dev=(HR@5:0.4387,NDCG@5:0.3225) [0.9 s]
INFO:root:Epoch 60    loss=0.1922 [20.1 s]    dev=(HR@5:0.4382,NDCG@5:0.3230) [0.9 s]
INFO:root:Epoch 61    loss=0.1923 [19.9 s]    dev=(HR@5:0.4398,NDCG@5:0.3255) [0.9 s]
INFO:root:Epoch 62    loss=0.1919 [19.8 s]    dev=(HR@5:0.4445,NDCG@5:0.3272) [0.9 s]
INFO:root:Epoch 63    loss=0.1924 [20.0 s]    dev=(HR@5:0.4476,NDCG@5:0.3297) [0.9 s] *
INFO:root:Epoch 64    loss=0.1913 [19.9 s]    dev=(HR@5:0.4453,NDCG@5:0.3270) [0.9 s]
INFO:root:Epoch 65    loss=0.1920 [19.8 s]    dev=(HR@5:0.4366,NDCG@5:0.3217) [0.9 s]
INFO:root:Epoch 66    loss=0.1904 [19.9 s]    dev=(HR@5:0.4387,NDCG@5:0.3222) [0.9 s]
INFO:root:Epoch 67    loss=0.1920 [19.9 s]    dev=(HR@5:0.4389,NDCG@5:0.3232) [0.9 s]
INFO:root:Epoch 68    loss=0.1894 [19.8 s]    dev=(HR@5:0.4401,NDCG@5:0.3248) [0.9 s]
INFO:root:Epoch 69    loss=0.1901 [19.9 s]    dev=(HR@5:0.4419,NDCG@5:0.3254) [0.9 s]
INFO:root:Epoch 70    loss=0.1902 [19.8 s]    dev=(HR@5:0.4409,NDCG@5:0.3264) [0.9 s]
INFO:root:Epoch 71    loss=0.1895 [19.9 s]    dev=(HR@5:0.4396,NDCG@5:0.3251) [0.9 s]
INFO:root:Epoch 72    loss=0.1897 [19.8 s]    dev=(HR@5:0.4381,NDCG@5:0.3233) [0.9 s]
INFO:root:Epoch 73    loss=0.1901 [20.1 s]    dev=(HR@5:0.4406,NDCG@5:0.3248) [0.9 s]
INFO:root:Epoch 74    loss=0.1899 [19.8 s]    dev=(HR@5:0.4390,NDCG@5:0.3234) [0.9 s]
INFO:root:Epoch 75    loss=0.1920 [19.8 s]    dev=(HR@5:0.4395,NDCG@5:0.3248) [0.9 s]
INFO:root:Epoch 76    loss=0.1903 [19.8 s]    dev=(HR@5:0.4425,NDCG@5:0.3269) [0.9 s]
INFO:root:Epoch 77    loss=0.1899 [20.0 s]    dev=(HR@5:0.4380,NDCG@5:0.3230) [0.9 s]
INFO:root:Epoch 78    loss=0.1894 [19.9 s]    dev=(HR@5:0.4410,NDCG@5:0.3242) [0.9 s]
INFO:root:Epoch 79    loss=0.1897 [19.8 s]    dev=(HR@5:0.4380,NDCG@5:0.3239) [0.9 s]
INFO:root:Epoch 80    loss=0.1885 [19.8 s]    dev=(HR@5:0.4408,NDCG@5:0.3240) [0.9 s]
INFO:root:Epoch 81    loss=0.1891 [19.9 s]    dev=(HR@5:0.4379,NDCG@5:0.3212) [0.9 s]
INFO:root:Epoch 82    loss=0.1905 [20.2 s]    dev=(HR@5:0.4400,NDCG@5:0.3248) [0.9 s]
INFO:root:Epoch 83    loss=0.1880 [20.3 s]    dev=(HR@5:0.4421,NDCG@5:0.3242) [0.9 s]
INFO:root:Early stop at 83 based on dev result.
INFO:root:
Best Iter(dev)=   63	 dev=(HR@5:0.4476,NDCG@5:0.3297) [1771.4 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.3986,NDCG@5:0.2860,HR@10:0.5038,NDCG@10:0.3200,HR@20:0.6278,NDCG@20:0.3513,HR@50:0.8377,NDCG@50:0.3928)
INFO:root:
--------------------------------------------- END: 2024-12-05 23:02:57 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 00:07:55 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [25.9 s]    dev=(HR@5:0.2511,NDCG@5:0.1669) [1.1 s] *
INFO:root:Epoch 2     loss=0.4327 [20.7 s]    dev=(HR@5:0.3208,NDCG@5:0.2173) [0.9 s] *
INFO:root:Epoch 3     loss=0.4004 [21.6 s]    dev=(HR@5:0.3372,NDCG@5:0.2270) [1.0 s] *
INFO:root:Epoch 4     loss=0.3864 [22.6 s]    dev=(HR@5:0.3495,NDCG@5:0.2394) [0.9 s] *
INFO:root:Epoch 5     loss=0.3677 [20.6 s]    dev=(HR@5:0.3643,NDCG@5:0.2512) [0.9 s] *
INFO:root:Epoch 6     loss=0.3442 [20.3 s]    dev=(HR@5:0.3836,NDCG@5:0.2697) [0.9 s] *
INFO:root:Epoch 7     loss=0.3245 [20.4 s]    dev=(HR@5:0.3951,NDCG@5:0.2779) [0.9 s] *
INFO:root:Epoch 8     loss=0.3050 [20.5 s]    dev=(HR@5:0.4032,NDCG@5:0.2867) [0.9 s] *
INFO:root:Epoch 9     loss=0.2880 [20.5 s]    dev=(HR@5:0.4065,NDCG@5:0.2914) [0.9 s] *
INFO:root:Epoch 10    loss=0.2770 [20.5 s]    dev=(HR@5:0.4143,NDCG@5:0.2975) [0.9 s] *
INFO:root:Epoch 11    loss=0.2654 [20.4 s]    dev=(HR@5:0.4173,NDCG@5:0.3000) [0.9 s] *
INFO:root:Epoch 12    loss=0.2561 [20.4 s]    dev=(HR@5:0.4198,NDCG@5:0.3042) [0.9 s] *
INFO:root:Epoch 13    loss=0.2501 [20.4 s]    dev=(HR@5:0.4274,NDCG@5:0.3109) [0.9 s] *
INFO:root:Epoch 14    loss=0.2438 [20.6 s]    dev=(HR@5:0.4252,NDCG@5:0.3096) [0.9 s]
INFO:root:Epoch 15    loss=0.2403 [20.4 s]    dev=(HR@5:0.4251,NDCG@5:0.3081) [0.9 s]
INFO:root:Epoch 16    loss=0.2369 [20.6 s]    dev=(HR@5:0.4309,NDCG@5:0.3147) [0.9 s] *
INFO:root:Epoch 17    loss=0.2326 [20.7 s]    dev=(HR@5:0.4304,NDCG@5:0.3147) [0.9 s]
INFO:root:Epoch 18    loss=0.2279 [20.5 s]    dev=(HR@5:0.4304,NDCG@5:0.3154) [0.9 s] *
INFO:root:Epoch 19    loss=0.2254 [20.7 s]    dev=(HR@5:0.4313,NDCG@5:0.3177) [1.0 s] *
INFO:root:Epoch 20    loss=0.2225 [20.9 s]    dev=(HR@5:0.4314,NDCG@5:0.3178) [0.9 s] *
INFO:root:Epoch 21    loss=0.2181 [21.2 s]    dev=(HR@5:0.4354,NDCG@5:0.3204) [1.0 s] *
INFO:root:Epoch 22    loss=0.2166 [20.7 s]    dev=(HR@5:0.4352,NDCG@5:0.3206) [0.9 s] *
INFO:root:Epoch 23    loss=0.2164 [20.5 s]    dev=(HR@5:0.4294,NDCG@5:0.3176) [0.9 s]
INFO:root:Epoch 24    loss=0.2158 [20.4 s]    dev=(HR@5:0.4351,NDCG@5:0.3187) [0.9 s]
INFO:root:Epoch 25    loss=0.2119 [20.5 s]    dev=(HR@5:0.4350,NDCG@5:0.3212) [0.9 s] *
INFO:root:Epoch 26    loss=0.2115 [20.8 s]    dev=(HR@5:0.4374,NDCG@5:0.3234) [0.9 s] *
INFO:root:Epoch 27    loss=0.2116 [21.1 s]    dev=(HR@5:0.4402,NDCG@5:0.3242) [1.0 s] *
INFO:root:Epoch 28    loss=0.2096 [20.1 s]    dev=(HR@5:0.4415,NDCG@5:0.3250) [0.9 s] *
INFO:root:Epoch 29    loss=0.2074 [20.4 s]    dev=(HR@5:0.4361,NDCG@5:0.3217) [0.9 s]
INFO:root:Epoch 30    loss=0.2072 [20.4 s]    dev=(HR@5:0.4357,NDCG@5:0.3205) [0.9 s]
INFO:root:Epoch 31    loss=0.2055 [20.6 s]    dev=(HR@5:0.4394,NDCG@5:0.3235) [0.9 s]
INFO:root:Epoch 32    loss=0.2061 [20.0 s]    dev=(HR@5:0.4385,NDCG@5:0.3238) [0.9 s]
INFO:root:Epoch 33    loss=0.2049 [20.2 s]    dev=(HR@5:0.4421,NDCG@5:0.3271) [0.9 s] *
INFO:root:Epoch 34    loss=0.2026 [20.1 s]    dev=(HR@5:0.4420,NDCG@5:0.3237) [0.9 s]
INFO:root:Epoch 35    loss=0.2039 [20.1 s]    dev=(HR@5:0.4376,NDCG@5:0.3220) [0.9 s]
INFO:root:Epoch 36    loss=0.2007 [19.9 s]    dev=(HR@5:0.4421,NDCG@5:0.3250) [0.9 s]
INFO:root:Epoch 37    loss=0.2021 [20.1 s]    dev=(HR@5:0.4447,NDCG@5:0.3260) [0.9 s]
INFO:root:Epoch 38    loss=0.2016 [20.0 s]    dev=(HR@5:0.4420,NDCG@5:0.3247) [0.9 s]
INFO:root:Epoch 39    loss=0.2015 [20.0 s]    dev=(HR@5:0.4396,NDCG@5:0.3216) [0.9 s]
INFO:root:Epoch 40    loss=0.2000 [19.9 s]    dev=(HR@5:0.4401,NDCG@5:0.3241) [0.9 s]
INFO:root:Epoch 41    loss=0.1996 [20.1 s]    dev=(HR@5:0.4386,NDCG@5:0.3230) [0.9 s]
INFO:root:Epoch 42    loss=0.2003 [20.1 s]    dev=(HR@5:0.4455,NDCG@5:0.3264) [0.9 s]
INFO:root:Epoch 43    loss=0.1987 [19.9 s]    dev=(HR@5:0.4462,NDCG@5:0.3296) [0.9 s] *
INFO:root:Epoch 44    loss=0.1993 [20.1 s]    dev=(HR@5:0.4432,NDCG@5:0.3273) [0.9 s]
INFO:root:Epoch 45    loss=0.1956 [20.0 s]    dev=(HR@5:0.4474,NDCG@5:0.3306) [0.9 s] *
INFO:root:Epoch 46    loss=0.1971 [20.7 s]    dev=(HR@5:0.4397,NDCG@5:0.3240) [1.0 s]
INFO:root:Epoch 47    loss=0.1976 [20.5 s]    dev=(HR@5:0.4425,NDCG@5:0.3249) [0.9 s]
INFO:root:Epoch 48    loss=0.1964 [20.7 s]    dev=(HR@5:0.4402,NDCG@5:0.3250) [0.9 s]
INFO:root:Epoch 49    loss=0.1951 [20.6 s]    dev=(HR@5:0.4446,NDCG@5:0.3257) [1.0 s]
INFO:root:Epoch 50    loss=0.1960 [20.7 s]    dev=(HR@5:0.4415,NDCG@5:0.3256) [0.9 s]
INFO:root:Epoch 51    loss=0.1949 [20.5 s]    dev=(HR@5:0.4447,NDCG@5:0.3285) [1.0 s]
INFO:root:Epoch 52    loss=0.1953 [20.4 s]    dev=(HR@5:0.4427,NDCG@5:0.3242) [0.9 s]
INFO:root:Epoch 53    loss=0.1940 [20.4 s]    dev=(HR@5:0.4390,NDCG@5:0.3228) [0.9 s]
INFO:root:Epoch 54    loss=0.1920 [20.3 s]    dev=(HR@5:0.4427,NDCG@5:0.3254) [0.9 s]
INFO:root:Epoch 55    loss=0.1929 [20.5 s]    dev=(HR@5:0.4424,NDCG@5:0.3259) [0.9 s]
INFO:root:Epoch 56    loss=0.1919 [20.4 s]    dev=(HR@5:0.4479,NDCG@5:0.3282) [0.9 s]
INFO:root:Epoch 57    loss=0.1925 [20.4 s]    dev=(HR@5:0.4430,NDCG@5:0.3276) [0.9 s]
INFO:root:Epoch 58    loss=0.1942 [20.7 s]    dev=(HR@5:0.4445,NDCG@5:0.3273) [1.0 s]
INFO:root:Epoch 59    loss=0.1928 [20.5 s]    dev=(HR@5:0.4430,NDCG@5:0.3262) [0.9 s]
INFO:root:Epoch 60    loss=0.1923 [20.4 s]    dev=(HR@5:0.4370,NDCG@5:0.3221) [0.9 s]
INFO:root:Epoch 61    loss=0.1920 [20.4 s]    dev=(HR@5:0.4460,NDCG@5:0.3284) [0.9 s]
INFO:root:Epoch 62    loss=0.1915 [20.5 s]    dev=(HR@5:0.4445,NDCG@5:0.3263) [0.9 s]
INFO:root:Epoch 63    loss=0.1927 [20.4 s]    dev=(HR@5:0.4480,NDCG@5:0.3311) [0.9 s] *
INFO:root:Epoch 64    loss=0.1905 [20.6 s]    dev=(HR@5:0.4427,NDCG@5:0.3257) [0.9 s]
INFO:root:Epoch 65    loss=0.1922 [20.3 s]    dev=(HR@5:0.4426,NDCG@5:0.3244) [0.9 s]
INFO:root:Epoch 66    loss=0.1905 [20.4 s]    dev=(HR@5:0.4422,NDCG@5:0.3233) [0.9 s]
INFO:root:Epoch 67    loss=0.1915 [20.4 s]    dev=(HR@5:0.4438,NDCG@5:0.3265) [0.9 s]
INFO:root:Epoch 68    loss=0.1893 [20.4 s]    dev=(HR@5:0.4468,NDCG@5:0.3285) [0.9 s]
INFO:root:Epoch 69    loss=0.1905 [20.4 s]    dev=(HR@5:0.4432,NDCG@5:0.3255) [0.9 s]
INFO:root:Epoch 70    loss=0.1904 [20.6 s]    dev=(HR@5:0.4452,NDCG@5:0.3266) [0.9 s]
INFO:root:Epoch 71    loss=0.1906 [20.5 s]    dev=(HR@5:0.4452,NDCG@5:0.3293) [0.9 s]
INFO:root:Epoch 72    loss=0.1893 [20.3 s]    dev=(HR@5:0.4418,NDCG@5:0.3260) [0.9 s]
INFO:root:Epoch 73    loss=0.1903 [20.4 s]    dev=(HR@5:0.4432,NDCG@5:0.3281) [0.9 s]
INFO:root:Epoch 74    loss=0.1905 [20.3 s]    dev=(HR@5:0.4398,NDCG@5:0.3225) [0.9 s]
INFO:root:Epoch 75    loss=0.1919 [20.4 s]    dev=(HR@5:0.4445,NDCG@5:0.3270) [0.9 s]
INFO:root:Epoch 76    loss=0.1899 [20.5 s]    dev=(HR@5:0.4453,NDCG@5:0.3281) [0.9 s]
INFO:root:Epoch 77    loss=0.1899 [20.4 s]    dev=(HR@5:0.4430,NDCG@5:0.3252) [0.9 s]
INFO:root:Epoch 78    loss=0.1896 [20.3 s]    dev=(HR@5:0.4453,NDCG@5:0.3259) [0.9 s]
INFO:root:Epoch 79    loss=0.1904 [20.5 s]    dev=(HR@5:0.4453,NDCG@5:0.3260) [0.9 s]
INFO:root:Epoch 80    loss=0.1881 [20.4 s]    dev=(HR@5:0.4410,NDCG@5:0.3229) [0.9 s]
INFO:root:Epoch 81    loss=0.1890 [20.4 s]    dev=(HR@5:0.4384,NDCG@5:0.3202) [0.9 s]
INFO:root:Epoch 82    loss=0.1902 [20.4 s]    dev=(HR@5:0.4413,NDCG@5:0.3236) [0.9 s]
INFO:root:Epoch 83    loss=0.1882 [20.3 s]    dev=(HR@5:0.4427,NDCG@5:0.3254) [0.9 s]
INFO:root:Early stop at 83 based on dev result.
INFO:root:
Best Iter(dev)=   63	 dev=(HR@5:0.4480,NDCG@5:0.3311) [1779.8 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.4015,NDCG@5:0.2898,HR@10:0.5075,NDCG@10:0.3241,HR@20:0.6344,NDCG@20:0.3561,HR@50:0.8392,NDCG@50:0.3967)
INFO:root:
--------------------------------------------- END: 2024-12-06 00:37:38 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 01:39:53 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5165 [22.3 s]    dev=(HR@5:0.2515,NDCG@5:0.1671) [0.9 s] *
INFO:root:Epoch 2     loss=0.4326 [20.3 s]    dev=(HR@5:0.3210,NDCG@5:0.2175) [0.9 s] *
INFO:root:Epoch 3     loss=0.4003 [20.3 s]    dev=(HR@5:0.3371,NDCG@5:0.2270) [0.9 s] *
INFO:root:Epoch 4     loss=0.3864 [20.2 s]    dev=(HR@5:0.3496,NDCG@5:0.2395) [0.9 s] *
INFO:root:Epoch 5     loss=0.3684 [20.3 s]    dev=(HR@5:0.3618,NDCG@5:0.2497) [0.9 s] *
INFO:root:Epoch 6     loss=0.3459 [20.4 s]    dev=(HR@5:0.3819,NDCG@5:0.2683) [0.9 s] *
INFO:root:Epoch 7     loss=0.3262 [20.3 s]    dev=(HR@5:0.3899,NDCG@5:0.2758) [0.9 s] *
INFO:root:Epoch 8     loss=0.3072 [20.4 s]    dev=(HR@5:0.4007,NDCG@5:0.2857) [0.9 s] *
INFO:root:Epoch 9     loss=0.2902 [20.3 s]    dev=(HR@5:0.4041,NDCG@5:0.2901) [0.9 s] *
INFO:root:Epoch 10    loss=0.2790 [20.2 s]    dev=(HR@5:0.4107,NDCG@5:0.2960) [0.9 s] *
INFO:root:Epoch 11    loss=0.2670 [20.1 s]    dev=(HR@5:0.4139,NDCG@5:0.2981) [0.9 s] *
INFO:root:Epoch 12    loss=0.2573 [20.4 s]    dev=(HR@5:0.4191,NDCG@5:0.3037) [0.9 s] *
INFO:root:Epoch 13    loss=0.2506 [20.4 s]    dev=(HR@5:0.4283,NDCG@5:0.3109) [0.9 s] *
INFO:root:Epoch 14    loss=0.2442 [20.4 s]    dev=(HR@5:0.4256,NDCG@5:0.3088) [0.9 s]
INFO:root:Epoch 15    loss=0.2407 [20.4 s]    dev=(HR@5:0.4234,NDCG@5:0.3063) [0.9 s]
INFO:root:Epoch 16    loss=0.2372 [20.4 s]    dev=(HR@5:0.4289,NDCG@5:0.3124) [0.9 s] *
INFO:root:Epoch 17    loss=0.2327 [20.4 s]    dev=(HR@5:0.4242,NDCG@5:0.3094) [0.9 s]
INFO:root:Epoch 18    loss=0.2278 [20.4 s]    dev=(HR@5:0.4291,NDCG@5:0.3138) [0.9 s] *
INFO:root:Epoch 19    loss=0.2253 [20.4 s]    dev=(HR@5:0.4320,NDCG@5:0.3163) [0.9 s] *
INFO:root:Epoch 20    loss=0.2224 [20.4 s]    dev=(HR@5:0.4307,NDCG@5:0.3166) [0.9 s] *
INFO:root:Epoch 21    loss=0.2174 [20.4 s]    dev=(HR@5:0.4359,NDCG@5:0.3193) [0.9 s] *
INFO:root:Epoch 22    loss=0.2166 [20.4 s]    dev=(HR@5:0.4336,NDCG@5:0.3190) [0.9 s]
INFO:root:Epoch 23    loss=0.2155 [20.4 s]    dev=(HR@5:0.4259,NDCG@5:0.3128) [0.9 s]
INFO:root:Epoch 24    loss=0.2150 [20.4 s]    dev=(HR@5:0.4353,NDCG@5:0.3191) [0.9 s]
INFO:root:Epoch 25    loss=0.2109 [20.4 s]    dev=(HR@5:0.4279,NDCG@5:0.3160) [0.9 s]
INFO:root:Epoch 26    loss=0.2104 [20.6 s]    dev=(HR@5:0.4310,NDCG@5:0.3193) [0.9 s] *
INFO:root:Epoch 27    loss=0.2096 [20.4 s]    dev=(HR@5:0.4330,NDCG@5:0.3201) [0.9 s] *
INFO:root:Epoch 28    loss=0.2084 [20.4 s]    dev=(HR@5:0.4355,NDCG@5:0.3212) [0.9 s] *
INFO:root:Epoch 29    loss=0.2057 [20.5 s]    dev=(HR@5:0.4341,NDCG@5:0.3198) [0.9 s]
INFO:root:Epoch 30    loss=0.2053 [20.4 s]    dev=(HR@5:0.4342,NDCG@5:0.3203) [0.9 s]
INFO:root:Epoch 31    loss=0.2038 [20.4 s]    dev=(HR@5:0.4353,NDCG@5:0.3213) [0.9 s] *
INFO:root:Epoch 32    loss=0.2041 [20.4 s]    dev=(HR@5:0.4357,NDCG@5:0.3205) [0.9 s]
INFO:root:Epoch 33    loss=0.2030 [20.4 s]    dev=(HR@5:0.4378,NDCG@5:0.3221) [0.9 s] *
INFO:root:Epoch 34    loss=0.2013 [20.4 s]    dev=(HR@5:0.4362,NDCG@5:0.3201) [0.9 s]
INFO:root:Epoch 35    loss=0.2026 [20.4 s]    dev=(HR@5:0.4325,NDCG@5:0.3186) [0.9 s]
INFO:root:Epoch 36    loss=0.1987 [20.4 s]    dev=(HR@5:0.4359,NDCG@5:0.3208) [0.9 s]
INFO:root:Epoch 37    loss=0.2004 [20.4 s]    dev=(HR@5:0.4387,NDCG@5:0.3237) [0.9 s] *
INFO:root:Epoch 38    loss=0.2000 [20.3 s]    dev=(HR@5:0.4393,NDCG@5:0.3224) [0.9 s]
INFO:root:Epoch 39    loss=0.1996 [20.3 s]    dev=(HR@5:0.4338,NDCG@5:0.3190) [0.9 s]
INFO:root:Epoch 40    loss=0.1990 [20.4 s]    dev=(HR@5:0.4357,NDCG@5:0.3214) [0.9 s]
INFO:root:Epoch 41    loss=0.1984 [20.3 s]    dev=(HR@5:0.4344,NDCG@5:0.3195) [0.9 s]
INFO:root:Epoch 42    loss=0.1992 [20.4 s]    dev=(HR@5:0.4394,NDCG@5:0.3231) [0.9 s]
INFO:root:Epoch 43    loss=0.1978 [20.3 s]    dev=(HR@5:0.4453,NDCG@5:0.3288) [0.9 s] *
INFO:root:Epoch 44    loss=0.1990 [20.3 s]    dev=(HR@5:0.4402,NDCG@5:0.3261) [0.9 s]
INFO:root:Epoch 45    loss=0.1950 [20.3 s]    dev=(HR@5:0.4437,NDCG@5:0.3278) [0.9 s]
INFO:root:Epoch 46    loss=0.1962 [20.3 s]    dev=(HR@5:0.4369,NDCG@5:0.3225) [0.9 s]
INFO:root:Epoch 47    loss=0.1964 [20.3 s]    dev=(HR@5:0.4404,NDCG@5:0.3252) [0.9 s]
INFO:root:Epoch 48    loss=0.1956 [20.4 s]    dev=(HR@5:0.4337,NDCG@5:0.3193) [0.9 s]
INFO:root:Epoch 49    loss=0.1941 [20.4 s]    dev=(HR@5:0.4415,NDCG@5:0.3243) [0.9 s]
INFO:root:Epoch 50    loss=0.1950 [20.5 s]    dev=(HR@5:0.4377,NDCG@5:0.3227) [0.9 s]
INFO:root:Epoch 51    loss=0.1937 [20.4 s]    dev=(HR@5:0.4382,NDCG@5:0.3242) [0.9 s]
INFO:root:Epoch 52    loss=0.1946 [20.4 s]    dev=(HR@5:0.4391,NDCG@5:0.3241) [0.9 s]
INFO:root:Epoch 53    loss=0.1940 [20.4 s]    dev=(HR@5:0.4389,NDCG@5:0.3250) [0.9 s]
INFO:root:Epoch 54    loss=0.1912 [20.3 s]    dev=(HR@5:0.4450,NDCG@5:0.3266) [0.9 s]
INFO:root:Epoch 55    loss=0.1917 [20.4 s]    dev=(HR@5:0.4434,NDCG@5:0.3251) [0.9 s]
INFO:root:Epoch 56    loss=0.1915 [20.4 s]    dev=(HR@5:0.4432,NDCG@5:0.3267) [0.9 s]
INFO:root:Epoch 57    loss=0.1912 [20.4 s]    dev=(HR@5:0.4445,NDCG@5:0.3287) [0.9 s]
INFO:root:Epoch 58    loss=0.1927 [20.3 s]    dev=(HR@5:0.4420,NDCG@5:0.3274) [0.9 s]
INFO:root:Epoch 59    loss=0.1912 [20.3 s]    dev=(HR@5:0.4423,NDCG@5:0.3256) [0.9 s]
INFO:root:Epoch 60    loss=0.1915 [20.4 s]    dev=(HR@5:0.4395,NDCG@5:0.3240) [0.9 s]
INFO:root:Epoch 61    loss=0.1916 [20.3 s]    dev=(HR@5:0.4442,NDCG@5:0.3268) [0.9 s]
INFO:root:Epoch 62    loss=0.1900 [20.3 s]    dev=(HR@5:0.4449,NDCG@5:0.3277) [0.9 s]
INFO:root:Epoch 63    loss=0.1919 [20.3 s]    dev=(HR@5:0.4464,NDCG@5:0.3297) [0.9 s] *
INFO:root:Epoch 64    loss=0.1904 [20.3 s]    dev=(HR@5:0.4440,NDCG@5:0.3264) [0.9 s]
INFO:root:Epoch 65    loss=0.1913 [20.4 s]    dev=(HR@5:0.4428,NDCG@5:0.3250) [0.9 s]
INFO:root:Epoch 66    loss=0.1892 [20.4 s]    dev=(HR@5:0.4445,NDCG@5:0.3257) [0.9 s]
INFO:root:Epoch 67    loss=0.1903 [20.5 s]    dev=(HR@5:0.4424,NDCG@5:0.3254) [0.9 s]
INFO:root:Epoch 68    loss=0.1881 [20.3 s]    dev=(HR@5:0.4471,NDCG@5:0.3286) [0.9 s]
INFO:root:Epoch 69    loss=0.1887 [20.3 s]    dev=(HR@5:0.4463,NDCG@5:0.3286) [0.9 s]
INFO:root:Epoch 70    loss=0.1889 [20.3 s]    dev=(HR@5:0.4465,NDCG@5:0.3294) [0.9 s]
INFO:root:Epoch 71    loss=0.1883 [20.3 s]    dev=(HR@5:0.4479,NDCG@5:0.3305) [0.9 s] *
INFO:root:Epoch 72    loss=0.1878 [20.3 s]    dev=(HR@5:0.4427,NDCG@5:0.3252) [0.9 s]
INFO:root:Epoch 73    loss=0.1886 [20.5 s]    dev=(HR@5:0.4474,NDCG@5:0.3301) [0.9 s]
INFO:root:Epoch 74    loss=0.1887 [20.3 s]    dev=(HR@5:0.4410,NDCG@5:0.3234) [0.9 s]
INFO:root:Epoch 75    loss=0.1903 [20.3 s]    dev=(HR@5:0.4435,NDCG@5:0.3273) [0.9 s]
INFO:root:Epoch 76    loss=0.1881 [20.4 s]    dev=(HR@5:0.4441,NDCG@5:0.3289) [0.9 s]
INFO:root:Epoch 77    loss=0.1881 [20.3 s]    dev=(HR@5:0.4436,NDCG@5:0.3277) [0.9 s]
INFO:root:Epoch 78    loss=0.1877 [20.3 s]    dev=(HR@5:0.4477,NDCG@5:0.3276) [0.9 s]
INFO:root:Epoch 79    loss=0.1884 [20.3 s]    dev=(HR@5:0.4467,NDCG@5:0.3287) [0.9 s]
INFO:root:Epoch 80    loss=0.1873 [20.4 s]    dev=(HR@5:0.4453,NDCG@5:0.3255) [0.9 s]
INFO:root:Epoch 81    loss=0.1869 [20.3 s]    dev=(HR@5:0.4396,NDCG@5:0.3200) [0.9 s]
INFO:root:Epoch 82    loss=0.1891 [20.4 s]    dev=(HR@5:0.4459,NDCG@5:0.3273) [0.9 s]
INFO:root:Epoch 83    loss=0.1866 [20.4 s]    dev=(HR@5:0.4453,NDCG@5:0.3263) [0.9 s]
INFO:root:Epoch 84    loss=0.1860 [20.5 s]    dev=(HR@5:0.4466,NDCG@5:0.3282) [0.9 s]
INFO:root:Epoch 85    loss=0.1877 [20.4 s]    dev=(HR@5:0.4483,NDCG@5:0.3295) [0.9 s]
INFO:root:Epoch 86    loss=0.1885 [20.4 s]    dev=(HR@5:0.4432,NDCG@5:0.3267) [0.9 s]
INFO:root:Epoch 87    loss=0.1873 [20.4 s]    dev=(HR@5:0.4455,NDCG@5:0.3277) [0.9 s]
INFO:root:Epoch 88    loss=0.1875 [20.3 s]    dev=(HR@5:0.4421,NDCG@5:0.3248) [0.9 s]
INFO:root:Epoch 89    loss=0.1852 [20.3 s]    dev=(HR@5:0.4396,NDCG@5:0.3236) [0.9 s]
INFO:root:Epoch 90    loss=0.1861 [20.4 s]    dev=(HR@5:0.4442,NDCG@5:0.3274) [0.9 s]
INFO:root:Epoch 91    loss=0.1863 [20.4 s]    dev=(HR@5:0.4464,NDCG@5:0.3296) [0.9 s]
INFO:root:Early stop at 91 based on dev result.
INFO:root:
Best Iter(dev)=   71	 dev=(HR@5:0.4479,NDCG@5:0.3305) [1937.9 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.3913,NDCG@5:0.2808,HR@10:0.4963,NDCG@10:0.3148,HR@20:0.6273,NDCG@20:0.3478,HR@50:0.8322,NDCG@50:0.3883)
INFO:root:
--------------------------------------------- END: 2024-12-06 02:12:13 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 03:14:26 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [21.9 s]    dev=(HR@5:0.2487,NDCG@5:0.1656) [0.9 s] *
INFO:root:Epoch 2     loss=0.4341 [20.0 s]    dev=(HR@5:0.3182,NDCG@5:0.2145) [0.9 s] *
INFO:root:Epoch 3     loss=0.3992 [19.9 s]    dev=(HR@5:0.3415,NDCG@5:0.2291) [0.9 s] *
INFO:root:Epoch 4     loss=0.3793 [20.0 s]    dev=(HR@5:0.3601,NDCG@5:0.2484) [0.9 s] *
INFO:root:Epoch 5     loss=0.3553 [20.0 s]    dev=(HR@5:0.3755,NDCG@5:0.2617) [0.9 s] *
INFO:root:Epoch 6     loss=0.3310 [20.0 s]    dev=(HR@5:0.3883,NDCG@5:0.2751) [0.9 s] *
INFO:root:Epoch 7     loss=0.3119 [20.0 s]    dev=(HR@5:0.3957,NDCG@5:0.2819) [0.9 s] *
INFO:root:Epoch 8     loss=0.2952 [19.9 s]    dev=(HR@5:0.4028,NDCG@5:0.2883) [0.9 s] *
INFO:root:Epoch 9     loss=0.2796 [19.9 s]    dev=(HR@5:0.4073,NDCG@5:0.2932) [0.9 s] *
INFO:root:Epoch 10    loss=0.2681 [20.0 s]    dev=(HR@5:0.4077,NDCG@5:0.2952) [0.9 s] *
INFO:root:Epoch 11    loss=0.2580 [20.0 s]    dev=(HR@5:0.4190,NDCG@5:0.2999) [0.9 s] *
INFO:root:Epoch 12    loss=0.2492 [19.9 s]    dev=(HR@5:0.4174,NDCG@5:0.3022) [0.9 s] *
INFO:root:Epoch 13    loss=0.2442 [20.6 s]    dev=(HR@5:0.4267,NDCG@5:0.3087) [1.0 s] *
INFO:root:Epoch 14    loss=0.2383 [20.1 s]    dev=(HR@5:0.4180,NDCG@5:0.3037) [0.9 s]
INFO:root:Epoch 15    loss=0.2356 [20.0 s]    dev=(HR@5:0.4204,NDCG@5:0.3052) [0.9 s]
INFO:root:Epoch 16    loss=0.2315 [20.0 s]    dev=(HR@5:0.4246,NDCG@5:0.3088) [0.9 s] *
INFO:root:Epoch 17    loss=0.2281 [20.0 s]    dev=(HR@5:0.4214,NDCG@5:0.3041) [0.9 s]
INFO:root:Epoch 18    loss=0.2234 [19.9 s]    dev=(HR@5:0.4237,NDCG@5:0.3081) [0.9 s]
INFO:root:Epoch 19    loss=0.2210 [20.0 s]    dev=(HR@5:0.4246,NDCG@5:0.3090) [0.9 s] *
INFO:root:Epoch 20    loss=0.2198 [20.0 s]    dev=(HR@5:0.4295,NDCG@5:0.3129) [0.9 s] *
INFO:root:Epoch 21    loss=0.2153 [20.2 s]    dev=(HR@5:0.4303,NDCG@5:0.3141) [0.9 s] *
INFO:root:Epoch 22    loss=0.2137 [20.0 s]    dev=(HR@5:0.4276,NDCG@5:0.3124) [0.9 s]
INFO:root:Epoch 23    loss=0.2139 [20.0 s]    dev=(HR@5:0.4242,NDCG@5:0.3112) [0.9 s]
INFO:root:Epoch 24    loss=0.2132 [20.1 s]    dev=(HR@5:0.4296,NDCG@5:0.3142) [0.9 s] *
INFO:root:Epoch 25    loss=0.2103 [20.1 s]    dev=(HR@5:0.4231,NDCG@5:0.3103) [0.9 s]
INFO:root:Epoch 26    loss=0.2101 [20.0 s]    dev=(HR@5:0.4297,NDCG@5:0.3137) [0.9 s]
INFO:root:Epoch 27    loss=0.2090 [20.0 s]    dev=(HR@5:0.4319,NDCG@5:0.3174) [0.9 s] *
INFO:root:Epoch 28    loss=0.2085 [20.0 s]    dev=(HR@5:0.4330,NDCG@5:0.3177) [0.9 s] *
INFO:root:Epoch 29    loss=0.2061 [20.0 s]    dev=(HR@5:0.4285,NDCG@5:0.3138) [0.9 s]
INFO:root:Epoch 30    loss=0.2062 [20.1 s]    dev=(HR@5:0.4277,NDCG@5:0.3147) [0.9 s]
INFO:root:Epoch 31    loss=0.2041 [20.0 s]    dev=(HR@5:0.4329,NDCG@5:0.3172) [0.9 s]
INFO:root:Epoch 32    loss=0.2046 [20.1 s]    dev=(HR@5:0.4296,NDCG@5:0.3137) [0.9 s]
INFO:root:Epoch 33    loss=0.2043 [20.1 s]    dev=(HR@5:0.4335,NDCG@5:0.3157) [0.9 s]
INFO:root:Epoch 34    loss=0.2030 [20.0 s]    dev=(HR@5:0.4322,NDCG@5:0.3149) [0.9 s]
INFO:root:Epoch 35    loss=0.2031 [20.0 s]    dev=(HR@5:0.4319,NDCG@5:0.3140) [0.9 s]
INFO:root:Epoch 36    loss=0.2019 [20.1 s]    dev=(HR@5:0.4293,NDCG@5:0.3133) [0.9 s]
INFO:root:Epoch 37    loss=0.2014 [20.0 s]    dev=(HR@5:0.4337,NDCG@5:0.3154) [0.9 s]
INFO:root:Epoch 38    loss=0.2024 [20.1 s]    dev=(HR@5:0.4337,NDCG@5:0.3157) [0.9 s]
INFO:root:Epoch 39    loss=0.2026 [20.0 s]    dev=(HR@5:0.4278,NDCG@5:0.3109) [0.9 s]
INFO:root:Epoch 40    loss=0.2009 [20.0 s]    dev=(HR@5:0.4360,NDCG@5:0.3177) [0.9 s] *
INFO:root:Epoch 41    loss=0.2020 [20.1 s]    dev=(HR@5:0.4324,NDCG@5:0.3138) [0.9 s]
INFO:root:Epoch 42    loss=0.2025 [20.0 s]    dev=(HR@5:0.4357,NDCG@5:0.3171) [0.9 s]
INFO:root:Epoch 43    loss=0.1999 [20.0 s]    dev=(HR@5:0.4381,NDCG@5:0.3209) [0.9 s] *
INFO:root:Epoch 44    loss=0.2015 [20.0 s]    dev=(HR@5:0.4351,NDCG@5:0.3169) [0.9 s]
INFO:root:Epoch 45    loss=0.1989 [20.0 s]    dev=(HR@5:0.4376,NDCG@5:0.3201) [0.9 s]
INFO:root:Epoch 46    loss=0.1994 [20.0 s]    dev=(HR@5:0.4329,NDCG@5:0.3161) [0.9 s]
INFO:root:Epoch 47    loss=0.2003 [20.1 s]    dev=(HR@5:0.4353,NDCG@5:0.3178) [0.9 s]
INFO:root:Epoch 48    loss=0.1994 [20.0 s]    dev=(HR@5:0.4306,NDCG@5:0.3141) [0.9 s]
INFO:root:Epoch 49    loss=0.1979 [20.0 s]    dev=(HR@5:0.4363,NDCG@5:0.3194) [0.9 s]
INFO:root:Epoch 50    loss=0.1990 [20.0 s]    dev=(HR@5:0.4326,NDCG@5:0.3163) [0.9 s]
INFO:root:Epoch 51    loss=0.1985 [20.1 s]    dev=(HR@5:0.4342,NDCG@5:0.3158) [0.9 s]
INFO:root:Epoch 52    loss=0.1977 [20.0 s]    dev=(HR@5:0.4357,NDCG@5:0.3182) [0.9 s]
INFO:root:Epoch 53    loss=0.1976 [20.0 s]    dev=(HR@5:0.4332,NDCG@5:0.3173) [0.9 s]
INFO:root:Epoch 54    loss=0.1951 [20.0 s]    dev=(HR@5:0.4383,NDCG@5:0.3203) [0.9 s]
INFO:root:Epoch 55    loss=0.1962 [20.0 s]    dev=(HR@5:0.4380,NDCG@5:0.3172) [0.9 s]
INFO:root:Epoch 56    loss=0.1954 [20.0 s]    dev=(HR@5:0.4374,NDCG@5:0.3199) [0.9 s]
INFO:root:Epoch 57    loss=0.1961 [20.1 s]    dev=(HR@5:0.4377,NDCG@5:0.3210) [0.9 s] *
INFO:root:Epoch 58    loss=0.1968 [19.9 s]    dev=(HR@5:0.4372,NDCG@5:0.3213) [0.9 s] *
INFO:root:Epoch 59    loss=0.1949 [20.0 s]    dev=(HR@5:0.4380,NDCG@5:0.3199) [0.9 s]
INFO:root:Epoch 60    loss=0.1957 [20.1 s]    dev=(HR@5:0.4357,NDCG@5:0.3182) [0.9 s]
INFO:root:Epoch 61    loss=0.1945 [20.1 s]    dev=(HR@5:0.4397,NDCG@5:0.3211) [0.9 s]
INFO:root:Epoch 62    loss=0.1942 [20.1 s]    dev=(HR@5:0.4382,NDCG@5:0.3195) [0.9 s]
INFO:root:Epoch 63    loss=0.1942 [20.0 s]    dev=(HR@5:0.4423,NDCG@5:0.3230) [0.9 s] *
INFO:root:Epoch 64    loss=0.1928 [20.0 s]    dev=(HR@5:0.4357,NDCG@5:0.3168) [0.9 s]
INFO:root:Epoch 65    loss=0.1942 [20.0 s]    dev=(HR@5:0.4363,NDCG@5:0.3182) [0.9 s]
INFO:root:Epoch 66    loss=0.1925 [20.0 s]    dev=(HR@5:0.4361,NDCG@5:0.3174) [0.9 s]
INFO:root:Epoch 67    loss=0.1928 [20.0 s]    dev=(HR@5:0.4380,NDCG@5:0.3193) [0.9 s]
INFO:root:Epoch 68    loss=0.1907 [20.0 s]    dev=(HR@5:0.4395,NDCG@5:0.3222) [0.9 s]
INFO:root:Epoch 69    loss=0.1922 [20.0 s]    dev=(HR@5:0.4361,NDCG@5:0.3205) [0.9 s]
INFO:root:Epoch 70    loss=0.1919 [20.0 s]    dev=(HR@5:0.4354,NDCG@5:0.3181) [0.9 s]
INFO:root:Epoch 71    loss=0.1908 [19.9 s]    dev=(HR@5:0.4340,NDCG@5:0.3185) [0.9 s]
INFO:root:Epoch 72    loss=0.1899 [20.1 s]    dev=(HR@5:0.4385,NDCG@5:0.3218) [0.9 s]
INFO:root:Epoch 73    loss=0.1912 [20.0 s]    dev=(HR@5:0.4391,NDCG@5:0.3207) [0.9 s]
INFO:root:Epoch 74    loss=0.1913 [20.1 s]    dev=(HR@5:0.4329,NDCG@5:0.3162) [0.9 s]
INFO:root:Epoch 75    loss=0.1933 [19.8 s]    dev=(HR@5:0.4372,NDCG@5:0.3200) [0.9 s]
INFO:root:Epoch 76    loss=0.1918 [19.9 s]    dev=(HR@5:0.4408,NDCG@5:0.3225) [0.9 s]
INFO:root:Epoch 77    loss=0.1906 [20.0 s]    dev=(HR@5:0.4389,NDCG@5:0.3203) [0.9 s]
INFO:root:Epoch 78    loss=0.1905 [20.0 s]    dev=(HR@5:0.4423,NDCG@5:0.3210) [0.9 s]
INFO:root:Epoch 79    loss=0.1902 [20.0 s]    dev=(HR@5:0.4437,NDCG@5:0.3235) [0.9 s] *
INFO:root:Epoch 80    loss=0.1897 [20.1 s]    dev=(HR@5:0.4406,NDCG@5:0.3211) [0.9 s]
INFO:root:Epoch 81    loss=0.1898 [20.0 s]    dev=(HR@5:0.4366,NDCG@5:0.3166) [0.9 s]
INFO:root:Epoch 82    loss=0.1918 [19.9 s]    dev=(HR@5:0.4385,NDCG@5:0.3196) [0.9 s]
INFO:root:Epoch 83    loss=0.1892 [20.0 s]    dev=(HR@5:0.4423,NDCG@5:0.3234) [0.9 s]
INFO:root:Epoch 84    loss=0.1898 [20.0 s]    dev=(HR@5:0.4423,NDCG@5:0.3233) [0.9 s]
INFO:root:Epoch 85    loss=0.1910 [19.9 s]    dev=(HR@5:0.4425,NDCG@5:0.3249) [0.9 s] *
INFO:root:Epoch 86    loss=0.1910 [20.1 s]    dev=(HR@5:0.4375,NDCG@5:0.3198) [0.9 s]
INFO:root:Epoch 87    loss=0.1894 [19.9 s]    dev=(HR@5:0.4356,NDCG@5:0.3190) [0.9 s]
INFO:root:Epoch 88    loss=0.1898 [20.0 s]    dev=(HR@5:0.4383,NDCG@5:0.3211) [0.9 s]
INFO:root:Epoch 89    loss=0.1893 [20.0 s]    dev=(HR@5:0.4382,NDCG@5:0.3210) [0.9 s]
INFO:root:Epoch 90    loss=0.1885 [20.1 s]    dev=(HR@5:0.4417,NDCG@5:0.3235) [0.9 s]
INFO:root:Epoch 91    loss=0.1890 [20.1 s]    dev=(HR@5:0.4440,NDCG@5:0.3249) [0.9 s]
INFO:root:Epoch 92    loss=0.1877 [20.1 s]    dev=(HR@5:0.4406,NDCG@5:0.3211) [0.9 s]
INFO:root:Epoch 93    loss=0.1900 [19.9 s]    dev=(HR@5:0.4391,NDCG@5:0.3198) [0.9 s]
INFO:root:Epoch 94    loss=0.1883 [20.0 s]    dev=(HR@5:0.4408,NDCG@5:0.3224) [0.9 s]
INFO:root:Epoch 95    loss=0.1893 [20.1 s]    dev=(HR@5:0.4431,NDCG@5:0.3244) [0.9 s]
INFO:root:Epoch 96    loss=0.1882 [19.9 s]    dev=(HR@5:0.4365,NDCG@5:0.3209) [0.9 s]
INFO:root:Epoch 97    loss=0.1887 [20.0 s]    dev=(HR@5:0.4374,NDCG@5:0.3191) [0.9 s]
INFO:root:Epoch 98    loss=0.1871 [20.0 s]    dev=(HR@5:0.4374,NDCG@5:0.3171) [0.9 s]
INFO:root:Epoch 99    loss=0.1885 [20.0 s]    dev=(HR@5:0.4393,NDCG@5:0.3214) [0.9 s]
INFO:root:Epoch 100   loss=0.1889 [20.1 s]    dev=(HR@5:0.4448,NDCG@5:0.3269) [0.9 s] *
INFO:root:Epoch 101   loss=0.1900 [20.0 s]    dev=(HR@5:0.4382,NDCG@5:0.3202) [0.9 s]
INFO:root:Epoch 102   loss=0.1896 [19.9 s]    dev=(HR@5:0.4421,NDCG@5:0.3235) [0.9 s]
INFO:root:Epoch 103   loss=0.1878 [20.0 s]    dev=(HR@5:0.4349,NDCG@5:0.3192) [0.9 s]
INFO:root:Epoch 104   loss=0.1891 [20.0 s]    dev=(HR@5:0.4402,NDCG@5:0.3228) [0.9 s]
INFO:root:Epoch 105   loss=0.1884 [20.1 s]    dev=(HR@5:0.4398,NDCG@5:0.3220) [0.9 s]
INFO:root:Epoch 106   loss=0.1882 [20.0 s]    dev=(HR@5:0.4391,NDCG@5:0.3210) [0.9 s]
INFO:root:Epoch 107   loss=0.1891 [20.0 s]    dev=(HR@5:0.4381,NDCG@5:0.3188) [0.9 s]
INFO:root:Epoch 108   loss=0.1879 [20.0 s]    dev=(HR@5:0.4438,NDCG@5:0.3241) [0.9 s]
INFO:root:Epoch 109   loss=0.1874 [20.1 s]    dev=(HR@5:0.4437,NDCG@5:0.3260) [0.9 s]
INFO:root:Epoch 110   loss=0.1880 [20.0 s]    dev=(HR@5:0.4428,NDCG@5:0.3254) [0.9 s]
INFO:root:Epoch 111   loss=0.1878 [20.0 s]    dev=(HR@5:0.4405,NDCG@5:0.3223) [0.9 s]
INFO:root:Epoch 112   loss=0.1893 [20.0 s]    dev=(HR@5:0.4420,NDCG@5:0.3226) [0.9 s]
INFO:root:Epoch 113   loss=0.1892 [20.0 s]    dev=(HR@5:0.4389,NDCG@5:0.3224) [0.9 s]
INFO:root:Epoch 114   loss=0.1882 [20.1 s]    dev=(HR@5:0.4387,NDCG@5:0.3207) [0.9 s]
INFO:root:Epoch 115   loss=0.1869 [20.0 s]    dev=(HR@5:0.4384,NDCG@5:0.3204) [0.9 s]
INFO:root:Epoch 116   loss=0.1877 [20.0 s]    dev=(HR@5:0.4395,NDCG@5:0.3222) [0.9 s]
INFO:root:Epoch 117   loss=0.1890 [20.1 s]    dev=(HR@5:0.4390,NDCG@5:0.3216) [0.9 s]
INFO:root:Epoch 118   loss=0.1891 [20.1 s]    dev=(HR@5:0.4395,NDCG@5:0.3247) [0.9 s]
INFO:root:Epoch 119   loss=0.1885 [19.9 s]    dev=(HR@5:0.4383,NDCG@5:0.3207) [0.9 s]
INFO:root:Epoch 120   loss=0.1877 [20.0 s]    dev=(HR@5:0.4408,NDCG@5:0.3220) [0.9 s]
INFO:root:Early stop at 120 based on dev result.
INFO:root:
Best Iter(dev)=  100	 dev=(HR@5:0.4448,NDCG@5:0.3269) [2511.8 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.3953,NDCG@5:0.2814,HR@10:0.5058,NDCG@10:0.3172,HR@20:0.6252,NDCG@20:0.3473,HR@50:0.8334,NDCG@50:0.3885)
INFO:root:
--------------------------------------------- END: 2024-12-06 03:56:19 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 04:52:39 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [22.3 s]    dev=(HR@5:0.2505,NDCG@5:0.1665) [0.9 s] *
INFO:root:Epoch 2     loss=0.4321 [20.1 s]    dev=(HR@5:0.3208,NDCG@5:0.2175) [0.9 s] *
INFO:root:Epoch 3     loss=0.3946 [20.1 s]    dev=(HR@5:0.3496,NDCG@5:0.2378) [0.9 s] *
INFO:root:Epoch 4     loss=0.3714 [20.1 s]    dev=(HR@5:0.3702,NDCG@5:0.2561) [0.9 s] *
INFO:root:Epoch 5     loss=0.3479 [20.1 s]    dev=(HR@5:0.3851,NDCG@5:0.2706) [0.9 s] *
INFO:root:Epoch 6     loss=0.3240 [20.2 s]    dev=(HR@5:0.4022,NDCG@5:0.2854) [0.9 s] *
INFO:root:Epoch 7     loss=0.3043 [20.1 s]    dev=(HR@5:0.4073,NDCG@5:0.2917) [0.9 s] *
INFO:root:Epoch 8     loss=0.2870 [20.1 s]    dev=(HR@5:0.4150,NDCG@5:0.2990) [0.9 s] *
INFO:root:Epoch 9     loss=0.2719 [20.1 s]    dev=(HR@5:0.4169,NDCG@5:0.3019) [0.9 s] *
INFO:root:Epoch 10    loss=0.2627 [20.1 s]    dev=(HR@5:0.4200,NDCG@5:0.3040) [0.9 s] *
INFO:root:Epoch 11    loss=0.2540 [20.1 s]    dev=(HR@5:0.4272,NDCG@5:0.3076) [0.9 s] *
INFO:root:Epoch 12    loss=0.2471 [20.2 s]    dev=(HR@5:0.4258,NDCG@5:0.3088) [0.9 s] *
INFO:root:Epoch 13    loss=0.2438 [20.1 s]    dev=(HR@5:0.4317,NDCG@5:0.3144) [0.9 s] *
INFO:root:Epoch 14    loss=0.2382 [20.0 s]    dev=(HR@5:0.4312,NDCG@5:0.3119) [0.9 s]
INFO:root:Epoch 15    loss=0.2359 [20.1 s]    dev=(HR@5:0.4293,NDCG@5:0.3106) [0.9 s]
INFO:root:Epoch 16    loss=0.2342 [20.0 s]    dev=(HR@5:0.4336,NDCG@5:0.3161) [0.9 s] *
INFO:root:Epoch 17    loss=0.2302 [20.1 s]    dev=(HR@5:0.4291,NDCG@5:0.3107) [0.9 s]
INFO:root:Epoch 18    loss=0.2266 [20.1 s]    dev=(HR@5:0.4334,NDCG@5:0.3160) [0.9 s]
INFO:root:Epoch 19    loss=0.2241 [20.1 s]    dev=(HR@5:0.4329,NDCG@5:0.3172) [0.9 s] *
INFO:root:Epoch 20    loss=0.2230 [20.1 s]    dev=(HR@5:0.4382,NDCG@5:0.3196) [0.9 s] *
INFO:root:Epoch 21    loss=0.2186 [20.1 s]    dev=(HR@5:0.4391,NDCG@5:0.3200) [0.9 s] *
INFO:root:Epoch 22    loss=0.2181 [20.2 s]    dev=(HR@5:0.4383,NDCG@5:0.3202) [0.9 s] *
INFO:root:Epoch 23    loss=0.2187 [20.2 s]    dev=(HR@5:0.4366,NDCG@5:0.3187) [0.9 s]
INFO:root:Epoch 24    loss=0.2178 [20.2 s]    dev=(HR@5:0.4408,NDCG@5:0.3199) [0.9 s]
INFO:root:Epoch 25    loss=0.2145 [20.1 s]    dev=(HR@5:0.4394,NDCG@5:0.3209) [0.9 s] *
INFO:root:Epoch 26    loss=0.2145 [20.2 s]    dev=(HR@5:0.4404,NDCG@5:0.3211) [0.9 s] *
INFO:root:Epoch 27    loss=0.2137 [20.1 s]    dev=(HR@5:0.4410,NDCG@5:0.3230) [0.9 s] *
INFO:root:Epoch 28    loss=0.2141 [20.1 s]    dev=(HR@5:0.4450,NDCG@5:0.3252) [0.9 s] *
INFO:root:Epoch 29    loss=0.2111 [20.1 s]    dev=(HR@5:0.4393,NDCG@5:0.3226) [0.9 s]
INFO:root:Epoch 30    loss=0.2104 [20.1 s]    dev=(HR@5:0.4401,NDCG@5:0.3234) [0.9 s]
INFO:root:Epoch 31    loss=0.2090 [20.2 s]    dev=(HR@5:0.4456,NDCG@5:0.3273) [0.9 s] *
INFO:root:Epoch 32    loss=0.2087 [20.0 s]    dev=(HR@5:0.4421,NDCG@5:0.3240) [0.9 s]
INFO:root:Epoch 33    loss=0.2082 [20.2 s]    dev=(HR@5:0.4436,NDCG@5:0.3242) [0.9 s]
INFO:root:Epoch 34    loss=0.2071 [20.1 s]    dev=(HR@5:0.4421,NDCG@5:0.3244) [0.9 s]
INFO:root:Epoch 35    loss=0.2070 [20.2 s]    dev=(HR@5:0.4435,NDCG@5:0.3245) [0.9 s]
INFO:root:Epoch 36    loss=0.2046 [20.1 s]    dev=(HR@5:0.4412,NDCG@5:0.3233) [0.9 s]
INFO:root:Epoch 37    loss=0.2052 [20.1 s]    dev=(HR@5:0.4440,NDCG@5:0.3240) [0.9 s]
INFO:root:Epoch 38    loss=0.2046 [20.1 s]    dev=(HR@5:0.4439,NDCG@5:0.3243) [0.9 s]
INFO:root:Epoch 39    loss=0.2037 [20.2 s]    dev=(HR@5:0.4419,NDCG@5:0.3212) [0.9 s]
INFO:root:Epoch 40    loss=0.2035 [20.2 s]    dev=(HR@5:0.4410,NDCG@5:0.3221) [0.9 s]
INFO:root:Epoch 41    loss=0.2032 [20.2 s]    dev=(HR@5:0.4449,NDCG@5:0.3239) [0.9 s]
INFO:root:Epoch 42    loss=0.2024 [20.1 s]    dev=(HR@5:0.4473,NDCG@5:0.3259) [0.9 s]
INFO:root:Epoch 43    loss=0.2014 [20.2 s]    dev=(HR@5:0.4447,NDCG@5:0.3256) [0.9 s]
INFO:root:Epoch 44    loss=0.2022 [20.1 s]    dev=(HR@5:0.4446,NDCG@5:0.3248) [0.9 s]
INFO:root:Epoch 45    loss=0.1986 [20.1 s]    dev=(HR@5:0.4477,NDCG@5:0.3287) [0.9 s] *
INFO:root:Epoch 46    loss=0.1996 [20.4 s]    dev=(HR@5:0.4429,NDCG@5:0.3239) [0.9 s]
INFO:root:Epoch 47    loss=0.1996 [20.2 s]    dev=(HR@5:0.4462,NDCG@5:0.3273) [0.9 s]
INFO:root:Epoch 48    loss=0.1986 [20.1 s]    dev=(HR@5:0.4413,NDCG@5:0.3212) [0.9 s]
INFO:root:Epoch 49    loss=0.1972 [20.2 s]    dev=(HR@5:0.4482,NDCG@5:0.3278) [0.9 s]
INFO:root:Epoch 50    loss=0.1978 [20.2 s]    dev=(HR@5:0.4417,NDCG@5:0.3235) [0.9 s]
INFO:root:Epoch 51    loss=0.1969 [20.1 s]    dev=(HR@5:0.4466,NDCG@5:0.3268) [0.9 s]
INFO:root:Epoch 52    loss=0.1967 [20.2 s]    dev=(HR@5:0.4432,NDCG@5:0.3240) [0.9 s]
INFO:root:Epoch 53    loss=0.1968 [20.2 s]    dev=(HR@5:0.4439,NDCG@5:0.3245) [0.9 s]
INFO:root:Epoch 54    loss=0.1954 [20.2 s]    dev=(HR@5:0.4462,NDCG@5:0.3269) [0.9 s]
INFO:root:Epoch 55    loss=0.1960 [20.1 s]    dev=(HR@5:0.4494,NDCG@5:0.3272) [0.9 s]
INFO:root:Epoch 56    loss=0.1953 [20.2 s]    dev=(HR@5:0.4496,NDCG@5:0.3293) [0.9 s] *
INFO:root:Epoch 57    loss=0.1943 [20.1 s]    dev=(HR@5:0.4481,NDCG@5:0.3295) [0.9 s] *
INFO:root:Epoch 58    loss=0.1959 [20.1 s]    dev=(HR@5:0.4467,NDCG@5:0.3301) [0.9 s] *
INFO:root:Epoch 59    loss=0.1950 [20.2 s]    dev=(HR@5:0.4475,NDCG@5:0.3283) [0.9 s]
INFO:root:Epoch 60    loss=0.1955 [20.2 s]    dev=(HR@5:0.4436,NDCG@5:0.3258) [0.9 s]
INFO:root:Epoch 61    loss=0.1944 [20.1 s]    dev=(HR@5:0.4509,NDCG@5:0.3323) [0.9 s] *
INFO:root:Epoch 62    loss=0.1946 [20.2 s]    dev=(HR@5:0.4492,NDCG@5:0.3308) [0.9 s]
INFO:root:Epoch 63    loss=0.1949 [20.2 s]    dev=(HR@5:0.4477,NDCG@5:0.3306) [0.9 s]
INFO:root:Epoch 64    loss=0.1932 [20.2 s]    dev=(HR@5:0.4463,NDCG@5:0.3274) [0.9 s]
INFO:root:Epoch 65    loss=0.1943 [20.1 s]    dev=(HR@5:0.4475,NDCG@5:0.3277) [0.9 s]
INFO:root:Epoch 66    loss=0.1923 [20.2 s]    dev=(HR@5:0.4462,NDCG@5:0.3261) [0.9 s]
INFO:root:Epoch 67    loss=0.1927 [20.3 s]    dev=(HR@5:0.4476,NDCG@5:0.3279) [0.9 s]
INFO:root:Epoch 68    loss=0.1915 [20.2 s]    dev=(HR@5:0.4492,NDCG@5:0.3287) [0.9 s]
INFO:root:Epoch 69    loss=0.1929 [20.2 s]    dev=(HR@5:0.4485,NDCG@5:0.3289) [0.9 s]
INFO:root:Epoch 70    loss=0.1925 [20.2 s]    dev=(HR@5:0.4444,NDCG@5:0.3265) [0.9 s]
INFO:root:Epoch 71    loss=0.1917 [20.1 s]    dev=(HR@5:0.4474,NDCG@5:0.3289) [0.9 s]
INFO:root:Epoch 72    loss=0.1912 [20.2 s]    dev=(HR@5:0.4474,NDCG@5:0.3286) [0.9 s]
INFO:root:Epoch 73    loss=0.1918 [20.2 s]    dev=(HR@5:0.4476,NDCG@5:0.3272) [0.9 s]
INFO:root:Epoch 74    loss=0.1926 [20.1 s]    dev=(HR@5:0.4455,NDCG@5:0.3240) [0.9 s]
INFO:root:Epoch 75    loss=0.1933 [20.6 s]    dev=(HR@5:0.4453,NDCG@5:0.3253) [0.9 s]
INFO:root:Epoch 76    loss=0.1925 [20.2 s]    dev=(HR@5:0.4492,NDCG@5:0.3274) [0.9 s]
INFO:root:Epoch 77    loss=0.1911 [20.0 s]    dev=(HR@5:0.4481,NDCG@5:0.3281) [0.9 s]
INFO:root:Epoch 78    loss=0.1913 [20.2 s]    dev=(HR@5:0.4464,NDCG@5:0.3247) [0.9 s]
INFO:root:Epoch 79    loss=0.1926 [20.0 s]    dev=(HR@5:0.4507,NDCG@5:0.3280) [0.9 s]
INFO:root:Epoch 80    loss=0.1905 [20.3 s]    dev=(HR@5:0.4521,NDCG@5:0.3285) [0.9 s]
INFO:root:Epoch 81    loss=0.1908 [20.3 s]    dev=(HR@5:0.4457,NDCG@5:0.3222) [0.9 s]
INFO:root:Early stop at 81 based on dev result.
INFO:root:
Best Iter(dev)=   61	 dev=(HR@5:0.4509,NDCG@5:0.3323) [1707.3 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.3979,NDCG@5:0.2855,HR@10:0.5105,NDCG@10:0.3220,HR@20:0.6333,NDCG@20:0.3530,HR@50:0.8351,NDCG@50:0.3929)
INFO:root:
--------------------------------------------- END: 2024-12-06 05:21:08 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 06:26:02 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [22.0 s]    dev=(HR@5:0.2527,NDCG@5:0.1683) [0.9 s] *
INFO:root:Epoch 2     loss=0.4299 [20.0 s]    dev=(HR@5:0.3273,NDCG@5:0.2224) [0.9 s] *
INFO:root:Epoch 3     loss=0.3926 [20.0 s]    dev=(HR@5:0.3543,NDCG@5:0.2425) [0.9 s] *
INFO:root:Epoch 4     loss=0.3711 [20.0 s]    dev=(HR@5:0.3704,NDCG@5:0.2564) [0.9 s] *
INFO:root:Epoch 5     loss=0.3496 [20.2 s]    dev=(HR@5:0.3870,NDCG@5:0.2700) [0.9 s] *
INFO:root:Epoch 6     loss=0.3288 [20.0 s]    dev=(HR@5:0.3995,NDCG@5:0.2836) [0.9 s] *
INFO:root:Epoch 7     loss=0.3124 [20.0 s]    dev=(HR@5:0.4047,NDCG@5:0.2881) [0.9 s] *
INFO:root:Epoch 8     loss=0.2957 [20.1 s]    dev=(HR@5:0.4146,NDCG@5:0.2975) [0.9 s] *
INFO:root:Epoch 9     loss=0.2784 [20.0 s]    dev=(HR@5:0.4214,NDCG@5:0.3034) [0.9 s] *
INFO:root:Epoch 10    loss=0.2674 [20.0 s]    dev=(HR@5:0.4227,NDCG@5:0.3064) [0.9 s] *
INFO:root:Epoch 11    loss=0.2570 [20.0 s]    dev=(HR@5:0.4312,NDCG@5:0.3092) [0.9 s] *
INFO:root:Epoch 12    loss=0.2481 [19.9 s]    dev=(HR@5:0.4299,NDCG@5:0.3109) [0.9 s] *
INFO:root:Epoch 13    loss=0.2442 [20.1 s]    dev=(HR@5:0.4368,NDCG@5:0.3187) [0.9 s] *
INFO:root:Epoch 14    loss=0.2380 [19.9 s]    dev=(HR@5:0.4370,NDCG@5:0.3167) [0.9 s]
INFO:root:Epoch 15    loss=0.2350 [20.0 s]    dev=(HR@5:0.4325,NDCG@5:0.3137) [0.9 s]
INFO:root:Epoch 16    loss=0.2334 [20.2 s]    dev=(HR@5:0.4378,NDCG@5:0.3201) [0.9 s] *
INFO:root:Epoch 17    loss=0.2295 [20.1 s]    dev=(HR@5:0.4331,NDCG@5:0.3141) [0.9 s]
INFO:root:Epoch 18    loss=0.2247 [20.0 s]    dev=(HR@5:0.4397,NDCG@5:0.3209) [0.9 s] *
INFO:root:Epoch 19    loss=0.2237 [20.1 s]    dev=(HR@5:0.4381,NDCG@5:0.3206) [0.9 s]
INFO:root:Epoch 20    loss=0.2213 [20.0 s]    dev=(HR@5:0.4409,NDCG@5:0.3240) [0.9 s] *
INFO:root:Epoch 21    loss=0.2174 [20.1 s]    dev=(HR@5:0.4418,NDCG@5:0.3217) [0.9 s]
INFO:root:Epoch 22    loss=0.2173 [20.1 s]    dev=(HR@5:0.4412,NDCG@5:0.3228) [0.9 s]
INFO:root:Epoch 23    loss=0.2181 [20.2 s]    dev=(HR@5:0.4413,NDCG@5:0.3231) [0.9 s]
INFO:root:Epoch 24    loss=0.2174 [20.3 s]    dev=(HR@5:0.4445,NDCG@5:0.3231) [0.9 s]
INFO:root:Epoch 25    loss=0.2136 [20.1 s]    dev=(HR@5:0.4437,NDCG@5:0.3234) [0.9 s]
INFO:root:Epoch 26    loss=0.2135 [20.1 s]    dev=(HR@5:0.4454,NDCG@5:0.3247) [0.9 s] *
INFO:root:Epoch 27    loss=0.2127 [20.1 s]    dev=(HR@5:0.4447,NDCG@5:0.3265) [0.9 s] *
INFO:root:Epoch 28    loss=0.2138 [20.0 s]    dev=(HR@5:0.4466,NDCG@5:0.3271) [0.9 s] *
INFO:root:Epoch 29    loss=0.2109 [20.0 s]    dev=(HR@5:0.4449,NDCG@5:0.3253) [0.9 s]
INFO:root:Epoch 30    loss=0.2099 [20.1 s]    dev=(HR@5:0.4441,NDCG@5:0.3268) [0.9 s]
INFO:root:Epoch 31    loss=0.2087 [20.1 s]    dev=(HR@5:0.4466,NDCG@5:0.3287) [0.9 s] *
INFO:root:Epoch 32    loss=0.2098 [20.1 s]    dev=(HR@5:0.4491,NDCG@5:0.3287) [0.9 s]
INFO:root:Epoch 33    loss=0.2092 [20.0 s]    dev=(HR@5:0.4479,NDCG@5:0.3272) [0.9 s]
INFO:root:Epoch 34    loss=0.2085 [20.1 s]    dev=(HR@5:0.4470,NDCG@5:0.3286) [0.9 s]
INFO:root:Epoch 35    loss=0.2090 [20.0 s]    dev=(HR@5:0.4451,NDCG@5:0.3242) [0.9 s]
INFO:root:Epoch 36    loss=0.2065 [20.0 s]    dev=(HR@5:0.4447,NDCG@5:0.3253) [0.9 s]
INFO:root:Epoch 37    loss=0.2068 [19.9 s]    dev=(HR@5:0.4481,NDCG@5:0.3264) [0.9 s]
INFO:root:Epoch 38    loss=0.2070 [20.0 s]    dev=(HR@5:0.4466,NDCG@5:0.3257) [0.9 s]
INFO:root:Epoch 39    loss=0.2060 [20.1 s]    dev=(HR@5:0.4404,NDCG@5:0.3214) [0.9 s]
INFO:root:Epoch 40    loss=0.2060 [20.1 s]    dev=(HR@5:0.4454,NDCG@5:0.3245) [0.9 s]
INFO:root:Epoch 41    loss=0.2060 [20.0 s]    dev=(HR@5:0.4417,NDCG@5:0.3213) [0.9 s]
INFO:root:Epoch 42    loss=0.2056 [20.1 s]    dev=(HR@5:0.4484,NDCG@5:0.3261) [0.9 s]
INFO:root:Epoch 43    loss=0.2030 [20.1 s]    dev=(HR@5:0.4472,NDCG@5:0.3267) [0.9 s]
INFO:root:Epoch 44    loss=0.2032 [20.1 s]    dev=(HR@5:0.4454,NDCG@5:0.3240) [0.9 s]
INFO:root:Epoch 45    loss=0.2007 [20.0 s]    dev=(HR@5:0.4475,NDCG@5:0.3288) [0.9 s] *
INFO:root:Epoch 46    loss=0.2019 [20.2 s]    dev=(HR@5:0.4420,NDCG@5:0.3227) [0.9 s]
INFO:root:Epoch 47    loss=0.2020 [20.0 s]    dev=(HR@5:0.4462,NDCG@5:0.3264) [0.9 s]
INFO:root:Epoch 48    loss=0.2011 [20.1 s]    dev=(HR@5:0.4423,NDCG@5:0.3222) [0.9 s]
INFO:root:Epoch 49    loss=0.1992 [20.0 s]    dev=(HR@5:0.4456,NDCG@5:0.3253) [0.9 s]
INFO:root:Epoch 50    loss=0.2005 [20.1 s]    dev=(HR@5:0.4447,NDCG@5:0.3266) [0.9 s]
INFO:root:Epoch 51    loss=0.1993 [20.1 s]    dev=(HR@5:0.4434,NDCG@5:0.3251) [0.9 s]
INFO:root:Epoch 52    loss=0.1994 [20.1 s]    dev=(HR@5:0.4433,NDCG@5:0.3231) [0.9 s]
INFO:root:Epoch 53    loss=0.1988 [20.1 s]    dev=(HR@5:0.4436,NDCG@5:0.3255) [0.9 s]
INFO:root:Epoch 54    loss=0.1966 [20.1 s]    dev=(HR@5:0.4496,NDCG@5:0.3267) [0.9 s]
INFO:root:Epoch 55    loss=0.1969 [20.1 s]    dev=(HR@5:0.4464,NDCG@5:0.3246) [0.9 s]
INFO:root:Epoch 56    loss=0.1968 [19.9 s]    dev=(HR@5:0.4466,NDCG@5:0.3282) [0.9 s]
INFO:root:Epoch 57    loss=0.1965 [20.0 s]    dev=(HR@5:0.4452,NDCG@5:0.3269) [0.9 s]
INFO:root:Epoch 58    loss=0.1978 [20.1 s]    dev=(HR@5:0.4477,NDCG@5:0.3276) [0.9 s]
INFO:root:Epoch 59    loss=0.1968 [20.2 s]    dev=(HR@5:0.4424,NDCG@5:0.3255) [0.9 s]
INFO:root:Epoch 60    loss=0.1967 [20.1 s]    dev=(HR@5:0.4453,NDCG@5:0.3248) [0.9 s]
INFO:root:Epoch 61    loss=0.1963 [20.0 s]    dev=(HR@5:0.4488,NDCG@5:0.3284) [0.9 s]
INFO:root:Epoch 62    loss=0.1960 [19.9 s]    dev=(HR@5:0.4477,NDCG@5:0.3266) [0.9 s]
INFO:root:Epoch 63    loss=0.1973 [20.0 s]    dev=(HR@5:0.4467,NDCG@5:0.3262) [0.9 s]
INFO:root:Epoch 64    loss=0.1950 [20.0 s]    dev=(HR@5:0.4449,NDCG@5:0.3240) [0.9 s]
INFO:root:Epoch 65    loss=0.1953 [20.0 s]    dev=(HR@5:0.4423,NDCG@5:0.3219) [0.9 s]
INFO:root:Early stop at 65 based on dev result.
INFO:root:
Best Iter(dev)=   45	 dev=(HR@5:0.4475,NDCG@5:0.3288) [1363.8 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.4014,NDCG@5:0.2850,HR@10:0.5139,NDCG@10:0.3215,HR@20:0.6361,NDCG@20:0.3524,HR@50:0.8393,NDCG@50:0.3926)
INFO:root:
--------------------------------------------- END: 2024-12-06 06:48:47 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 07:26:40 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5165 [22.0 s]    dev=(HR@5:0.2530,NDCG@5:0.1686) [0.9 s] *
INFO:root:Epoch 2     loss=0.4298 [20.1 s]    dev=(HR@5:0.3263,NDCG@5:0.2223) [0.9 s] *
INFO:root:Epoch 3     loss=0.3933 [20.1 s]    dev=(HR@5:0.3526,NDCG@5:0.2410) [0.9 s] *
INFO:root:Epoch 4     loss=0.3723 [20.0 s]    dev=(HR@5:0.3710,NDCG@5:0.2569) [0.9 s] *
INFO:root:Epoch 5     loss=0.3494 [20.0 s]    dev=(HR@5:0.3896,NDCG@5:0.2733) [0.9 s] *
INFO:root:Epoch 6     loss=0.3247 [20.1 s]    dev=(HR@5:0.4069,NDCG@5:0.2922) [0.9 s] *
INFO:root:Epoch 7     loss=0.3041 [20.0 s]    dev=(HR@5:0.4143,NDCG@5:0.2983) [0.9 s] *
INFO:root:Epoch 8     loss=0.2870 [20.1 s]    dev=(HR@5:0.4241,NDCG@5:0.3062) [0.9 s] *
INFO:root:Epoch 9     loss=0.2715 [19.9 s]    dev=(HR@5:0.4277,NDCG@5:0.3091) [0.9 s] *
INFO:root:Epoch 10    loss=0.2625 [20.0 s]    dev=(HR@5:0.4308,NDCG@5:0.3120) [0.9 s] *
INFO:root:Epoch 11    loss=0.2533 [20.0 s]    dev=(HR@5:0.4347,NDCG@5:0.3132) [0.9 s] *
INFO:root:Epoch 12    loss=0.2457 [20.0 s]    dev=(HR@5:0.4346,NDCG@5:0.3156) [0.9 s] *
INFO:root:Epoch 13    loss=0.2423 [20.1 s]    dev=(HR@5:0.4408,NDCG@5:0.3202) [0.9 s] *
INFO:root:Epoch 14    loss=0.2367 [20.0 s]    dev=(HR@5:0.4383,NDCG@5:0.3178) [0.9 s]
INFO:root:Epoch 15    loss=0.2339 [20.1 s]    dev=(HR@5:0.4353,NDCG@5:0.3154) [0.9 s]
INFO:root:Epoch 16    loss=0.2327 [19.9 s]    dev=(HR@5:0.4395,NDCG@5:0.3207) [0.9 s] *
INFO:root:Epoch 17    loss=0.2285 [20.1 s]    dev=(HR@5:0.4342,NDCG@5:0.3158) [0.9 s]
INFO:root:Epoch 18    loss=0.2245 [20.1 s]    dev=(HR@5:0.4389,NDCG@5:0.3212) [0.9 s] *
INFO:root:Epoch 19    loss=0.2231 [20.1 s]    dev=(HR@5:0.4392,NDCG@5:0.3208) [0.9 s]
INFO:root:Epoch 20    loss=0.2203 [19.9 s]    dev=(HR@5:0.4397,NDCG@5:0.3223) [0.9 s] *
INFO:root:Epoch 21    loss=0.2166 [20.0 s]    dev=(HR@5:0.4401,NDCG@5:0.3213) [0.9 s]
INFO:root:Epoch 22    loss=0.2168 [19.9 s]    dev=(HR@5:0.4417,NDCG@5:0.3223) [0.9 s]
INFO:root:Epoch 23    loss=0.2168 [20.2 s]    dev=(HR@5:0.4417,NDCG@5:0.3227) [0.9 s] *
INFO:root:Epoch 24    loss=0.2166 [20.1 s]    dev=(HR@5:0.4436,NDCG@5:0.3225) [0.9 s]
INFO:root:Epoch 25    loss=0.2131 [20.0 s]    dev=(HR@5:0.4417,NDCG@5:0.3219) [0.9 s]
INFO:root:Epoch 26    loss=0.2134 [20.0 s]    dev=(HR@5:0.4432,NDCG@5:0.3235) [0.9 s] *
INFO:root:Epoch 27    loss=0.2130 [20.1 s]    dev=(HR@5:0.4437,NDCG@5:0.3254) [0.9 s] *
INFO:root:Epoch 28    loss=0.2124 [20.0 s]    dev=(HR@5:0.4464,NDCG@5:0.3275) [0.9 s] *
INFO:root:Epoch 29    loss=0.2105 [20.0 s]    dev=(HR@5:0.4442,NDCG@5:0.3252) [0.9 s]
INFO:root:Epoch 30    loss=0.2102 [20.0 s]    dev=(HR@5:0.4443,NDCG@5:0.3261) [0.9 s]
INFO:root:Epoch 31    loss=0.2091 [20.0 s]    dev=(HR@5:0.4439,NDCG@5:0.3260) [0.9 s]
INFO:root:Epoch 32    loss=0.2094 [20.1 s]    dev=(HR@5:0.4432,NDCG@5:0.3247) [0.9 s]
INFO:root:Epoch 33    loss=0.2091 [20.0 s]    dev=(HR@5:0.4452,NDCG@5:0.3261) [0.9 s]
INFO:root:Epoch 34    loss=0.2083 [19.9 s]    dev=(HR@5:0.4448,NDCG@5:0.3261) [0.9 s]
INFO:root:Epoch 35    loss=0.2089 [20.0 s]    dev=(HR@5:0.4419,NDCG@5:0.3232) [0.9 s]
INFO:root:Epoch 36    loss=0.2059 [20.0 s]    dev=(HR@5:0.4431,NDCG@5:0.3246) [0.9 s]
INFO:root:Epoch 37    loss=0.2069 [20.1 s]    dev=(HR@5:0.4432,NDCG@5:0.3232) [0.9 s]
INFO:root:Epoch 38    loss=0.2069 [19.9 s]    dev=(HR@5:0.4478,NDCG@5:0.3261) [0.9 s]
INFO:root:Epoch 39    loss=0.2069 [20.1 s]    dev=(HR@5:0.4402,NDCG@5:0.3216) [0.9 s]
INFO:root:Epoch 40    loss=0.2064 [20.1 s]    dev=(HR@5:0.4389,NDCG@5:0.3207) [0.9 s]
INFO:root:Epoch 41    loss=0.2071 [20.1 s]    dev=(HR@5:0.4393,NDCG@5:0.3209) [0.9 s]
INFO:root:Epoch 42    loss=0.2071 [20.1 s]    dev=(HR@5:0.4479,NDCG@5:0.3260) [0.9 s]
INFO:root:Epoch 43    loss=0.2052 [20.1 s]    dev=(HR@5:0.4463,NDCG@5:0.3273) [0.9 s]
INFO:root:Epoch 44    loss=0.2049 [20.1 s]    dev=(HR@5:0.4447,NDCG@5:0.3241) [0.9 s]
INFO:root:Epoch 45    loss=0.2020 [20.0 s]    dev=(HR@5:0.4470,NDCG@5:0.3276) [0.9 s] *
INFO:root:Epoch 46    loss=0.2027 [20.0 s]    dev=(HR@5:0.4427,NDCG@5:0.3246) [0.9 s]
INFO:root:Epoch 47    loss=0.2020 [20.1 s]    dev=(HR@5:0.4449,NDCG@5:0.3248) [0.9 s]
INFO:root:Epoch 48    loss=0.2018 [20.0 s]    dev=(HR@5:0.4398,NDCG@5:0.3197) [0.9 s]
INFO:root:Epoch 49    loss=0.2001 [20.0 s]    dev=(HR@5:0.4442,NDCG@5:0.3239) [0.9 s]
INFO:root:Epoch 50    loss=0.2016 [20.1 s]    dev=(HR@5:0.4440,NDCG@5:0.3254) [0.9 s]
INFO:root:Epoch 51    loss=0.1997 [20.1 s]    dev=(HR@5:0.4435,NDCG@5:0.3248) [0.9 s]
INFO:root:Epoch 52    loss=0.2006 [20.0 s]    dev=(HR@5:0.4413,NDCG@5:0.3219) [0.9 s]
INFO:root:Epoch 53    loss=0.1998 [20.1 s]    dev=(HR@5:0.4418,NDCG@5:0.3223) [0.9 s]
INFO:root:Epoch 54    loss=0.1985 [20.1 s]    dev=(HR@5:0.4444,NDCG@5:0.3231) [0.9 s]
INFO:root:Epoch 55    loss=0.1984 [20.0 s]    dev=(HR@5:0.4416,NDCG@5:0.3224) [0.9 s]
INFO:root:Epoch 56    loss=0.1978 [20.1 s]    dev=(HR@5:0.4453,NDCG@5:0.3278) [0.9 s] *
INFO:root:Epoch 57    loss=0.1987 [20.0 s]    dev=(HR@5:0.4451,NDCG@5:0.3270) [0.9 s]
INFO:root:Epoch 58    loss=0.2002 [20.0 s]    dev=(HR@5:0.4464,NDCG@5:0.3289) [0.9 s] *
INFO:root:Epoch 59    loss=0.1982 [20.0 s]    dev=(HR@5:0.4449,NDCG@5:0.3269) [0.9 s]
INFO:root:Epoch 60    loss=0.1984 [20.0 s]    dev=(HR@5:0.4417,NDCG@5:0.3229) [0.9 s]
INFO:root:Epoch 61    loss=0.1975 [20.0 s]    dev=(HR@5:0.4445,NDCG@5:0.3259) [0.9 s]
INFO:root:Epoch 62    loss=0.1975 [20.0 s]    dev=(HR@5:0.4483,NDCG@5:0.3283) [0.9 s]
INFO:root:Epoch 63    loss=0.1997 [20.0 s]    dev=(HR@5:0.4456,NDCG@5:0.3268) [0.9 s]
INFO:root:Epoch 64    loss=0.1971 [20.0 s]    dev=(HR@5:0.4437,NDCG@5:0.3232) [0.9 s]
INFO:root:Epoch 65    loss=0.1977 [20.1 s]    dev=(HR@5:0.4434,NDCG@5:0.3223) [0.9 s]
INFO:root:Epoch 66    loss=0.1960 [20.2 s]    dev=(HR@5:0.4440,NDCG@5:0.3227) [0.9 s]
INFO:root:Epoch 67    loss=0.1963 [20.0 s]    dev=(HR@5:0.4438,NDCG@5:0.3227) [0.9 s]
INFO:root:Epoch 68    loss=0.1946 [20.1 s]    dev=(HR@5:0.4443,NDCG@5:0.3235) [0.9 s]
INFO:root:Epoch 69    loss=0.1966 [20.0 s]    dev=(HR@5:0.4432,NDCG@5:0.3245) [0.9 s]
INFO:root:Epoch 70    loss=0.1963 [20.0 s]    dev=(HR@5:0.4416,NDCG@5:0.3232) [0.9 s]
INFO:root:Epoch 71    loss=0.1963 [20.0 s]    dev=(HR@5:0.4432,NDCG@5:0.3235) [0.9 s]
INFO:root:Epoch 72    loss=0.1960 [20.0 s]    dev=(HR@5:0.4440,NDCG@5:0.3253) [0.9 s]
INFO:root:Epoch 73    loss=0.1954 [20.1 s]    dev=(HR@5:0.4404,NDCG@5:0.3234) [0.9 s]
INFO:root:Epoch 74    loss=0.1969 [20.1 s]    dev=(HR@5:0.4430,NDCG@5:0.3218) [0.9 s]
INFO:root:Epoch 75    loss=0.1971 [20.1 s]    dev=(HR@5:0.4411,NDCG@5:0.3224) [0.9 s]
INFO:root:Epoch 76    loss=0.1959 [20.1 s]    dev=(HR@5:0.4440,NDCG@5:0.3254) [0.9 s]
INFO:root:Epoch 77    loss=0.1963 [20.1 s]    dev=(HR@5:0.4403,NDCG@5:0.3222) [0.9 s]
INFO:root:Epoch 78    loss=0.1958 [20.0 s]    dev=(HR@5:0.4415,NDCG@5:0.3217) [0.9 s]
INFO:root:Early stop at 78 based on dev result.
INFO:root:
Best Iter(dev)=   58	 dev=(HR@5:0.4464,NDCG@5:0.3289) [1635.1 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.3989,NDCG@5:0.2844,HR@10:0.5065,NDCG@10:0.3193,HR@20:0.6294,NDCG@20:0.3503,HR@50:0.8365,NDCG@50:0.3913)
INFO:root:
--------------------------------------------- END: 2024-12-06 07:53:57 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 08:38:04 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5166 [21.9 s]    dev=(HR@5:0.2528,NDCG@5:0.1681) [0.9 s] *
INFO:root:Epoch 2     loss=0.4306 [19.9 s]    dev=(HR@5:0.3244,NDCG@5:0.2205) [0.9 s] *
INFO:root:Epoch 3     loss=0.3946 [20.0 s]    dev=(HR@5:0.3478,NDCG@5:0.2370) [0.9 s] *
INFO:root:Epoch 4     loss=0.3736 [20.0 s]    dev=(HR@5:0.3687,NDCG@5:0.2562) [0.9 s] *
INFO:root:Epoch 5     loss=0.3496 [20.0 s]    dev=(HR@5:0.3873,NDCG@5:0.2719) [0.9 s] *
INFO:root:Epoch 6     loss=0.3267 [20.0 s]    dev=(HR@5:0.4019,NDCG@5:0.2871) [0.9 s] *
INFO:root:Epoch 7     loss=0.3110 [20.1 s]    dev=(HR@5:0.4045,NDCG@5:0.2894) [0.9 s] *
INFO:root:Epoch 8     loss=0.2980 [20.0 s]    dev=(HR@5:0.4118,NDCG@5:0.2952) [0.9 s] *
INFO:root:Epoch 9     loss=0.2844 [20.0 s]    dev=(HR@5:0.4161,NDCG@5:0.3004) [0.9 s] *
INFO:root:Epoch 10    loss=0.2761 [20.0 s]    dev=(HR@5:0.4169,NDCG@5:0.3009) [0.9 s] *
INFO:root:Epoch 11    loss=0.2665 [20.1 s]    dev=(HR@5:0.4225,NDCG@5:0.3041) [0.9 s] *
INFO:root:Epoch 12    loss=0.2580 [20.1 s]    dev=(HR@5:0.4239,NDCG@5:0.3086) [0.9 s] *
INFO:root:Epoch 13    loss=0.2528 [19.9 s]    dev=(HR@5:0.4321,NDCG@5:0.3145) [0.9 s] *
INFO:root:Epoch 14    loss=0.2467 [20.0 s]    dev=(HR@5:0.4297,NDCG@5:0.3114) [0.9 s]
INFO:root:Epoch 15    loss=0.2423 [20.0 s]    dev=(HR@5:0.4279,NDCG@5:0.3101) [0.9 s]
INFO:root:Epoch 16    loss=0.2398 [20.1 s]    dev=(HR@5:0.4306,NDCG@5:0.3147) [0.9 s] *
INFO:root:Epoch 17    loss=0.2342 [19.9 s]    dev=(HR@5:0.4305,NDCG@5:0.3134) [0.9 s]
INFO:root:Epoch 18    loss=0.2293 [20.1 s]    dev=(HR@5:0.4374,NDCG@5:0.3177) [0.9 s] *
INFO:root:Epoch 19    loss=0.2271 [19.9 s]    dev=(HR@5:0.4374,NDCG@5:0.3192) [0.9 s] *
INFO:root:Epoch 20    loss=0.2234 [20.1 s]    dev=(HR@5:0.4397,NDCG@5:0.3223) [0.9 s] *
INFO:root:Epoch 21    loss=0.2196 [20.0 s]    dev=(HR@5:0.4391,NDCG@5:0.3211) [0.9 s]
INFO:root:Epoch 22    loss=0.2190 [20.0 s]    dev=(HR@5:0.4346,NDCG@5:0.3183) [0.9 s]
INFO:root:Epoch 23    loss=0.2175 [20.0 s]    dev=(HR@5:0.4350,NDCG@5:0.3186) [0.9 s]
INFO:root:Epoch 24    loss=0.2174 [20.1 s]    dev=(HR@5:0.4403,NDCG@5:0.3196) [0.9 s]
INFO:root:Epoch 25    loss=0.2144 [19.9 s]    dev=(HR@5:0.4345,NDCG@5:0.3158) [0.9 s]
INFO:root:Epoch 26    loss=0.2140 [20.0 s]    dev=(HR@5:0.4386,NDCG@5:0.3201) [0.9 s]
INFO:root:Epoch 27    loss=0.2135 [19.9 s]    dev=(HR@5:0.4389,NDCG@5:0.3206) [0.9 s]
INFO:root:Epoch 28    loss=0.2134 [19.9 s]    dev=(HR@5:0.4453,NDCG@5:0.3251) [0.9 s] *
INFO:root:Epoch 29    loss=0.2109 [20.1 s]    dev=(HR@5:0.4410,NDCG@5:0.3228) [0.9 s]
INFO:root:Epoch 30    loss=0.2104 [20.0 s]    dev=(HR@5:0.4397,NDCG@5:0.3230) [0.9 s]
INFO:root:Epoch 31    loss=0.2089 [20.0 s]    dev=(HR@5:0.4391,NDCG@5:0.3229) [0.9 s]
INFO:root:Epoch 32    loss=0.2096 [20.0 s]    dev=(HR@5:0.4400,NDCG@5:0.3231) [0.9 s]
INFO:root:Epoch 33    loss=0.2086 [20.0 s]    dev=(HR@5:0.4398,NDCG@5:0.3220) [0.9 s]
INFO:root:Epoch 34    loss=0.2078 [20.1 s]    dev=(HR@5:0.4417,NDCG@5:0.3239) [0.9 s]
INFO:root:Epoch 35    loss=0.2081 [20.1 s]    dev=(HR@5:0.4395,NDCG@5:0.3206) [0.9 s]
INFO:root:Epoch 36    loss=0.2055 [20.0 s]    dev=(HR@5:0.4376,NDCG@5:0.3206) [0.9 s]
INFO:root:Epoch 37    loss=0.2059 [19.9 s]    dev=(HR@5:0.4389,NDCG@5:0.3200) [0.9 s]
INFO:root:Epoch 38    loss=0.2067 [20.2 s]    dev=(HR@5:0.4400,NDCG@5:0.3209) [0.9 s]
INFO:root:Epoch 39    loss=0.2051 [20.0 s]    dev=(HR@5:0.4351,NDCG@5:0.3159) [0.9 s]
INFO:root:Epoch 40    loss=0.2055 [19.9 s]    dev=(HR@5:0.4351,NDCG@5:0.3178) [0.9 s]
INFO:root:Epoch 41    loss=0.2056 [19.9 s]    dev=(HR@5:0.4384,NDCG@5:0.3183) [0.9 s]
INFO:root:Epoch 42    loss=0.2060 [20.0 s]    dev=(HR@5:0.4393,NDCG@5:0.3213) [0.9 s]
INFO:root:Epoch 43    loss=0.2038 [20.0 s]    dev=(HR@5:0.4433,NDCG@5:0.3253) [0.9 s] *
INFO:root:Epoch 44    loss=0.2042 [19.9 s]    dev=(HR@5:0.4385,NDCG@5:0.3210) [0.9 s]
INFO:root:Epoch 45    loss=0.2010 [19.9 s]    dev=(HR@5:0.4409,NDCG@5:0.3235) [0.9 s]
INFO:root:Epoch 46    loss=0.2029 [20.0 s]    dev=(HR@5:0.4363,NDCG@5:0.3205) [0.9 s]
INFO:root:Epoch 47    loss=0.2025 [20.0 s]    dev=(HR@5:0.4370,NDCG@5:0.3192) [0.9 s]
INFO:root:Epoch 48    loss=0.2012 [20.0 s]    dev=(HR@5:0.4357,NDCG@5:0.3175) [0.9 s]
INFO:root:Epoch 49    loss=0.2008 [20.0 s]    dev=(HR@5:0.4367,NDCG@5:0.3203) [0.9 s]
INFO:root:Epoch 50    loss=0.2024 [20.0 s]    dev=(HR@5:0.4372,NDCG@5:0.3207) [0.9 s]
INFO:root:Epoch 51    loss=0.2014 [20.0 s]    dev=(HR@5:0.4385,NDCG@5:0.3212) [0.9 s]
INFO:root:Epoch 52    loss=0.2008 [20.0 s]    dev=(HR@5:0.4366,NDCG@5:0.3189) [0.9 s]
INFO:root:Epoch 53    loss=0.2007 [19.9 s]    dev=(HR@5:0.4344,NDCG@5:0.3166) [0.9 s]
INFO:root:Epoch 54    loss=0.1996 [20.1 s]    dev=(HR@5:0.4391,NDCG@5:0.3192) [0.9 s]
INFO:root:Epoch 55    loss=0.1993 [20.0 s]    dev=(HR@5:0.4366,NDCG@5:0.3192) [0.9 s]
INFO:root:Epoch 56    loss=0.1993 [20.0 s]    dev=(HR@5:0.4406,NDCG@5:0.3240) [0.9 s]
INFO:root:Epoch 57    loss=0.1996 [19.8 s]    dev=(HR@5:0.4413,NDCG@5:0.3230) [0.9 s]
INFO:root:Epoch 58    loss=0.2007 [20.0 s]    dev=(HR@5:0.4417,NDCG@5:0.3234) [0.9 s]
INFO:root:Epoch 59    loss=0.1984 [20.1 s]    dev=(HR@5:0.4418,NDCG@5:0.3231) [0.9 s]
INFO:root:Epoch 60    loss=0.1993 [20.0 s]    dev=(HR@5:0.4376,NDCG@5:0.3204) [0.9 s]
INFO:root:Epoch 61    loss=0.1985 [20.1 s]    dev=(HR@5:0.4404,NDCG@5:0.3229) [0.9 s]
INFO:root:Epoch 62    loss=0.1983 [20.1 s]    dev=(HR@5:0.4417,NDCG@5:0.3238) [0.9 s]
INFO:root:Epoch 63    loss=0.2000 [20.1 s]    dev=(HR@5:0.4390,NDCG@5:0.3216) [0.9 s]
INFO:root:Early stop at 63 based on dev result.
INFO:root:
Best Iter(dev)=   43	 dev=(HR@5:0.4433,NDCG@5:0.3253) [1319.0 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.3918,NDCG@5:0.2778,HR@10:0.4990,NDCG@10:0.3125,HR@20:0.6190,NDCG@20:0.3427,HR@50:0.8279,NDCG@50:0.3841)
INFO:root:
--------------------------------------------- END: 2024-12-06 09:00:05 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 10:01:39 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5159 [22.0 s]    dev=(HR@5:0.2509,NDCG@5:0.1668) [0.9 s] *
INFO:root:Epoch 2     loss=0.4333 [19.9 s]    dev=(HR@5:0.3180,NDCG@5:0.2144) [0.9 s] *
INFO:root:Epoch 3     loss=0.3983 [20.0 s]    dev=(HR@5:0.3415,NDCG@5:0.2298) [0.9 s] *
INFO:root:Epoch 4     loss=0.3762 [19.9 s]    dev=(HR@5:0.3640,NDCG@5:0.2506) [0.9 s] *
INFO:root:Epoch 5     loss=0.3506 [19.9 s]    dev=(HR@5:0.3779,NDCG@5:0.2644) [0.9 s] *
INFO:root:Epoch 6     loss=0.3261 [19.9 s]    dev=(HR@5:0.3905,NDCG@5:0.2778) [0.9 s] *
INFO:root:Epoch 7     loss=0.3073 [20.0 s]    dev=(HR@5:0.3949,NDCG@5:0.2821) [0.9 s] *
INFO:root:Epoch 8     loss=0.2910 [19.9 s]    dev=(HR@5:0.4031,NDCG@5:0.2888) [0.9 s] *
INFO:root:Epoch 9     loss=0.2757 [20.1 s]    dev=(HR@5:0.4043,NDCG@5:0.2932) [0.9 s] *
INFO:root:Epoch 10    loss=0.2649 [20.1 s]    dev=(HR@5:0.4086,NDCG@5:0.2958) [0.9 s] *
INFO:root:Epoch 11    loss=0.2555 [19.9 s]    dev=(HR@5:0.4166,NDCG@5:0.3015) [0.9 s] *
INFO:root:Epoch 12    loss=0.2463 [19.9 s]    dev=(HR@5:0.4199,NDCG@5:0.3051) [0.9 s] *
INFO:root:Epoch 13    loss=0.2431 [20.0 s]    dev=(HR@5:0.4261,NDCG@5:0.3096) [0.9 s] *
INFO:root:Epoch 14    loss=0.2368 [19.9 s]    dev=(HR@5:0.4240,NDCG@5:0.3077) [0.9 s]
INFO:root:Epoch 15    loss=0.2343 [20.0 s]    dev=(HR@5:0.4244,NDCG@5:0.3068) [0.9 s]
INFO:root:Epoch 16    loss=0.2307 [20.0 s]    dev=(HR@5:0.4267,NDCG@5:0.3099) [0.9 s] *
INFO:root:Epoch 17    loss=0.2277 [20.0 s]    dev=(HR@5:0.4236,NDCG@5:0.3068) [0.9 s]
INFO:root:Epoch 18    loss=0.2234 [20.0 s]    dev=(HR@5:0.4291,NDCG@5:0.3124) [0.9 s] *
INFO:root:Epoch 19    loss=0.2215 [20.1 s]    dev=(HR@5:0.4300,NDCG@5:0.3137) [0.9 s] *
INFO:root:Epoch 20    loss=0.2197 [20.0 s]    dev=(HR@5:0.4321,NDCG@5:0.3154) [0.9 s] *
INFO:root:Epoch 21    loss=0.2159 [19.9 s]    dev=(HR@5:0.4328,NDCG@5:0.3157) [0.9 s] *
INFO:root:Epoch 22    loss=0.2146 [20.0 s]    dev=(HR@5:0.4351,NDCG@5:0.3172) [0.9 s] *
INFO:root:Epoch 23    loss=0.2153 [20.0 s]    dev=(HR@5:0.4265,NDCG@5:0.3133) [0.9 s]
INFO:root:Epoch 24    loss=0.2139 [19.9 s]    dev=(HR@5:0.4353,NDCG@5:0.3173) [0.9 s] *
INFO:root:Epoch 25    loss=0.2115 [19.9 s]    dev=(HR@5:0.4319,NDCG@5:0.3157) [0.9 s]
INFO:root:Epoch 26    loss=0.2122 [19.9 s]    dev=(HR@5:0.4316,NDCG@5:0.3156) [0.9 s]
INFO:root:Epoch 27    loss=0.2106 [20.0 s]    dev=(HR@5:0.4364,NDCG@5:0.3192) [0.9 s] *
INFO:root:Epoch 28    loss=0.2107 [19.9 s]    dev=(HR@5:0.4387,NDCG@5:0.3209) [0.9 s] *
INFO:root:Epoch 29    loss=0.2080 [19.9 s]    dev=(HR@5:0.4353,NDCG@5:0.3180) [0.9 s]
INFO:root:Epoch 30    loss=0.2077 [19.9 s]    dev=(HR@5:0.4338,NDCG@5:0.3184) [0.9 s]
INFO:root:Epoch 31    loss=0.2054 [19.9 s]    dev=(HR@5:0.4428,NDCG@5:0.3236) [0.9 s] *
INFO:root:Epoch 32    loss=0.2062 [20.0 s]    dev=(HR@5:0.4393,NDCG@5:0.3203) [0.9 s]
INFO:root:Epoch 33    loss=0.2051 [20.0 s]    dev=(HR@5:0.4387,NDCG@5:0.3211) [0.9 s]
INFO:root:Epoch 34    loss=0.2039 [19.9 s]    dev=(HR@5:0.4405,NDCG@5:0.3214) [0.9 s]
INFO:root:Epoch 35    loss=0.2037 [20.0 s]    dev=(HR@5:0.4404,NDCG@5:0.3204) [0.9 s]
INFO:root:Epoch 36    loss=0.2022 [20.0 s]    dev=(HR@5:0.4398,NDCG@5:0.3202) [0.9 s]
INFO:root:Epoch 37    loss=0.2022 [20.1 s]    dev=(HR@5:0.4436,NDCG@5:0.3225) [0.9 s]
INFO:root:Epoch 38    loss=0.2020 [19.9 s]    dev=(HR@5:0.4414,NDCG@5:0.3208) [0.9 s]
INFO:root:Epoch 39    loss=0.2020 [20.0 s]    dev=(HR@5:0.4360,NDCG@5:0.3169) [0.9 s]
INFO:root:Epoch 40    loss=0.2007 [20.0 s]    dev=(HR@5:0.4401,NDCG@5:0.3223) [0.9 s]
INFO:root:Epoch 41    loss=0.2023 [20.0 s]    dev=(HR@5:0.4368,NDCG@5:0.3167) [0.9 s]
INFO:root:Epoch 42    loss=0.2020 [20.0 s]    dev=(HR@5:0.4432,NDCG@5:0.3223) [0.9 s]
INFO:root:Epoch 43    loss=0.1984 [20.0 s]    dev=(HR@5:0.4404,NDCG@5:0.3230) [0.9 s]
INFO:root:Epoch 44    loss=0.2010 [19.9 s]    dev=(HR@5:0.4421,NDCG@5:0.3231) [0.9 s]
INFO:root:Epoch 45    loss=0.1967 [20.0 s]    dev=(HR@5:0.4442,NDCG@5:0.3256) [0.9 s] *
INFO:root:Epoch 46    loss=0.1983 [20.0 s]    dev=(HR@5:0.4408,NDCG@5:0.3204) [0.9 s]
INFO:root:Epoch 47    loss=0.1988 [19.9 s]    dev=(HR@5:0.4455,NDCG@5:0.3251) [0.9 s]
INFO:root:Epoch 48    loss=0.1980 [20.0 s]    dev=(HR@5:0.4413,NDCG@5:0.3221) [0.9 s]
INFO:root:Epoch 49    loss=0.1970 [19.9 s]    dev=(HR@5:0.4449,NDCG@5:0.3249) [0.9 s]
INFO:root:Epoch 50    loss=0.1981 [20.6 s]    dev=(HR@5:0.4384,NDCG@5:0.3210) [0.9 s]
INFO:root:Epoch 51    loss=0.1964 [19.9 s]    dev=(HR@5:0.4421,NDCG@5:0.3215) [0.9 s]
INFO:root:Epoch 52    loss=0.1968 [20.0 s]    dev=(HR@5:0.4440,NDCG@5:0.3218) [0.9 s]
INFO:root:Epoch 53    loss=0.1967 [20.0 s]    dev=(HR@5:0.4454,NDCG@5:0.3242) [0.9 s]
INFO:root:Epoch 54    loss=0.1951 [19.9 s]    dev=(HR@5:0.4460,NDCG@5:0.3257) [0.9 s] *
INFO:root:Epoch 55    loss=0.1947 [19.9 s]    dev=(HR@5:0.4445,NDCG@5:0.3232) [0.9 s]
INFO:root:Epoch 56    loss=0.1945 [20.1 s]    dev=(HR@5:0.4482,NDCG@5:0.3275) [0.9 s] *
INFO:root:Epoch 57    loss=0.1952 [19.9 s]    dev=(HR@5:0.4447,NDCG@5:0.3265) [0.9 s]
INFO:root:Epoch 58    loss=0.1959 [20.1 s]    dev=(HR@5:0.4471,NDCG@5:0.3274) [0.9 s]
INFO:root:Epoch 59    loss=0.1949 [20.0 s]    dev=(HR@5:0.4445,NDCG@5:0.3243) [0.9 s]
INFO:root:Epoch 60    loss=0.1956 [20.0 s]    dev=(HR@5:0.4412,NDCG@5:0.3232) [0.9 s]
INFO:root:Epoch 61    loss=0.1951 [20.1 s]    dev=(HR@5:0.4463,NDCG@5:0.3276) [0.9 s] *
INFO:root:Epoch 62    loss=0.1943 [19.9 s]    dev=(HR@5:0.4450,NDCG@5:0.3268) [0.9 s]
INFO:root:Epoch 63    loss=0.1948 [20.0 s]    dev=(HR@5:0.4484,NDCG@5:0.3282) [0.9 s] *
INFO:root:Epoch 64    loss=0.1935 [20.1 s]    dev=(HR@5:0.4435,NDCG@5:0.3242) [0.9 s]
INFO:root:Epoch 65    loss=0.1945 [20.1 s]    dev=(HR@5:0.4438,NDCG@5:0.3241) [0.9 s]
INFO:root:Epoch 66    loss=0.1925 [20.0 s]    dev=(HR@5:0.4438,NDCG@5:0.3236) [0.9 s]
INFO:root:Epoch 67    loss=0.1942 [20.1 s]    dev=(HR@5:0.4462,NDCG@5:0.3252) [0.9 s]
INFO:root:Epoch 68    loss=0.1916 [20.0 s]    dev=(HR@5:0.4447,NDCG@5:0.3249) [0.9 s]
INFO:root:Epoch 69    loss=0.1937 [20.0 s]    dev=(HR@5:0.4450,NDCG@5:0.3260) [0.9 s]
INFO:root:Epoch 70    loss=0.1931 [20.1 s]    dev=(HR@5:0.4475,NDCG@5:0.3287) [0.9 s] *
INFO:root:Epoch 71    loss=0.1927 [19.9 s]    dev=(HR@5:0.4449,NDCG@5:0.3275) [0.9 s]
INFO:root:Epoch 72    loss=0.1916 [20.0 s]    dev=(HR@5:0.4430,NDCG@5:0.3249) [0.9 s]
INFO:root:Epoch 73    loss=0.1923 [20.0 s]    dev=(HR@5:0.4453,NDCG@5:0.3268) [0.9 s]
INFO:root:Epoch 74    loss=0.1928 [20.0 s]    dev=(HR@5:0.4432,NDCG@5:0.3244) [0.9 s]
INFO:root:Epoch 75    loss=0.1943 [20.0 s]    dev=(HR@5:0.4444,NDCG@5:0.3258) [0.9 s]
INFO:root:Epoch 76    loss=0.1939 [20.0 s]    dev=(HR@5:0.4468,NDCG@5:0.3281) [0.9 s]
INFO:root:Epoch 77    loss=0.1920 [20.0 s]    dev=(HR@5:0.4464,NDCG@5:0.3280) [0.9 s]
INFO:root:Epoch 78    loss=0.1923 [20.0 s]    dev=(HR@5:0.4467,NDCG@5:0.3274) [0.9 s]
INFO:root:Epoch 79    loss=0.1925 [20.0 s]    dev=(HR@5:0.4504,NDCG@5:0.3298) [0.9 s] *
INFO:root:Epoch 80    loss=0.1916 [19.9 s]    dev=(HR@5:0.4480,NDCG@5:0.3279) [0.9 s]
INFO:root:Epoch 81    loss=0.1919 [20.0 s]    dev=(HR@5:0.4427,NDCG@5:0.3219) [0.9 s]
INFO:root:Epoch 82    loss=0.1937 [20.0 s]    dev=(HR@5:0.4447,NDCG@5:0.3268) [0.9 s]
INFO:root:Epoch 83    loss=0.1921 [20.0 s]    dev=(HR@5:0.4489,NDCG@5:0.3293) [0.9 s]
INFO:root:Epoch 84    loss=0.1921 [20.0 s]    dev=(HR@5:0.4474,NDCG@5:0.3276) [0.9 s]
INFO:root:Epoch 85    loss=0.1927 [20.0 s]    dev=(HR@5:0.4489,NDCG@5:0.3294) [0.9 s]
INFO:root:Epoch 86    loss=0.1934 [20.1 s]    dev=(HR@5:0.4419,NDCG@5:0.3240) [0.9 s]
INFO:root:Epoch 87    loss=0.1923 [19.9 s]    dev=(HR@5:0.4469,NDCG@5:0.3268) [0.9 s]
INFO:root:Epoch 88    loss=0.1926 [20.0 s]    dev=(HR@5:0.4456,NDCG@5:0.3252) [0.9 s]
INFO:root:Epoch 89    loss=0.1913 [20.0 s]    dev=(HR@5:0.4443,NDCG@5:0.3266) [0.9 s]
INFO:root:Epoch 90    loss=0.1913 [20.0 s]    dev=(HR@5:0.4481,NDCG@5:0.3291) [0.9 s]
INFO:root:Epoch 91    loss=0.1911 [20.0 s]    dev=(HR@5:0.4496,NDCG@5:0.3298) [0.9 s] *
INFO:root:Epoch 92    loss=0.1904 [20.0 s]    dev=(HR@5:0.4489,NDCG@5:0.3283) [0.9 s]
INFO:root:Epoch 93    loss=0.1917 [20.1 s]    dev=(HR@5:0.4449,NDCG@5:0.3250) [0.9 s]
INFO:root:Epoch 94    loss=0.1927 [19.9 s]    dev=(HR@5:0.4449,NDCG@5:0.3261) [0.9 s]
INFO:root:Epoch 95    loss=0.1915 [19.9 s]    dev=(HR@5:0.4541,NDCG@5:0.3306) [0.9 s] *
INFO:root:Epoch 96    loss=0.1906 [20.1 s]    dev=(HR@5:0.4466,NDCG@5:0.3277) [0.9 s]
INFO:root:Epoch 97    loss=0.1909 [20.0 s]    dev=(HR@5:0.4435,NDCG@5:0.3244) [0.9 s]
INFO:root:Epoch 98    loss=0.1902 [20.0 s]    dev=(HR@5:0.4436,NDCG@5:0.3233) [0.9 s]
INFO:root:Epoch 99    loss=0.1908 [20.0 s]    dev=(HR@5:0.4460,NDCG@5:0.3265) [0.9 s]
INFO:root:Epoch 100   loss=0.1908 [20.0 s]    dev=(HR@5:0.4507,NDCG@5:0.3298) [0.9 s]
INFO:root:Epoch 101   loss=0.1934 [20.1 s]    dev=(HR@5:0.4463,NDCG@5:0.3260) [0.9 s]
INFO:root:Epoch 102   loss=0.1925 [20.0 s]    dev=(HR@5:0.4465,NDCG@5:0.3278) [0.9 s]
INFO:root:Epoch 103   loss=0.1906 [20.0 s]    dev=(HR@5:0.4448,NDCG@5:0.3251) [0.9 s]
INFO:root:Epoch 104   loss=0.1915 [19.9 s]    dev=(HR@5:0.4444,NDCG@5:0.3240) [0.9 s]
INFO:root:Epoch 105   loss=0.1911 [19.9 s]    dev=(HR@5:0.4466,NDCG@5:0.3256) [0.9 s]
INFO:root:Epoch 106   loss=0.1909 [20.0 s]    dev=(HR@5:0.4458,NDCG@5:0.3244) [0.9 s]
INFO:root:Epoch 107   loss=0.1912 [20.0 s]    dev=(HR@5:0.4417,NDCG@5:0.3222) [0.9 s]
INFO:root:Epoch 108   loss=0.1908 [19.9 s]    dev=(HR@5:0.4434,NDCG@5:0.3232) [0.9 s]
INFO:root:Epoch 109   loss=0.1903 [19.9 s]    dev=(HR@5:0.4466,NDCG@5:0.3289) [0.9 s]
INFO:root:Epoch 110   loss=0.1896 [20.0 s]    dev=(HR@5:0.4436,NDCG@5:0.3273) [0.9 s]
INFO:root:Epoch 111   loss=0.1901 [20.1 s]    dev=(HR@5:0.4425,NDCG@5:0.3254) [0.9 s]
INFO:root:Epoch 112   loss=0.1925 [19.9 s]    dev=(HR@5:0.4413,NDCG@5:0.3246) [0.9 s]
INFO:root:Epoch 113   loss=0.1914 [19.9 s]    dev=(HR@5:0.4438,NDCG@5:0.3255) [0.9 s]
INFO:root:Epoch 114   loss=0.1896 [20.1 s]    dev=(HR@5:0.4418,NDCG@5:0.3222) [0.9 s]
INFO:root:Epoch 115   loss=0.1891 [19.9 s]    dev=(HR@5:0.4439,NDCG@5:0.3254) [0.9 s]
INFO:root:Early stop at 115 based on dev result.
INFO:root:
Best Iter(dev)=   95	 dev=(HR@5:0.4541,NDCG@5:0.3306) [2403.9 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.4010,NDCG@5:0.2870,HR@10:0.5080,NDCG@10:0.3216,HR@20:0.6297,NDCG@20:0.3523,HR@50:0.8339,NDCG@50:0.3928)
INFO:root:
--------------------------------------------- END: 2024-12-06 10:41:45 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 11:27:13 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5163 [22.0 s]    dev=(HR@5:0.2514,NDCG@5:0.1674) [0.9 s] *
INFO:root:Epoch 2     loss=0.4302 [20.1 s]    dev=(HR@5:0.3229,NDCG@5:0.2191) [0.9 s] *
INFO:root:Epoch 3     loss=0.3927 [20.1 s]    dev=(HR@5:0.3524,NDCG@5:0.2395) [0.9 s] *
INFO:root:Epoch 4     loss=0.3685 [20.0 s]    dev=(HR@5:0.3741,NDCG@5:0.2595) [0.9 s] *
INFO:root:Epoch 5     loss=0.3431 [19.9 s]    dev=(HR@5:0.3915,NDCG@5:0.2751) [0.9 s] *
INFO:root:Epoch 6     loss=0.3179 [20.0 s]    dev=(HR@5:0.4096,NDCG@5:0.2908) [0.9 s] *
INFO:root:Epoch 7     loss=0.2981 [20.0 s]    dev=(HR@5:0.4172,NDCG@5:0.2972) [0.9 s] *
INFO:root:Epoch 8     loss=0.2820 [20.3 s]    dev=(HR@5:0.4222,NDCG@5:0.3039) [0.9 s] *
INFO:root:Epoch 9     loss=0.2672 [20.2 s]    dev=(HR@5:0.4267,NDCG@5:0.3093) [0.9 s] *
INFO:root:Epoch 10    loss=0.2580 [20.1 s]    dev=(HR@5:0.4278,NDCG@5:0.3100) [0.9 s] *
INFO:root:Epoch 11    loss=0.2484 [20.1 s]    dev=(HR@5:0.4321,NDCG@5:0.3130) [0.9 s] *
INFO:root:Epoch 12    loss=0.2404 [20.1 s]    dev=(HR@5:0.4365,NDCG@5:0.3167) [0.9 s] *
INFO:root:Epoch 13    loss=0.2363 [20.1 s]    dev=(HR@5:0.4404,NDCG@5:0.3210) [0.9 s] *
INFO:root:Epoch 14    loss=0.2317 [20.0 s]    dev=(HR@5:0.4425,NDCG@5:0.3205) [0.9 s]
INFO:root:Epoch 15    loss=0.2285 [20.1 s]    dev=(HR@5:0.4406,NDCG@5:0.3185) [0.9 s]
INFO:root:Epoch 16    loss=0.2256 [20.0 s]    dev=(HR@5:0.4419,NDCG@5:0.3211) [0.9 s] *
INFO:root:Epoch 17    loss=0.2226 [20.2 s]    dev=(HR@5:0.4410,NDCG@5:0.3181) [0.9 s]
INFO:root:Epoch 18    loss=0.2180 [20.2 s]    dev=(HR@5:0.4438,NDCG@5:0.3231) [0.9 s] *
INFO:root:Epoch 19    loss=0.2165 [20.0 s]    dev=(HR@5:0.4436,NDCG@5:0.3236) [0.9 s] *
INFO:root:Epoch 20    loss=0.2138 [20.0 s]    dev=(HR@5:0.4459,NDCG@5:0.3273) [0.9 s] *
INFO:root:Epoch 21    loss=0.2108 [20.1 s]    dev=(HR@5:0.4419,NDCG@5:0.3244) [0.9 s]
INFO:root:Epoch 22    loss=0.2098 [20.1 s]    dev=(HR@5:0.4447,NDCG@5:0.3246) [0.9 s]
INFO:root:Epoch 23    loss=0.2104 [20.1 s]    dev=(HR@5:0.4416,NDCG@5:0.3242) [0.9 s]
INFO:root:Epoch 24    loss=0.2095 [20.1 s]    dev=(HR@5:0.4500,NDCG@5:0.3280) [0.9 s] *
INFO:root:Epoch 25    loss=0.2057 [20.2 s]    dev=(HR@5:0.4444,NDCG@5:0.3252) [0.9 s]
INFO:root:Epoch 26    loss=0.2061 [20.1 s]    dev=(HR@5:0.4475,NDCG@5:0.3263) [0.9 s]
INFO:root:Epoch 27    loss=0.2052 [20.2 s]    dev=(HR@5:0.4504,NDCG@5:0.3292) [0.9 s] *
INFO:root:Epoch 28    loss=0.2055 [20.0 s]    dev=(HR@5:0.4492,NDCG@5:0.3293) [0.9 s] *
INFO:root:Epoch 29    loss=0.2030 [20.1 s]    dev=(HR@5:0.4460,NDCG@5:0.3275) [0.9 s]
INFO:root:Epoch 30    loss=0.2018 [20.0 s]    dev=(HR@5:0.4423,NDCG@5:0.3233) [0.9 s]
INFO:root:Epoch 31    loss=0.2007 [20.1 s]    dev=(HR@5:0.4499,NDCG@5:0.3297) [0.9 s] *
INFO:root:Epoch 32    loss=0.2008 [20.0 s]    dev=(HR@5:0.4479,NDCG@5:0.3281) [0.9 s]
INFO:root:Epoch 33    loss=0.2006 [63.7 s]    dev=(HR@5:0.4485,NDCG@5:0.3295) [0.9 s]
INFO:root:Epoch 34    loss=0.1996 [20.1 s]    dev=(HR@5:0.4456,NDCG@5:0.3258) [0.9 s]
INFO:root:Epoch 35    loss=0.2006 [20.1 s]    dev=(HR@5:0.4420,NDCG@5:0.3231) [0.9 s]
INFO:root:Epoch 36    loss=0.1978 [20.1 s]    dev=(HR@5:0.4423,NDCG@5:0.3225) [0.9 s]
INFO:root:Epoch 37    loss=0.1989 [20.1 s]    dev=(HR@5:0.4480,NDCG@5:0.3269) [0.9 s]
INFO:root:Epoch 38    loss=0.1972 [20.2 s]    dev=(HR@5:0.4468,NDCG@5:0.3257) [0.9 s]
INFO:root:Epoch 39    loss=0.1984 [20.1 s]    dev=(HR@5:0.4415,NDCG@5:0.3209) [0.9 s]
INFO:root:Epoch 40    loss=0.1981 [20.1 s]    dev=(HR@5:0.4421,NDCG@5:0.3228) [0.9 s]
INFO:root:Epoch 41    loss=0.1983 [20.2 s]    dev=(HR@5:0.4426,NDCG@5:0.3230) [0.9 s]
INFO:root:Epoch 42    loss=0.1976 [20.2 s]    dev=(HR@5:0.4459,NDCG@5:0.3254) [0.9 s]
INFO:root:Epoch 43    loss=0.1963 [20.1 s]    dev=(HR@5:0.4499,NDCG@5:0.3288) [0.9 s]
INFO:root:Epoch 44    loss=0.1978 [20.1 s]    dev=(HR@5:0.4449,NDCG@5:0.3243) [0.9 s]
INFO:root:Epoch 45    loss=0.1948 [20.0 s]    dev=(HR@5:0.4503,NDCG@5:0.3291) [0.9 s]
INFO:root:Epoch 46    loss=0.1960 [20.2 s]    dev=(HR@5:0.4438,NDCG@5:0.3241) [0.9 s]
INFO:root:Epoch 47    loss=0.1964 [20.2 s]    dev=(HR@5:0.4448,NDCG@5:0.3245) [0.9 s]
INFO:root:Epoch 48    loss=0.1961 [20.1 s]    dev=(HR@5:0.4390,NDCG@5:0.3199) [0.9 s]
INFO:root:Epoch 49    loss=0.1944 [20.2 s]    dev=(HR@5:0.4490,NDCG@5:0.3290) [0.9 s]
INFO:root:Epoch 50    loss=0.1961 [20.5 s]    dev=(HR@5:0.4434,NDCG@5:0.3247) [0.9 s]
INFO:root:Epoch 51    loss=0.1941 [19.8 s]    dev=(HR@5:0.4502,NDCG@5:0.3291) [0.9 s]
INFO:root:Early stop at 51 based on dev result.
INFO:root:
Best Iter(dev)=   31	 dev=(HR@5:0.4499,NDCG@5:0.3297) [1116.7 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.3992,NDCG@5:0.2835,HR@10:0.5106,NDCG@10:0.3195,HR@20:0.6295,NDCG@20:0.3494,HR@50:0.8350,NDCG@50:0.3902)
INFO:root:
--------------------------------------------- END: 2024-12-06 11:45:52 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 12:34:28 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [28.3 s]    dev=(HR@5:0.2530,NDCG@5:0.1688) [1.0 s] *
INFO:root:Epoch 2     loss=0.4284 [21.4 s]    dev=(HR@5:0.3289,NDCG@5:0.2236) [0.9 s] *
INFO:root:Epoch 3     loss=0.3896 [19.9 s]    dev=(HR@5:0.3608,NDCG@5:0.2480) [0.9 s] *
INFO:root:Epoch 4     loss=0.3643 [20.3 s]    dev=(HR@5:0.3829,NDCG@5:0.2669) [1.0 s] *
INFO:root:Epoch 5     loss=0.3397 [20.7 s]    dev=(HR@5:0.3979,NDCG@5:0.2820) [0.9 s] *
INFO:root:Epoch 6     loss=0.3151 [20.5 s]    dev=(HR@5:0.4152,NDCG@5:0.2986) [1.0 s] *
INFO:root:Epoch 7     loss=0.2958 [20.7 s]    dev=(HR@5:0.4230,NDCG@5:0.3028) [1.0 s] *
INFO:root:Epoch 8     loss=0.2801 [21.2 s]    dev=(HR@5:0.4324,NDCG@5:0.3117) [0.9 s] *
INFO:root:Epoch 9     loss=0.2656 [21.0 s]    dev=(HR@5:0.4348,NDCG@5:0.3149) [0.9 s] *
INFO:root:Epoch 10    loss=0.2563 [20.3 s]    dev=(HR@5:0.4342,NDCG@5:0.3155) [0.9 s] *
INFO:root:Epoch 11    loss=0.2474 [20.4 s]    dev=(HR@5:0.4394,NDCG@5:0.3186) [0.9 s] *
INFO:root:Epoch 12    loss=0.2393 [20.7 s]    dev=(HR@5:0.4387,NDCG@5:0.3203) [0.9 s] *
INFO:root:Epoch 13    loss=0.2353 [20.4 s]    dev=(HR@5:0.4451,NDCG@5:0.3252) [0.9 s] *
INFO:root:Epoch 14    loss=0.2300 [20.4 s]    dev=(HR@5:0.4453,NDCG@5:0.3243) [0.9 s]
INFO:root:Epoch 15    loss=0.2273 [20.3 s]    dev=(HR@5:0.4431,NDCG@5:0.3219) [0.9 s]
INFO:root:Epoch 16    loss=0.2251 [20.7 s]    dev=(HR@5:0.4457,NDCG@5:0.3250) [0.9 s]
INFO:root:Epoch 17    loss=0.2217 [22.6 s]    dev=(HR@5:0.4451,NDCG@5:0.3231) [1.0 s]
INFO:root:Epoch 18    loss=0.2175 [21.2 s]    dev=(HR@5:0.4520,NDCG@5:0.3305) [0.9 s] *
INFO:root:Epoch 19    loss=0.2159 [79.1 s]    dev=(HR@5:0.4477,NDCG@5:0.3288) [0.9 s]
INFO:root:Epoch 20    loss=0.2130 [21.1 s]    dev=(HR@5:0.4499,NDCG@5:0.3313) [0.9 s] *
INFO:root:Epoch 21    loss=0.2098 [20.7 s]    dev=(HR@5:0.4502,NDCG@5:0.3290) [0.9 s]
INFO:root:Epoch 22    loss=0.2095 [20.4 s]    dev=(HR@5:0.4495,NDCG@5:0.3287) [1.0 s]
INFO:root:Epoch 23    loss=0.2099 [20.6 s]    dev=(HR@5:0.4497,NDCG@5:0.3296) [1.0 s]
INFO:root:Epoch 24    loss=0.2094 [20.5 s]    dev=(HR@5:0.4520,NDCG@5:0.3304) [0.9 s]
INFO:root:Epoch 25    loss=0.2061 [20.3 s]    dev=(HR@5:0.4513,NDCG@5:0.3299) [0.9 s]
INFO:root:Epoch 26    loss=0.2064 [20.3 s]    dev=(HR@5:0.4510,NDCG@5:0.3304) [0.9 s]
INFO:root:Epoch 27    loss=0.2056 [20.3 s]    dev=(HR@5:0.4527,NDCG@5:0.3322) [0.9 s] *
INFO:root:Epoch 28    loss=0.2065 [20.7 s]    dev=(HR@5:0.4540,NDCG@5:0.3332) [0.9 s] *
INFO:root:Epoch 29    loss=0.2040 [20.5 s]    dev=(HR@5:0.4545,NDCG@5:0.3327) [0.9 s]
INFO:root:Epoch 30    loss=0.2024 [20.5 s]    dev=(HR@5:0.4503,NDCG@5:0.3309) [0.9 s]
INFO:root:Epoch 31    loss=0.2020 [20.6 s]    dev=(HR@5:0.4549,NDCG@5:0.3348) [0.9 s] *
INFO:root:Epoch 32    loss=0.2021 [20.3 s]    dev=(HR@5:0.4544,NDCG@5:0.3325) [0.9 s]
INFO:root:Epoch 33    loss=0.2020 [20.2 s]    dev=(HR@5:0.4546,NDCG@5:0.3344) [0.9 s]
INFO:root:Epoch 34    loss=0.2012 [20.8 s]    dev=(HR@5:0.4526,NDCG@5:0.3320) [1.0 s]
INFO:root:Epoch 35    loss=0.2022 [20.7 s]    dev=(HR@5:0.4505,NDCG@5:0.3313) [0.9 s]
INFO:root:Epoch 36    loss=0.1992 [20.4 s]    dev=(HR@5:0.4541,NDCG@5:0.3309) [0.9 s]
INFO:root:Epoch 37    loss=0.1993 [20.3 s]    dev=(HR@5:0.4530,NDCG@5:0.3305) [0.9 s]
INFO:root:Epoch 38    loss=0.1993 [20.1 s]    dev=(HR@5:0.4545,NDCG@5:0.3324) [0.9 s]
INFO:root:Epoch 39    loss=0.1991 [19.9 s]    dev=(HR@5:0.4470,NDCG@5:0.3262) [0.9 s]
INFO:root:Epoch 40    loss=0.1988 [20.0 s]    dev=(HR@5:0.4513,NDCG@5:0.3289) [0.9 s]
INFO:root:Epoch 41    loss=0.1990 [20.1 s]    dev=(HR@5:0.4485,NDCG@5:0.3272) [0.9 s]
INFO:root:Epoch 42    loss=0.1983 [20.2 s]    dev=(HR@5:0.4523,NDCG@5:0.3314) [0.9 s]
INFO:root:Epoch 43    loss=0.1967 [20.3 s]    dev=(HR@5:0.4519,NDCG@5:0.3320) [0.9 s]
INFO:root:Epoch 44    loss=0.1976 [20.1 s]    dev=(HR@5:0.4471,NDCG@5:0.3289) [0.9 s]
INFO:root:Epoch 45    loss=0.1944 [20.0 s]    dev=(HR@5:0.4549,NDCG@5:0.3349) [0.9 s] *
INFO:root:Epoch 46    loss=0.1956 [20.1 s]    dev=(HR@5:0.4486,NDCG@5:0.3299) [0.9 s]
INFO:root:Epoch 47    loss=0.1952 [20.5 s]    dev=(HR@5:0.4510,NDCG@5:0.3302) [0.9 s]
INFO:root:Epoch 48    loss=0.1948 [20.2 s]    dev=(HR@5:0.4478,NDCG@5:0.3273) [0.9 s]
INFO:root:Epoch 49    loss=0.1938 [20.3 s]    dev=(HR@5:0.4536,NDCG@5:0.3343) [0.9 s]
INFO:root:Epoch 50    loss=0.1952 [20.2 s]    dev=(HR@5:0.4482,NDCG@5:0.3287) [0.9 s]
INFO:root:Epoch 51    loss=0.1936 [20.2 s]    dev=(HR@5:0.4508,NDCG@5:0.3293) [0.9 s]
INFO:root:Epoch 52    loss=0.1942 [20.4 s]    dev=(HR@5:0.4521,NDCG@5:0.3309) [0.9 s]
INFO:root:Epoch 53    loss=0.1944 [20.1 s]    dev=(HR@5:0.4481,NDCG@5:0.3296) [0.9 s]
INFO:root:Epoch 54    loss=0.1930 [20.1 s]    dev=(HR@5:0.4486,NDCG@5:0.3288) [0.9 s]
INFO:root:Epoch 55    loss=0.1929 [20.2 s]    dev=(HR@5:0.4507,NDCG@5:0.3297) [0.9 s]
INFO:root:Epoch 56    loss=0.1925 [20.1 s]    dev=(HR@5:0.4525,NDCG@5:0.3329) [0.9 s]
INFO:root:Epoch 57    loss=0.1932 [20.2 s]    dev=(HR@5:0.4470,NDCG@5:0.3294) [0.9 s]
INFO:root:Epoch 58    loss=0.1938 [20.2 s]    dev=(HR@5:0.4498,NDCG@5:0.3314) [0.9 s]
INFO:root:Epoch 59    loss=0.1929 [20.1 s]    dev=(HR@5:0.4489,NDCG@5:0.3302) [0.9 s]
INFO:root:Epoch 60    loss=0.1926 [20.2 s]    dev=(HR@5:0.4492,NDCG@5:0.3293) [0.9 s]
INFO:root:Epoch 61    loss=0.1929 [20.2 s]    dev=(HR@5:0.4520,NDCG@5:0.3308) [0.9 s]
INFO:root:Epoch 62    loss=0.1927 [20.1 s]    dev=(HR@5:0.4526,NDCG@5:0.3328) [0.9 s]
INFO:root:Epoch 63    loss=0.1937 [20.2 s]    dev=(HR@5:0.4528,NDCG@5:0.3325) [0.9 s]
INFO:root:Epoch 64    loss=0.1920 [20.5 s]    dev=(HR@5:0.4488,NDCG@5:0.3291) [0.9 s]
INFO:root:Epoch 65    loss=0.1926 [20.2 s]    dev=(HR@5:0.4470,NDCG@5:0.3268) [0.9 s]
INFO:root:Early stop at 65 based on dev result.
INFO:root:
Best Iter(dev)=   45	 dev=(HR@5:0.4549,NDCG@5:0.3349) [1454.5 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.4085,NDCG@5:0.2924,HR@10:0.5173,NDCG@10:0.3276,HR@20:0.6400,NDCG@20:0.3585,HR@50:0.8398,NDCG@50:0.3981)
INFO:root:
--------------------------------------------- END: 2024-12-06 12:58:45 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 13:32:58 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5165 [21.8 s]    dev=(HR@5:0.2545,NDCG@5:0.1699) [0.9 s] *
INFO:root:Epoch 2     loss=0.4277 [19.8 s]    dev=(HR@5:0.3300,NDCG@5:0.2246) [0.9 s] *
INFO:root:Epoch 3     loss=0.3899 [19.9 s]    dev=(HR@5:0.3588,NDCG@5:0.2449) [0.9 s] *
INFO:root:Epoch 4     loss=0.3649 [19.7 s]    dev=(HR@5:0.3822,NDCG@5:0.2654) [0.9 s] *
INFO:root:Epoch 5     loss=0.3389 [19.7 s]    dev=(HR@5:0.4016,NDCG@5:0.2834) [0.9 s] *
INFO:root:Epoch 6     loss=0.3134 [19.6 s]    dev=(HR@5:0.4163,NDCG@5:0.2991) [0.9 s] *
INFO:root:Epoch 7     loss=0.2948 [19.7 s]    dev=(HR@5:0.4229,NDCG@5:0.3026) [0.9 s] *
INFO:root:Epoch 8     loss=0.2812 [19.8 s]    dev=(HR@5:0.4282,NDCG@5:0.3092) [0.9 s] *
INFO:root:Epoch 9     loss=0.2685 [19.8 s]    dev=(HR@5:0.4297,NDCG@5:0.3113) [0.9 s] *
INFO:root:Epoch 10    loss=0.2604 [19.7 s]    dev=(HR@5:0.4299,NDCG@5:0.3127) [0.9 s] *
INFO:root:Epoch 11    loss=0.2522 [19.6 s]    dev=(HR@5:0.4338,NDCG@5:0.3138) [0.9 s] *
INFO:root:Epoch 12    loss=0.2460 [19.8 s]    dev=(HR@5:0.4353,NDCG@5:0.3161) [0.9 s] *
INFO:root:Epoch 13    loss=0.2428 [19.7 s]    dev=(HR@5:0.4394,NDCG@5:0.3201) [0.9 s] *
INFO:root:Epoch 14    loss=0.2382 [19.7 s]    dev=(HR@5:0.4393,NDCG@5:0.3188) [0.9 s]
INFO:root:Epoch 15    loss=0.2356 [19.8 s]    dev=(HR@5:0.4378,NDCG@5:0.3174) [0.9 s]
INFO:root:Epoch 16    loss=0.2340 [19.7 s]    dev=(HR@5:0.4398,NDCG@5:0.3207) [0.9 s] *
INFO:root:Epoch 17    loss=0.2310 [19.7 s]    dev=(HR@5:0.4361,NDCG@5:0.3169) [0.9 s]
INFO:root:Epoch 18    loss=0.2268 [19.7 s]    dev=(HR@5:0.4408,NDCG@5:0.3222) [0.9 s] *
INFO:root:Epoch 19    loss=0.2258 [19.8 s]    dev=(HR@5:0.4385,NDCG@5:0.3200) [0.9 s]
INFO:root:Epoch 20    loss=0.2228 [19.7 s]    dev=(HR@5:0.4404,NDCG@5:0.3231) [0.9 s] *
INFO:root:Epoch 21    loss=0.2191 [19.7 s]    dev=(HR@5:0.4400,NDCG@5:0.3219) [0.9 s]
INFO:root:Epoch 22    loss=0.2196 [19.7 s]    dev=(HR@5:0.4397,NDCG@5:0.3229) [0.9 s]
INFO:root:Epoch 23    loss=0.2203 [19.8 s]    dev=(HR@5:0.4370,NDCG@5:0.3206) [0.9 s]
INFO:root:Epoch 24    loss=0.2197 [19.6 s]    dev=(HR@5:0.4403,NDCG@5:0.3213) [0.9 s]
INFO:root:Epoch 25    loss=0.2162 [19.6 s]    dev=(HR@5:0.4379,NDCG@5:0.3203) [0.9 s]
INFO:root:Epoch 26    loss=0.2169 [19.7 s]    dev=(HR@5:0.4411,NDCG@5:0.3219) [0.9 s]
INFO:root:Epoch 27    loss=0.2171 [19.7 s]    dev=(HR@5:0.4405,NDCG@5:0.3229) [0.9 s]
INFO:root:Epoch 28    loss=0.2165 [19.6 s]    dev=(HR@5:0.4423,NDCG@5:0.3249) [0.9 s] *
INFO:root:Epoch 29    loss=0.2144 [19.6 s]    dev=(HR@5:0.4417,NDCG@5:0.3235) [0.9 s]
INFO:root:Epoch 30    loss=0.2143 [19.7 s]    dev=(HR@5:0.4399,NDCG@5:0.3216) [0.9 s]
INFO:root:Epoch 31    loss=0.2137 [19.7 s]    dev=(HR@5:0.4430,NDCG@5:0.3249) [0.9 s] *
INFO:root:Epoch 32    loss=0.2139 [19.8 s]    dev=(HR@5:0.4366,NDCG@5:0.3189) [0.9 s]
INFO:root:Epoch 33    loss=0.2135 [19.9 s]    dev=(HR@5:0.4410,NDCG@5:0.3226) [0.9 s]
INFO:root:Epoch 34    loss=0.2132 [19.8 s]    dev=(HR@5:0.4427,NDCG@5:0.3246) [0.9 s]
INFO:root:Epoch 35    loss=0.2135 [19.7 s]    dev=(HR@5:0.4349,NDCG@5:0.3174) [0.9 s]
INFO:root:Epoch 36    loss=0.2105 [19.6 s]    dev=(HR@5:0.4387,NDCG@5:0.3207) [0.9 s]
INFO:root:Epoch 37    loss=0.2123 [19.7 s]    dev=(HR@5:0.4379,NDCG@5:0.3197) [0.9 s]
INFO:root:Epoch 38    loss=0.2127 [19.7 s]    dev=(HR@5:0.4424,NDCG@5:0.3227) [0.9 s]
INFO:root:Epoch 39    loss=0.2130 [19.8 s]    dev=(HR@5:0.4361,NDCG@5:0.3173) [0.9 s]
INFO:root:Epoch 40    loss=0.2122 [19.7 s]    dev=(HR@5:0.4393,NDCG@5:0.3199) [0.9 s]
INFO:root:Epoch 41    loss=0.2126 [19.7 s]    dev=(HR@5:0.4306,NDCG@5:0.3144) [0.9 s]
INFO:root:Epoch 42    loss=0.2120 [19.7 s]    dev=(HR@5:0.4398,NDCG@5:0.3200) [0.9 s]
INFO:root:Epoch 43    loss=0.2104 [19.8 s]    dev=(HR@5:0.4421,NDCG@5:0.3235) [0.9 s]
INFO:root:Epoch 44    loss=0.2116 [19.8 s]    dev=(HR@5:0.4385,NDCG@5:0.3182) [0.9 s]
INFO:root:Epoch 45    loss=0.2091 [19.7 s]    dev=(HR@5:0.4403,NDCG@5:0.3229) [0.9 s]
INFO:root:Epoch 46    loss=0.2100 [19.8 s]    dev=(HR@5:0.4359,NDCG@5:0.3200) [0.9 s]
INFO:root:Epoch 47    loss=0.2098 [19.8 s]    dev=(HR@5:0.4405,NDCG@5:0.3212) [0.9 s]
INFO:root:Epoch 48    loss=0.2101 [19.8 s]    dev=(HR@5:0.4361,NDCG@5:0.3175) [0.9 s]
INFO:root:Epoch 49    loss=0.2088 [19.7 s]    dev=(HR@5:0.4426,NDCG@5:0.3222) [0.9 s]
INFO:root:Epoch 50    loss=0.2101 [19.8 s]    dev=(HR@5:0.4395,NDCG@5:0.3215) [0.9 s]
INFO:root:Epoch 51    loss=0.2092 [19.7 s]    dev=(HR@5:0.4407,NDCG@5:0.3230) [0.9 s]
INFO:root:Early stop at 51 based on dev result.
INFO:root:
Best Iter(dev)=   31	 dev=(HR@5:0.4430,NDCG@5:0.3249) [1053.9 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.3939,NDCG@5:0.2811,HR@10:0.5041,NDCG@10:0.3167,HR@20:0.6254,NDCG@20:0.3472,HR@50:0.8390,NDCG@50:0.3896)
INFO:root:
--------------------------------------------- END: 2024-12-06 13:50:34 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 14:32:25 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5165 [22.1 s]    dev=(HR@5:0.2558,NDCG@5:0.1709) [0.9 s] *
INFO:root:Epoch 2     loss=0.4269 [20.1 s]    dev=(HR@5:0.3316,NDCG@5:0.2258) [0.9 s] *
INFO:root:Epoch 3     loss=0.3879 [20.2 s]    dev=(HR@5:0.3638,NDCG@5:0.2493) [0.9 s] *
INFO:root:Epoch 4     loss=0.3620 [20.2 s]    dev=(HR@5:0.3885,NDCG@5:0.2692) [0.9 s] *
INFO:root:Epoch 5     loss=0.3348 [20.7 s]    dev=(HR@5:0.4070,NDCG@5:0.2883) [0.9 s] *
INFO:root:Epoch 6     loss=0.3091 [20.4 s]    dev=(HR@5:0.4203,NDCG@5:0.3023) [0.9 s] *
INFO:root:Epoch 7     loss=0.2917 [20.1 s]    dev=(HR@5:0.4261,NDCG@5:0.3066) [0.9 s] *
INFO:root:Epoch 8     loss=0.2784 [20.3 s]    dev=(HR@5:0.4309,NDCG@5:0.3123) [0.9 s] *
INFO:root:Epoch 9     loss=0.2660 [20.1 s]    dev=(HR@5:0.4341,NDCG@5:0.3163) [0.9 s] *
INFO:root:Epoch 10    loss=0.2573 [20.2 s]    dev=(HR@5:0.4328,NDCG@5:0.3161) [0.9 s]
INFO:root:Epoch 11    loss=0.2484 [20.3 s]    dev=(HR@5:0.4386,NDCG@5:0.3194) [0.9 s] *
INFO:root:Epoch 12    loss=0.2411 [20.1 s]    dev=(HR@5:0.4439,NDCG@5:0.3231) [0.9 s] *
INFO:root:Epoch 13    loss=0.2374 [20.2 s]    dev=(HR@5:0.4456,NDCG@5:0.3273) [0.9 s] *
INFO:root:Epoch 14    loss=0.2327 [20.3 s]    dev=(HR@5:0.4474,NDCG@5:0.3262) [0.9 s]
INFO:root:Epoch 15    loss=0.2292 [20.2 s]    dev=(HR@5:0.4442,NDCG@5:0.3253) [0.9 s]
INFO:root:Epoch 16    loss=0.2277 [20.2 s]    dev=(HR@5:0.4425,NDCG@5:0.3251) [0.9 s]
INFO:root:Epoch 17    loss=0.2238 [20.2 s]    dev=(HR@5:0.4426,NDCG@5:0.3239) [0.9 s]
INFO:root:Epoch 18    loss=0.2192 [20.2 s]    dev=(HR@5:0.4466,NDCG@5:0.3277) [0.9 s] *
INFO:root:Epoch 19    loss=0.2184 [20.2 s]    dev=(HR@5:0.4439,NDCG@5:0.3260) [0.9 s]
INFO:root:Epoch 20    loss=0.2156 [20.1 s]    dev=(HR@5:0.4453,NDCG@5:0.3303) [0.9 s] *
INFO:root:Epoch 21    loss=0.2119 [20.3 s]    dev=(HR@5:0.4434,NDCG@5:0.3283) [0.9 s]
INFO:root:Epoch 22    loss=0.2122 [20.2 s]    dev=(HR@5:0.4442,NDCG@5:0.3281) [0.9 s]
INFO:root:Epoch 23    loss=0.2129 [20.2 s]    dev=(HR@5:0.4434,NDCG@5:0.3274) [0.9 s]
INFO:root:Epoch 24    loss=0.2117 [20.2 s]    dev=(HR@5:0.4450,NDCG@5:0.3278) [0.9 s]
INFO:root:Epoch 25    loss=0.2085 [20.2 s]    dev=(HR@5:0.4431,NDCG@5:0.3271) [0.9 s]
INFO:root:Epoch 26    loss=0.2087 [20.2 s]    dev=(HR@5:0.4440,NDCG@5:0.3269) [0.9 s]
INFO:root:Epoch 27    loss=0.2092 [20.2 s]    dev=(HR@5:0.4434,NDCG@5:0.3291) [0.9 s]
INFO:root:Epoch 28    loss=0.2083 [20.2 s]    dev=(HR@5:0.4464,NDCG@5:0.3308) [0.9 s] *
INFO:root:Epoch 29    loss=0.2069 [20.3 s]    dev=(HR@5:0.4465,NDCG@5:0.3294) [0.9 s]
INFO:root:Epoch 30    loss=0.2061 [20.3 s]    dev=(HR@5:0.4421,NDCG@5:0.3270) [0.9 s]
INFO:root:Epoch 31    loss=0.2049 [20.2 s]    dev=(HR@5:0.4479,NDCG@5:0.3324) [0.9 s] *
INFO:root:Epoch 32    loss=0.2055 [20.3 s]    dev=(HR@5:0.4412,NDCG@5:0.3274) [0.9 s]
INFO:root:Epoch 33    loss=0.2051 [20.2 s]    dev=(HR@5:0.4464,NDCG@5:0.3298) [0.9 s]
INFO:root:Epoch 34    loss=0.2047 [20.2 s]    dev=(HR@5:0.4499,NDCG@5:0.3314) [0.9 s]
INFO:root:Epoch 35    loss=0.2057 [20.2 s]    dev=(HR@5:0.4447,NDCG@5:0.3274) [0.9 s]
INFO:root:Epoch 36    loss=0.2030 [20.2 s]    dev=(HR@5:0.4471,NDCG@5:0.3278) [0.9 s]
INFO:root:Epoch 37    loss=0.2033 [20.2 s]    dev=(HR@5:0.4436,NDCG@5:0.3258) [0.9 s]
INFO:root:Epoch 38    loss=0.2047 [20.2 s]    dev=(HR@5:0.4477,NDCG@5:0.3286) [0.9 s]
INFO:root:Epoch 39    loss=0.2047 [20.1 s]    dev=(HR@5:0.4382,NDCG@5:0.3220) [0.9 s]
INFO:root:Epoch 40    loss=0.2036 [20.2 s]    dev=(HR@5:0.4432,NDCG@5:0.3254) [0.9 s]
INFO:root:Epoch 41    loss=0.2040 [20.1 s]    dev=(HR@5:0.4416,NDCG@5:0.3230) [0.9 s]
INFO:root:Epoch 42    loss=0.2034 [20.2 s]    dev=(HR@5:0.4472,NDCG@5:0.3272) [0.9 s]
INFO:root:Epoch 43    loss=0.2016 [20.2 s]    dev=(HR@5:0.4479,NDCG@5:0.3293) [0.9 s]
INFO:root:Epoch 44    loss=0.2036 [20.2 s]    dev=(HR@5:0.4423,NDCG@5:0.3250) [0.9 s]
INFO:root:Epoch 45    loss=0.2001 [20.2 s]    dev=(HR@5:0.4489,NDCG@5:0.3310) [0.9 s]
INFO:root:Epoch 46    loss=0.2020 [20.2 s]    dev=(HR@5:0.4447,NDCG@5:0.3272) [0.9 s]
INFO:root:Epoch 47    loss=0.2025 [20.2 s]    dev=(HR@5:0.4465,NDCG@5:0.3277) [0.9 s]
INFO:root:Epoch 48    loss=0.2015 [20.3 s]    dev=(HR@5:0.4429,NDCG@5:0.3242) [0.9 s]
INFO:root:Epoch 49    loss=0.2011 [53.3 s]    dev=(HR@5:0.4479,NDCG@5:0.3292) [0.9 s]
INFO:root:Epoch 50    loss=0.2024 [20.3 s]    dev=(HR@5:0.4426,NDCG@5:0.3266) [0.9 s]
INFO:root:Epoch 51    loss=0.2014 [20.2 s]    dev=(HR@5:0.4465,NDCG@5:0.3304) [0.9 s]
INFO:root:Early stop at 51 based on dev result.
INFO:root:
Best Iter(dev)=   31	 dev=(HR@5:0.4479,NDCG@5:0.3324) [1112.4 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.4002,NDCG@5:0.2879,HR@10:0.5031,NDCG@10:0.3212,HR@20:0.6280,NDCG@20:0.3527,HR@50:0.8346,NDCG@50:0.3936)
INFO:root:
--------------------------------------------- END: 2024-12-06 14:50:59 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 15:37:41 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5151 [22.4 s]    dev=(HR@5:0.2522,NDCG@5:0.1680) [0.9 s] *
INFO:root:Epoch 2     loss=0.4312 [20.2 s]    dev=(HR@5:0.3197,NDCG@5:0.2160) [0.9 s] *
INFO:root:Epoch 3     loss=0.3972 [20.2 s]    dev=(HR@5:0.3428,NDCG@5:0.2299) [0.9 s] *
INFO:root:Epoch 4     loss=0.3764 [20.3 s]    dev=(HR@5:0.3589,NDCG@5:0.2454) [0.9 s] *
INFO:root:Epoch 5     loss=0.3537 [20.1 s]    dev=(HR@5:0.3772,NDCG@5:0.2632) [0.9 s] *
INFO:root:Epoch 6     loss=0.3310 [20.2 s]    dev=(HR@5:0.3919,NDCG@5:0.2781) [0.9 s] *
INFO:root:Epoch 7     loss=0.3120 [20.2 s]    dev=(HR@5:0.3981,NDCG@5:0.2834) [0.9 s] *
INFO:root:Epoch 8     loss=0.2967 [20.1 s]    dev=(HR@5:0.4040,NDCG@5:0.2883) [0.9 s] *
INFO:root:Epoch 9     loss=0.2808 [20.2 s]    dev=(HR@5:0.4062,NDCG@5:0.2914) [0.9 s] *
INFO:root:Epoch 10    loss=0.2704 [20.2 s]    dev=(HR@5:0.4097,NDCG@5:0.2956) [0.9 s] *
INFO:root:Epoch 11    loss=0.2605 [20.2 s]    dev=(HR@5:0.4141,NDCG@5:0.2985) [0.9 s] *
INFO:root:Epoch 12    loss=0.2502 [20.3 s]    dev=(HR@5:0.4216,NDCG@5:0.3047) [0.9 s] *
INFO:root:Epoch 13    loss=0.2466 [20.2 s]    dev=(HR@5:0.4227,NDCG@5:0.3062) [0.9 s] *
INFO:root:Epoch 14    loss=0.2415 [20.2 s]    dev=(HR@5:0.4221,NDCG@5:0.3047) [0.9 s]
INFO:root:Epoch 15    loss=0.2376 [20.2 s]    dev=(HR@5:0.4205,NDCG@5:0.3043) [0.9 s]
INFO:root:Epoch 16    loss=0.2340 [20.1 s]    dev=(HR@5:0.4218,NDCG@5:0.3068) [0.9 s] *
INFO:root:Epoch 17    loss=0.2299 [20.3 s]    dev=(HR@5:0.4246,NDCG@5:0.3083) [0.9 s] *
INFO:root:Epoch 18    loss=0.2252 [20.2 s]    dev=(HR@5:0.4242,NDCG@5:0.3078) [0.9 s]
INFO:root:Epoch 19    loss=0.2229 [20.3 s]    dev=(HR@5:0.4287,NDCG@5:0.3136) [0.9 s] *
INFO:root:Epoch 20    loss=0.2207 [20.2 s]    dev=(HR@5:0.4305,NDCG@5:0.3138) [0.9 s] *
INFO:root:Epoch 21    loss=0.2170 [20.2 s]    dev=(HR@5:0.4350,NDCG@5:0.3170) [0.9 s] *
INFO:root:Epoch 22    loss=0.2155 [20.3 s]    dev=(HR@5:0.4337,NDCG@5:0.3164) [0.9 s]
INFO:root:Epoch 23    loss=0.2160 [20.2 s]    dev=(HR@5:0.4261,NDCG@5:0.3125) [0.9 s]
INFO:root:Epoch 24    loss=0.2141 [20.2 s]    dev=(HR@5:0.4374,NDCG@5:0.3189) [0.9 s] *
INFO:root:Epoch 25    loss=0.2112 [20.2 s]    dev=(HR@5:0.4304,NDCG@5:0.3155) [0.9 s]
INFO:root:Epoch 26    loss=0.2117 [20.2 s]    dev=(HR@5:0.4351,NDCG@5:0.3190) [0.9 s] *
INFO:root:Epoch 27    loss=0.2101 [20.3 s]    dev=(HR@5:0.4365,NDCG@5:0.3208) [0.9 s] *
INFO:root:Epoch 28    loss=0.2099 [20.2 s]    dev=(HR@5:0.4348,NDCG@5:0.3201) [0.9 s]
INFO:root:Epoch 29    loss=0.2082 [20.2 s]    dev=(HR@5:0.4333,NDCG@5:0.3172) [0.9 s]
INFO:root:Epoch 30    loss=0.2070 [20.3 s]    dev=(HR@5:0.4361,NDCG@5:0.3200) [0.9 s]
INFO:root:Epoch 31    loss=0.2064 [20.2 s]    dev=(HR@5:0.4379,NDCG@5:0.3239) [0.9 s] *
INFO:root:Epoch 32    loss=0.2069 [20.2 s]    dev=(HR@5:0.4340,NDCG@5:0.3185) [0.9 s]
INFO:root:Epoch 33    loss=0.2061 [20.3 s]    dev=(HR@5:0.4385,NDCG@5:0.3221) [0.9 s]
INFO:root:Epoch 34    loss=0.2054 [20.2 s]    dev=(HR@5:0.4380,NDCG@5:0.3204) [0.9 s]
INFO:root:Epoch 35    loss=0.2058 [20.3 s]    dev=(HR@5:0.4331,NDCG@5:0.3157) [0.9 s]
INFO:root:Epoch 36    loss=0.2027 [20.3 s]    dev=(HR@5:0.4365,NDCG@5:0.3185) [0.9 s]
INFO:root:Epoch 37    loss=0.2034 [20.3 s]    dev=(HR@5:0.4394,NDCG@5:0.3215) [0.9 s]
INFO:root:Epoch 38    loss=0.2029 [20.3 s]    dev=(HR@5:0.4393,NDCG@5:0.3198) [0.9 s]
INFO:root:Epoch 39    loss=0.2046 [20.2 s]    dev=(HR@5:0.4336,NDCG@5:0.3162) [0.9 s]
INFO:root:Epoch 40    loss=0.2033 [20.3 s]    dev=(HR@5:0.4363,NDCG@5:0.3188) [0.9 s]
INFO:root:Epoch 41    loss=0.2043 [20.3 s]    dev=(HR@5:0.4308,NDCG@5:0.3146) [0.9 s]
INFO:root:Epoch 42    loss=0.2043 [20.2 s]    dev=(HR@5:0.4380,NDCG@5:0.3183) [0.9 s]
INFO:root:Epoch 43    loss=0.2021 [20.3 s]    dev=(HR@5:0.4407,NDCG@5:0.3238) [0.9 s]
INFO:root:Epoch 44    loss=0.2035 [20.2 s]    dev=(HR@5:0.4374,NDCG@5:0.3192) [0.9 s]
INFO:root:Epoch 45    loss=0.2002 [20.3 s]    dev=(HR@5:0.4380,NDCG@5:0.3206) [0.9 s]
INFO:root:Epoch 46    loss=0.2013 [20.2 s]    dev=(HR@5:0.4336,NDCG@5:0.3174) [0.9 s]
INFO:root:Epoch 47    loss=0.2021 [20.2 s]    dev=(HR@5:0.4374,NDCG@5:0.3201) [0.9 s]
INFO:root:Epoch 48    loss=0.2015 [20.3 s]    dev=(HR@5:0.4354,NDCG@5:0.3192) [0.9 s]
INFO:root:Epoch 49    loss=0.1995 [20.2 s]    dev=(HR@5:0.4426,NDCG@5:0.3246) [0.9 s] *
INFO:root:Epoch 50    loss=0.2012 [20.2 s]    dev=(HR@5:0.4372,NDCG@5:0.3221) [0.9 s]
INFO:root:Epoch 51    loss=0.1999 [20.3 s]    dev=(HR@5:0.4391,NDCG@5:0.3209) [0.9 s]
INFO:root:Epoch 52    loss=0.1996 [20.2 s]    dev=(HR@5:0.4389,NDCG@5:0.3188) [0.9 s]
INFO:root:Epoch 53    loss=0.1996 [21.0 s]    dev=(HR@5:0.4383,NDCG@5:0.3209) [1.0 s]
INFO:root:Epoch 54    loss=0.1981 [20.5 s]    dev=(HR@5:0.4389,NDCG@5:0.3196) [0.9 s]
INFO:root:Epoch 55    loss=0.1977 [20.3 s]    dev=(HR@5:0.4420,NDCG@5:0.3220) [0.9 s]
INFO:root:Epoch 56    loss=0.1979 [20.3 s]    dev=(HR@5:0.4405,NDCG@5:0.3234) [0.9 s]
INFO:root:Epoch 57    loss=0.1988 [20.2 s]    dev=(HR@5:0.4423,NDCG@5:0.3233) [0.9 s]
INFO:root:Epoch 58    loss=0.1992 [20.3 s]    dev=(HR@5:0.4472,NDCG@5:0.3293) [0.9 s] *
INFO:root:Epoch 59    loss=0.1985 [20.3 s]    dev=(HR@5:0.4398,NDCG@5:0.3228) [0.9 s]
INFO:root:Epoch 60    loss=0.1988 [20.2 s]    dev=(HR@5:0.4380,NDCG@5:0.3200) [0.9 s]
INFO:root:Epoch 61    loss=0.1981 [20.3 s]    dev=(HR@5:0.4441,NDCG@5:0.3273) [0.9 s]
INFO:root:Epoch 62    loss=0.1975 [20.3 s]    dev=(HR@5:0.4440,NDCG@5:0.3266) [0.9 s]
INFO:root:Epoch 63    loss=0.1993 [20.3 s]    dev=(HR@5:0.4440,NDCG@5:0.3245) [0.9 s]
INFO:root:Epoch 64    loss=0.1973 [20.3 s]    dev=(HR@5:0.4410,NDCG@5:0.3226) [0.9 s]
INFO:root:Epoch 65    loss=0.1981 [20.3 s]    dev=(HR@5:0.4387,NDCG@5:0.3214) [0.9 s]
INFO:root:Epoch 66    loss=0.1966 [20.3 s]    dev=(HR@5:0.4389,NDCG@5:0.3195) [0.9 s]
INFO:root:Epoch 67    loss=0.1971 [20.3 s]    dev=(HR@5:0.4397,NDCG@5:0.3226) [0.9 s]
INFO:root:Epoch 68    loss=0.1958 [20.2 s]    dev=(HR@5:0.4412,NDCG@5:0.3231) [0.9 s]
INFO:root:Epoch 69    loss=0.1975 [20.2 s]    dev=(HR@5:0.4379,NDCG@5:0.3210) [0.9 s]
INFO:root:Epoch 70    loss=0.1965 [20.4 s]    dev=(HR@5:0.4408,NDCG@5:0.3239) [0.9 s]
INFO:root:Epoch 71    loss=0.1954 [20.3 s]    dev=(HR@5:0.4389,NDCG@5:0.3234) [0.9 s]
INFO:root:Epoch 72    loss=0.1950 [20.2 s]    dev=(HR@5:0.4440,NDCG@5:0.3252) [0.9 s]
INFO:root:Epoch 73    loss=0.1967 [20.3 s]    dev=(HR@5:0.4416,NDCG@5:0.3219) [0.9 s]
INFO:root:Epoch 74    loss=0.1959 [20.2 s]    dev=(HR@5:0.4366,NDCG@5:0.3180) [0.9 s]
INFO:root:Epoch 75    loss=0.1974 [20.3 s]    dev=(HR@5:0.4410,NDCG@5:0.3226) [0.9 s]
INFO:root:Epoch 76    loss=0.1967 [20.3 s]    dev=(HR@5:0.4427,NDCG@5:0.3243) [0.9 s]
INFO:root:Epoch 77    loss=0.1950 [20.2 s]    dev=(HR@5:0.4419,NDCG@5:0.3240) [0.9 s]
INFO:root:Epoch 78    loss=0.1954 [20.4 s]    dev=(HR@5:0.4482,NDCG@5:0.3265) [0.9 s]
INFO:root:Early stop at 78 based on dev result.
INFO:root:
Best Iter(dev)=   58	 dev=(HR@5:0.4472,NDCG@5:0.3293) [1653.1 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.3972,NDCG@5:0.2847,HR@10:0.5051,NDCG@10:0.3197,HR@20:0.6280,NDCG@20:0.3506,HR@50:0.8303,NDCG@50:0.3907)
INFO:root:
--------------------------------------------- END: 2024-12-06 16:05:16 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 16:50:46 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5150 [22.5 s]    dev=(HR@5:0.2561,NDCG@5:0.1712) [0.9 s] *
INFO:root:Epoch 2     loss=0.4258 [20.1 s]    dev=(HR@5:0.3304,NDCG@5:0.2245) [0.9 s] *
INFO:root:Epoch 3     loss=0.3887 [20.3 s]    dev=(HR@5:0.3586,NDCG@5:0.2435) [0.9 s] *
INFO:root:Epoch 4     loss=0.3652 [20.2 s]    dev=(HR@5:0.3780,NDCG@5:0.2623) [0.9 s] *
INFO:root:Epoch 5     loss=0.3410 [20.2 s]    dev=(HR@5:0.3976,NDCG@5:0.2801) [0.9 s] *
INFO:root:Epoch 6     loss=0.3168 [20.3 s]    dev=(HR@5:0.4124,NDCG@5:0.2950) [0.9 s] *
INFO:root:Epoch 7     loss=0.2997 [20.2 s]    dev=(HR@5:0.4160,NDCG@5:0.2977) [0.9 s] *
INFO:root:Epoch 8     loss=0.2851 [20.2 s]    dev=(HR@5:0.4230,NDCG@5:0.3052) [0.9 s] *
INFO:root:Epoch 9     loss=0.2719 [20.2 s]    dev=(HR@5:0.4297,NDCG@5:0.3086) [0.9 s] *
INFO:root:Epoch 10    loss=0.2629 [20.2 s]    dev=(HR@5:0.4282,NDCG@5:0.3090) [0.9 s] *
INFO:root:Epoch 11    loss=0.2526 [20.2 s]    dev=(HR@5:0.4351,NDCG@5:0.3144) [0.9 s] *
INFO:root:Epoch 12    loss=0.2457 [20.2 s]    dev=(HR@5:0.4358,NDCG@5:0.3163) [0.9 s] *
INFO:root:Epoch 13    loss=0.2411 [20.2 s]    dev=(HR@5:0.4385,NDCG@5:0.3199) [0.9 s] *
INFO:root:Epoch 14    loss=0.2369 [20.1 s]    dev=(HR@5:0.4400,NDCG@5:0.3186) [0.9 s]
INFO:root:Epoch 15    loss=0.2333 [20.3 s]    dev=(HR@5:0.4393,NDCG@5:0.3182) [0.9 s]
INFO:root:Epoch 16    loss=0.2309 [20.1 s]    dev=(HR@5:0.4383,NDCG@5:0.3203) [0.9 s] *
INFO:root:Epoch 17    loss=0.2276 [20.2 s]    dev=(HR@5:0.4416,NDCG@5:0.3198) [0.9 s]
INFO:root:Epoch 18    loss=0.2230 [20.4 s]    dev=(HR@5:0.4367,NDCG@5:0.3180) [0.9 s]
INFO:root:Epoch 19    loss=0.2210 [20.1 s]    dev=(HR@5:0.4412,NDCG@5:0.3210) [0.9 s] *
INFO:root:Epoch 20    loss=0.2187 [20.3 s]    dev=(HR@5:0.4427,NDCG@5:0.3233) [0.9 s] *
INFO:root:Epoch 21    loss=0.2151 [20.2 s]    dev=(HR@5:0.4412,NDCG@5:0.3220) [0.9 s]
INFO:root:Epoch 22    loss=0.2148 [20.2 s]    dev=(HR@5:0.4411,NDCG@5:0.3231) [0.9 s]
INFO:root:Epoch 23    loss=0.2157 [20.2 s]    dev=(HR@5:0.4402,NDCG@5:0.3227) [0.9 s]
INFO:root:Epoch 24    loss=0.2151 [20.2 s]    dev=(HR@5:0.4402,NDCG@5:0.3218) [0.9 s]
INFO:root:Epoch 25    loss=0.2108 [20.2 s]    dev=(HR@5:0.4402,NDCG@5:0.3204) [0.9 s]
INFO:root:Epoch 26    loss=0.2116 [20.2 s]    dev=(HR@5:0.4416,NDCG@5:0.3225) [0.9 s]
INFO:root:Epoch 27    loss=0.2115 [20.3 s]    dev=(HR@5:0.4427,NDCG@5:0.3233) [0.9 s]
INFO:root:Epoch 28    loss=0.2108 [20.3 s]    dev=(HR@5:0.4426,NDCG@5:0.3238) [0.9 s] *
INFO:root:Epoch 29    loss=0.2096 [20.3 s]    dev=(HR@5:0.4411,NDCG@5:0.3214) [0.9 s]
INFO:root:Epoch 30    loss=0.2088 [20.3 s]    dev=(HR@5:0.4393,NDCG@5:0.3222) [0.9 s]
INFO:root:Epoch 31    loss=0.2079 [20.2 s]    dev=(HR@5:0.4420,NDCG@5:0.3239) [0.9 s] *
INFO:root:Epoch 32    loss=0.2079 [20.3 s]    dev=(HR@5:0.4409,NDCG@5:0.3218) [0.9 s]
INFO:root:Epoch 33    loss=0.2077 [20.3 s]    dev=(HR@5:0.4447,NDCG@5:0.3254) [0.9 s] *
INFO:root:Epoch 34    loss=0.2067 [20.3 s]    dev=(HR@5:0.4430,NDCG@5:0.3247) [0.9 s]
INFO:root:Epoch 35    loss=0.2074 [20.3 s]    dev=(HR@5:0.4340,NDCG@5:0.3159) [0.9 s]
INFO:root:Epoch 36    loss=0.2050 [20.4 s]    dev=(HR@5:0.4373,NDCG@5:0.3182) [0.9 s]
INFO:root:Epoch 37    loss=0.2067 [20.3 s]    dev=(HR@5:0.4422,NDCG@5:0.3220) [0.9 s]
INFO:root:Epoch 38    loss=0.2061 [20.4 s]    dev=(HR@5:0.4396,NDCG@5:0.3199) [0.9 s]
INFO:root:Epoch 39    loss=0.2068 [20.1 s]    dev=(HR@5:0.4353,NDCG@5:0.3161) [0.9 s]
INFO:root:Epoch 40    loss=0.2056 [20.2 s]    dev=(HR@5:0.4387,NDCG@5:0.3199) [0.9 s]
INFO:root:Epoch 41    loss=0.2068 [20.3 s]    dev=(HR@5:0.4377,NDCG@5:0.3177) [0.9 s]
INFO:root:Epoch 42    loss=0.2061 [20.2 s]    dev=(HR@5:0.4424,NDCG@5:0.3211) [0.9 s]
INFO:root:Epoch 43    loss=0.2047 [20.3 s]    dev=(HR@5:0.4423,NDCG@5:0.3237) [0.9 s]
INFO:root:Epoch 44    loss=0.2062 [20.3 s]    dev=(HR@5:0.4355,NDCG@5:0.3176) [0.9 s]
INFO:root:Epoch 45    loss=0.2025 [20.1 s]    dev=(HR@5:0.4387,NDCG@5:0.3201) [0.9 s]
INFO:root:Epoch 46    loss=0.2044 [20.2 s]    dev=(HR@5:0.4375,NDCG@5:0.3189) [0.9 s]
INFO:root:Epoch 47    loss=0.2042 [20.3 s]    dev=(HR@5:0.4430,NDCG@5:0.3215) [0.9 s]
INFO:root:Epoch 48    loss=0.2037 [20.3 s]    dev=(HR@5:0.4400,NDCG@5:0.3199) [0.9 s]
INFO:root:Epoch 49    loss=0.2023 [20.2 s]    dev=(HR@5:0.4438,NDCG@5:0.3248) [0.9 s]
INFO:root:Epoch 50    loss=0.2043 [20.2 s]    dev=(HR@5:0.4367,NDCG@5:0.3220) [0.9 s]
INFO:root:Epoch 51    loss=0.2022 [20.2 s]    dev=(HR@5:0.4410,NDCG@5:0.3232) [0.9 s]
INFO:root:Epoch 52    loss=0.2027 [20.3 s]    dev=(HR@5:0.4387,NDCG@5:0.3223) [0.9 s]
INFO:root:Epoch 53    loss=0.2028 [20.3 s]    dev=(HR@5:0.4399,NDCG@5:0.3221) [0.9 s]
INFO:root:Early stop at 53 based on dev result.
INFO:root:
Best Iter(dev)=   33	 dev=(HR@5:0.4447,NDCG@5:0.3254) [1122.9 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.3949,NDCG@5:0.2809,HR@10:0.5039,NDCG@10:0.3162,HR@20:0.6273,NDCG@20:0.3474,HR@50:0.8356,NDCG@50:0.3886)
INFO:root:
--------------------------------------------- END: 2024-12-06 17:09:31 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 17:44:59 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5153 [22.5 s]    dev=(HR@5:0.2561,NDCG@5:0.1717) [0.9 s] *
INFO:root:Epoch 2     loss=0.4248 [20.4 s]    dev=(HR@5:0.3346,NDCG@5:0.2272) [0.9 s] *
INFO:root:Epoch 3     loss=0.3866 [20.3 s]    dev=(HR@5:0.3631,NDCG@5:0.2479) [0.9 s] *
INFO:root:Epoch 4     loss=0.3614 [20.3 s]    dev=(HR@5:0.3855,NDCG@5:0.2689) [0.9 s] *
INFO:root:Epoch 5     loss=0.3366 [20.2 s]    dev=(HR@5:0.4024,NDCG@5:0.2856) [0.9 s] *
INFO:root:Epoch 6     loss=0.3127 [20.3 s]    dev=(HR@5:0.4168,NDCG@5:0.2977) [0.9 s] *
INFO:root:Epoch 7     loss=0.2956 [20.4 s]    dev=(HR@5:0.4197,NDCG@5:0.3001) [0.9 s] *
INFO:root:Epoch 8     loss=0.2813 [20.1 s]    dev=(HR@5:0.4272,NDCG@5:0.3079) [0.9 s] *
INFO:root:Epoch 9     loss=0.2682 [20.3 s]    dev=(HR@5:0.4305,NDCG@5:0.3120) [0.9 s] *
INFO:root:Epoch 10    loss=0.2576 [20.3 s]    dev=(HR@5:0.4338,NDCG@5:0.3157) [0.9 s] *
INFO:root:Epoch 11    loss=0.2475 [20.1 s]    dev=(HR@5:0.4361,NDCG@5:0.3173) [0.9 s] *
INFO:root:Epoch 12    loss=0.2387 [20.3 s]    dev=(HR@5:0.4400,NDCG@5:0.3224) [0.9 s] *
INFO:root:Epoch 13    loss=0.2340 [20.2 s]    dev=(HR@5:0.4461,NDCG@5:0.3263) [0.9 s] *
INFO:root:Epoch 14    loss=0.2295 [20.3 s]    dev=(HR@5:0.4457,NDCG@5:0.3248) [0.9 s]
INFO:root:Epoch 15    loss=0.2254 [20.3 s]    dev=(HR@5:0.4438,NDCG@5:0.3244) [0.9 s]
INFO:root:Epoch 16    loss=0.2215 [20.3 s]    dev=(HR@5:0.4449,NDCG@5:0.3261) [0.9 s]
INFO:root:Epoch 17    loss=0.2177 [20.4 s]    dev=(HR@5:0.4450,NDCG@5:0.3243) [0.9 s]
INFO:root:Epoch 18    loss=0.2132 [119.4 s]    dev=(HR@5:0.4468,NDCG@5:0.3280) [0.9 s] *
INFO:root:Epoch 19    loss=0.2112 [20.3 s]    dev=(HR@5:0.4466,NDCG@5:0.3282) [0.9 s] *
INFO:root:Epoch 20    loss=0.2083 [20.3 s]    dev=(HR@5:0.4511,NDCG@5:0.3314) [0.9 s] *
INFO:root:Epoch 21    loss=0.2050 [20.2 s]    dev=(HR@5:0.4505,NDCG@5:0.3312) [0.9 s]
INFO:root:Epoch 22    loss=0.2049 [20.3 s]    dev=(HR@5:0.4500,NDCG@5:0.3316) [0.9 s] *
INFO:root:Epoch 23    loss=0.2051 [20.3 s]    dev=(HR@5:0.4460,NDCG@5:0.3292) [0.9 s]
INFO:root:Epoch 24    loss=0.2043 [20.2 s]    dev=(HR@5:0.4493,NDCG@5:0.3294) [0.9 s]
INFO:root:Epoch 25    loss=0.2005 [20.3 s]    dev=(HR@5:0.4491,NDCG@5:0.3290) [0.9 s]
INFO:root:Epoch 26    loss=0.2008 [20.3 s]    dev=(HR@5:0.4499,NDCG@5:0.3308) [0.9 s]
INFO:root:Epoch 27    loss=0.2001 [20.3 s]    dev=(HR@5:0.4518,NDCG@5:0.3324) [0.9 s] *
INFO:root:Epoch 28    loss=0.2005 [20.4 s]    dev=(HR@5:0.4567,NDCG@5:0.3343) [0.9 s] *
INFO:root:Epoch 29    loss=0.1986 [20.3 s]    dev=(HR@5:0.4511,NDCG@5:0.3310) [0.9 s]
INFO:root:Epoch 30    loss=0.1977 [20.3 s]    dev=(HR@5:0.4491,NDCG@5:0.3309) [0.9 s]
INFO:root:Epoch 31    loss=0.1970 [20.3 s]    dev=(HR@5:0.4558,NDCG@5:0.3352) [0.9 s] *
INFO:root:Epoch 32    loss=0.1970 [20.3 s]    dev=(HR@5:0.4520,NDCG@5:0.3323) [0.9 s]
INFO:root:Epoch 33    loss=0.1971 [20.5 s]    dev=(HR@5:0.4535,NDCG@5:0.3347) [0.9 s]
INFO:root:Epoch 34    loss=0.1965 [20.3 s]    dev=(HR@5:0.4514,NDCG@5:0.3302) [0.9 s]
INFO:root:Epoch 35    loss=0.1971 [20.3 s]    dev=(HR@5:0.4501,NDCG@5:0.3298) [0.9 s]
INFO:root:Epoch 36    loss=0.1944 [20.3 s]    dev=(HR@5:0.4497,NDCG@5:0.3298) [0.9 s]
INFO:root:Epoch 37    loss=0.1957 [20.3 s]    dev=(HR@5:0.4509,NDCG@5:0.3307) [0.9 s]
INFO:root:Epoch 38    loss=0.1954 [20.3 s]    dev=(HR@5:0.4534,NDCG@5:0.3308) [0.9 s]
INFO:root:Epoch 39    loss=0.1958 [20.2 s]    dev=(HR@5:0.4478,NDCG@5:0.3278) [0.9 s]
INFO:root:Epoch 40    loss=0.1951 [20.3 s]    dev=(HR@5:0.4510,NDCG@5:0.3310) [0.9 s]
INFO:root:Epoch 41    loss=0.1952 [20.3 s]    dev=(HR@5:0.4507,NDCG@5:0.3297) [0.9 s]
INFO:root:Epoch 42    loss=0.1949 [20.4 s]    dev=(HR@5:0.4540,NDCG@5:0.3319) [0.9 s]
INFO:root:Epoch 43    loss=0.1936 [20.3 s]    dev=(HR@5:0.4561,NDCG@5:0.3340) [0.9 s]
INFO:root:Epoch 44    loss=0.1944 [20.3 s]    dev=(HR@5:0.4512,NDCG@5:0.3307) [0.9 s]
INFO:root:Epoch 45    loss=0.1926 [20.3 s]    dev=(HR@5:0.4502,NDCG@5:0.3334) [0.9 s]
INFO:root:Epoch 46    loss=0.1932 [20.3 s]    dev=(HR@5:0.4489,NDCG@5:0.3299) [0.9 s]
INFO:root:Epoch 47    loss=0.1933 [20.2 s]    dev=(HR@5:0.4478,NDCG@5:0.3294) [0.9 s]
INFO:root:Epoch 48    loss=0.1929 [20.2 s]    dev=(HR@5:0.4493,NDCG@5:0.3296) [0.9 s]
INFO:root:Epoch 49    loss=0.1918 [20.4 s]    dev=(HR@5:0.4511,NDCG@5:0.3324) [0.9 s]
INFO:root:Epoch 50    loss=0.1942 [20.2 s]    dev=(HR@5:0.4502,NDCG@5:0.3312) [0.9 s]
INFO:root:Epoch 51    loss=0.1928 [20.4 s]    dev=(HR@5:0.4531,NDCG@5:0.3321) [0.9 s]
INFO:root:Early stop at 51 based on dev result.
INFO:root:
Best Iter(dev)=   31	 dev=(HR@5:0.4558,NDCG@5:0.3352) [1182.9 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.4049,NDCG@5:0.2902,HR@10:0.5117,NDCG@10:0.3246,HR@20:0.6332,NDCG@20:0.3552,HR@50:0.8365,NDCG@50:0.3954)
INFO:root:
--------------------------------------------- END: 2024-12-06 18:04:43 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 18:41:55 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5154 [22.3 s]    dev=(HR@5:0.2593,NDCG@5:0.1739) [0.9 s] *
INFO:root:Epoch 2     loss=0.4237 [20.2 s]    dev=(HR@5:0.3370,NDCG@5:0.2292) [0.9 s] *
INFO:root:Epoch 3     loss=0.3860 [20.3 s]    dev=(HR@5:0.3636,NDCG@5:0.2492) [0.9 s] *
INFO:root:Epoch 4     loss=0.3606 [20.1 s]    dev=(HR@5:0.3868,NDCG@5:0.2708) [0.9 s] *
INFO:root:Epoch 5     loss=0.3358 [20.2 s]    dev=(HR@5:0.4026,NDCG@5:0.2865) [0.9 s] *
INFO:root:Epoch 6     loss=0.3122 [20.3 s]    dev=(HR@5:0.4199,NDCG@5:0.3002) [0.9 s] *
INFO:root:Epoch 7     loss=0.2943 [20.3 s]    dev=(HR@5:0.4216,NDCG@5:0.3030) [0.9 s] *
INFO:root:Epoch 8     loss=0.2790 [20.1 s]    dev=(HR@5:0.4319,NDCG@5:0.3122) [0.9 s] *
INFO:root:Epoch 9     loss=0.2651 [20.2 s]    dev=(HR@5:0.4344,NDCG@5:0.3161) [0.9 s] *
INFO:root:Epoch 10    loss=0.2551 [20.5 s]    dev=(HR@5:0.4384,NDCG@5:0.3204) [0.9 s] *
INFO:root:Epoch 11    loss=0.2448 [20.5 s]    dev=(HR@5:0.4406,NDCG@5:0.3212) [0.9 s] *
INFO:root:Epoch 12    loss=0.2365 [21.9 s]    dev=(HR@5:0.4449,NDCG@5:0.3251) [0.9 s] *
INFO:root:Epoch 13    loss=0.2320 [20.9 s]    dev=(HR@5:0.4466,NDCG@5:0.3285) [0.9 s] *
INFO:root:Epoch 14    loss=0.2274 [20.0 s]    dev=(HR@5:0.4466,NDCG@5:0.3277) [0.9 s]
INFO:root:Epoch 15    loss=0.2237 [20.1 s]    dev=(HR@5:0.4457,NDCG@5:0.3263) [0.9 s]
INFO:root:Epoch 16    loss=0.2208 [20.1 s]    dev=(HR@5:0.4495,NDCG@5:0.3293) [0.9 s] *
INFO:root:Epoch 17    loss=0.2173 [20.0 s]    dev=(HR@5:0.4478,NDCG@5:0.3288) [0.9 s]
INFO:root:Epoch 18    loss=0.2133 [19.8 s]    dev=(HR@5:0.4473,NDCG@5:0.3287) [0.9 s]
INFO:root:Epoch 19    loss=0.2113 [20.0 s]    dev=(HR@5:0.4478,NDCG@5:0.3296) [0.9 s] *
INFO:root:Epoch 20    loss=0.2087 [20.0 s]    dev=(HR@5:0.4490,NDCG@5:0.3312) [0.9 s] *
INFO:root:Epoch 21    loss=0.2058 [20.0 s]    dev=(HR@5:0.4534,NDCG@5:0.3323) [0.9 s] *
INFO:root:Epoch 22    loss=0.2059 [20.1 s]    dev=(HR@5:0.4482,NDCG@5:0.3300) [0.9 s]
INFO:root:Epoch 23    loss=0.2062 [20.0 s]    dev=(HR@5:0.4479,NDCG@5:0.3300) [0.9 s]
INFO:root:Epoch 24    loss=0.2057 [20.0 s]    dev=(HR@5:0.4513,NDCG@5:0.3308) [0.9 s]
INFO:root:Epoch 25    loss=0.2016 [20.1 s]    dev=(HR@5:0.4447,NDCG@5:0.3269) [0.9 s]
INFO:root:Epoch 26    loss=0.2026 [20.1 s]    dev=(HR@5:0.4477,NDCG@5:0.3302) [0.9 s]
INFO:root:Epoch 27    loss=0.2026 [20.0 s]    dev=(HR@5:0.4507,NDCG@5:0.3325) [0.9 s] *
INFO:root:Epoch 28    loss=0.2022 [20.1 s]    dev=(HR@5:0.4509,NDCG@5:0.3338) [0.9 s] *
INFO:root:Epoch 29    loss=0.2009 [20.1 s]    dev=(HR@5:0.4482,NDCG@5:0.3315) [0.9 s]
INFO:root:Epoch 30    loss=0.2007 [20.0 s]    dev=(HR@5:0.4506,NDCG@5:0.3334) [0.9 s]
INFO:root:Epoch 31    loss=0.1988 [20.0 s]    dev=(HR@5:0.4528,NDCG@5:0.3349) [0.9 s] *
INFO:root:Epoch 32    loss=0.1997 [19.9 s]    dev=(HR@5:0.4503,NDCG@5:0.3316) [0.9 s]
INFO:root:Epoch 33    loss=0.2002 [20.0 s]    dev=(HR@5:0.4516,NDCG@5:0.3358) [0.9 s] *
INFO:root:Epoch 34    loss=0.1992 [20.0 s]    dev=(HR@5:0.4516,NDCG@5:0.3347) [0.9 s]
INFO:root:Epoch 35    loss=0.1989 [20.1 s]    dev=(HR@5:0.4528,NDCG@5:0.3338) [0.9 s]
INFO:root:Epoch 36    loss=0.1976 [21.0 s]    dev=(HR@5:0.4526,NDCG@5:0.3318) [0.9 s]
INFO:root:Epoch 37    loss=0.1980 [21.2 s]    dev=(HR@5:0.4525,NDCG@5:0.3325) [0.9 s]
INFO:root:Epoch 38    loss=0.1984 [20.4 s]    dev=(HR@5:0.4527,NDCG@5:0.3327) [0.9 s]
INFO:root:Epoch 39    loss=0.1985 [20.5 s]    dev=(HR@5:0.4433,NDCG@5:0.3262) [0.9 s]
INFO:root:Epoch 40    loss=0.1975 [20.5 s]    dev=(HR@5:0.4477,NDCG@5:0.3306) [0.9 s]
INFO:root:Epoch 41    loss=0.1982 [20.1 s]    dev=(HR@5:0.4505,NDCG@5:0.3314) [0.9 s]
INFO:root:Epoch 42    loss=0.1976 [20.6 s]    dev=(HR@5:0.4527,NDCG@5:0.3310) [0.9 s]
INFO:root:Epoch 43    loss=0.1962 [20.5 s]    dev=(HR@5:0.4541,NDCG@5:0.3354) [0.9 s]
INFO:root:Epoch 44    loss=0.1974 [21.1 s]    dev=(HR@5:0.4526,NDCG@5:0.3320) [0.9 s]
INFO:root:Epoch 45    loss=0.1949 [20.7 s]    dev=(HR@5:0.4525,NDCG@5:0.3354) [0.9 s]
INFO:root:Epoch 46    loss=0.1957 [20.2 s]    dev=(HR@5:0.4535,NDCG@5:0.3338) [0.9 s]
INFO:root:Epoch 47    loss=0.1961 [20.1 s]    dev=(HR@5:0.4509,NDCG@5:0.3309) [0.9 s]
INFO:root:Epoch 48    loss=0.1959 [20.1 s]    dev=(HR@5:0.4502,NDCG@5:0.3304) [0.9 s]
INFO:root:Epoch 49    loss=0.1941 [20.1 s]    dev=(HR@5:0.4550,NDCG@5:0.3333) [0.9 s]
INFO:root:Epoch 50    loss=0.1968 [20.3 s]    dev=(HR@5:0.4516,NDCG@5:0.3322) [0.9 s]
INFO:root:Epoch 51    loss=0.1944 [20.3 s]    dev=(HR@5:0.4505,NDCG@5:0.3317) [0.9 s]
INFO:root:Epoch 52    loss=0.1960 [20.3 s]    dev=(HR@5:0.4528,NDCG@5:0.3312) [0.9 s]
INFO:root:Epoch 53    loss=0.1948 [20.1 s]    dev=(HR@5:0.4493,NDCG@5:0.3309) [0.9 s]
INFO:root:Early stop at 53 based on dev result.
INFO:root:
Best Iter(dev)=   33	 dev=(HR@5:0.4516,NDCG@5:0.3358) [1124.4 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.4032,NDCG@5:0.2907,HR@10:0.5115,NDCG@10:0.3258,HR@20:0.6334,NDCG@20:0.3565,HR@50:0.8383,NDCG@50:0.3972)
INFO:root:
--------------------------------------------- END: 2024-12-06 19:00:42 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 19:39:52 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5158 [22.5 s]    dev=(HR@5:0.2581,NDCG@5:0.1730) [0.9 s] *
INFO:root:Epoch 2     loss=0.4246 [20.7 s]    dev=(HR@5:0.3348,NDCG@5:0.2272) [0.9 s] *
INFO:root:Epoch 3     loss=0.3855 [20.6 s]    dev=(HR@5:0.3659,NDCG@5:0.2515) [0.9 s] *
INFO:root:Epoch 4     loss=0.3586 [20.5 s]    dev=(HR@5:0.3919,NDCG@5:0.2743) [0.9 s] *
INFO:root:Epoch 5     loss=0.3315 [20.5 s]    dev=(HR@5:0.4096,NDCG@5:0.2909) [0.9 s] *
INFO:root:Epoch 6     loss=0.3058 [20.6 s]    dev=(HR@5:0.4270,NDCG@5:0.3070) [0.9 s] *
INFO:root:Epoch 7     loss=0.2873 [20.5 s]    dev=(HR@5:0.4303,NDCG@5:0.3109) [0.9 s] *
INFO:root:Epoch 8     loss=0.2714 [20.6 s]    dev=(HR@5:0.4414,NDCG@5:0.3212) [0.9 s] *
INFO:root:Epoch 9     loss=0.2584 [20.5 s]    dev=(HR@5:0.4406,NDCG@5:0.3224) [0.9 s] *
INFO:root:Epoch 10    loss=0.2486 [20.7 s]    dev=(HR@5:0.4434,NDCG@5:0.3250) [0.9 s] *
INFO:root:Epoch 11    loss=0.2392 [20.7 s]    dev=(HR@5:0.4454,NDCG@5:0.3269) [0.9 s] *
INFO:root:Epoch 12    loss=0.2314 [20.8 s]    dev=(HR@5:0.4508,NDCG@5:0.3305) [1.0 s] *
INFO:root:Epoch 13    loss=0.2278 [20.7 s]    dev=(HR@5:0.4532,NDCG@5:0.3339) [0.9 s] *
INFO:root:Epoch 14    loss=0.2231 [20.6 s]    dev=(HR@5:0.4550,NDCG@5:0.3349) [0.9 s] *
INFO:root:Epoch 15    loss=0.2197 [20.5 s]    dev=(HR@5:0.4515,NDCG@5:0.3314) [0.9 s]
INFO:root:Epoch 16    loss=0.2167 [20.6 s]    dev=(HR@5:0.4527,NDCG@5:0.3340) [0.9 s]
INFO:root:Epoch 17    loss=0.2132 [20.5 s]    dev=(HR@5:0.4492,NDCG@5:0.3317) [0.9 s]
INFO:root:Epoch 18    loss=0.2093 [20.5 s]    dev=(HR@5:0.4566,NDCG@5:0.3361) [0.9 s] *
INFO:root:Epoch 19    loss=0.2081 [20.6 s]    dev=(HR@5:0.4549,NDCG@5:0.3352) [0.9 s]
INFO:root:Epoch 20    loss=0.2050 [20.4 s]    dev=(HR@5:0.4539,NDCG@5:0.3363) [0.9 s] *
INFO:root:Epoch 21    loss=0.2016 [20.6 s]    dev=(HR@5:0.4553,NDCG@5:0.3365) [0.9 s] *
INFO:root:Epoch 22    loss=0.2022 [20.7 s]    dev=(HR@5:0.4515,NDCG@5:0.3347) [0.9 s]
INFO:root:Epoch 23    loss=0.2025 [20.5 s]    dev=(HR@5:0.4502,NDCG@5:0.3340) [0.9 s]
INFO:root:Epoch 24    loss=0.2014 [20.6 s]    dev=(HR@5:0.4543,NDCG@5:0.3349) [0.9 s]
INFO:root:Epoch 25    loss=0.1981 [20.6 s]    dev=(HR@5:0.4504,NDCG@5:0.3325) [0.9 s]
INFO:root:Epoch 26    loss=0.1988 [20.5 s]    dev=(HR@5:0.4542,NDCG@5:0.3354) [0.9 s]
INFO:root:Epoch 27    loss=0.1986 [20.8 s]    dev=(HR@5:0.4530,NDCG@5:0.3350) [1.0 s]
INFO:root:Epoch 28    loss=0.1983 [20.7 s]    dev=(HR@5:0.4549,NDCG@5:0.3369) [0.9 s] *
INFO:root:Epoch 29    loss=0.1967 [20.6 s]    dev=(HR@5:0.4541,NDCG@5:0.3364) [0.9 s]
INFO:root:Epoch 30    loss=0.1969 [20.7 s]    dev=(HR@5:0.4537,NDCG@5:0.3352) [0.9 s]
INFO:root:Epoch 31    loss=0.1943 [20.6 s]    dev=(HR@5:0.4571,NDCG@5:0.3398) [0.9 s] *
INFO:root:Epoch 32    loss=0.1953 [20.6 s]    dev=(HR@5:0.4545,NDCG@5:0.3352) [0.9 s]
INFO:root:Epoch 33    loss=0.1960 [20.7 s]    dev=(HR@5:0.4577,NDCG@5:0.3414) [0.9 s] *
INFO:root:Epoch 34    loss=0.1951 [20.6 s]    dev=(HR@5:0.4607,NDCG@5:0.3400) [0.9 s]
INFO:root:Epoch 35    loss=0.1952 [20.5 s]    dev=(HR@5:0.4543,NDCG@5:0.3361) [0.9 s]
INFO:root:Epoch 36    loss=0.1935 [20.7 s]    dev=(HR@5:0.4547,NDCG@5:0.3346) [0.9 s]
INFO:root:Epoch 37    loss=0.1936 [20.6 s]    dev=(HR@5:0.4537,NDCG@5:0.3350) [0.9 s]
INFO:root:Epoch 38    loss=0.1949 [20.5 s]    dev=(HR@5:0.4553,NDCG@5:0.3355) [0.9 s]
INFO:root:Epoch 39    loss=0.1940 [20.6 s]    dev=(HR@5:0.4509,NDCG@5:0.3323) [0.9 s]
INFO:root:Epoch 40    loss=0.1939 [20.6 s]    dev=(HR@5:0.4540,NDCG@5:0.3355) [0.9 s]
INFO:root:Epoch 41    loss=0.1940 [20.7 s]    dev=(HR@5:0.4537,NDCG@5:0.3347) [0.9 s]
INFO:root:Epoch 42    loss=0.1938 [20.5 s]    dev=(HR@5:0.4535,NDCG@5:0.3347) [0.9 s]
INFO:root:Epoch 43    loss=0.1923 [20.6 s]    dev=(HR@5:0.4568,NDCG@5:0.3363) [0.9 s]
INFO:root:Epoch 44    loss=0.1936 [20.5 s]    dev=(HR@5:0.4536,NDCG@5:0.3349) [0.9 s]
INFO:root:Epoch 45    loss=0.1912 [20.4 s]    dev=(HR@5:0.4557,NDCG@5:0.3389) [0.9 s]
INFO:root:Epoch 46    loss=0.1921 [20.7 s]    dev=(HR@5:0.4544,NDCG@5:0.3361) [0.9 s]
INFO:root:Epoch 47    loss=0.1920 [20.4 s]    dev=(HR@5:0.4547,NDCG@5:0.3350) [0.9 s]
INFO:root:Epoch 48    loss=0.1913 [20.6 s]    dev=(HR@5:0.4547,NDCG@5:0.3359) [0.9 s]
INFO:root:Epoch 49    loss=0.1901 [20.5 s]    dev=(HR@5:0.4588,NDCG@5:0.3378) [0.9 s]
INFO:root:Epoch 50    loss=0.1922 [20.6 s]    dev=(HR@5:0.4532,NDCG@5:0.3337) [0.9 s]
INFO:root:Epoch 51    loss=0.1899 [20.5 s]    dev=(HR@5:0.4544,NDCG@5:0.3358) [0.9 s]
INFO:root:Epoch 52    loss=0.1911 [20.5 s]    dev=(HR@5:0.4542,NDCG@5:0.3352) [0.9 s]
INFO:root:Epoch 53    loss=0.1904 [20.6 s]    dev=(HR@5:0.4541,NDCG@5:0.3342) [0.9 s]
INFO:root:Early stop at 53 based on dev result.
INFO:root:
Best Iter(dev)=   33	 dev=(HR@5:0.4577,NDCG@5:0.3414) [1141.5 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.4077,NDCG@5:0.2961,HR@10:0.5138,NDCG@10:0.3305,HR@20:0.6356,NDCG@20:0.3611,HR@50:0.8354,NDCG@50:0.4007)
INFO:root:
--------------------------------------------- END: 2024-12-06 19:58:55 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 20:45:42 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5142 [23.1 s]    dev=(HR@5:0.2523,NDCG@5:0.1677) [1.0 s] *
INFO:root:Epoch 2     loss=0.4310 [20.9 s]    dev=(HR@5:0.3166,NDCG@5:0.2139) [0.9 s] *
INFO:root:Epoch 3     loss=0.3976 [20.8 s]    dev=(HR@5:0.3404,NDCG@5:0.2289) [0.9 s] *
INFO:root:Epoch 4     loss=0.3759 [20.9 s]    dev=(HR@5:0.3587,NDCG@5:0.2450) [1.0 s] *
INFO:root:Epoch 5     loss=0.3519 [20.7 s]    dev=(HR@5:0.3748,NDCG@5:0.2609) [1.0 s] *
INFO:root:Epoch 6     loss=0.3283 [21.1 s]    dev=(HR@5:0.3938,NDCG@5:0.2785) [0.9 s] *
INFO:root:Epoch 7     loss=0.3112 [20.6 s]    dev=(HR@5:0.3970,NDCG@5:0.2806) [0.9 s] *
INFO:root:Epoch 8     loss=0.2995 [20.9 s]    dev=(HR@5:0.4004,NDCG@5:0.2860) [0.9 s] *
INFO:root:Epoch 9     loss=0.2862 [20.7 s]    dev=(HR@5:0.4008,NDCG@5:0.2860) [1.0 s] *
INFO:root:Epoch 10    loss=0.2786 [21.0 s]    dev=(HR@5:0.4044,NDCG@5:0.2886) [0.9 s] *
INFO:root:Epoch 11    loss=0.2697 [20.5 s]    dev=(HR@5:0.4074,NDCG@5:0.2896) [0.9 s] *
INFO:root:Epoch 12    loss=0.2616 [21.0 s]    dev=(HR@5:0.4129,NDCG@5:0.2968) [0.9 s] *
INFO:root:Epoch 13    loss=0.2568 [20.8 s]    dev=(HR@5:0.4184,NDCG@5:0.3002) [1.0 s] *
INFO:root:Epoch 14    loss=0.2515 [20.8 s]    dev=(HR@5:0.4146,NDCG@5:0.2970) [0.9 s]
INFO:root:Epoch 15    loss=0.2479 [20.3 s]    dev=(HR@5:0.4171,NDCG@5:0.2982) [0.9 s]
INFO:root:Epoch 16    loss=0.2445 [19.9 s]    dev=(HR@5:0.4174,NDCG@5:0.3011) [0.9 s] *
INFO:root:Epoch 17    loss=0.2403 [20.1 s]    dev=(HR@5:0.4153,NDCG@5:0.2985) [0.9 s]
INFO:root:Epoch 18    loss=0.2360 [20.1 s]    dev=(HR@5:0.4160,NDCG@5:0.3011) [0.9 s]
INFO:root:Epoch 19    loss=0.2325 [20.1 s]    dev=(HR@5:0.4212,NDCG@5:0.3059) [0.9 s] *
INFO:root:Epoch 20    loss=0.2304 [20.1 s]    dev=(HR@5:0.4284,NDCG@5:0.3102) [1.0 s] *
INFO:root:Epoch 21    loss=0.2256 [20.5 s]    dev=(HR@5:0.4305,NDCG@5:0.3116) [0.9 s] *
INFO:root:Epoch 22    loss=0.2243 [20.9 s]    dev=(HR@5:0.4267,NDCG@5:0.3100) [0.9 s]
INFO:root:Epoch 23    loss=0.2247 [20.8 s]    dev=(HR@5:0.4254,NDCG@5:0.3101) [0.9 s]
INFO:root:Epoch 24    loss=0.2226 [21.0 s]    dev=(HR@5:0.4350,NDCG@5:0.3144) [0.9 s] *
INFO:root:Epoch 25    loss=0.2195 [21.1 s]    dev=(HR@5:0.4305,NDCG@5:0.3126) [0.9 s]
INFO:root:Epoch 26    loss=0.2198 [21.1 s]    dev=(HR@5:0.4340,NDCG@5:0.3153) [0.9 s] *
INFO:root:Epoch 27    loss=0.2187 [21.0 s]    dev=(HR@5:0.4318,NDCG@5:0.3143) [1.0 s]
INFO:root:Epoch 28    loss=0.2190 [21.1 s]    dev=(HR@5:0.4363,NDCG@5:0.3174) [0.9 s] *
INFO:root:Epoch 29    loss=0.2160 [21.0 s]    dev=(HR@5:0.4293,NDCG@5:0.3143) [0.9 s]
INFO:root:Epoch 30    loss=0.2156 [20.5 s]    dev=(HR@5:0.4338,NDCG@5:0.3174) [1.0 s]
INFO:root:Epoch 31    loss=0.2141 [21.1 s]    dev=(HR@5:0.4340,NDCG@5:0.3183) [0.9 s] *
INFO:root:Epoch 32    loss=0.2150 [21.1 s]    dev=(HR@5:0.4316,NDCG@5:0.3148) [0.9 s]
INFO:root:Epoch 33    loss=0.2140 [21.2 s]    dev=(HR@5:0.4351,NDCG@5:0.3176) [0.9 s]
INFO:root:Epoch 34    loss=0.2134 [21.3 s]    dev=(HR@5:0.4385,NDCG@5:0.3180) [1.0 s]
INFO:root:Epoch 35    loss=0.2132 [20.7 s]    dev=(HR@5:0.4338,NDCG@5:0.3145) [0.9 s]
INFO:root:Epoch 36    loss=0.2110 [21.0 s]    dev=(HR@5:0.4325,NDCG@5:0.3132) [0.9 s]
INFO:root:Epoch 37    loss=0.2116 [20.4 s]    dev=(HR@5:0.4323,NDCG@5:0.3161) [0.9 s]
INFO:root:Epoch 38    loss=0.2112 [20.6 s]    dev=(HR@5:0.4325,NDCG@5:0.3144) [0.9 s]
INFO:root:Epoch 39    loss=0.2115 [20.0 s]    dev=(HR@5:0.4291,NDCG@5:0.3113) [0.9 s]
INFO:root:Epoch 40    loss=0.2113 [20.1 s]    dev=(HR@5:0.4349,NDCG@5:0.3154) [0.9 s]
INFO:root:Epoch 41    loss=0.2117 [20.1 s]    dev=(HR@5:0.4322,NDCG@5:0.3129) [0.9 s]
INFO:root:Epoch 42    loss=0.2114 [20.7 s]    dev=(HR@5:0.4370,NDCG@5:0.3184) [0.9 s] *
INFO:root:Epoch 43    loss=0.2098 [20.3 s]    dev=(HR@5:0.4398,NDCG@5:0.3202) [0.9 s] *
INFO:root:Epoch 44    loss=0.2111 [20.1 s]    dev=(HR@5:0.4367,NDCG@5:0.3165) [0.9 s]
INFO:root:Epoch 45    loss=0.2079 [19.9 s]    dev=(HR@5:0.4416,NDCG@5:0.3215) [0.9 s] *
INFO:root:Epoch 46    loss=0.2087 [20.0 s]    dev=(HR@5:0.4327,NDCG@5:0.3143) [0.9 s]
INFO:root:Epoch 47    loss=0.2096 [20.0 s]    dev=(HR@5:0.4371,NDCG@5:0.3167) [0.9 s]
INFO:root:Epoch 48    loss=0.2087 [20.6 s]    dev=(HR@5:0.4376,NDCG@5:0.3169) [0.9 s]
INFO:root:Epoch 49    loss=0.2069 [20.9 s]    dev=(HR@5:0.4418,NDCG@5:0.3208) [1.0 s]
INFO:root:Epoch 50    loss=0.2081 [20.6 s]    dev=(HR@5:0.4366,NDCG@5:0.3192) [0.9 s]
INFO:root:Epoch 51    loss=0.2074 [20.5 s]    dev=(HR@5:0.4373,NDCG@5:0.3189) [1.0 s]
INFO:root:Epoch 52    loss=0.2071 [20.7 s]    dev=(HR@5:0.4400,NDCG@5:0.3189) [0.9 s]
INFO:root:Epoch 53    loss=0.2074 [20.3 s]    dev=(HR@5:0.4360,NDCG@5:0.3179) [0.9 s]
INFO:root:Epoch 54    loss=0.2053 [20.7 s]    dev=(HR@5:0.4403,NDCG@5:0.3191) [0.9 s]
INFO:root:Epoch 55    loss=0.2060 [20.7 s]    dev=(HR@5:0.4395,NDCG@5:0.3197) [0.9 s]
INFO:root:Epoch 56    loss=0.2059 [20.3 s]    dev=(HR@5:0.4462,NDCG@5:0.3243) [0.9 s] *
INFO:root:Epoch 57    loss=0.2064 [20.8 s]    dev=(HR@5:0.4424,NDCG@5:0.3225) [0.9 s]
INFO:root:Epoch 58    loss=0.2067 [20.8 s]    dev=(HR@5:0.4453,NDCG@5:0.3255) [0.9 s] *
INFO:root:Epoch 59    loss=0.2055 [20.2 s]    dev=(HR@5:0.4433,NDCG@5:0.3236) [1.0 s]
INFO:root:Epoch 60    loss=0.2062 [20.7 s]    dev=(HR@5:0.4405,NDCG@5:0.3213) [0.9 s]
INFO:root:Epoch 61    loss=0.2057 [20.9 s]    dev=(HR@5:0.4449,NDCG@5:0.3255) [1.0 s] *
INFO:root:Epoch 62    loss=0.2047 [20.3 s]    dev=(HR@5:0.4453,NDCG@5:0.3244) [0.9 s]
INFO:root:Epoch 63    loss=0.2070 [20.7 s]    dev=(HR@5:0.4425,NDCG@5:0.3224) [0.9 s]
INFO:root:Epoch 64    loss=0.2041 [20.9 s]    dev=(HR@5:0.4415,NDCG@5:0.3224) [1.0 s]
INFO:root:Epoch 65    loss=0.2055 [20.3 s]    dev=(HR@5:0.4379,NDCG@5:0.3192) [0.9 s]
INFO:root:Epoch 66    loss=0.2039 [20.3 s]    dev=(HR@5:0.4392,NDCG@5:0.3194) [1.0 s]
INFO:root:Epoch 67    loss=0.2045 [20.8 s]    dev=(HR@5:0.4415,NDCG@5:0.3217) [0.9 s]
INFO:root:Epoch 68    loss=0.2029 [20.9 s]    dev=(HR@5:0.4411,NDCG@5:0.3217) [0.9 s]
INFO:root:Epoch 69    loss=0.2054 [21.2 s]    dev=(HR@5:0.4364,NDCG@5:0.3183) [0.9 s]
INFO:root:Epoch 70    loss=0.2045 [26.8 s]    dev=(HR@5:0.4372,NDCG@5:0.3197) [1.0 s]
INFO:root:Epoch 71    loss=0.2030 [37.3 s]    dev=(HR@5:0.4352,NDCG@5:0.3175) [0.9 s]
INFO:root:Epoch 72    loss=0.2034 [21.4 s]    dev=(HR@5:0.4394,NDCG@5:0.3222) [0.9 s]
INFO:root:Epoch 73    loss=0.2042 [20.9 s]    dev=(HR@5:0.4396,NDCG@5:0.3204) [0.9 s]
INFO:root:Epoch 74    loss=0.2037 [21.1 s]    dev=(HR@5:0.4389,NDCG@5:0.3181) [0.9 s]
INFO:root:Epoch 75    loss=0.2052 [20.9 s]    dev=(HR@5:0.4397,NDCG@5:0.3181) [0.9 s]
INFO:root:Epoch 76    loss=0.2036 [20.9 s]    dev=(HR@5:0.4466,NDCG@5:0.3243) [0.9 s]
INFO:root:Epoch 77    loss=0.2032 [20.9 s]    dev=(HR@5:0.4421,NDCG@5:0.3223) [0.9 s]
INFO:root:Epoch 78    loss=0.2031 [20.7 s]    dev=(HR@5:0.4428,NDCG@5:0.3210) [0.9 s]
INFO:root:Epoch 79    loss=0.2038 [20.9 s]    dev=(HR@5:0.4422,NDCG@5:0.3213) [0.9 s]
INFO:root:Epoch 80    loss=0.2007 [21.1 s]    dev=(HR@5:0.4438,NDCG@5:0.3204) [0.9 s]
INFO:root:Epoch 81    loss=0.2015 [21.1 s]    dev=(HR@5:0.4375,NDCG@5:0.3164) [0.9 s]
INFO:root:Early stop at 81 based on dev result.
INFO:root:
Best Iter(dev)=   61	 dev=(HR@5:0.4449,NDCG@5:0.3255) [1776.1 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.3936,NDCG@5:0.2790,HR@10:0.5080,NDCG@10:0.3161,HR@20:0.6281,NDCG@20:0.3464,HR@50:0.8358,NDCG@50:0.3875)
INFO:root:
--------------------------------------------- END: 2024-12-06 21:15:20 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 22:02:33 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5142 [25.1 s]    dev=(HR@5:0.2588,NDCG@5:0.1732) [1.0 s] *
INFO:root:Epoch 2     loss=0.4238 [20.7 s]    dev=(HR@5:0.3314,NDCG@5:0.2258) [0.9 s] *
INFO:root:Epoch 3     loss=0.3866 [20.9 s]    dev=(HR@5:0.3630,NDCG@5:0.2488) [1.0 s] *
INFO:root:Epoch 4     loss=0.3621 [20.7 s]    dev=(HR@5:0.3831,NDCG@5:0.2654) [0.9 s] *
INFO:root:Epoch 5     loss=0.3373 [20.7 s]    dev=(HR@5:0.3992,NDCG@5:0.2789) [0.9 s] *
INFO:root:Epoch 6     loss=0.3132 [20.5 s]    dev=(HR@5:0.4110,NDCG@5:0.2901) [1.0 s] *
INFO:root:Epoch 7     loss=0.2962 [21.0 s]    dev=(HR@5:0.4141,NDCG@5:0.2945) [0.9 s] *
INFO:root:Epoch 8     loss=0.2828 [21.2 s]    dev=(HR@5:0.4214,NDCG@5:0.3026) [1.0 s] *
INFO:root:Epoch 9     loss=0.2697 [20.9 s]    dev=(HR@5:0.4201,NDCG@5:0.3024) [0.9 s]
INFO:root:Epoch 10    loss=0.2607 [21.1 s]    dev=(HR@5:0.4257,NDCG@5:0.3078) [0.9 s] *
INFO:root:Epoch 11    loss=0.2517 [20.7 s]    dev=(HR@5:0.4313,NDCG@5:0.3121) [0.9 s] *
INFO:root:Epoch 12    loss=0.2437 [21.0 s]    dev=(HR@5:0.4351,NDCG@5:0.3151) [0.9 s] *
INFO:root:Epoch 13    loss=0.2385 [20.7 s]    dev=(HR@5:0.4405,NDCG@5:0.3205) [1.0 s] *
INFO:root:Epoch 14    loss=0.2335 [20.7 s]    dev=(HR@5:0.4408,NDCG@5:0.3194) [0.9 s]
INFO:root:Epoch 15    loss=0.2297 [20.8 s]    dev=(HR@5:0.4408,NDCG@5:0.3206) [1.0 s] *
INFO:root:Epoch 16    loss=0.2263 [21.2 s]    dev=(HR@5:0.4409,NDCG@5:0.3217) [0.9 s] *
INFO:root:Epoch 17    loss=0.2221 [20.8 s]    dev=(HR@5:0.4425,NDCG@5:0.3217) [0.9 s]
INFO:root:Epoch 18    loss=0.2171 [21.0 s]    dev=(HR@5:0.4447,NDCG@5:0.3239) [1.0 s] *
INFO:root:Epoch 19    loss=0.2153 [20.6 s]    dev=(HR@5:0.4436,NDCG@5:0.3236) [0.9 s]
INFO:root:Epoch 20    loss=0.2131 [20.2 s]    dev=(HR@5:0.4481,NDCG@5:0.3276) [0.9 s] *
INFO:root:Epoch 21    loss=0.2091 [21.1 s]    dev=(HR@5:0.4462,NDCG@5:0.3262) [1.0 s]
INFO:root:Epoch 22    loss=0.2085 [21.2 s]    dev=(HR@5:0.4455,NDCG@5:0.3257) [0.9 s]
INFO:root:Epoch 23    loss=0.2086 [20.6 s]    dev=(HR@5:0.4405,NDCG@5:0.3245) [0.9 s]
INFO:root:Epoch 24    loss=0.2078 [21.4 s]    dev=(HR@5:0.4455,NDCG@5:0.3257) [1.0 s]
INFO:root:Epoch 25    loss=0.2046 [20.8 s]    dev=(HR@5:0.4432,NDCG@5:0.3237) [0.9 s]
INFO:root:Epoch 26    loss=0.2050 [20.9 s]    dev=(HR@5:0.4433,NDCG@5:0.3238) [0.9 s]
INFO:root:Epoch 27    loss=0.2034 [20.6 s]    dev=(HR@5:0.4446,NDCG@5:0.3252) [1.0 s]
INFO:root:Epoch 28    loss=0.2037 [21.6 s]    dev=(HR@5:0.4476,NDCG@5:0.3287) [1.0 s] *
INFO:root:Epoch 29    loss=0.2018 [21.2 s]    dev=(HR@5:0.4470,NDCG@5:0.3264) [0.9 s]
INFO:root:Epoch 30    loss=0.2013 [20.6 s]    dev=(HR@5:0.4446,NDCG@5:0.3268) [0.9 s]
INFO:root:Epoch 31    loss=0.2009 [20.7 s]    dev=(HR@5:0.4455,NDCG@5:0.3285) [1.0 s]
INFO:root:Epoch 32    loss=0.2004 [20.8 s]    dev=(HR@5:0.4432,NDCG@5:0.3247) [1.0 s]
INFO:root:Epoch 33    loss=0.2013 [21.0 s]    dev=(HR@5:0.4437,NDCG@5:0.3279) [0.9 s]
INFO:root:Epoch 34    loss=0.1999 [20.7 s]    dev=(HR@5:0.4472,NDCG@5:0.3279) [0.9 s]
INFO:root:Epoch 35    loss=0.2007 [20.7 s]    dev=(HR@5:0.4440,NDCG@5:0.3244) [0.9 s]
INFO:root:Epoch 36    loss=0.1991 [21.0 s]    dev=(HR@5:0.4456,NDCG@5:0.3264) [0.9 s]
INFO:root:Epoch 37    loss=0.1999 [20.0 s]    dev=(HR@5:0.4453,NDCG@5:0.3255) [0.9 s]
INFO:root:Epoch 38    loss=0.1996 [20.3 s]    dev=(HR@5:0.4451,NDCG@5:0.3263) [1.0 s]
INFO:root:Epoch 39    loss=0.2000 [21.2 s]    dev=(HR@5:0.4397,NDCG@5:0.3210) [0.9 s]
INFO:root:Epoch 40    loss=0.1992 [20.1 s]    dev=(HR@5:0.4414,NDCG@5:0.3219) [0.9 s]
INFO:root:Epoch 41    loss=0.2001 [20.2 s]    dev=(HR@5:0.4460,NDCG@5:0.3270) [1.0 s]
INFO:root:Epoch 42    loss=0.1996 [21.0 s]    dev=(HR@5:0.4496,NDCG@5:0.3280) [0.9 s]
INFO:root:Epoch 43    loss=0.1986 [20.3 s]    dev=(HR@5:0.4499,NDCG@5:0.3296) [0.9 s] *
INFO:root:Epoch 44    loss=0.1999 [20.6 s]    dev=(HR@5:0.4447,NDCG@5:0.3257) [0.9 s]
INFO:root:Epoch 45    loss=0.1961 [21.3 s]    dev=(HR@5:0.4496,NDCG@5:0.3301) [1.0 s] *
INFO:root:Epoch 46    loss=0.1982 [21.4 s]    dev=(HR@5:0.4392,NDCG@5:0.3219) [0.9 s]
INFO:root:Epoch 47    loss=0.1979 [20.9 s]    dev=(HR@5:0.4439,NDCG@5:0.3245) [0.9 s]
INFO:root:Epoch 48    loss=0.1979 [20.8 s]    dev=(HR@5:0.4429,NDCG@5:0.3240) [1.0 s]
INFO:root:Epoch 49    loss=0.1959 [20.3 s]    dev=(HR@5:0.4473,NDCG@5:0.3287) [0.9 s]
INFO:root:Epoch 50    loss=0.1980 [20.3 s]    dev=(HR@5:0.4430,NDCG@5:0.3254) [0.9 s]
INFO:root:Epoch 51    loss=0.1966 [21.3 s]    dev=(HR@5:0.4438,NDCG@5:0.3265) [0.9 s]
INFO:root:Epoch 52    loss=0.1968 [20.5 s]    dev=(HR@5:0.4437,NDCG@5:0.3248) [1.0 s]
INFO:root:Epoch 53    loss=0.1968 [20.8 s]    dev=(HR@5:0.4388,NDCG@5:0.3227) [0.9 s]
INFO:root:Epoch 54    loss=0.1957 [20.8 s]    dev=(HR@5:0.4440,NDCG@5:0.3269) [0.9 s]
INFO:root:Epoch 55    loss=0.1960 [21.4 s]    dev=(HR@5:0.4454,NDCG@5:0.3276) [1.0 s]
INFO:root:Epoch 56    loss=0.1968 [20.7 s]    dev=(HR@5:0.4459,NDCG@5:0.3284) [0.9 s]
INFO:root:Epoch 57    loss=0.1958 [20.3 s]    dev=(HR@5:0.4419,NDCG@5:0.3268) [0.9 s]
INFO:root:Epoch 58    loss=0.1976 [20.5 s]    dev=(HR@5:0.4453,NDCG@5:0.3292) [1.0 s]
INFO:root:Epoch 59    loss=0.1967 [21.1 s]    dev=(HR@5:0.4462,NDCG@5:0.3281) [1.0 s]
INFO:root:Epoch 60    loss=0.1966 [21.2 s]    dev=(HR@5:0.4436,NDCG@5:0.3278) [1.0 s]
INFO:root:Epoch 61    loss=0.1966 [20.4 s]    dev=(HR@5:0.4466,NDCG@5:0.3292) [1.0 s]
INFO:root:Epoch 62    loss=0.1955 [20.8 s]    dev=(HR@5:0.4474,NDCG@5:0.3285) [0.9 s]
INFO:root:Epoch 63    loss=0.1980 [21.1 s]    dev=(HR@5:0.4462,NDCG@5:0.3289) [0.9 s]
INFO:root:Epoch 64    loss=0.1955 [20.3 s]    dev=(HR@5:0.4458,NDCG@5:0.3273) [0.9 s]
INFO:root:Epoch 65    loss=0.1971 [20.6 s]    dev=(HR@5:0.4451,NDCG@5:0.3256) [0.9 s]
INFO:root:Early stop at 65 based on dev result.
INFO:root:
Best Iter(dev)=   45	 dev=(HR@5:0.4496,NDCG@5:0.3301) [1417.2 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.3998,NDCG@5:0.2848,HR@10:0.5089,NDCG@10:0.3201,HR@20:0.6286,NDCG@20:0.3502,HR@50:0.8288,NDCG@50:0.3898)
INFO:root:
--------------------------------------------- END: 2024-12-06 22:26:12 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 23:02:31 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5141 [26.9 s]    dev=(HR@5:0.2639,NDCG@5:0.1767) [1.0 s] *
INFO:root:Epoch 2     loss=0.4214 [20.2 s]    dev=(HR@5:0.3392,NDCG@5:0.2313) [0.9 s] *
INFO:root:Epoch 3     loss=0.3843 [20.0 s]    dev=(HR@5:0.3679,NDCG@5:0.2525) [0.9 s] *
INFO:root:Epoch 4     loss=0.3607 [20.1 s]    dev=(HR@5:0.3870,NDCG@5:0.2683) [0.9 s] *
INFO:root:Epoch 5     loss=0.3377 [19.9 s]    dev=(HR@5:0.4003,NDCG@5:0.2827) [0.9 s] *
INFO:root:Epoch 6     loss=0.3132 [19.9 s]    dev=(HR@5:0.4161,NDCG@5:0.2973) [0.9 s] *
INFO:root:Epoch 7     loss=0.2955 [20.0 s]    dev=(HR@5:0.4225,NDCG@5:0.3024) [0.9 s] *
INFO:root:Epoch 8     loss=0.2808 [19.9 s]    dev=(HR@5:0.4281,NDCG@5:0.3087) [0.9 s] *
INFO:root:Epoch 9     loss=0.2672 [19.9 s]    dev=(HR@5:0.4299,NDCG@5:0.3110) [0.9 s] *
INFO:root:Epoch 10    loss=0.2582 [20.1 s]    dev=(HR@5:0.4336,NDCG@5:0.3153) [0.9 s] *
INFO:root:Epoch 11    loss=0.2485 [20.0 s]    dev=(HR@5:0.4380,NDCG@5:0.3181) [0.9 s] *
INFO:root:Epoch 12    loss=0.2407 [20.0 s]    dev=(HR@5:0.4415,NDCG@5:0.3227) [0.9 s] *
INFO:root:Epoch 13    loss=0.2359 [20.0 s]    dev=(HR@5:0.4447,NDCG@5:0.3269) [0.9 s] *
INFO:root:Epoch 14    loss=0.2312 [19.9 s]    dev=(HR@5:0.4432,NDCG@5:0.3254) [0.9 s]
INFO:root:Epoch 15    loss=0.2273 [19.8 s]    dev=(HR@5:0.4434,NDCG@5:0.3258) [0.9 s]
INFO:root:Epoch 16    loss=0.2246 [20.0 s]    dev=(HR@5:0.4465,NDCG@5:0.3273) [0.9 s] *
INFO:root:Epoch 17    loss=0.2211 [20.0 s]    dev=(HR@5:0.4427,NDCG@5:0.3263) [0.9 s]
INFO:root:Epoch 18    loss=0.2164 [19.9 s]    dev=(HR@5:0.4467,NDCG@5:0.3290) [0.9 s] *
INFO:root:Epoch 19    loss=0.2148 [20.0 s]    dev=(HR@5:0.4494,NDCG@5:0.3310) [0.9 s] *
INFO:root:Epoch 20    loss=0.2113 [20.0 s]    dev=(HR@5:0.4496,NDCG@5:0.3326) [0.9 s] *
INFO:root:Epoch 21    loss=0.2080 [19.9 s]    dev=(HR@5:0.4492,NDCG@5:0.3312) [0.9 s]
INFO:root:Epoch 22    loss=0.2075 [19.9 s]    dev=(HR@5:0.4470,NDCG@5:0.3300) [0.9 s]
INFO:root:Epoch 23    loss=0.2077 [19.9 s]    dev=(HR@5:0.4464,NDCG@5:0.3320) [0.9 s]
INFO:root:Epoch 24    loss=0.2068 [20.1 s]    dev=(HR@5:0.4487,NDCG@5:0.3296) [0.9 s]
INFO:root:Epoch 25    loss=0.2039 [20.0 s]    dev=(HR@5:0.4456,NDCG@5:0.3295) [0.9 s]
INFO:root:Epoch 26    loss=0.2038 [20.0 s]    dev=(HR@5:0.4469,NDCG@5:0.3305) [0.9 s]
INFO:root:Epoch 27    loss=0.2035 [20.0 s]    dev=(HR@5:0.4483,NDCG@5:0.3325) [0.9 s]
INFO:root:Epoch 28    loss=0.2030 [19.9 s]    dev=(HR@5:0.4498,NDCG@5:0.3341) [0.9 s] *
INFO:root:Epoch 29    loss=0.2018 [20.0 s]    dev=(HR@5:0.4468,NDCG@5:0.3306) [0.9 s]
INFO:root:Epoch 30    loss=0.2012 [19.9 s]    dev=(HR@5:0.4487,NDCG@5:0.3320) [0.9 s]
INFO:root:Epoch 31    loss=0.2009 [20.1 s]    dev=(HR@5:0.4530,NDCG@5:0.3367) [0.9 s] *
INFO:root:Epoch 32    loss=0.2010 [19.9 s]    dev=(HR@5:0.4495,NDCG@5:0.3335) [0.9 s]
INFO:root:Epoch 33    loss=0.2014 [19.9 s]    dev=(HR@5:0.4492,NDCG@5:0.3350) [0.9 s]
INFO:root:Epoch 34    loss=0.2005 [19.9 s]    dev=(HR@5:0.4509,NDCG@5:0.3343) [0.9 s]
INFO:root:Epoch 35    loss=0.2008 [19.9 s]    dev=(HR@5:0.4465,NDCG@5:0.3303) [0.9 s]
INFO:root:Epoch 36    loss=0.1983 [20.0 s]    dev=(HR@5:0.4461,NDCG@5:0.3304) [0.9 s]
INFO:root:Epoch 37    loss=0.1989 [20.0 s]    dev=(HR@5:0.4489,NDCG@5:0.3324) [0.9 s]
INFO:root:Epoch 38    loss=0.1989 [19.9 s]    dev=(HR@5:0.4492,NDCG@5:0.3325) [0.9 s]
INFO:root:Epoch 39    loss=0.1999 [20.0 s]    dev=(HR@5:0.4419,NDCG@5:0.3256) [0.9 s]
INFO:root:Epoch 40    loss=0.1978 [20.0 s]    dev=(HR@5:0.4462,NDCG@5:0.3290) [0.9 s]
INFO:root:Epoch 41    loss=0.1989 [19.9 s]    dev=(HR@5:0.4472,NDCG@5:0.3297) [0.9 s]
INFO:root:Epoch 42    loss=0.1986 [20.0 s]    dev=(HR@5:0.4499,NDCG@5:0.3307) [0.9 s]
INFO:root:Epoch 43    loss=0.1968 [20.0 s]    dev=(HR@5:0.4511,NDCG@5:0.3333) [0.9 s]
INFO:root:Epoch 44    loss=0.1990 [20.0 s]    dev=(HR@5:0.4487,NDCG@5:0.3308) [0.9 s]
INFO:root:Epoch 45    loss=0.1957 [19.9 s]    dev=(HR@5:0.4511,NDCG@5:0.3340) [0.9 s]
INFO:root:Epoch 46    loss=0.1971 [19.9 s]    dev=(HR@5:0.4449,NDCG@5:0.3290) [0.9 s]
INFO:root:Epoch 47    loss=0.1974 [20.5 s]    dev=(HR@5:0.4455,NDCG@5:0.3286) [0.9 s]
INFO:root:Epoch 48    loss=0.1974 [19.9 s]    dev=(HR@5:0.4440,NDCG@5:0.3293) [0.9 s]
INFO:root:Epoch 49    loss=0.1964 [19.9 s]    dev=(HR@5:0.4505,NDCG@5:0.3325) [0.9 s]
INFO:root:Epoch 50    loss=0.1976 [19.9 s]    dev=(HR@5:0.4458,NDCG@5:0.3294) [0.9 s]
INFO:root:Epoch 51    loss=0.1959 [19.9 s]    dev=(HR@5:0.4462,NDCG@5:0.3316) [0.9 s]
INFO:root:Early stop at 51 based on dev result.
INFO:root:
Best Iter(dev)=   31	 dev=(HR@5:0.4530,NDCG@5:0.3367) [1071.5 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.4037,NDCG@5:0.2908,HR@10:0.5138,NDCG@10:0.3264,HR@20:0.6322,NDCG@20:0.3562,HR@50:0.8339,NDCG@50:0.3961)
INFO:root:
--------------------------------------------- END: 2024-12-06 23:20:24 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-07 00:01:18 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5143 [22.1 s]    dev=(HR@5:0.2600,NDCG@5:0.1743) [0.9 s] *
INFO:root:Epoch 2     loss=0.4231 [19.9 s]    dev=(HR@5:0.3351,NDCG@5:0.2280) [0.9 s] *
INFO:root:Epoch 3     loss=0.3857 [19.9 s]    dev=(HR@5:0.3635,NDCG@5:0.2486) [0.9 s] *
INFO:root:Epoch 4     loss=0.3594 [20.0 s]    dev=(HR@5:0.3893,NDCG@5:0.2714) [0.9 s] *
INFO:root:Epoch 5     loss=0.3329 [20.0 s]    dev=(HR@5:0.4046,NDCG@5:0.2879) [0.9 s] *
INFO:root:Epoch 6     loss=0.3085 [20.0 s]    dev=(HR@5:0.4200,NDCG@5:0.3001) [0.9 s] *
INFO:root:Epoch 7     loss=0.2918 [19.9 s]    dev=(HR@5:0.4233,NDCG@5:0.3035) [0.9 s] *
INFO:root:Epoch 8     loss=0.2786 [20.1 s]    dev=(HR@5:0.4285,NDCG@5:0.3091) [0.9 s] *
INFO:root:Epoch 9     loss=0.2663 [20.0 s]    dev=(HR@5:0.4307,NDCG@5:0.3107) [0.9 s] *
INFO:root:Epoch 10    loss=0.2583 [20.0 s]    dev=(HR@5:0.4312,NDCG@5:0.3135) [0.9 s] *
INFO:root:Epoch 11    loss=0.2497 [20.0 s]    dev=(HR@5:0.4355,NDCG@5:0.3149) [0.9 s] *
INFO:root:Epoch 12    loss=0.2427 [20.0 s]    dev=(HR@5:0.4376,NDCG@5:0.3180) [0.9 s] *
INFO:root:Epoch 13    loss=0.2395 [20.0 s]    dev=(HR@5:0.4414,NDCG@5:0.3224) [0.9 s] *
INFO:root:Epoch 14    loss=0.2355 [20.0 s]    dev=(HR@5:0.4416,NDCG@5:0.3213) [0.9 s]
INFO:root:Epoch 15    loss=0.2314 [20.0 s]    dev=(HR@5:0.4404,NDCG@5:0.3211) [0.9 s]
INFO:root:Epoch 16    loss=0.2300 [20.0 s]    dev=(HR@5:0.4413,NDCG@5:0.3210) [0.9 s]
INFO:root:Epoch 17    loss=0.2264 [20.0 s]    dev=(HR@5:0.4387,NDCG@5:0.3202) [0.9 s]
INFO:root:Epoch 18    loss=0.2216 [20.0 s]    dev=(HR@5:0.4423,NDCG@5:0.3225) [0.9 s] *
INFO:root:Epoch 19    loss=0.2211 [20.1 s]    dev=(HR@5:0.4396,NDCG@5:0.3227) [0.9 s] *
INFO:root:Epoch 20    loss=0.2172 [20.0 s]    dev=(HR@5:0.4425,NDCG@5:0.3252) [0.9 s] *
INFO:root:Epoch 21    loss=0.2148 [20.0 s]    dev=(HR@5:0.4426,NDCG@5:0.3249) [0.9 s]
INFO:root:Epoch 22    loss=0.2142 [20.0 s]    dev=(HR@5:0.4353,NDCG@5:0.3218) [0.9 s]
INFO:root:Epoch 23    loss=0.2149 [20.0 s]    dev=(HR@5:0.4409,NDCG@5:0.3258) [0.9 s] *
INFO:root:Epoch 24    loss=0.2143 [20.0 s]    dev=(HR@5:0.4404,NDCG@5:0.3229) [0.9 s]
INFO:root:Epoch 25    loss=0.2107 [20.1 s]    dev=(HR@5:0.4393,NDCG@5:0.3231) [0.9 s]
INFO:root:Epoch 26    loss=0.2113 [20.0 s]    dev=(HR@5:0.4434,NDCG@5:0.3276) [0.9 s] *
INFO:root:Epoch 27    loss=0.2114 [20.0 s]    dev=(HR@5:0.4432,NDCG@5:0.3264) [0.9 s]
INFO:root:Epoch 28    loss=0.2112 [20.1 s]    dev=(HR@5:0.4419,NDCG@5:0.3272) [0.9 s]
INFO:root:Epoch 29    loss=0.2090 [19.9 s]    dev=(HR@5:0.4419,NDCG@5:0.3248) [0.9 s]
INFO:root:Epoch 30    loss=0.2094 [20.0 s]    dev=(HR@5:0.4423,NDCG@5:0.3272) [0.9 s]
INFO:root:Epoch 31    loss=0.2073 [20.1 s]    dev=(HR@5:0.4432,NDCG@5:0.3284) [0.9 s] *
INFO:root:Epoch 32    loss=0.2086 [20.0 s]    dev=(HR@5:0.4406,NDCG@5:0.3258) [0.9 s]
INFO:root:Epoch 33    loss=0.2080 [20.0 s]    dev=(HR@5:0.4415,NDCG@5:0.3277) [0.9 s]
INFO:root:Epoch 34    loss=0.2085 [20.0 s]    dev=(HR@5:0.4392,NDCG@5:0.3258) [0.9 s]
INFO:root:Epoch 35    loss=0.2084 [20.0 s]    dev=(HR@5:0.4402,NDCG@5:0.3247) [0.9 s]
INFO:root:Epoch 36    loss=0.2064 [20.0 s]    dev=(HR@5:0.4395,NDCG@5:0.3238) [0.9 s]
INFO:root:Epoch 37    loss=0.2065 [21.4 s]    dev=(HR@5:0.4437,NDCG@5:0.3271) [1.1 s]
INFO:root:Epoch 38    loss=0.2073 [21.0 s]    dev=(HR@5:0.4392,NDCG@5:0.3247) [0.9 s]
INFO:root:Epoch 39    loss=0.2072 [20.6 s]    dev=(HR@5:0.4352,NDCG@5:0.3212) [0.9 s]
INFO:root:Epoch 40    loss=0.2063 [20.1 s]    dev=(HR@5:0.4378,NDCG@5:0.3230) [0.9 s]
INFO:root:Epoch 41    loss=0.2071 [20.0 s]    dev=(HR@5:0.4396,NDCG@5:0.3228) [0.9 s]
INFO:root:Epoch 42    loss=0.2064 [20.0 s]    dev=(HR@5:0.4419,NDCG@5:0.3242) [0.9 s]
INFO:root:Epoch 43    loss=0.2050 [20.1 s]    dev=(HR@5:0.4429,NDCG@5:0.3257) [0.9 s]
INFO:root:Epoch 44    loss=0.2060 [20.7 s]    dev=(HR@5:0.4417,NDCG@5:0.3256) [0.9 s]
INFO:root:Epoch 45    loss=0.2039 [20.3 s]    dev=(HR@5:0.4437,NDCG@5:0.3290) [0.9 s] *
INFO:root:Epoch 46    loss=0.2043 [20.6 s]    dev=(HR@5:0.4407,NDCG@5:0.3266) [0.9 s]
INFO:root:Epoch 47    loss=0.2050 [20.4 s]    dev=(HR@5:0.4417,NDCG@5:0.3250) [0.9 s]
INFO:root:Epoch 48    loss=0.2046 [20.4 s]    dev=(HR@5:0.4401,NDCG@5:0.3256) [0.9 s]
INFO:root:Epoch 49    loss=0.2029 [20.7 s]    dev=(HR@5:0.4440,NDCG@5:0.3274) [0.9 s]
INFO:root:Epoch 50    loss=0.2049 [20.9 s]    dev=(HR@5:0.4405,NDCG@5:0.3248) [0.9 s]
INFO:root:Epoch 51    loss=0.2030 [20.8 s]    dev=(HR@5:0.4408,NDCG@5:0.3258) [0.9 s]
INFO:root:Epoch 52    loss=0.2036 [20.3 s]    dev=(HR@5:0.4396,NDCG@5:0.3239) [1.0 s]
INFO:root:Epoch 53    loss=0.2039 [20.5 s]    dev=(HR@5:0.4393,NDCG@5:0.3228) [0.9 s]
INFO:root:Epoch 54    loss=0.2021 [20.8 s]    dev=(HR@5:0.4374,NDCG@5:0.3217) [0.9 s]
INFO:root:Epoch 55    loss=0.2024 [20.6 s]    dev=(HR@5:0.4445,NDCG@5:0.3266) [1.0 s]
INFO:root:Epoch 56    loss=0.2024 [20.9 s]    dev=(HR@5:0.4425,NDCG@5:0.3258) [0.9 s]
INFO:root:Epoch 57    loss=0.2032 [20.1 s]    dev=(HR@5:0.4396,NDCG@5:0.3259) [1.0 s]
INFO:root:Epoch 58    loss=0.2036 [20.7 s]    dev=(HR@5:0.4430,NDCG@5:0.3279) [0.9 s]
INFO:root:Epoch 59    loss=0.2025 [22.4 s]    dev=(HR@5:0.4419,NDCG@5:0.3260) [1.0 s]
INFO:root:Epoch 60    loss=0.2035 [20.9 s]    dev=(HR@5:0.4434,NDCG@5:0.3283) [0.9 s]
INFO:root:Epoch 61    loss=0.2027 [20.9 s]    dev=(HR@5:0.4445,NDCG@5:0.3278) [0.9 s]
INFO:root:Epoch 62    loss=0.2019 [20.5 s]    dev=(HR@5:0.4464,NDCG@5:0.3282) [0.9 s]
INFO:root:Epoch 63    loss=0.2038 [20.4 s]    dev=(HR@5:0.4474,NDCG@5:0.3294) [0.9 s] *
INFO:root:Epoch 64    loss=0.2005 [20.3 s]    dev=(HR@5:0.4420,NDCG@5:0.3251) [0.9 s]
INFO:root:Epoch 65    loss=0.2021 [20.2 s]    dev=(HR@5:0.4380,NDCG@5:0.3231) [0.9 s]
INFO:root:Epoch 66    loss=0.2004 [20.1 s]    dev=(HR@5:0.4451,NDCG@5:0.3267) [0.9 s]
INFO:root:Epoch 67    loss=0.2006 [20.6 s]    dev=(HR@5:0.4420,NDCG@5:0.3253) [0.9 s]
INFO:root:Epoch 68    loss=0.2001 [20.7 s]    dev=(HR@5:0.4450,NDCG@5:0.3280) [0.9 s]
INFO:root:Epoch 69    loss=0.2017 [20.3 s]    dev=(HR@5:0.4435,NDCG@5:0.3277) [0.9 s]
INFO:root:Epoch 70    loss=0.1995 [20.9 s]    dev=(HR@5:0.4438,NDCG@5:0.3277) [0.9 s]
INFO:root:Epoch 71    loss=0.2003 [20.3 s]    dev=(HR@5:0.4460,NDCG@5:0.3291) [0.9 s]
INFO:root:Epoch 72    loss=0.1992 [20.3 s]    dev=(HR@5:0.4441,NDCG@5:0.3270) [0.9 s]
INFO:root:Epoch 73    loss=0.1990 [20.5 s]    dev=(HR@5:0.4442,NDCG@5:0.3261) [0.9 s]
INFO:root:Epoch 74    loss=0.2001 [20.4 s]    dev=(HR@5:0.4449,NDCG@5:0.3260) [0.9 s]
INFO:root:Epoch 75    loss=0.2002 [20.3 s]    dev=(HR@5:0.4430,NDCG@5:0.3259) [0.9 s]
INFO:root:Epoch 76    loss=0.1999 [20.6 s]    dev=(HR@5:0.4431,NDCG@5:0.3276) [1.0 s]
INFO:root:Epoch 77    loss=0.1982 [20.7 s]    dev=(HR@5:0.4409,NDCG@5:0.3251) [0.9 s]
INFO:root:Epoch 78    loss=0.1987 [20.3 s]    dev=(HR@5:0.4431,NDCG@5:0.3253) [0.9 s]
INFO:root:Epoch 79    loss=0.1988 [20.4 s]    dev=(HR@5:0.4413,NDCG@5:0.3238) [0.9 s]
INFO:root:Epoch 80    loss=0.1966 [20.2 s]    dev=(HR@5:0.4423,NDCG@5:0.3238) [0.9 s]
INFO:root:Epoch 81    loss=0.1971 [20.4 s]    dev=(HR@5:0.4402,NDCG@5:0.3219) [0.9 s]
INFO:root:Epoch 82    loss=0.1978 [20.3 s]    dev=(HR@5:0.4445,NDCG@5:0.3258) [0.9 s]
INFO:root:Epoch 83    loss=0.1966 [20.1 s]    dev=(HR@5:0.4419,NDCG@5:0.3254) [0.9 s]
INFO:root:Early stop at 83 based on dev result.
INFO:root:
Best Iter(dev)=   63	 dev=(HR@5:0.4474,NDCG@5:0.3294) [1763.2 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.3936,NDCG@5:0.2833,HR@10:0.5058,NDCG@10:0.3196,HR@20:0.6271,NDCG@20:0.3501,HR@50:0.8330,NDCG@50:0.3909)
INFO:root:
--------------------------------------------- END: 2024-12-07 00:30:43 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-07 00:43:51 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:30:45 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:30:55 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:31:06 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:31:16 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:31:26 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:31:35 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:31:44 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:31:53 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:32:03 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:32:12 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:32:22 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:32:33 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:32:43 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:32:52 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:33:01 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:33:10 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:33:20 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:33:30 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:33:39 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:33:48 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:33:57 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:34:07 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:34:17 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:34:26 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:34:37 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:38:23 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:38:33 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:38:43 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:38:52 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:39:01 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:39:10 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:39:20 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:39:29 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:39:38 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:39:47 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:39:56 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:40:07 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:40:17 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:40:27 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:40:36 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:40:45 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:40:54 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:41:03 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:41:13 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:41:21 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-22 12:37:14 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [12.6 s]    dev=(HR@5:0.2498,NDCG@5:0.1660) [0.4 s] *
INFO:root:Epoch 2     loss=0.4332 [11.2 s]    dev=(HR@5:0.3195,NDCG@5:0.2164) [0.4 s] *
INFO:root:Epoch 3     loss=0.3997 [11.0 s]    dev=(HR@5:0.3410,NDCG@5:0.2303) [0.4 s] *
INFO:root:Epoch 4     loss=0.3807 [10.8 s]    dev=(HR@5:0.3647,NDCG@5:0.2514) [0.4 s] *
INFO:root:Epoch 5     loss=0.3591 [10.9 s]    dev=(HR@5:0.3748,NDCG@5:0.2597) [0.4 s] *
INFO:root:Epoch 6     loss=0.3385 [10.4 s]    dev=(HR@5:0.3854,NDCG@5:0.2708) [0.4 s] *
INFO:root:Epoch 7     loss=0.3231 [9.7 s]    dev=(HR@5:0.3923,NDCG@5:0.2769) [0.4 s] *
INFO:root:Epoch 8     loss=0.3068 [10.7 s]    dev=(HR@5:0.3974,NDCG@5:0.2850) [0.4 s] *
INFO:root:Epoch 9     loss=0.2901 [10.8 s]    dev=(HR@5:0.4049,NDCG@5:0.2906) [0.3 s] *
INFO:root:Epoch 10    loss=0.2794 [10.3 s]    dev=(HR@5:0.4088,NDCG@5:0.2935) [0.3 s] *
INFO:root:Epoch 11    loss=0.2674 [10.9 s]    dev=(HR@5:0.4139,NDCG@5:0.2956) [0.4 s] *
INFO:root:Epoch 12    loss=0.2590 [11.3 s]    dev=(HR@5:0.4192,NDCG@5:0.3017) [0.4 s] *
INFO:root:Epoch 13    loss=0.2545 [10.8 s]    dev=(HR@5:0.4195,NDCG@5:0.3034) [0.4 s] *
INFO:root:Epoch 14    loss=0.2479 [10.7 s]    dev=(HR@5:0.4203,NDCG@5:0.3038) [0.4 s] *
INFO:root:Epoch 15    loss=0.2441 [10.4 s]    dev=(HR@5:0.4206,NDCG@5:0.3044) [0.4 s] *
INFO:root:Epoch 16    loss=0.2411 [10.6 s]    dev=(HR@5:0.4219,NDCG@5:0.3046) [0.4 s] *
INFO:root:Epoch 17    loss=0.2370 [10.5 s]    dev=(HR@5:0.4161,NDCG@5:0.3024) [0.3 s]
INFO:root:Epoch 18    loss=0.2322 [10.5 s]    dev=(HR@5:0.4225,NDCG@5:0.3068) [0.4 s] *
INFO:root:Epoch 19    loss=0.2289 [9.5 s]    dev=(HR@5:0.4240,NDCG@5:0.3089) [0.3 s] *
INFO:root:Epoch 20    loss=0.2266 [10.8 s]    dev=(HR@5:0.4244,NDCG@5:0.3113) [0.4 s] *
INFO:root:Epoch 21    loss=0.2217 [10.2 s]    dev=(HR@5:0.4271,NDCG@5:0.3112) [0.4 s]
INFO:root:Epoch 22    loss=0.2217 [11.0 s]    dev=(HR@5:0.4268,NDCG@5:0.3112) [0.4 s]
INFO:root:Epoch 23    loss=0.2213 [10.2 s]    dev=(HR@5:0.4204,NDCG@5:0.3068) [0.4 s]
INFO:root:Epoch 24    loss=0.2201 [10.5 s]    dev=(HR@5:0.4266,NDCG@5:0.3102) [0.3 s]
INFO:root:Epoch 25    loss=0.2168 [11.0 s]    dev=(HR@5:0.4213,NDCG@5:0.3077) [0.4 s]
INFO:root:Epoch 26    loss=0.2173 [11.0 s]    dev=(HR@5:0.4282,NDCG@5:0.3123) [0.4 s] *
INFO:root:Epoch 27    loss=0.2160 [10.3 s]    dev=(HR@5:0.4284,NDCG@5:0.3124) [0.4 s] *
INFO:root:Epoch 28    loss=0.2145 [10.5 s]    dev=(HR@5:0.4281,NDCG@5:0.3136) [0.3 s] *
INFO:root:Epoch 29    loss=0.2132 [9.7 s]    dev=(HR@5:0.4280,NDCG@5:0.3101) [0.4 s]
INFO:root:Epoch 30    loss=0.2122 [10.9 s]    dev=(HR@5:0.4280,NDCG@5:0.3128) [0.4 s]
INFO:root:Epoch 31    loss=0.2111 [10.5 s]    dev=(HR@5:0.4299,NDCG@5:0.3151) [0.4 s] *
INFO:root:Epoch 32    loss=0.2122 [11.1 s]    dev=(HR@5:0.4293,NDCG@5:0.3127) [0.4 s]
INFO:root:Epoch 33    loss=0.2108 [10.3 s]    dev=(HR@5:0.4297,NDCG@5:0.3138) [0.4 s]
INFO:root:Epoch 34    loss=0.2089 [11.1 s]    dev=(HR@5:0.4289,NDCG@5:0.3121) [0.4 s]
INFO:root:Epoch 35    loss=0.2105 [10.7 s]    dev=(HR@5:0.4299,NDCG@5:0.3134) [0.5 s]
INFO:root:Epoch 36    loss=0.2078 [10.1 s]    dev=(HR@5:0.4293,NDCG@5:0.3129) [0.3 s]
INFO:root:Epoch 37    loss=0.2075 [10.9 s]    dev=(HR@5:0.4296,NDCG@5:0.3122) [0.4 s]
INFO:root:Epoch 38    loss=0.2086 [10.6 s]    dev=(HR@5:0.4286,NDCG@5:0.3105) [0.4 s]
INFO:root:Epoch 39    loss=0.2072 [10.9 s]    dev=(HR@5:0.4256,NDCG@5:0.3080) [0.4 s]
INFO:root:Epoch 40    loss=0.2072 [10.6 s]    dev=(HR@5:0.4253,NDCG@5:0.3114) [0.4 s]
INFO:root:Epoch 41    loss=0.2074 [11.3 s]    dev=(HR@5:0.4321,NDCG@5:0.3132) [0.4 s]
INFO:root:Epoch 42    loss=0.2075 [10.6 s]    dev=(HR@5:0.4307,NDCG@5:0.3134) [0.4 s]
INFO:root:Epoch 43    loss=0.2047 [10.8 s]    dev=(HR@5:0.4274,NDCG@5:0.3132) [0.4 s]
INFO:root:Epoch 44    loss=0.2060 [10.6 s]    dev=(HR@5:0.4311,NDCG@5:0.3147) [0.3 s]
INFO:root:Epoch 45    loss=0.2019 [10.2 s]    dev=(HR@5:0.4327,NDCG@5:0.3172) [0.4 s] *
INFO:root:Epoch 46    loss=0.2044 [11.3 s]    dev=(HR@5:0.4257,NDCG@5:0.3118) [0.4 s]
INFO:root:Epoch 47    loss=0.2048 [10.5 s]    dev=(HR@5:0.4276,NDCG@5:0.3121) [0.3 s]
INFO:root:Epoch 48    loss=0.2017 [10.4 s]    dev=(HR@5:0.4197,NDCG@5:0.3048) [0.3 s]
INFO:root:Epoch 49    loss=0.2024 [9.6 s]    dev=(HR@5:0.4319,NDCG@5:0.3142) [0.4 s]
INFO:root:Epoch 50    loss=0.2021 [11.1 s]    dev=(HR@5:0.4246,NDCG@5:0.3100) [0.4 s]
INFO:root:Epoch 51    loss=0.2017 [10.0 s]    dev=(HR@5:0.4285,NDCG@5:0.3130) [0.4 s]
INFO:root:Epoch 52    loss=0.2008 [11.1 s]    dev=(HR@5:0.4219,NDCG@5:0.3081) [0.4 s]
INFO:root:Epoch 53    loss=0.2009 [10.6 s]    dev=(HR@5:0.4274,NDCG@5:0.3117) [0.4 s]
INFO:root:Epoch 54    loss=0.1988 [11.2 s]    dev=(HR@5:0.4271,NDCG@5:0.3123) [0.4 s]
INFO:root:Epoch 55    loss=0.1987 [11.3 s]    dev=(HR@5:0.4248,NDCG@5:0.3094) [0.4 s]
INFO:root:Epoch 56    loss=0.1977 [9.9 s]    dev=(HR@5:0.4259,NDCG@5:0.3126) [0.4 s]
INFO:root:Epoch 57    loss=0.1991 [9.9 s]    dev=(HR@5:0.4291,NDCG@5:0.3135) [0.4 s]
INFO:root:Epoch 58    loss=0.1993 [10.3 s]    dev=(HR@5:0.4304,NDCG@5:0.3131) [0.3 s]
INFO:root:Epoch 59    loss=0.1974 [10.7 s]    dev=(HR@5:0.4333,NDCG@5:0.3166) [0.4 s]
INFO:root:Epoch 60    loss=0.1985 [11.1 s]    dev=(HR@5:0.4277,NDCG@5:0.3133) [0.4 s]
INFO:root:Epoch 61    loss=0.1979 [9.5 s]    dev=(HR@5:0.4304,NDCG@5:0.3150) [0.4 s]
INFO:root:Epoch 62    loss=0.1970 [11.4 s]    dev=(HR@5:0.4308,NDCG@5:0.3146) [0.4 s]
INFO:root:Epoch 63    loss=0.1976 [10.8 s]    dev=(HR@5:0.4301,NDCG@5:0.3147) [0.4 s]
INFO:root:Epoch 64    loss=0.1979 [11.4 s]    dev=(HR@5:0.4277,NDCG@5:0.3100) [0.4 s]
INFO:root:Epoch 65    loss=0.1983 [11.7 s]    dev=(HR@5:0.4289,NDCG@5:0.3127) [0.4 s]
INFO:root:Early stop at 65 based on dev result.
INFO:root:
Best Iter(dev)=   45	 dev=(HR@5:0.4327,NDCG@5:0.3172) [718.2 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.3808,NDCG@5:0.2710,HR@10:0.4872,NDCG@10:0.3054,HR@20:0.6120,NDCG@20:0.3368,HR@50:0.8204,NDCG@50:0.3780)
INFO:root:
--------------------------------------------- END: 2024-12-22 12:49:15 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-22 13:09:53 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [11.8 s]    dev=(HR@5:0.2503,NDCG@5:0.1664) [0.4 s] *
INFO:root:Epoch 2     loss=0.4330 [9.7 s]    dev=(HR@5:0.3197,NDCG@5:0.2167) [0.4 s] *
INFO:root:Epoch 3     loss=0.3997 [10.4 s]    dev=(HR@5:0.3404,NDCG@5:0.2295) [0.4 s] *
INFO:root:Epoch 4     loss=0.3820 [10.0 s]    dev=(HR@5:0.3612,NDCG@5:0.2494) [0.4 s] *
INFO:root:Epoch 5     loss=0.3586 [10.4 s]    dev=(HR@5:0.3742,NDCG@5:0.2592) [0.4 s] *
INFO:root:Epoch 6     loss=0.3356 [9.8 s]    dev=(HR@5:0.3902,NDCG@5:0.2756) [0.3 s] *
INFO:root:Epoch 7     loss=0.3170 [10.2 s]    dev=(HR@5:0.3988,NDCG@5:0.2821) [0.4 s] *
INFO:root:Epoch 8     loss=0.2990 [10.5 s]    dev=(HR@5:0.4043,NDCG@5:0.2906) [0.4 s] *
INFO:root:Epoch 9     loss=0.2825 [9.4 s]    dev=(HR@5:0.4050,NDCG@5:0.2922) [0.4 s] *
INFO:root:Epoch 10    loss=0.2723 [9.9 s]    dev=(HR@5:0.4113,NDCG@5:0.2963) [0.4 s] *
INFO:root:Epoch 11    loss=0.2601 [10.0 s]    dev=(HR@5:0.4182,NDCG@5:0.3007) [0.4 s] *
INFO:root:Epoch 12    loss=0.2522 [10.4 s]    dev=(HR@5:0.4228,NDCG@5:0.3057) [0.4 s] *
INFO:root:Epoch 13    loss=0.2472 [10.5 s]    dev=(HR@5:0.4236,NDCG@5:0.3078) [0.4 s] *
INFO:root:Epoch 14    loss=0.2410 [9.7 s]    dev=(HR@5:0.4231,NDCG@5:0.3072) [0.4 s]
INFO:root:Epoch 15    loss=0.2375 [10.2 s]    dev=(HR@5:0.4225,NDCG@5:0.3069) [0.4 s]
INFO:root:Epoch 16    loss=0.2338 [11.0 s]    dev=(HR@5:0.4230,NDCG@5:0.3088) [0.3 s] *
INFO:root:Epoch 17    loss=0.2300 [9.7 s]    dev=(HR@5:0.4224,NDCG@5:0.3084) [0.4 s]
INFO:root:Epoch 18    loss=0.2252 [9.9 s]    dev=(HR@5:0.4267,NDCG@5:0.3121) [0.4 s] *
INFO:root:Epoch 19    loss=0.2226 [10.0 s]    dev=(HR@5:0.4303,NDCG@5:0.3152) [0.4 s] *
INFO:root:Epoch 20    loss=0.2207 [10.5 s]    dev=(HR@5:0.4311,NDCG@5:0.3171) [0.4 s] *
INFO:root:Epoch 21    loss=0.2158 [10.2 s]    dev=(HR@5:0.4310,NDCG@5:0.3158) [0.4 s]
INFO:root:Epoch 22    loss=0.2149 [9.9 s]    dev=(HR@5:0.4328,NDCG@5:0.3169) [0.4 s]
INFO:root:Epoch 23    loss=0.2146 [9.7 s]    dev=(HR@5:0.4266,NDCG@5:0.3136) [0.4 s]
INFO:root:Epoch 24    loss=0.2143 [10.3 s]    dev=(HR@5:0.4336,NDCG@5:0.3176) [0.4 s] *
INFO:root:Epoch 25    loss=0.2101 [10.3 s]    dev=(HR@5:0.4292,NDCG@5:0.3146) [0.4 s]
INFO:root:Epoch 26    loss=0.2109 [10.5 s]    dev=(HR@5:0.4340,NDCG@5:0.3188) [0.5 s] *
INFO:root:Epoch 27    loss=0.2101 [10.3 s]    dev=(HR@5:0.4356,NDCG@5:0.3206) [0.4 s] *
INFO:root:Epoch 28    loss=0.2087 [9.4 s]    dev=(HR@5:0.4402,NDCG@5:0.3223) [0.4 s] *
INFO:root:Epoch 29    loss=0.2080 [10.4 s]    dev=(HR@5:0.4327,NDCG@5:0.3163) [0.4 s]
INFO:root:Epoch 30    loss=0.2070 [10.4 s]    dev=(HR@5:0.4365,NDCG@5:0.3206) [0.4 s]
INFO:root:Epoch 31    loss=0.2059 [10.1 s]    dev=(HR@5:0.4350,NDCG@5:0.3193) [0.4 s]
INFO:root:Epoch 32    loss=0.2061 [10.7 s]    dev=(HR@5:0.4358,NDCG@5:0.3206) [0.4 s]
INFO:root:Epoch 33    loss=0.2056 [10.9 s]    dev=(HR@5:0.4387,NDCG@5:0.3222) [0.4 s]
INFO:root:Epoch 34    loss=0.2032 [10.5 s]    dev=(HR@5:0.4342,NDCG@5:0.3174) [0.4 s]
INFO:root:Epoch 35    loss=0.2048 [9.7 s]    dev=(HR@5:0.4340,NDCG@5:0.3174) [0.4 s]
INFO:root:Epoch 36    loss=0.2027 [10.5 s]    dev=(HR@5:0.4398,NDCG@5:0.3205) [0.4 s]
INFO:root:Epoch 37    loss=0.2023 [10.5 s]    dev=(HR@5:0.4379,NDCG@5:0.3208) [0.4 s]
INFO:root:Epoch 38    loss=0.2031 [10.1 s]    dev=(HR@5:0.4358,NDCG@5:0.3201) [0.4 s]
INFO:root:Epoch 39    loss=0.2023 [10.7 s]    dev=(HR@5:0.4339,NDCG@5:0.3176) [0.4 s]
INFO:root:Epoch 40    loss=0.2018 [10.7 s]    dev=(HR@5:0.4359,NDCG@5:0.3214) [0.4 s]
INFO:root:Epoch 41    loss=0.2018 [10.4 s]    dev=(HR@5:0.4370,NDCG@5:0.3194) [0.4 s]
INFO:root:Epoch 42    loss=0.2023 [10.2 s]    dev=(HR@5:0.4387,NDCG@5:0.3205) [0.4 s]
INFO:root:Epoch 43    loss=0.2003 [10.8 s]    dev=(HR@5:0.4392,NDCG@5:0.3226) [0.4 s] *
INFO:root:Epoch 44    loss=0.2013 [11.3 s]    dev=(HR@5:0.4369,NDCG@5:0.3203) [0.4 s]
INFO:root:Epoch 45    loss=0.1980 [10.0 s]    dev=(HR@5:0.4446,NDCG@5:0.3275) [0.4 s] *
INFO:root:Epoch 46    loss=0.1999 [10.0 s]    dev=(HR@5:0.4363,NDCG@5:0.3206) [0.4 s]
INFO:root:Epoch 47    loss=0.2008 [10.5 s]    dev=(HR@5:0.4391,NDCG@5:0.3209) [0.4 s]
INFO:root:Epoch 48    loss=0.1979 [11.1 s]    dev=(HR@5:0.4335,NDCG@5:0.3159) [0.4 s]
INFO:root:Epoch 49    loss=0.1970 [10.0 s]    dev=(HR@5:0.4414,NDCG@5:0.3239) [0.4 s]
INFO:root:Epoch 50    loss=0.1983 [11.2 s]    dev=(HR@5:0.4362,NDCG@5:0.3209) [0.4 s]
INFO:root:Epoch 51    loss=0.1978 [10.5 s]    dev=(HR@5:0.4380,NDCG@5:0.3214) [0.4 s]
INFO:root:Epoch 52    loss=0.1975 [11.3 s]    dev=(HR@5:0.4378,NDCG@5:0.3201) [0.3 s]
INFO:root:Epoch 53    loss=0.1968 [10.8 s]    dev=(HR@5:0.4360,NDCG@5:0.3204) [0.4 s]
INFO:root:Epoch 54    loss=0.1944 [9.8 s]    dev=(HR@5:0.4396,NDCG@5:0.3222) [0.4 s]
INFO:root:Epoch 55    loss=0.1949 [9.2 s]    dev=(HR@5:0.4385,NDCG@5:0.3201) [0.4 s]
INFO:root:Epoch 56    loss=0.1944 [10.1 s]    dev=(HR@5:0.4412,NDCG@5:0.3235) [0.4 s]
INFO:root:Epoch 57    loss=0.1946 [10.8 s]    dev=(HR@5:0.4402,NDCG@5:0.3242) [0.4 s]
INFO:root:Epoch 58    loss=0.1958 [9.8 s]    dev=(HR@5:0.4380,NDCG@5:0.3215) [0.4 s]
INFO:root:Epoch 59    loss=0.1940 [9.6 s]    dev=(HR@5:0.4387,NDCG@5:0.3223) [0.4 s]
INFO:root:Epoch 60    loss=0.1946 [10.2 s]    dev=(HR@5:0.4402,NDCG@5:0.3224) [0.3 s]
INFO:root:Epoch 61    loss=0.1947 [10.1 s]    dev=(HR@5:0.4400,NDCG@5:0.3228) [0.4 s]
INFO:root:Epoch 62    loss=0.1937 [9.3 s]    dev=(HR@5:0.4368,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 63    loss=0.1946 [10.1 s]    dev=(HR@5:0.4410,NDCG@5:0.3247) [0.4 s]
INFO:root:Epoch 64    loss=0.1940 [9.0 s]    dev=(HR@5:0.4401,NDCG@5:0.3220) [0.5 s]
INFO:root:Epoch 65    loss=0.1947 [10.2 s]    dev=(HR@5:0.4413,NDCG@5:0.3238) [0.4 s]
INFO:root:Early stop at 65 based on dev result.
INFO:root:
Best Iter(dev)=   45	 dev=(HR@5:0.4446,NDCG@5:0.3275) [692.4 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.3905,NDCG@5:0.2801,HR@10:0.4995,NDCG@10:0.3152,HR@20:0.6204,NDCG@20:0.3456,HR@50:0.8246,NDCG@50:0.3861)
INFO:root:
--------------------------------------------- END: 2024-12-22 13:21:28 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-22 14:12:11 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [12.4 s]    dev=(HR@5:0.2498,NDCG@5:0.1660) [0.4 s] *
INFO:root:Epoch 2     loss=0.4332 [10.9 s]    dev=(HR@5:0.3195,NDCG@5:0.2164) [0.4 s] *
INFO:root:Epoch 3     loss=0.3997 [11.4 s]    dev=(HR@5:0.3410,NDCG@5:0.2303) [0.4 s] *
INFO:root:Epoch 4     loss=0.3807 [11.4 s]    dev=(HR@5:0.3647,NDCG@5:0.2514) [0.4 s] *
INFO:root:Epoch 5     loss=0.3591 [11.3 s]    dev=(HR@5:0.3748,NDCG@5:0.2597) [0.4 s] *
INFO:root:Epoch 6     loss=0.3385 [10.4 s]    dev=(HR@5:0.3854,NDCG@5:0.2708) [0.4 s] *
INFO:root:Epoch 7     loss=0.3231 [11.5 s]    dev=(HR@5:0.3923,NDCG@5:0.2769) [0.4 s] *
INFO:root:Epoch 8     loss=0.3068 [11.3 s]    dev=(HR@5:0.3974,NDCG@5:0.2850) [0.4 s] *
INFO:root:Epoch 9     loss=0.2901 [11.2 s]    dev=(HR@5:0.4049,NDCG@5:0.2906) [0.4 s] *
INFO:root:Epoch 10    loss=0.2794 [11.1 s]    dev=(HR@5:0.4088,NDCG@5:0.2935) [0.4 s] *
INFO:root:Epoch 11    loss=0.2674 [11.5 s]    dev=(HR@5:0.4139,NDCG@5:0.2956) [0.4 s] *
INFO:root:Epoch 12    loss=0.2590 [11.0 s]    dev=(HR@5:0.4192,NDCG@5:0.3017) [0.4 s] *
INFO:root:Epoch 13    loss=0.2545 [11.4 s]    dev=(HR@5:0.4195,NDCG@5:0.3034) [0.4 s] *
INFO:root:Epoch 14    loss=0.2479 [11.1 s]    dev=(HR@5:0.4203,NDCG@5:0.3038) [0.4 s] *
INFO:root:Epoch 15    loss=0.2441 [10.1 s]    dev=(HR@5:0.4206,NDCG@5:0.3044) [0.4 s] *
INFO:root:Epoch 16    loss=0.2411 [9.9 s]    dev=(HR@5:0.4219,NDCG@5:0.3046) [0.4 s] *
INFO:root:Epoch 17    loss=0.2370 [10.9 s]    dev=(HR@5:0.4161,NDCG@5:0.3024) [0.4 s]
INFO:root:Epoch 18    loss=0.2322 [9.3 s]    dev=(HR@5:0.4225,NDCG@5:0.3068) [0.4 s] *
INFO:root:Epoch 19    loss=0.2289 [11.3 s]    dev=(HR@5:0.4240,NDCG@5:0.3089) [0.4 s] *
INFO:root:Epoch 20    loss=0.2266 [11.1 s]    dev=(HR@5:0.4244,NDCG@5:0.3113) [0.4 s] *
INFO:root:Epoch 21    loss=0.2217 [11.2 s]    dev=(HR@5:0.4271,NDCG@5:0.3112) [0.4 s]
INFO:root:Epoch 22    loss=0.2217 [11.5 s]    dev=(HR@5:0.4268,NDCG@5:0.3112) [0.4 s]
INFO:root:Epoch 23    loss=0.2213 [11.4 s]    dev=(HR@5:0.4204,NDCG@5:0.3068) [0.4 s]
INFO:root:Epoch 24    loss=0.2201 [11.1 s]    dev=(HR@5:0.4266,NDCG@5:0.3102) [0.4 s]
INFO:root:Epoch 25    loss=0.2168 [11.3 s]    dev=(HR@5:0.4213,NDCG@5:0.3077) [0.4 s]
INFO:root:Epoch 26    loss=0.2173 [9.4 s]    dev=(HR@5:0.4282,NDCG@5:0.3123) [0.4 s] *
INFO:root:Epoch 27    loss=0.2160 [11.3 s]    dev=(HR@5:0.4284,NDCG@5:0.3124) [0.4 s] *
INFO:root:Epoch 28    loss=0.2145 [11.2 s]    dev=(HR@5:0.4281,NDCG@5:0.3136) [0.4 s] *
INFO:root:Epoch 29    loss=0.2132 [11.4 s]    dev=(HR@5:0.4280,NDCG@5:0.3101) [0.4 s]
INFO:root:Epoch 30    loss=0.2122 [11.6 s]    dev=(HR@5:0.4280,NDCG@5:0.3128) [0.4 s]
INFO:root:Epoch 31    loss=0.2111 [11.4 s]    dev=(HR@5:0.4299,NDCG@5:0.3151) [0.4 s] *
INFO:root:Epoch 32    loss=0.2122 [10.7 s]    dev=(HR@5:0.4293,NDCG@5:0.3127) [0.4 s]
INFO:root:Epoch 33    loss=0.2108 [11.3 s]    dev=(HR@5:0.4297,NDCG@5:0.3138) [0.4 s]
INFO:root:Epoch 34    loss=0.2089 [11.4 s]    dev=(HR@5:0.4289,NDCG@5:0.3121) [0.4 s]
INFO:root:Epoch 35    loss=0.2105 [11.4 s]    dev=(HR@5:0.4299,NDCG@5:0.3134) [0.4 s]
INFO:root:Epoch 36    loss=0.2078 [11.1 s]    dev=(HR@5:0.4293,NDCG@5:0.3129) [0.4 s]
INFO:root:Epoch 37    loss=0.2075 [11.0 s]    dev=(HR@5:0.4296,NDCG@5:0.3122) [0.4 s]
INFO:root:Epoch 38    loss=0.2086 [11.2 s]    dev=(HR@5:0.4286,NDCG@5:0.3105) [0.4 s]
INFO:root:Epoch 39    loss=0.2072 [11.5 s]    dev=(HR@5:0.4256,NDCG@5:0.3080) [0.4 s]
INFO:root:Epoch 40    loss=0.2072 [10.1 s]    dev=(HR@5:0.4253,NDCG@5:0.3114) [0.4 s]
INFO:root:Epoch 41    loss=0.2074 [11.2 s]    dev=(HR@5:0.4321,NDCG@5:0.3132) [0.4 s]
INFO:root:Epoch 42    loss=0.2075 [10.6 s]    dev=(HR@5:0.4307,NDCG@5:0.3134) [0.4 s]
INFO:root:Epoch 43    loss=0.2047 [10.8 s]    dev=(HR@5:0.4274,NDCG@5:0.3132) [0.3 s]
INFO:root:Epoch 44    loss=0.2060 [10.2 s]    dev=(HR@5:0.4311,NDCG@5:0.3147) [0.4 s]
INFO:root:Epoch 45    loss=0.2019 [11.2 s]    dev=(HR@5:0.4327,NDCG@5:0.3172) [0.4 s] *
INFO:root:Epoch 46    loss=0.2044 [10.6 s]    dev=(HR@5:0.4257,NDCG@5:0.3118) [0.4 s]
INFO:root:Epoch 47    loss=0.2048 [10.9 s]    dev=(HR@5:0.4276,NDCG@5:0.3121) [0.4 s]
INFO:root:Epoch 48    loss=0.2017 [9.5 s]    dev=(HR@5:0.4197,NDCG@5:0.3048) [0.4 s]
INFO:root:Epoch 49    loss=0.2024 [10.9 s]    dev=(HR@5:0.4319,NDCG@5:0.3142) [0.4 s]
INFO:root:Epoch 50    loss=0.2021 [11.1 s]    dev=(HR@5:0.4246,NDCG@5:0.3100) [0.4 s]
INFO:root:Epoch 51    loss=0.2017 [10.3 s]    dev=(HR@5:0.4285,NDCG@5:0.3130) [0.4 s]
INFO:root:Epoch 52    loss=0.2008 [11.2 s]    dev=(HR@5:0.4219,NDCG@5:0.3081) [0.4 s]
INFO:root:Epoch 53    loss=0.2009 [10.2 s]    dev=(HR@5:0.4274,NDCG@5:0.3117) [0.4 s]
INFO:root:Epoch 54    loss=0.1988 [11.3 s]    dev=(HR@5:0.4271,NDCG@5:0.3123) [0.4 s]
INFO:root:Epoch 55    loss=0.1987 [11.0 s]    dev=(HR@5:0.4248,NDCG@5:0.3094) [0.4 s]
INFO:root:Epoch 56    loss=0.1977 [9.2 s]    dev=(HR@5:0.4259,NDCG@5:0.3126) [0.4 s]
INFO:root:Epoch 57    loss=0.1991 [11.1 s]    dev=(HR@5:0.4291,NDCG@5:0.3135) [0.4 s]
INFO:root:Epoch 58    loss=0.1993 [10.9 s]    dev=(HR@5:0.4304,NDCG@5:0.3131) [0.4 s]
INFO:root:Epoch 59    loss=0.1974 [10.7 s]    dev=(HR@5:0.4333,NDCG@5:0.3166) [0.4 s]
INFO:root:Epoch 60    loss=0.1985 [9.8 s]    dev=(HR@5:0.4277,NDCG@5:0.3133) [0.4 s]
INFO:root:Epoch 61    loss=0.1979 [9.6 s]    dev=(HR@5:0.4304,NDCG@5:0.3150) [0.4 s]
INFO:root:Epoch 62    loss=0.1970 [11.0 s]    dev=(HR@5:0.4308,NDCG@5:0.3146) [0.4 s]
INFO:root:Epoch 63    loss=0.1976 [11.1 s]    dev=(HR@5:0.4301,NDCG@5:0.3147) [0.4 s]
INFO:root:Epoch 64    loss=0.1979 [10.5 s]    dev=(HR@5:0.4277,NDCG@5:0.3100) [0.4 s]
INFO:root:Epoch 65    loss=0.1983 [11.2 s]    dev=(HR@5:0.4289,NDCG@5:0.3127) [0.3 s]
INFO:root:Early stop at 65 based on dev result.
INFO:root:
Best Iter(dev)=   45	 dev=(HR@5:0.4327,NDCG@5:0.3172) [734.4 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.3808,NDCG@5:0.2710,HR@10:0.4872,NDCG@10:0.3054,HR@20:0.6120,NDCG@20:0.3368,HR@50:0.8204,NDCG@50:0.3780)
INFO:root:
--------------------------------------------- END: 2024-12-22 14:24:28 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-22 14:45:54 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [12.2 s]    dev=(HR@5:0.2503,NDCG@5:0.1664) [0.4 s] *
INFO:root:Epoch 2     loss=0.4330 [11.3 s]    dev=(HR@5:0.3197,NDCG@5:0.2167) [0.3 s] *
INFO:root:Epoch 3     loss=0.3997 [11.4 s]    dev=(HR@5:0.3404,NDCG@5:0.2295) [0.4 s] *
INFO:root:Epoch 4     loss=0.3820 [9.9 s]    dev=(HR@5:0.3612,NDCG@5:0.2494) [0.4 s] *
INFO:root:Epoch 5     loss=0.3586 [10.8 s]    dev=(HR@5:0.3742,NDCG@5:0.2592) [0.4 s] *
INFO:root:Epoch 6     loss=0.3356 [10.9 s]    dev=(HR@5:0.3902,NDCG@5:0.2756) [0.4 s] *
INFO:root:Epoch 7     loss=0.3170 [11.3 s]    dev=(HR@5:0.3988,NDCG@5:0.2821) [0.4 s] *
INFO:root:Epoch 8     loss=0.2990 [11.1 s]    dev=(HR@5:0.4043,NDCG@5:0.2906) [0.4 s] *
INFO:root:Epoch 9     loss=0.2825 [11.1 s]    dev=(HR@5:0.4050,NDCG@5:0.2922) [0.4 s] *
INFO:root:Epoch 10    loss=0.2723 [11.2 s]    dev=(HR@5:0.4113,NDCG@5:0.2963) [0.4 s] *
INFO:root:Epoch 11    loss=0.2601 [9.7 s]    dev=(HR@5:0.4182,NDCG@5:0.3007) [0.4 s] *
INFO:root:Epoch 12    loss=0.2522 [11.1 s]    dev=(HR@5:0.4228,NDCG@5:0.3057) [0.4 s] *
INFO:root:Epoch 13    loss=0.2472 [10.9 s]    dev=(HR@5:0.4236,NDCG@5:0.3078) [0.4 s] *
INFO:root:Epoch 14    loss=0.2410 [11.8 s]    dev=(HR@5:0.4231,NDCG@5:0.3072) [0.4 s]
INFO:root:Epoch 15    loss=0.2375 [11.0 s]    dev=(HR@5:0.4225,NDCG@5:0.3069) [0.4 s]
INFO:root:Epoch 16    loss=0.2338 [10.4 s]    dev=(HR@5:0.4230,NDCG@5:0.3088) [0.4 s] *
INFO:root:Epoch 17    loss=0.2300 [10.3 s]    dev=(HR@5:0.4224,NDCG@5:0.3084) [0.3 s]
INFO:root:Epoch 18    loss=0.2252 [11.1 s]    dev=(HR@5:0.4267,NDCG@5:0.3121) [0.4 s] *
INFO:root:Epoch 19    loss=0.2226 [11.0 s]    dev=(HR@5:0.4303,NDCG@5:0.3152) [0.4 s] *
INFO:root:Epoch 20    loss=0.2207 [11.0 s]    dev=(HR@5:0.4311,NDCG@5:0.3171) [0.4 s] *
INFO:root:Epoch 21    loss=0.2158 [11.8 s]    dev=(HR@5:0.4310,NDCG@5:0.3158) [0.4 s]
INFO:root:Epoch 22    loss=0.2149 [9.8 s]    dev=(HR@5:0.4328,NDCG@5:0.3169) [0.4 s]
INFO:root:Epoch 23    loss=0.2146 [11.7 s]    dev=(HR@5:0.4266,NDCG@5:0.3136) [0.4 s]
INFO:root:Epoch 24    loss=0.2143 [11.0 s]    dev=(HR@5:0.4336,NDCG@5:0.3176) [0.4 s] *
INFO:root:Epoch 25    loss=0.2101 [11.2 s]    dev=(HR@5:0.4292,NDCG@5:0.3146) [0.3 s]
INFO:root:Epoch 26    loss=0.2109 [11.0 s]    dev=(HR@5:0.4340,NDCG@5:0.3188) [0.4 s] *
INFO:root:Epoch 27    loss=0.2101 [11.7 s]    dev=(HR@5:0.4356,NDCG@5:0.3206) [0.3 s] *
INFO:root:Epoch 28    loss=0.2087 [10.5 s]    dev=(HR@5:0.4402,NDCG@5:0.3223) [0.4 s] *
INFO:root:Epoch 29    loss=0.2080 [11.5 s]    dev=(HR@5:0.4327,NDCG@5:0.3163) [0.4 s]
INFO:root:Epoch 30    loss=0.2070 [10.7 s]    dev=(HR@5:0.4365,NDCG@5:0.3206) [0.3 s]
INFO:root:Epoch 31    loss=0.2059 [11.0 s]    dev=(HR@5:0.4350,NDCG@5:0.3193) [0.4 s]
INFO:root:Epoch 32    loss=0.2061 [9.5 s]    dev=(HR@5:0.4358,NDCG@5:0.3206) [0.5 s]
INFO:root:Epoch 33    loss=0.2056 [10.9 s]    dev=(HR@5:0.4387,NDCG@5:0.3222) [0.4 s]
INFO:root:Epoch 34    loss=0.2032 [10.1 s]    dev=(HR@5:0.4342,NDCG@5:0.3174) [0.4 s]
INFO:root:Epoch 35    loss=0.2048 [10.9 s]    dev=(HR@5:0.4340,NDCG@5:0.3174) [0.4 s]
INFO:root:Epoch 36    loss=0.2027 [11.3 s]    dev=(HR@5:0.4398,NDCG@5:0.3205) [0.4 s]
INFO:root:Epoch 37    loss=0.2023 [11.2 s]    dev=(HR@5:0.4379,NDCG@5:0.3208) [0.4 s]
INFO:root:Epoch 38    loss=0.2031 [10.6 s]    dev=(HR@5:0.4358,NDCG@5:0.3201) [0.3 s]
INFO:root:Epoch 39    loss=0.2023 [11.4 s]    dev=(HR@5:0.4339,NDCG@5:0.3176) [0.4 s]
INFO:root:Epoch 40    loss=0.2018 [10.9 s]    dev=(HR@5:0.4359,NDCG@5:0.3214) [0.4 s]
INFO:root:Epoch 41    loss=0.2018 [11.5 s]    dev=(HR@5:0.4370,NDCG@5:0.3194) [0.4 s]
INFO:root:Epoch 42    loss=0.2023 [10.6 s]    dev=(HR@5:0.4387,NDCG@5:0.3205) [0.4 s]
INFO:root:Epoch 43    loss=0.2003 [10.7 s]    dev=(HR@5:0.4392,NDCG@5:0.3226) [0.4 s] *
INFO:root:Epoch 44    loss=0.2013 [11.2 s]    dev=(HR@5:0.4369,NDCG@5:0.3203) [0.4 s]
INFO:root:Epoch 45    loss=0.1980 [10.3 s]    dev=(HR@5:0.4446,NDCG@5:0.3275) [0.4 s] *
INFO:root:Epoch 46    loss=0.1999 [10.7 s]    dev=(HR@5:0.4363,NDCG@5:0.3206) [0.4 s]
INFO:root:Epoch 47    loss=0.2008 [10.9 s]    dev=(HR@5:0.4391,NDCG@5:0.3209) [0.4 s]
INFO:root:Epoch 48    loss=0.1979 [10.1 s]    dev=(HR@5:0.4335,NDCG@5:0.3159) [0.4 s]
INFO:root:Epoch 49    loss=0.1970 [11.3 s]    dev=(HR@5:0.4414,NDCG@5:0.3239) [0.4 s]
INFO:root:Epoch 50    loss=0.1983 [10.5 s]    dev=(HR@5:0.4362,NDCG@5:0.3209) [0.4 s]
INFO:root:Epoch 51    loss=0.1978 [11.0 s]    dev=(HR@5:0.4380,NDCG@5:0.3214) [0.4 s]
INFO:root:Epoch 52    loss=0.1975 [10.5 s]    dev=(HR@5:0.4378,NDCG@5:0.3201) [0.4 s]
INFO:root:Epoch 53    loss=0.1968 [11.4 s]    dev=(HR@5:0.4360,NDCG@5:0.3204) [0.4 s]
INFO:root:Epoch 54    loss=0.1944 [11.1 s]    dev=(HR@5:0.4396,NDCG@5:0.3222) [0.4 s]
INFO:root:Epoch 55    loss=0.1949 [10.8 s]    dev=(HR@5:0.4385,NDCG@5:0.3201) [0.4 s]
INFO:root:Epoch 56    loss=0.1944 [11.4 s]    dev=(HR@5:0.4412,NDCG@5:0.3235) [0.3 s]
INFO:root:Epoch 57    loss=0.1946 [11.2 s]    dev=(HR@5:0.4402,NDCG@5:0.3242) [0.4 s]
INFO:root:Epoch 58    loss=0.1958 [11.5 s]    dev=(HR@5:0.4380,NDCG@5:0.3215) [0.4 s]
INFO:root:Epoch 59    loss=0.1940 [11.0 s]    dev=(HR@5:0.4387,NDCG@5:0.3223) [0.4 s]
INFO:root:Epoch 60    loss=0.1946 [11.5 s]    dev=(HR@5:0.4402,NDCG@5:0.3224) [0.4 s]
INFO:root:Epoch 61    loss=0.1947 [10.8 s]    dev=(HR@5:0.4400,NDCG@5:0.3228) [0.3 s]
INFO:root:Epoch 62    loss=0.1937 [11.2 s]    dev=(HR@5:0.4368,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 63    loss=0.1946 [10.4 s]    dev=(HR@5:0.4410,NDCG@5:0.3247) [0.4 s]
INFO:root:Epoch 64    loss=0.1940 [10.9 s]    dev=(HR@5:0.4401,NDCG@5:0.3220) [0.4 s]
INFO:root:Epoch 65    loss=0.1947 [10.4 s]    dev=(HR@5:0.4413,NDCG@5:0.3238) [0.4 s]
INFO:root:Early stop at 65 based on dev result.
INFO:root:
Best Iter(dev)=   45	 dev=(HR@5:0.4446,NDCG@5:0.3275) [736.3 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.3905,NDCG@5:0.2801,HR@10:0.4995,NDCG@10:0.3152,HR@20:0.6204,NDCG@20:0.3456,HR@50:0.8246,NDCG@50:0.3861)
INFO:root:
--------------------------------------------- END: 2024-12-22 14:58:14 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-22 15:31:39 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5165 [11.8 s]    dev=(HR@5:0.2501,NDCG@5:0.1663) [0.4 s] *
INFO:root:Epoch 2     loss=0.4330 [11.1 s]    dev=(HR@5:0.3210,NDCG@5:0.2173) [0.4 s] *
INFO:root:Epoch 3     loss=0.3998 [10.2 s]    dev=(HR@5:0.3394,NDCG@5:0.2286) [0.4 s] *
INFO:root:Epoch 4     loss=0.3834 [10.3 s]    dev=(HR@5:0.3570,NDCG@5:0.2455) [0.3 s] *
INFO:root:Epoch 5     loss=0.3606 [10.4 s]    dev=(HR@5:0.3725,NDCG@5:0.2578) [0.3 s] *
INFO:root:Epoch 6     loss=0.3365 [10.1 s]    dev=(HR@5:0.3895,NDCG@5:0.2754) [0.4 s] *
INFO:root:Epoch 7     loss=0.3167 [10.2 s]    dev=(HR@5:0.3996,NDCG@5:0.2832) [0.4 s] *
INFO:root:Epoch 8     loss=0.2980 [10.3 s]    dev=(HR@5:0.4063,NDCG@5:0.2918) [0.4 s] *
INFO:root:Epoch 9     loss=0.2814 [10.7 s]    dev=(HR@5:0.4092,NDCG@5:0.2953) [0.4 s] *
INFO:root:Epoch 10    loss=0.2712 [10.7 s]    dev=(HR@5:0.4118,NDCG@5:0.2971) [0.4 s] *
INFO:root:Epoch 11    loss=0.2592 [10.3 s]    dev=(HR@5:0.4185,NDCG@5:0.3021) [0.4 s] *
INFO:root:Epoch 12    loss=0.2512 [10.6 s]    dev=(HR@5:0.4225,NDCG@5:0.3069) [0.4 s] *
INFO:root:Epoch 13    loss=0.2461 [9.8 s]    dev=(HR@5:0.4246,NDCG@5:0.3098) [0.4 s] *
INFO:root:Epoch 14    loss=0.2400 [10.6 s]    dev=(HR@5:0.4242,NDCG@5:0.3087) [0.4 s]
INFO:root:Epoch 15    loss=0.2365 [9.9 s]    dev=(HR@5:0.4240,NDCG@5:0.3083) [0.4 s]
INFO:root:Epoch 16    loss=0.2326 [9.9 s]    dev=(HR@5:0.4245,NDCG@5:0.3114) [0.4 s] *
INFO:root:Epoch 17    loss=0.2290 [10.0 s]    dev=(HR@5:0.4248,NDCG@5:0.3104) [0.4 s]
INFO:root:Epoch 18    loss=0.2244 [10.8 s]    dev=(HR@5:0.4268,NDCG@5:0.3130) [0.4 s] *
INFO:root:Epoch 19    loss=0.2215 [10.3 s]    dev=(HR@5:0.4274,NDCG@5:0.3152) [0.3 s] *
INFO:root:Epoch 20    loss=0.2195 [10.6 s]    dev=(HR@5:0.4306,NDCG@5:0.3170) [0.4 s] *
INFO:root:Epoch 21    loss=0.2149 [10.5 s]    dev=(HR@5:0.4293,NDCG@5:0.3156) [0.3 s]
INFO:root:Epoch 22    loss=0.2137 [10.8 s]    dev=(HR@5:0.4310,NDCG@5:0.3169) [0.4 s]
INFO:root:Epoch 23    loss=0.2136 [9.5 s]    dev=(HR@5:0.4264,NDCG@5:0.3142) [0.4 s]
INFO:root:Epoch 24    loss=0.2133 [10.7 s]    dev=(HR@5:0.4314,NDCG@5:0.3167) [0.4 s]
INFO:root:Epoch 25    loss=0.2093 [10.7 s]    dev=(HR@5:0.4286,NDCG@5:0.3140) [0.4 s]
INFO:root:Epoch 26    loss=0.2095 [10.1 s]    dev=(HR@5:0.4289,NDCG@5:0.3158) [0.4 s]
INFO:root:Epoch 27    loss=0.2093 [9.7 s]    dev=(HR@5:0.4336,NDCG@5:0.3186) [0.5 s] *
INFO:root:Epoch 28    loss=0.2077 [10.9 s]    dev=(HR@5:0.4344,NDCG@5:0.3205) [0.4 s] *
INFO:root:Epoch 29    loss=0.2063 [10.2 s]    dev=(HR@5:0.4304,NDCG@5:0.3149) [0.4 s]
INFO:root:Epoch 30    loss=0.2059 [9.9 s]    dev=(HR@5:0.4338,NDCG@5:0.3196) [0.4 s]
INFO:root:Epoch 31    loss=0.2045 [10.6 s]    dev=(HR@5:0.4325,NDCG@5:0.3189) [0.4 s]
INFO:root:Epoch 32    loss=0.2048 [11.1 s]    dev=(HR@5:0.4333,NDCG@5:0.3198) [0.4 s]
INFO:root:Epoch 33    loss=0.2038 [11.1 s]    dev=(HR@5:0.4337,NDCG@5:0.3203) [0.4 s]
INFO:root:Epoch 34    loss=0.2020 [10.1 s]    dev=(HR@5:0.4313,NDCG@5:0.3168) [0.4 s]
INFO:root:Epoch 35    loss=0.2030 [11.1 s]    dev=(HR@5:0.4321,NDCG@5:0.3165) [0.4 s]
INFO:root:Epoch 36    loss=0.2007 [10.3 s]    dev=(HR@5:0.4344,NDCG@5:0.3176) [0.4 s]
INFO:root:Epoch 37    loss=0.1997 [11.1 s]    dev=(HR@5:0.4353,NDCG@5:0.3190) [0.4 s]
INFO:root:Epoch 38    loss=0.2003 [11.3 s]    dev=(HR@5:0.4340,NDCG@5:0.3179) [0.4 s]
INFO:root:Epoch 39    loss=0.1997 [10.4 s]    dev=(HR@5:0.4305,NDCG@5:0.3145) [0.4 s]
INFO:root:Epoch 40    loss=0.1992 [11.0 s]    dev=(HR@5:0.4345,NDCG@5:0.3197) [0.4 s]
INFO:root:Epoch 41    loss=0.1991 [10.7 s]    dev=(HR@5:0.4335,NDCG@5:0.3176) [0.3 s]
INFO:root:Epoch 42    loss=0.1991 [11.2 s]    dev=(HR@5:0.4385,NDCG@5:0.3211) [0.4 s] *
INFO:root:Epoch 43    loss=0.1973 [10.5 s]    dev=(HR@5:0.4361,NDCG@5:0.3219) [0.4 s] *
INFO:root:Epoch 44    loss=0.1983 [10.6 s]    dev=(HR@5:0.4343,NDCG@5:0.3184) [0.4 s]
INFO:root:Epoch 45    loss=0.1945 [11.0 s]    dev=(HR@5:0.4399,NDCG@5:0.3243) [0.4 s] *
INFO:root:Epoch 46    loss=0.1956 [10.2 s]    dev=(HR@5:0.4327,NDCG@5:0.3187) [0.4 s]
INFO:root:Epoch 47    loss=0.1973 [10.7 s]    dev=(HR@5:0.4343,NDCG@5:0.3196) [0.4 s]
INFO:root:Epoch 48    loss=0.1945 [11.1 s]    dev=(HR@5:0.4346,NDCG@5:0.3179) [0.4 s]
INFO:root:Epoch 49    loss=0.1937 [10.2 s]    dev=(HR@5:0.4400,NDCG@5:0.3243) [0.4 s] *
INFO:root:Epoch 50    loss=0.1951 [10.2 s]    dev=(HR@5:0.4333,NDCG@5:0.3197) [0.4 s]
INFO:root:Epoch 51    loss=0.1944 [11.1 s]    dev=(HR@5:0.4373,NDCG@5:0.3224) [0.4 s]
INFO:root:Epoch 52    loss=0.1939 [10.7 s]    dev=(HR@5:0.4380,NDCG@5:0.3204) [0.4 s]
INFO:root:Epoch 53    loss=0.1942 [10.4 s]    dev=(HR@5:0.4379,NDCG@5:0.3212) [0.4 s]
INFO:root:Epoch 54    loss=0.1912 [11.3 s]    dev=(HR@5:0.4389,NDCG@5:0.3226) [0.4 s]
INFO:root:Epoch 55    loss=0.1917 [10.9 s]    dev=(HR@5:0.4371,NDCG@5:0.3196) [0.4 s]
INFO:root:Epoch 56    loss=0.1909 [11.3 s]    dev=(HR@5:0.4365,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 57    loss=0.1919 [11.4 s]    dev=(HR@5:0.4410,NDCG@5:0.3257) [0.4 s] *
INFO:root:Epoch 58    loss=0.1932 [10.3 s]    dev=(HR@5:0.4380,NDCG@5:0.3231) [0.4 s]
INFO:root:Epoch 59    loss=0.1904 [11.3 s]    dev=(HR@5:0.4361,NDCG@5:0.3212) [0.3 s]
INFO:root:Epoch 60    loss=0.1910 [10.3 s]    dev=(HR@5:0.4398,NDCG@5:0.3234) [0.4 s]
INFO:root:Epoch 61    loss=0.1913 [11.2 s]    dev=(HR@5:0.4425,NDCG@5:0.3251) [0.4 s]
INFO:root:Epoch 62    loss=0.1906 [10.4 s]    dev=(HR@5:0.4380,NDCG@5:0.3229) [0.4 s]
INFO:root:Epoch 63    loss=0.1918 [10.4 s]    dev=(HR@5:0.4442,NDCG@5:0.3263) [0.4 s] *
INFO:root:Epoch 64    loss=0.1910 [10.7 s]    dev=(HR@5:0.4394,NDCG@5:0.3228) [0.4 s]
INFO:root:Epoch 65    loss=0.1915 [11.2 s]    dev=(HR@5:0.4392,NDCG@5:0.3229) [0.4 s]
INFO:root:Epoch 66    loss=0.1902 [10.4 s]    dev=(HR@5:0.4419,NDCG@5:0.3231) [0.4 s]
INFO:root:Epoch 67    loss=0.1896 [9.5 s]    dev=(HR@5:0.4403,NDCG@5:0.3227) [0.3 s]
INFO:root:Epoch 68    loss=0.1883 [11.1 s]    dev=(HR@5:0.4423,NDCG@5:0.3252) [0.4 s]
INFO:root:Epoch 69    loss=0.1896 [10.6 s]    dev=(HR@5:0.4377,NDCG@5:0.3218) [0.4 s]
INFO:root:Epoch 70    loss=0.1895 [9.4 s]    dev=(HR@5:0.4405,NDCG@5:0.3253) [0.4 s]
INFO:root:Epoch 71    loss=0.1889 [10.8 s]    dev=(HR@5:0.4391,NDCG@5:0.3229) [0.4 s]
INFO:root:Epoch 72    loss=0.1881 [9.9 s]    dev=(HR@5:0.4378,NDCG@5:0.3207) [0.4 s]
INFO:root:Epoch 73    loss=0.1881 [10.5 s]    dev=(HR@5:0.4417,NDCG@5:0.3237) [0.4 s]
INFO:root:Epoch 74    loss=0.1889 [10.1 s]    dev=(HR@5:0.4391,NDCG@5:0.3208) [0.4 s]
INFO:root:Epoch 75    loss=0.1904 [10.8 s]    dev=(HR@5:0.4382,NDCG@5:0.3237) [0.4 s]
INFO:root:Epoch 76    loss=0.1894 [11.0 s]    dev=(HR@5:0.4379,NDCG@5:0.3234) [0.4 s]
INFO:root:Epoch 77    loss=0.1876 [9.1 s]    dev=(HR@5:0.4403,NDCG@5:0.3252) [0.4 s]
INFO:root:Epoch 78    loss=0.1873 [10.0 s]    dev=(HR@5:0.4372,NDCG@5:0.3210) [0.3 s]
INFO:root:Epoch 79    loss=0.1887 [10.6 s]    dev=(HR@5:0.4425,NDCG@5:0.3267) [0.4 s] *
INFO:root:Epoch 80    loss=0.1872 [9.5 s]    dev=(HR@5:0.4442,NDCG@5:0.3243) [0.4 s]
INFO:root:Epoch 81    loss=0.1871 [11.0 s]    dev=(HR@5:0.4377,NDCG@5:0.3197) [0.4 s]
INFO:root:Epoch 82    loss=0.1882 [10.5 s]    dev=(HR@5:0.4392,NDCG@5:0.3226) [0.4 s]
INFO:root:Epoch 83    loss=0.1874 [10.4 s]    dev=(HR@5:0.4408,NDCG@5:0.3244) [0.4 s]
INFO:root:Epoch 84    loss=0.1881 [10.4 s]    dev=(HR@5:0.4403,NDCG@5:0.3253) [0.4 s]
INFO:root:Epoch 85    loss=0.1885 [11.1 s]    dev=(HR@5:0.4404,NDCG@5:0.3237) [0.4 s]
INFO:root:Epoch 86    loss=0.1885 [9.8 s]    dev=(HR@5:0.4392,NDCG@5:0.3239) [0.3 s]
INFO:root:Epoch 87    loss=0.1869 [9.5 s]    dev=(HR@5:0.4353,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 88    loss=0.1866 [10.6 s]    dev=(HR@5:0.4427,NDCG@5:0.3245) [0.4 s]
INFO:root:Epoch 89    loss=0.1862 [10.4 s]    dev=(HR@5:0.4406,NDCG@5:0.3238) [0.4 s]
INFO:root:Epoch 90    loss=0.1860 [9.0 s]    dev=(HR@5:0.4393,NDCG@5:0.3225) [0.4 s]
INFO:root:Epoch 91    loss=0.1861 [10.1 s]    dev=(HR@5:0.4430,NDCG@5:0.3259) [0.4 s]
INFO:root:Epoch 92    loss=0.1846 [9.8 s]    dev=(HR@5:0.4406,NDCG@5:0.3218) [0.4 s]
INFO:root:Epoch 93    loss=0.1873 [9.6 s]    dev=(HR@5:0.4425,NDCG@5:0.3231) [0.4 s]
INFO:root:Epoch 94    loss=0.1860 [10.3 s]    dev=(HR@5:0.4427,NDCG@5:0.3256) [0.4 s]
INFO:root:Epoch 95    loss=0.1867 [9.3 s]    dev=(HR@5:0.4405,NDCG@5:0.3243) [0.4 s]
INFO:root:Epoch 96    loss=0.1845 [9.8 s]    dev=(HR@5:0.4388,NDCG@5:0.3242) [0.4 s]
INFO:root:Epoch 97    loss=0.1857 [10.5 s]    dev=(HR@5:0.4326,NDCG@5:0.3173) [0.4 s]
INFO:root:Epoch 98    loss=0.1844 [10.1 s]    dev=(HR@5:0.4320,NDCG@5:0.3170) [0.3 s]
INFO:root:Epoch 99    loss=0.1857 [10.7 s]    dev=(HR@5:0.4400,NDCG@5:0.3233) [0.4 s]
INFO:root:Early stop at 99 based on dev result.
INFO:root:
Best Iter(dev)=   79	 dev=(HR@5:0.4425,NDCG@5:0.3267) [1072.9 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.3979,NDCG@5:0.2861,HR@10:0.5062,NDCG@10:0.3213,HR@20:0.6304,NDCG@20:0.3525,HR@50:0.8364,NDCG@50:0.3934)
INFO:root:
--------------------------------------------- END: 2024-12-22 15:49:35 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-22 16:19:53 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-22 20:35:57 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [12.6 s]    dev=(HR@5:0.2498,NDCG@5:0.1660) [0.4 s] *
INFO:root:Epoch 2     loss=0.4332 [11.2 s]    dev=(HR@5:0.3195,NDCG@5:0.2164) [0.4 s] *
INFO:root:Epoch 3     loss=0.3997 [11.0 s]    dev=(HR@5:0.3410,NDCG@5:0.2303) [0.4 s] *
INFO:root:Epoch 4     loss=0.3807 [10.7 s]    dev=(HR@5:0.3647,NDCG@5:0.2514) [0.4 s] *
INFO:root:Epoch 5     loss=0.3591 [11.4 s]    dev=(HR@5:0.3748,NDCG@5:0.2597) [0.4 s] *
INFO:root:Epoch 6     loss=0.3385 [11.2 s]    dev=(HR@5:0.3854,NDCG@5:0.2708) [0.4 s] *
INFO:root:Epoch 7     loss=0.3231 [11.4 s]    dev=(HR@5:0.3923,NDCG@5:0.2769) [0.4 s] *
INFO:root:Epoch 8     loss=0.3068 [11.0 s]    dev=(HR@5:0.3974,NDCG@5:0.2850) [0.4 s] *
INFO:root:Epoch 9     loss=0.2901 [10.8 s]    dev=(HR@5:0.4049,NDCG@5:0.2906) [0.4 s] *
INFO:root:Epoch 10    loss=0.2794 [11.3 s]    dev=(HR@5:0.4088,NDCG@5:0.2935) [0.4 s] *
INFO:root:Epoch 11    loss=0.2674 [10.9 s]    dev=(HR@5:0.4139,NDCG@5:0.2956) [0.4 s] *
INFO:root:Epoch 12    loss=0.2590 [11.3 s]    dev=(HR@5:0.4192,NDCG@5:0.3017) [0.4 s] *
INFO:root:Epoch 13    loss=0.2545 [11.5 s]    dev=(HR@5:0.4195,NDCG@5:0.3034) [0.4 s] *
INFO:root:Epoch 14    loss=0.2479 [11.4 s]    dev=(HR@5:0.4203,NDCG@5:0.3038) [0.4 s] *
INFO:root:Epoch 15    loss=0.2441 [11.1 s]    dev=(HR@5:0.4206,NDCG@5:0.3044) [0.4 s] *
INFO:root:Epoch 16    loss=0.2411 [11.4 s]    dev=(HR@5:0.4219,NDCG@5:0.3046) [0.4 s] *
INFO:root:Epoch 17    loss=0.2370 [11.4 s]    dev=(HR@5:0.4161,NDCG@5:0.3024) [0.4 s]
INFO:root:Epoch 18    loss=0.2322 [11.5 s]    dev=(HR@5:0.4225,NDCG@5:0.3068) [0.4 s] *
INFO:root:Epoch 19    loss=0.2289 [10.1 s]    dev=(HR@5:0.4240,NDCG@5:0.3089) [0.4 s] *
INFO:root:Epoch 20    loss=0.2266 [10.1 s]    dev=(HR@5:0.4244,NDCG@5:0.3113) [0.4 s] *
INFO:root:Epoch 21    loss=0.2217 [11.0 s]    dev=(HR@5:0.4271,NDCG@5:0.3112) [0.4 s]
INFO:root:Epoch 22    loss=0.2217 [11.0 s]    dev=(HR@5:0.4268,NDCG@5:0.3112) [0.4 s]
INFO:root:Epoch 23    loss=0.2213 [10.7 s]    dev=(HR@5:0.4204,NDCG@5:0.3068) [0.4 s]
INFO:root:Epoch 24    loss=0.2201 [11.0 s]    dev=(HR@5:0.4266,NDCG@5:0.3102) [0.4 s]
INFO:root:Epoch 25    loss=0.2168 [10.8 s]    dev=(HR@5:0.4213,NDCG@5:0.3077) [0.4 s]
INFO:root:Epoch 26    loss=0.2173 [10.5 s]    dev=(HR@5:0.4282,NDCG@5:0.3123) [0.4 s] *
INFO:root:Epoch 27    loss=0.2160 [10.9 s]    dev=(HR@5:0.4284,NDCG@5:0.3124) [0.4 s] *
INFO:root:Epoch 28    loss=0.2145 [10.9 s]    dev=(HR@5:0.4281,NDCG@5:0.3136) [0.4 s] *
INFO:root:Epoch 29    loss=0.2132 [10.3 s]    dev=(HR@5:0.4280,NDCG@5:0.3101) [0.4 s]
INFO:root:Epoch 30    loss=0.2122 [11.2 s]    dev=(HR@5:0.4280,NDCG@5:0.3128) [0.4 s]
INFO:root:Epoch 31    loss=0.2111 [11.4 s]    dev=(HR@5:0.4299,NDCG@5:0.3151) [0.4 s] *
INFO:root:Epoch 32    loss=0.2122 [11.1 s]    dev=(HR@5:0.4293,NDCG@5:0.3127) [0.4 s]
INFO:root:Epoch 33    loss=0.2108 [11.1 s]    dev=(HR@5:0.4297,NDCG@5:0.3138) [0.4 s]
INFO:root:Epoch 34    loss=0.2089 [10.9 s]    dev=(HR@5:0.4289,NDCG@5:0.3121) [0.4 s]
INFO:root:Epoch 35    loss=0.2105 [11.1 s]    dev=(HR@5:0.4299,NDCG@5:0.3134) [0.4 s]
INFO:root:Epoch 36    loss=0.2078 [11.2 s]    dev=(HR@5:0.4293,NDCG@5:0.3129) [0.4 s]
INFO:root:Epoch 37    loss=0.2075 [11.2 s]    dev=(HR@5:0.4296,NDCG@5:0.3122) [0.4 s]
INFO:root:Epoch 38    loss=0.2086 [11.3 s]    dev=(HR@5:0.4286,NDCG@5:0.3105) [0.4 s]
INFO:root:Epoch 39    loss=0.2072 [10.6 s]    dev=(HR@5:0.4256,NDCG@5:0.3080) [0.4 s]
INFO:root:Epoch 40    loss=0.2072 [10.3 s]    dev=(HR@5:0.4253,NDCG@5:0.3114) [0.4 s]
INFO:root:Epoch 41    loss=0.2074 [11.4 s]    dev=(HR@5:0.4321,NDCG@5:0.3132) [0.4 s]
INFO:root:Epoch 42    loss=0.2075 [11.3 s]    dev=(HR@5:0.4307,NDCG@5:0.3134) [0.4 s]
INFO:root:Epoch 43    loss=0.2047 [11.6 s]    dev=(HR@5:0.4274,NDCG@5:0.3132) [0.3 s]
INFO:root:Epoch 44    loss=0.2060 [11.2 s]    dev=(HR@5:0.4311,NDCG@5:0.3147) [0.4 s]
INFO:root:Epoch 45    loss=0.2019 [10.8 s]    dev=(HR@5:0.4327,NDCG@5:0.3172) [0.4 s] *
INFO:root:Epoch 46    loss=0.2044 [11.2 s]    dev=(HR@5:0.4257,NDCG@5:0.3118) [0.4 s]
INFO:root:Epoch 47    loss=0.2048 [11.1 s]    dev=(HR@5:0.4276,NDCG@5:0.3121) [0.4 s]
INFO:root:Epoch 48    loss=0.2017 [11.0 s]    dev=(HR@5:0.4197,NDCG@5:0.3048) [0.4 s]
INFO:root:Epoch 49    loss=0.2024 [11.1 s]    dev=(HR@5:0.4319,NDCG@5:0.3142) [0.4 s]
INFO:root:Epoch 50    loss=0.2021 [11.1 s]    dev=(HR@5:0.4246,NDCG@5:0.3100) [0.4 s]
INFO:root:Epoch 51    loss=0.2017 [10.9 s]    dev=(HR@5:0.4285,NDCG@5:0.3130) [0.5 s]
INFO:root:Epoch 52    loss=0.2008 [10.8 s]    dev=(HR@5:0.4219,NDCG@5:0.3081) [0.4 s]
INFO:root:Epoch 53    loss=0.2009 [11.4 s]    dev=(HR@5:0.4274,NDCG@5:0.3117) [0.4 s]
INFO:root:Epoch 54    loss=0.1988 [11.6 s]    dev=(HR@5:0.4271,NDCG@5:0.3123) [0.4 s]
INFO:root:Epoch 55    loss=0.1987 [11.1 s]    dev=(HR@5:0.4248,NDCG@5:0.3094) [0.4 s]
INFO:root:Epoch 56    loss=0.1977 [10.9 s]    dev=(HR@5:0.4259,NDCG@5:0.3126) [0.4 s]
INFO:root:Epoch 57    loss=0.1991 [11.1 s]    dev=(HR@5:0.4291,NDCG@5:0.3135) [0.4 s]
INFO:root:Epoch 58    loss=0.1993 [11.5 s]    dev=(HR@5:0.4304,NDCG@5:0.3131) [0.4 s]
INFO:root:Epoch 59    loss=0.1974 [11.2 s]    dev=(HR@5:0.4333,NDCG@5:0.3166) [0.4 s]
INFO:root:Epoch 60    loss=0.1985 [11.2 s]    dev=(HR@5:0.4277,NDCG@5:0.3133) [0.4 s]
INFO:root:Epoch 61    loss=0.1979 [11.3 s]    dev=(HR@5:0.4304,NDCG@5:0.3150) [0.4 s]
INFO:root:Epoch 62    loss=0.1970 [11.0 s]    dev=(HR@5:0.4308,NDCG@5:0.3146) [0.4 s]
INFO:root:Epoch 63    loss=0.1976 [11.4 s]    dev=(HR@5:0.4301,NDCG@5:0.3147) [0.4 s]
INFO:root:Epoch 64    loss=0.1979 [11.2 s]    dev=(HR@5:0.4277,NDCG@5:0.3100) [0.4 s]
INFO:root:Epoch 65    loss=0.1983 [11.6 s]    dev=(HR@5:0.4289,NDCG@5:0.3127) [0.4 s]
INFO:root:Early stop at 65 based on dev result.
INFO:root:
Best Iter(dev)=   45	 dev=(HR@5:0.4327,NDCG@5:0.3172) [747.2 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.3808,NDCG@5:0.2710,HR@10:0.4872,NDCG@10:0.3054,HR@20:0.6120,NDCG@20:0.3368,HR@50:0.8204,NDCG@50:0.3780)
INFO:root:
--------------------------------------------- END: 2024-12-22 20:48:27 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-22 21:10:03 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [13.0 s]    dev=(HR@5:0.2503,NDCG@5:0.1664) [0.4 s] *
INFO:root:Epoch 2     loss=0.4330 [11.4 s]    dev=(HR@5:0.3197,NDCG@5:0.2167) [0.4 s] *
INFO:root:Epoch 3     loss=0.3997 [10.7 s]    dev=(HR@5:0.3404,NDCG@5:0.2295) [0.4 s] *
INFO:root:Epoch 4     loss=0.3820 [11.2 s]    dev=(HR@5:0.3612,NDCG@5:0.2494) [0.4 s] *
INFO:root:Epoch 5     loss=0.3586 [11.2 s]    dev=(HR@5:0.3742,NDCG@5:0.2592) [0.4 s] *
INFO:root:Epoch 6     loss=0.3356 [11.3 s]    dev=(HR@5:0.3902,NDCG@5:0.2756) [0.4 s] *
INFO:root:Epoch 7     loss=0.3170 [11.4 s]    dev=(HR@5:0.3988,NDCG@5:0.2821) [0.4 s] *
INFO:root:Epoch 8     loss=0.2990 [11.2 s]    dev=(HR@5:0.4043,NDCG@5:0.2906) [0.4 s] *
INFO:root:Epoch 9     loss=0.2825 [11.5 s]    dev=(HR@5:0.4050,NDCG@5:0.2922) [0.4 s] *
INFO:root:Epoch 10    loss=0.2723 [11.4 s]    dev=(HR@5:0.4113,NDCG@5:0.2963) [0.4 s] *
INFO:root:Epoch 11    loss=0.2601 [11.4 s]    dev=(HR@5:0.4182,NDCG@5:0.3007) [0.4 s] *
INFO:root:Epoch 12    loss=0.2522 [11.3 s]    dev=(HR@5:0.4228,NDCG@5:0.3057) [0.4 s] *
INFO:root:Epoch 13    loss=0.2472 [11.4 s]    dev=(HR@5:0.4236,NDCG@5:0.3078) [0.4 s] *
INFO:root:Epoch 14    loss=0.2410 [11.6 s]    dev=(HR@5:0.4231,NDCG@5:0.3072) [0.4 s]
INFO:root:Epoch 15    loss=0.2375 [11.1 s]    dev=(HR@5:0.4225,NDCG@5:0.3069) [0.4 s]
INFO:root:Epoch 16    loss=0.2338 [10.9 s]    dev=(HR@5:0.4230,NDCG@5:0.3088) [0.4 s] *
INFO:root:Epoch 17    loss=0.2300 [11.0 s]    dev=(HR@5:0.4224,NDCG@5:0.3084) [0.4 s]
INFO:root:Epoch 18    loss=0.2252 [10.9 s]    dev=(HR@5:0.4267,NDCG@5:0.3121) [0.4 s] *
INFO:root:Epoch 19    loss=0.2226 [11.2 s]    dev=(HR@5:0.4303,NDCG@5:0.3152) [0.4 s] *
INFO:root:Epoch 20    loss=0.2207 [11.1 s]    dev=(HR@5:0.4311,NDCG@5:0.3171) [0.4 s] *
INFO:root:Epoch 21    loss=0.2158 [11.2 s]    dev=(HR@5:0.4310,NDCG@5:0.3158) [0.4 s]
INFO:root:Epoch 22    loss=0.2149 [11.0 s]    dev=(HR@5:0.4328,NDCG@5:0.3169) [0.4 s]
INFO:root:Epoch 23    loss=0.2146 [11.2 s]    dev=(HR@5:0.4266,NDCG@5:0.3136) [0.4 s]
INFO:root:Epoch 24    loss=0.2143 [11.3 s]    dev=(HR@5:0.4336,NDCG@5:0.3176) [0.4 s] *
INFO:root:Epoch 25    loss=0.2101 [11.3 s]    dev=(HR@5:0.4292,NDCG@5:0.3146) [0.4 s]
INFO:root:Epoch 26    loss=0.2109 [11.0 s]    dev=(HR@5:0.4340,NDCG@5:0.3188) [0.4 s] *
INFO:root:Epoch 27    loss=0.2101 [11.0 s]    dev=(HR@5:0.4356,NDCG@5:0.3206) [0.4 s] *
INFO:root:Epoch 28    loss=0.2087 [11.3 s]    dev=(HR@5:0.4402,NDCG@5:0.3223) [0.4 s] *
INFO:root:Epoch 29    loss=0.2080 [11.3 s]    dev=(HR@5:0.4327,NDCG@5:0.3163) [0.4 s]
INFO:root:Epoch 30    loss=0.2070 [11.3 s]    dev=(HR@5:0.4365,NDCG@5:0.3206) [0.4 s]
INFO:root:Epoch 31    loss=0.2059 [11.3 s]    dev=(HR@5:0.4350,NDCG@5:0.3193) [0.4 s]
INFO:root:Epoch 32    loss=0.2061 [11.3 s]    dev=(HR@5:0.4358,NDCG@5:0.3206) [0.4 s]
INFO:root:Epoch 33    loss=0.2056 [11.2 s]    dev=(HR@5:0.4387,NDCG@5:0.3222) [0.4 s]
INFO:root:Epoch 34    loss=0.2032 [11.4 s]    dev=(HR@5:0.4342,NDCG@5:0.3174) [0.4 s]
INFO:root:Epoch 35    loss=0.2048 [11.3 s]    dev=(HR@5:0.4340,NDCG@5:0.3174) [0.4 s]
INFO:root:Epoch 36    loss=0.2027 [11.6 s]    dev=(HR@5:0.4398,NDCG@5:0.3205) [0.4 s]
INFO:root:Epoch 37    loss=0.2023 [11.3 s]    dev=(HR@5:0.4379,NDCG@5:0.3208) [0.4 s]
INFO:root:Epoch 38    loss=0.2031 [11.5 s]    dev=(HR@5:0.4358,NDCG@5:0.3201) [0.4 s]
INFO:root:Epoch 39    loss=0.2023 [11.2 s]    dev=(HR@5:0.4339,NDCG@5:0.3176) [0.4 s]
INFO:root:Epoch 40    loss=0.2018 [11.2 s]    dev=(HR@5:0.4359,NDCG@5:0.3214) [0.4 s]
INFO:root:Epoch 41    loss=0.2018 [10.8 s]    dev=(HR@5:0.4370,NDCG@5:0.3194) [0.4 s]
INFO:root:Epoch 42    loss=0.2023 [11.1 s]    dev=(HR@5:0.4387,NDCG@5:0.3205) [0.4 s]
INFO:root:Epoch 43    loss=0.2003 [10.8 s]    dev=(HR@5:0.4392,NDCG@5:0.3226) [0.4 s] *
INFO:root:Epoch 44    loss=0.2013 [11.3 s]    dev=(HR@5:0.4369,NDCG@5:0.3203) [0.4 s]
INFO:root:Epoch 45    loss=0.1980 [11.3 s]    dev=(HR@5:0.4446,NDCG@5:0.3275) [0.4 s] *
INFO:root:Epoch 46    loss=0.1999 [11.4 s]    dev=(HR@5:0.4363,NDCG@5:0.3206) [0.4 s]
INFO:root:Epoch 47    loss=0.2008 [11.2 s]    dev=(HR@5:0.4391,NDCG@5:0.3209) [0.4 s]
INFO:root:Epoch 48    loss=0.1979 [11.5 s]    dev=(HR@5:0.4335,NDCG@5:0.3159) [0.4 s]
INFO:root:Epoch 49    loss=0.1970 [11.0 s]    dev=(HR@5:0.4414,NDCG@5:0.3239) [0.4 s]
INFO:root:Epoch 50    loss=0.1983 [11.1 s]    dev=(HR@5:0.4362,NDCG@5:0.3209) [0.4 s]
INFO:root:Epoch 51    loss=0.1978 [11.3 s]    dev=(HR@5:0.4380,NDCG@5:0.3214) [0.4 s]
INFO:root:Epoch 52    loss=0.1975 [11.3 s]    dev=(HR@5:0.4378,NDCG@5:0.3201) [0.4 s]
INFO:root:Epoch 53    loss=0.1968 [11.6 s]    dev=(HR@5:0.4360,NDCG@5:0.3204) [0.4 s]
INFO:root:Epoch 54    loss=0.1944 [10.6 s]    dev=(HR@5:0.4396,NDCG@5:0.3222) [0.4 s]
INFO:root:Epoch 55    loss=0.1949 [11.3 s]    dev=(HR@5:0.4385,NDCG@5:0.3201) [0.4 s]
INFO:root:Epoch 56    loss=0.1944 [11.4 s]    dev=(HR@5:0.4412,NDCG@5:0.3235) [0.4 s]
INFO:root:Epoch 57    loss=0.1946 [11.4 s]    dev=(HR@5:0.4402,NDCG@5:0.3242) [0.4 s]
INFO:root:Epoch 58    loss=0.1958 [10.5 s]    dev=(HR@5:0.4380,NDCG@5:0.3215) [0.4 s]
INFO:root:Epoch 59    loss=0.1940 [10.7 s]    dev=(HR@5:0.4387,NDCG@5:0.3223) [0.4 s]
INFO:root:Epoch 60    loss=0.1946 [11.4 s]    dev=(HR@5:0.4402,NDCG@5:0.3224) [0.4 s]
INFO:root:Epoch 61    loss=0.1947 [11.2 s]    dev=(HR@5:0.4400,NDCG@5:0.3228) [0.4 s]
INFO:root:Epoch 62    loss=0.1937 [11.4 s]    dev=(HR@5:0.4368,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 63    loss=0.1946 [11.3 s]    dev=(HR@5:0.4410,NDCG@5:0.3247) [0.4 s]
INFO:root:Epoch 64    loss=0.1940 [10.8 s]    dev=(HR@5:0.4401,NDCG@5:0.3220) [0.4 s]
INFO:root:Epoch 65    loss=0.1947 [11.1 s]    dev=(HR@5:0.4413,NDCG@5:0.3238) [0.4 s]
INFO:root:Early stop at 65 based on dev result.
INFO:root:
Best Iter(dev)=   45	 dev=(HR@5:0.4446,NDCG@5:0.3275) [755.7 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.3905,NDCG@5:0.2801,HR@10:0.4995,NDCG@10:0.3152,HR@20:0.6204,NDCG@20:0.3456,HR@50:0.8246,NDCG@50:0.3861)
INFO:root:
--------------------------------------------- END: 2024-12-22 21:22:42 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-22 21:57:38 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5165 [12.5 s]    dev=(HR@5:0.2501,NDCG@5:0.1663) [0.4 s] *
INFO:root:Epoch 2     loss=0.4330 [10.8 s]    dev=(HR@5:0.3210,NDCG@5:0.2173) [0.4 s] *
INFO:root:Epoch 3     loss=0.3998 [11.3 s]    dev=(HR@5:0.3394,NDCG@5:0.2286) [0.4 s] *
INFO:root:Epoch 4     loss=0.3834 [11.2 s]    dev=(HR@5:0.3570,NDCG@5:0.2455) [0.4 s] *
INFO:root:Epoch 5     loss=0.3606 [11.3 s]    dev=(HR@5:0.3725,NDCG@5:0.2578) [0.4 s] *
INFO:root:Epoch 6     loss=0.3365 [11.2 s]    dev=(HR@5:0.3895,NDCG@5:0.2754) [0.4 s] *
INFO:root:Epoch 7     loss=0.3167 [11.3 s]    dev=(HR@5:0.3996,NDCG@5:0.2832) [0.4 s] *
INFO:root:Epoch 8     loss=0.2980 [11.1 s]    dev=(HR@5:0.4063,NDCG@5:0.2918) [0.4 s] *
INFO:root:Epoch 9     loss=0.2814 [11.1 s]    dev=(HR@5:0.4092,NDCG@5:0.2953) [0.4 s] *
INFO:root:Epoch 10    loss=0.2712 [11.2 s]    dev=(HR@5:0.4118,NDCG@5:0.2971) [0.4 s] *
INFO:root:Epoch 11    loss=0.2592 [11.1 s]    dev=(HR@5:0.4185,NDCG@5:0.3021) [0.4 s] *
INFO:root:Epoch 12    loss=0.2512 [11.0 s]    dev=(HR@5:0.4225,NDCG@5:0.3069) [0.4 s] *
INFO:root:Epoch 13    loss=0.2461 [10.4 s]    dev=(HR@5:0.4246,NDCG@5:0.3098) [0.4 s] *
INFO:root:Epoch 14    loss=0.2400 [11.1 s]    dev=(HR@5:0.4242,NDCG@5:0.3087) [0.4 s]
INFO:root:Epoch 15    loss=0.2365 [10.9 s]    dev=(HR@5:0.4240,NDCG@5:0.3083) [0.4 s]
INFO:root:Epoch 16    loss=0.2326 [10.6 s]    dev=(HR@5:0.4245,NDCG@5:0.3114) [0.4 s] *
INFO:root:Epoch 17    loss=0.2290 [11.2 s]    dev=(HR@5:0.4248,NDCG@5:0.3104) [0.4 s]
INFO:root:Epoch 18    loss=0.2244 [11.1 s]    dev=(HR@5:0.4268,NDCG@5:0.3130) [0.4 s] *
INFO:root:Epoch 19    loss=0.2215 [11.3 s]    dev=(HR@5:0.4274,NDCG@5:0.3152) [0.4 s] *
INFO:root:Epoch 20    loss=0.2195 [11.2 s]    dev=(HR@5:0.4306,NDCG@5:0.3170) [0.4 s] *
INFO:root:Epoch 21    loss=0.2149 [11.3 s]    dev=(HR@5:0.4293,NDCG@5:0.3156) [0.4 s]
INFO:root:Epoch 22    loss=0.2137 [10.9 s]    dev=(HR@5:0.4310,NDCG@5:0.3169) [0.4 s]
INFO:root:Epoch 23    loss=0.2136 [11.4 s]    dev=(HR@5:0.4264,NDCG@5:0.3142) [0.4 s]
INFO:root:Epoch 24    loss=0.2133 [11.1 s]    dev=(HR@5:0.4314,NDCG@5:0.3167) [0.4 s]
INFO:root:Epoch 25    loss=0.2093 [10.7 s]    dev=(HR@5:0.4286,NDCG@5:0.3140) [0.4 s]
INFO:root:Epoch 26    loss=0.2095 [11.5 s]    dev=(HR@5:0.4289,NDCG@5:0.3158) [0.4 s]
INFO:root:Epoch 27    loss=0.2093 [11.6 s]    dev=(HR@5:0.4336,NDCG@5:0.3186) [0.4 s] *
INFO:root:Epoch 28    loss=0.2077 [11.3 s]    dev=(HR@5:0.4344,NDCG@5:0.3205) [0.4 s] *
INFO:root:Epoch 29    loss=0.2063 [11.2 s]    dev=(HR@5:0.4304,NDCG@5:0.3149) [0.4 s]
INFO:root:Epoch 30    loss=0.2059 [11.4 s]    dev=(HR@5:0.4338,NDCG@5:0.3196) [0.4 s]
INFO:root:Epoch 31    loss=0.2045 [11.4 s]    dev=(HR@5:0.4325,NDCG@5:0.3189) [0.4 s]
INFO:root:Epoch 32    loss=0.2048 [11.1 s]    dev=(HR@5:0.4333,NDCG@5:0.3198) [0.4 s]
INFO:root:Epoch 33    loss=0.2038 [11.1 s]    dev=(HR@5:0.4337,NDCG@5:0.3203) [0.4 s]
INFO:root:Epoch 34    loss=0.2020 [11.4 s]    dev=(HR@5:0.4313,NDCG@5:0.3168) [0.4 s]
INFO:root:Epoch 35    loss=0.2030 [10.6 s]    dev=(HR@5:0.4321,NDCG@5:0.3165) [0.4 s]
INFO:root:Epoch 36    loss=0.2007 [11.3 s]    dev=(HR@5:0.4344,NDCG@5:0.3176) [0.4 s]
INFO:root:Epoch 37    loss=0.1997 [11.2 s]    dev=(HR@5:0.4353,NDCG@5:0.3190) [0.4 s]
INFO:root:Epoch 38    loss=0.2003 [11.2 s]    dev=(HR@5:0.4340,NDCG@5:0.3179) [0.4 s]
INFO:root:Epoch 39    loss=0.1997 [11.1 s]    dev=(HR@5:0.4305,NDCG@5:0.3145) [0.4 s]
INFO:root:Epoch 40    loss=0.1992 [11.3 s]    dev=(HR@5:0.4345,NDCG@5:0.3197) [0.4 s]
INFO:root:Epoch 41    loss=0.1991 [10.2 s]    dev=(HR@5:0.4335,NDCG@5:0.3176) [0.4 s]
INFO:root:Epoch 42    loss=0.1991 [11.1 s]    dev=(HR@5:0.4385,NDCG@5:0.3211) [0.4 s] *
INFO:root:Epoch 43    loss=0.1973 [11.0 s]    dev=(HR@5:0.4361,NDCG@5:0.3219) [0.4 s] *
INFO:root:Epoch 44    loss=0.1983 [11.3 s]    dev=(HR@5:0.4343,NDCG@5:0.3184) [0.4 s]
INFO:root:Epoch 45    loss=0.1945 [11.3 s]    dev=(HR@5:0.4399,NDCG@5:0.3243) [0.4 s] *
INFO:root:Epoch 46    loss=0.1956 [11.3 s]    dev=(HR@5:0.4327,NDCG@5:0.3187) [0.4 s]
INFO:root:Epoch 47    loss=0.1973 [11.4 s]    dev=(HR@5:0.4343,NDCG@5:0.3196) [0.4 s]
INFO:root:Epoch 48    loss=0.1945 [11.5 s]    dev=(HR@5:0.4346,NDCG@5:0.3179) [0.4 s]
INFO:root:Epoch 49    loss=0.1937 [11.4 s]    dev=(HR@5:0.4400,NDCG@5:0.3243) [0.4 s] *
INFO:root:Epoch 50    loss=0.1951 [11.3 s]    dev=(HR@5:0.4333,NDCG@5:0.3197) [0.4 s]
INFO:root:Epoch 51    loss=0.1944 [10.7 s]    dev=(HR@5:0.4373,NDCG@5:0.3224) [0.4 s]
INFO:root:Epoch 52    loss=0.1939 [11.4 s]    dev=(HR@5:0.4380,NDCG@5:0.3204) [0.4 s]
INFO:root:Epoch 53    loss=0.1942 [11.3 s]    dev=(HR@5:0.4379,NDCG@5:0.3212) [0.4 s]
INFO:root:Epoch 54    loss=0.1912 [10.8 s]    dev=(HR@5:0.4389,NDCG@5:0.3226) [0.4 s]
INFO:root:Epoch 55    loss=0.1917 [11.0 s]    dev=(HR@5:0.4371,NDCG@5:0.3196) [0.4 s]
INFO:root:Epoch 56    loss=0.1909 [11.6 s]    dev=(HR@5:0.4365,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 57    loss=0.1919 [11.0 s]    dev=(HR@5:0.4410,NDCG@5:0.3257) [0.4 s] *
INFO:root:Epoch 58    loss=0.1932 [11.0 s]    dev=(HR@5:0.4380,NDCG@5:0.3231) [0.4 s]
INFO:root:Epoch 59    loss=0.1904 [11.1 s]    dev=(HR@5:0.4361,NDCG@5:0.3212) [0.4 s]
INFO:root:Epoch 60    loss=0.1910 [11.3 s]    dev=(HR@5:0.4398,NDCG@5:0.3234) [0.4 s]
INFO:root:Epoch 61    loss=0.1913 [11.0 s]    dev=(HR@5:0.4425,NDCG@5:0.3251) [0.4 s]
INFO:root:Epoch 62    loss=0.1906 [11.3 s]    dev=(HR@5:0.4380,NDCG@5:0.3229) [0.4 s]
INFO:root:Epoch 63    loss=0.1918 [10.8 s]    dev=(HR@5:0.4442,NDCG@5:0.3263) [0.4 s] *
INFO:root:Epoch 64    loss=0.1910 [10.2 s]    dev=(HR@5:0.4394,NDCG@5:0.3228) [0.4 s]
INFO:root:Epoch 65    loss=0.1915 [11.4 s]    dev=(HR@5:0.4392,NDCG@5:0.3229) [0.4 s]
INFO:root:Epoch 66    loss=0.1902 [11.2 s]    dev=(HR@5:0.4419,NDCG@5:0.3231) [0.4 s]
INFO:root:Epoch 67    loss=0.1896 [11.2 s]    dev=(HR@5:0.4403,NDCG@5:0.3227) [0.4 s]
INFO:root:Epoch 68    loss=0.1883 [11.3 s]    dev=(HR@5:0.4423,NDCG@5:0.3252) [0.4 s]
INFO:root:Epoch 69    loss=0.1896 [11.3 s]    dev=(HR@5:0.4377,NDCG@5:0.3218) [0.4 s]
INFO:root:Epoch 70    loss=0.1895 [11.1 s]    dev=(HR@5:0.4405,NDCG@5:0.3253) [0.4 s]
INFO:root:Epoch 71    loss=0.1889 [11.2 s]    dev=(HR@5:0.4391,NDCG@5:0.3229) [0.4 s]
INFO:root:Epoch 72    loss=0.1881 [10.2 s]    dev=(HR@5:0.4378,NDCG@5:0.3207) [0.4 s]
INFO:root:Epoch 73    loss=0.1881 [10.8 s]    dev=(HR@5:0.4417,NDCG@5:0.3237) [0.4 s]
INFO:root:Epoch 74    loss=0.1889 [11.1 s]    dev=(HR@5:0.4391,NDCG@5:0.3208) [0.4 s]
INFO:root:Epoch 75    loss=0.1904 [11.3 s]    dev=(HR@5:0.4382,NDCG@5:0.3237) [0.4 s]
INFO:root:Epoch 76    loss=0.1894 [10.9 s]    dev=(HR@5:0.4379,NDCG@5:0.3234) [0.4 s]
INFO:root:Epoch 77    loss=0.1876 [10.2 s]    dev=(HR@5:0.4403,NDCG@5:0.3252) [0.4 s]
INFO:root:Epoch 78    loss=0.1873 [9.8 s]    dev=(HR@5:0.4372,NDCG@5:0.3210) [0.4 s]
INFO:root:Epoch 79    loss=0.1887 [9.9 s]    dev=(HR@5:0.4425,NDCG@5:0.3267) [0.4 s] *
INFO:root:Epoch 80    loss=0.1872 [10.6 s]    dev=(HR@5:0.4442,NDCG@5:0.3243) [0.4 s]
INFO:root:Epoch 81    loss=0.1871 [10.2 s]    dev=(HR@5:0.4377,NDCG@5:0.3197) [0.4 s]
INFO:root:Epoch 82    loss=0.1882 [11.2 s]    dev=(HR@5:0.4392,NDCG@5:0.3226) [0.4 s]
INFO:root:Epoch 83    loss=0.1874 [11.3 s]    dev=(HR@5:0.4408,NDCG@5:0.3244) [0.4 s]
INFO:root:Epoch 84    loss=0.1881 [11.1 s]    dev=(HR@5:0.4403,NDCG@5:0.3253) [0.4 s]
INFO:root:Epoch 85    loss=0.1885 [11.2 s]    dev=(HR@5:0.4404,NDCG@5:0.3237) [0.4 s]
INFO:root:Epoch 86    loss=0.1885 [10.8 s]    dev=(HR@5:0.4392,NDCG@5:0.3239) [0.4 s]
INFO:root:Epoch 87    loss=0.1869 [11.1 s]    dev=(HR@5:0.4353,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 88    loss=0.1866 [10.8 s]    dev=(HR@5:0.4427,NDCG@5:0.3245) [0.4 s]
INFO:root:Epoch 89    loss=0.1862 [11.6 s]    dev=(HR@5:0.4406,NDCG@5:0.3238) [0.4 s]
INFO:root:Epoch 90    loss=0.1860 [11.1 s]    dev=(HR@5:0.4393,NDCG@5:0.3225) [0.4 s]
INFO:root:Epoch 91    loss=0.1861 [11.1 s]    dev=(HR@5:0.4430,NDCG@5:0.3259) [0.4 s]
INFO:root:Epoch 92    loss=0.1846 [11.1 s]    dev=(HR@5:0.4406,NDCG@5:0.3218) [0.4 s]
INFO:root:Epoch 93    loss=0.1873 [11.2 s]    dev=(HR@5:0.4425,NDCG@5:0.3231) [0.4 s]
INFO:root:Epoch 94    loss=0.1860 [11.4 s]    dev=(HR@5:0.4427,NDCG@5:0.3256) [0.4 s]
INFO:root:Epoch 95    loss=0.1867 [11.3 s]    dev=(HR@5:0.4405,NDCG@5:0.3243) [0.4 s]
INFO:root:Epoch 96    loss=0.1845 [11.4 s]    dev=(HR@5:0.4388,NDCG@5:0.3242) [0.4 s]
INFO:root:Epoch 97    loss=0.1857 [11.2 s]    dev=(HR@5:0.4326,NDCG@5:0.3173) [0.4 s]
INFO:root:Epoch 98    loss=0.1844 [11.6 s]    dev=(HR@5:0.4320,NDCG@5:0.3170) [0.4 s]
INFO:root:Epoch 99    loss=0.1857 [11.0 s]    dev=(HR@5:0.4400,NDCG@5:0.3233) [0.4 s]
INFO:root:Early stop at 99 based on dev result.
INFO:root:
Best Iter(dev)=   79	 dev=(HR@5:0.4425,NDCG@5:0.3267) [1137.2 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.3979,NDCG@5:0.2861,HR@10:0.5062,NDCG@10:0.3213,HR@20:0.6304,NDCG@20:0.3525,HR@50:0.8364,NDCG@50:0.3934)
INFO:root:
--------------------------------------------- END: 2024-12-22 22:16:38 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-22 22:47:19 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5165 [12.8 s]    dev=(HR@5:0.2505,NDCG@5:0.1665) [0.4 s] *
INFO:root:Epoch 2     loss=0.4330 [11.2 s]    dev=(HR@5:0.3210,NDCG@5:0.2174) [0.4 s] *
INFO:root:Epoch 3     loss=0.3998 [11.5 s]    dev=(HR@5:0.3399,NDCG@5:0.2290) [0.4 s] *
INFO:root:Epoch 4     loss=0.3833 [11.3 s]    dev=(HR@5:0.3550,NDCG@5:0.2443) [0.4 s] *
INFO:root:Epoch 5     loss=0.3608 [11.0 s]    dev=(HR@5:0.3719,NDCG@5:0.2571) [0.4 s] *
INFO:root:Epoch 6     loss=0.3364 [10.9 s]    dev=(HR@5:0.3898,NDCG@5:0.2752) [0.4 s] *
INFO:root:Epoch 7     loss=0.3165 [11.3 s]    dev=(HR@5:0.3970,NDCG@5:0.2816) [0.4 s] *
INFO:root:Epoch 8     loss=0.2979 [11.4 s]    dev=(HR@5:0.4057,NDCG@5:0.2911) [0.4 s] *
INFO:root:Epoch 9     loss=0.2816 [11.5 s]    dev=(HR@5:0.4079,NDCG@5:0.2942) [0.4 s] *
INFO:root:Epoch 10    loss=0.2712 [11.5 s]    dev=(HR@5:0.4120,NDCG@5:0.2969) [0.4 s] *
INFO:root:Epoch 11    loss=0.2593 [11.7 s]    dev=(HR@5:0.4186,NDCG@5:0.3019) [0.4 s] *
INFO:root:Epoch 12    loss=0.2510 [11.4 s]    dev=(HR@5:0.4219,NDCG@5:0.3063) [0.4 s] *
INFO:root:Epoch 13    loss=0.2461 [11.3 s]    dev=(HR@5:0.4245,NDCG@5:0.3097) [0.4 s] *
INFO:root:Epoch 14    loss=0.2402 [11.6 s]    dev=(HR@5:0.4240,NDCG@5:0.3087) [0.4 s]
INFO:root:Epoch 15    loss=0.2366 [11.0 s]    dev=(HR@5:0.4242,NDCG@5:0.3076) [0.4 s]
INFO:root:Epoch 16    loss=0.2326 [11.3 s]    dev=(HR@5:0.4244,NDCG@5:0.3113) [0.4 s] *
INFO:root:Epoch 17    loss=0.2290 [11.0 s]    dev=(HR@5:0.4219,NDCG@5:0.3095) [0.4 s]
INFO:root:Epoch 18    loss=0.2242 [11.5 s]    dev=(HR@5:0.4282,NDCG@5:0.3138) [0.4 s] *
INFO:root:Epoch 19    loss=0.2215 [11.1 s]    dev=(HR@5:0.4286,NDCG@5:0.3158) [0.4 s] *
INFO:root:Epoch 20    loss=0.2194 [11.3 s]    dev=(HR@5:0.4314,NDCG@5:0.3174) [0.4 s] *
INFO:root:Epoch 21    loss=0.2148 [11.2 s]    dev=(HR@5:0.4296,NDCG@5:0.3161) [0.4 s]
INFO:root:Epoch 22    loss=0.2138 [11.5 s]    dev=(HR@5:0.4326,NDCG@5:0.3176) [0.4 s] *
INFO:root:Epoch 23    loss=0.2135 [10.7 s]    dev=(HR@5:0.4267,NDCG@5:0.3144) [0.4 s]
INFO:root:Epoch 24    loss=0.2132 [10.7 s]    dev=(HR@5:0.4316,NDCG@5:0.3170) [0.4 s]
INFO:root:Epoch 25    loss=0.2093 [11.2 s]    dev=(HR@5:0.4306,NDCG@5:0.3160) [0.4 s]
INFO:root:Epoch 26    loss=0.2094 [11.6 s]    dev=(HR@5:0.4301,NDCG@5:0.3174) [0.4 s]
INFO:root:Epoch 27    loss=0.2093 [11.4 s]    dev=(HR@5:0.4329,NDCG@5:0.3185) [0.4 s] *
INFO:root:Epoch 28    loss=0.2076 [9.7 s]    dev=(HR@5:0.4362,NDCG@5:0.3221) [0.4 s] *
INFO:root:Epoch 29    loss=0.2063 [10.5 s]    dev=(HR@5:0.4321,NDCG@5:0.3165) [0.4 s]
INFO:root:Epoch 30    loss=0.2058 [11.9 s]    dev=(HR@5:0.4346,NDCG@5:0.3206) [0.4 s]
INFO:root:Epoch 31    loss=0.2044 [11.4 s]    dev=(HR@5:0.4331,NDCG@5:0.3196) [0.4 s]
INFO:root:Epoch 32    loss=0.2046 [11.8 s]    dev=(HR@5:0.4347,NDCG@5:0.3206) [0.4 s]
INFO:root:Epoch 33    loss=0.2036 [11.9 s]    dev=(HR@5:0.4361,NDCG@5:0.3219) [0.4 s]
INFO:root:Epoch 34    loss=0.2018 [11.0 s]    dev=(HR@5:0.4334,NDCG@5:0.3180) [0.4 s]
INFO:root:Epoch 35    loss=0.2029 [12.0 s]    dev=(HR@5:0.4339,NDCG@5:0.3183) [0.4 s]
INFO:root:Epoch 36    loss=0.2006 [11.1 s]    dev=(HR@5:0.4363,NDCG@5:0.3197) [0.4 s]
INFO:root:Epoch 37    loss=0.1993 [11.9 s]    dev=(HR@5:0.4366,NDCG@5:0.3211) [0.4 s]
INFO:root:Epoch 38    loss=0.2001 [11.7 s]    dev=(HR@5:0.4380,NDCG@5:0.3210) [0.4 s]
INFO:root:Epoch 39    loss=0.1994 [11.6 s]    dev=(HR@5:0.4340,NDCG@5:0.3172) [0.4 s]
INFO:root:Epoch 40    loss=0.1987 [11.8 s]    dev=(HR@5:0.4369,NDCG@5:0.3217) [0.4 s]
INFO:root:Epoch 41    loss=0.1987 [12.1 s]    dev=(HR@5:0.4373,NDCG@5:0.3204) [0.4 s]
INFO:root:Epoch 42    loss=0.1986 [12.0 s]    dev=(HR@5:0.4402,NDCG@5:0.3224) [0.4 s] *
INFO:root:Epoch 43    loss=0.1969 [11.9 s]    dev=(HR@5:0.4409,NDCG@5:0.3251) [0.4 s] *
INFO:root:Epoch 44    loss=0.1977 [12.0 s]    dev=(HR@5:0.4377,NDCG@5:0.3212) [0.4 s]
INFO:root:Epoch 45    loss=0.1942 [12.1 s]    dev=(HR@5:0.4415,NDCG@5:0.3269) [0.4 s] *
INFO:root:Epoch 46    loss=0.1951 [11.6 s]    dev=(HR@5:0.4382,NDCG@5:0.3227) [0.4 s]
INFO:root:Epoch 47    loss=0.1968 [11.7 s]    dev=(HR@5:0.4370,NDCG@5:0.3214) [0.4 s]
INFO:root:Epoch 48    loss=0.1939 [12.1 s]    dev=(HR@5:0.4340,NDCG@5:0.3185) [0.4 s]
INFO:root:Epoch 49    loss=0.1932 [11.6 s]    dev=(HR@5:0.4395,NDCG@5:0.3241) [0.4 s]
INFO:root:Epoch 50    loss=0.1945 [11.1 s]    dev=(HR@5:0.4351,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 51    loss=0.1939 [11.9 s]    dev=(HR@5:0.4374,NDCG@5:0.3227) [0.4 s]
INFO:root:Epoch 52    loss=0.1934 [11.9 s]    dev=(HR@5:0.4365,NDCG@5:0.3214) [0.4 s]
INFO:root:Epoch 53    loss=0.1935 [10.9 s]    dev=(HR@5:0.4376,NDCG@5:0.3221) [0.3 s]
INFO:root:Epoch 54    loss=0.1909 [11.4 s]    dev=(HR@5:0.4392,NDCG@5:0.3244) [0.4 s]
INFO:root:Epoch 55    loss=0.1915 [11.8 s]    dev=(HR@5:0.4405,NDCG@5:0.3224) [0.4 s]
INFO:root:Epoch 56    loss=0.1901 [11.9 s]    dev=(HR@5:0.4404,NDCG@5:0.3245) [0.4 s]
INFO:root:Epoch 57    loss=0.1918 [11.8 s]    dev=(HR@5:0.4410,NDCG@5:0.3256) [0.4 s]
INFO:root:Epoch 58    loss=0.1922 [12.1 s]    dev=(HR@5:0.4391,NDCG@5:0.3231) [0.4 s]
INFO:root:Epoch 59    loss=0.1903 [12.2 s]    dev=(HR@5:0.4404,NDCG@5:0.3235) [0.4 s]
INFO:root:Epoch 60    loss=0.1905 [12.1 s]    dev=(HR@5:0.4391,NDCG@5:0.3239) [0.4 s]
INFO:root:Epoch 61    loss=0.1911 [12.1 s]    dev=(HR@5:0.4441,NDCG@5:0.3270) [0.4 s] *
INFO:root:Epoch 62    loss=0.1904 [12.0 s]    dev=(HR@5:0.4402,NDCG@5:0.3250) [0.4 s]
INFO:root:Epoch 63    loss=0.1913 [11.9 s]    dev=(HR@5:0.4419,NDCG@5:0.3254) [0.4 s]
INFO:root:Epoch 64    loss=0.1903 [12.0 s]    dev=(HR@5:0.4406,NDCG@5:0.3223) [0.4 s]
INFO:root:Epoch 65    loss=0.1908 [11.8 s]    dev=(HR@5:0.4403,NDCG@5:0.3243) [0.4 s]
INFO:root:Epoch 66    loss=0.1897 [11.6 s]    dev=(HR@5:0.4413,NDCG@5:0.3242) [0.4 s]
INFO:root:Epoch 67    loss=0.1895 [11.7 s]    dev=(HR@5:0.4414,NDCG@5:0.3240) [0.4 s]
INFO:root:Epoch 68    loss=0.1877 [11.6 s]    dev=(HR@5:0.4422,NDCG@5:0.3250) [0.4 s]
INFO:root:Epoch 69    loss=0.1892 [11.9 s]    dev=(HR@5:0.4406,NDCG@5:0.3254) [0.4 s]
INFO:root:Epoch 70    loss=0.1884 [11.8 s]    dev=(HR@5:0.4396,NDCG@5:0.3249) [0.4 s]
INFO:root:Epoch 71    loss=0.1888 [11.7 s]    dev=(HR@5:0.4400,NDCG@5:0.3255) [0.3 s]
INFO:root:Epoch 72    loss=0.1882 [11.8 s]    dev=(HR@5:0.4408,NDCG@5:0.3233) [0.4 s]
INFO:root:Epoch 73    loss=0.1876 [11.3 s]    dev=(HR@5:0.4420,NDCG@5:0.3248) [0.4 s]
INFO:root:Epoch 74    loss=0.1885 [12.0 s]    dev=(HR@5:0.4375,NDCG@5:0.3198) [0.4 s]
INFO:root:Epoch 75    loss=0.1896 [11.9 s]    dev=(HR@5:0.4370,NDCG@5:0.3225) [0.4 s]
INFO:root:Epoch 76    loss=0.1886 [11.9 s]    dev=(HR@5:0.4363,NDCG@5:0.3224) [0.4 s]
INFO:root:Epoch 77    loss=0.1869 [10.6 s]    dev=(HR@5:0.4398,NDCG@5:0.3240) [0.4 s]
INFO:root:Epoch 78    loss=0.1867 [10.3 s]    dev=(HR@5:0.4359,NDCG@5:0.3209) [0.4 s]
INFO:root:Epoch 79    loss=0.1887 [12.0 s]    dev=(HR@5:0.4433,NDCG@5:0.3260) [0.4 s]
INFO:root:Epoch 80    loss=0.1867 [11.9 s]    dev=(HR@5:0.4410,NDCG@5:0.3219) [0.4 s]
INFO:root:Epoch 81    loss=0.1866 [11.8 s]    dev=(HR@5:0.4388,NDCG@5:0.3197) [0.4 s]
INFO:root:Early stop at 81 based on dev result.
INFO:root:
Best Iter(dev)=   61	 dev=(HR@5:0.4441,NDCG@5:0.3270) [968.0 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.3975,NDCG@5:0.2831,HR@10:0.5039,NDCG@10:0.3176,HR@20:0.6254,NDCG@20:0.3482,HR@50:0.8294,NDCG@50:0.3885)
INFO:root:
--------------------------------------------- END: 2024-12-22 23:03:30 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-22 23:38:32 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5165 [13.3 s]    dev=(HR@5:0.2506,NDCG@5:0.1666) [0.4 s] *
INFO:root:Epoch 2     loss=0.4329 [11.4 s]    dev=(HR@5:0.3207,NDCG@5:0.2172) [0.4 s] *
INFO:root:Epoch 3     loss=0.3998 [11.6 s]    dev=(HR@5:0.3402,NDCG@5:0.2294) [0.4 s] *
INFO:root:Epoch 4     loss=0.3830 [11.4 s]    dev=(HR@5:0.3556,NDCG@5:0.2448) [0.4 s] *
INFO:root:Epoch 5     loss=0.3608 [11.1 s]    dev=(HR@5:0.3705,NDCG@5:0.2554) [0.4 s] *
INFO:root:Epoch 6     loss=0.3371 [11.4 s]    dev=(HR@5:0.3885,NDCG@5:0.2738) [0.4 s] *
INFO:root:Epoch 7     loss=0.3167 [11.3 s]    dev=(HR@5:0.3951,NDCG@5:0.2805) [0.4 s] *
INFO:root:Epoch 8     loss=0.2979 [11.2 s]    dev=(HR@5:0.4062,NDCG@5:0.2905) [0.4 s] *
INFO:root:Epoch 9     loss=0.2811 [11.1 s]    dev=(HR@5:0.4081,NDCG@5:0.2938) [0.4 s] *
INFO:root:Epoch 10    loss=0.2706 [11.1 s]    dev=(HR@5:0.4133,NDCG@5:0.2976) [0.4 s] *
INFO:root:Epoch 11    loss=0.2584 [10.6 s]    dev=(HR@5:0.4199,NDCG@5:0.3025) [0.3 s] *
INFO:root:Epoch 12    loss=0.2504 [11.0 s]    dev=(HR@5:0.4232,NDCG@5:0.3062) [0.4 s] *
INFO:root:Epoch 13    loss=0.2458 [11.3 s]    dev=(HR@5:0.4249,NDCG@5:0.3099) [0.4 s] *
INFO:root:Epoch 14    loss=0.2398 [10.8 s]    dev=(HR@5:0.4239,NDCG@5:0.3084) [0.4 s]
INFO:root:Epoch 15    loss=0.2370 [10.3 s]    dev=(HR@5:0.4241,NDCG@5:0.3079) [0.4 s]
INFO:root:Epoch 16    loss=0.2330 [11.1 s]    dev=(HR@5:0.4251,NDCG@5:0.3105) [0.4 s] *
INFO:root:Epoch 17    loss=0.2291 [11.1 s]    dev=(HR@5:0.4242,NDCG@5:0.3104) [0.4 s]
INFO:root:Epoch 18    loss=0.2248 [11.3 s]    dev=(HR@5:0.4275,NDCG@5:0.3129) [0.4 s] *
INFO:root:Epoch 19    loss=0.2215 [11.2 s]    dev=(HR@5:0.4295,NDCG@5:0.3157) [0.4 s] *
INFO:root:Epoch 20    loss=0.2194 [11.2 s]    dev=(HR@5:0.4331,NDCG@5:0.3182) [0.4 s] *
INFO:root:Epoch 21    loss=0.2149 [11.3 s]    dev=(HR@5:0.4323,NDCG@5:0.3178) [0.4 s]
INFO:root:Epoch 22    loss=0.2138 [11.4 s]    dev=(HR@5:0.4342,NDCG@5:0.3180) [0.4 s]
INFO:root:Epoch 23    loss=0.2130 [11.4 s]    dev=(HR@5:0.4293,NDCG@5:0.3147) [0.4 s]
INFO:root:Epoch 24    loss=0.2126 [11.2 s]    dev=(HR@5:0.4339,NDCG@5:0.3177) [0.4 s]
INFO:root:Epoch 25    loss=0.2081 [11.2 s]    dev=(HR@5:0.4332,NDCG@5:0.3172) [0.4 s]
INFO:root:Epoch 26    loss=0.2084 [11.1 s]    dev=(HR@5:0.4356,NDCG@5:0.3204) [0.4 s] *
INFO:root:Epoch 27    loss=0.2081 [10.6 s]    dev=(HR@5:0.4327,NDCG@5:0.3194) [0.4 s]
INFO:root:Epoch 28    loss=0.2063 [11.3 s]    dev=(HR@5:0.4397,NDCG@5:0.3240) [0.4 s] *
INFO:root:Epoch 29    loss=0.2051 [11.2 s]    dev=(HR@5:0.4336,NDCG@5:0.3179) [0.4 s]
INFO:root:Epoch 30    loss=0.2045 [11.1 s]    dev=(HR@5:0.4390,NDCG@5:0.3226) [0.4 s]
INFO:root:Epoch 31    loss=0.2031 [11.5 s]    dev=(HR@5:0.4355,NDCG@5:0.3206) [0.4 s]
INFO:root:Epoch 32    loss=0.2028 [11.2 s]    dev=(HR@5:0.4371,NDCG@5:0.3221) [0.4 s]
INFO:root:Epoch 33    loss=0.2023 [11.4 s]    dev=(HR@5:0.4376,NDCG@5:0.3234) [0.4 s]
INFO:root:Epoch 34    loss=0.2004 [11.3 s]    dev=(HR@5:0.4360,NDCG@5:0.3203) [0.4 s]
INFO:root:Epoch 35    loss=0.2015 [11.3 s]    dev=(HR@5:0.4345,NDCG@5:0.3193) [0.4 s]
INFO:root:Epoch 36    loss=0.1991 [11.1 s]    dev=(HR@5:0.4404,NDCG@5:0.3221) [0.4 s]
INFO:root:Epoch 37    loss=0.1986 [11.2 s]    dev=(HR@5:0.4375,NDCG@5:0.3219) [0.4 s]
INFO:root:Epoch 38    loss=0.1997 [11.3 s]    dev=(HR@5:0.4385,NDCG@5:0.3209) [0.4 s]
INFO:root:Epoch 39    loss=0.1987 [11.1 s]    dev=(HR@5:0.4337,NDCG@5:0.3177) [0.4 s]
INFO:root:Epoch 40    loss=0.1979 [11.3 s]    dev=(HR@5:0.4376,NDCG@5:0.3222) [0.4 s]
INFO:root:Epoch 41    loss=0.1978 [11.4 s]    dev=(HR@5:0.4357,NDCG@5:0.3200) [0.4 s]
INFO:root:Epoch 42    loss=0.1984 [11.3 s]    dev=(HR@5:0.4403,NDCG@5:0.3219) [0.4 s]
INFO:root:Epoch 43    loss=0.1965 [11.0 s]    dev=(HR@5:0.4413,NDCG@5:0.3257) [0.4 s] *
INFO:root:Epoch 44    loss=0.1975 [11.2 s]    dev=(HR@5:0.4377,NDCG@5:0.3215) [0.4 s]
INFO:root:Epoch 45    loss=0.1942 [11.3 s]    dev=(HR@5:0.4440,NDCG@5:0.3276) [0.4 s] *
INFO:root:Epoch 46    loss=0.1956 [11.1 s]    dev=(HR@5:0.4378,NDCG@5:0.3226) [0.4 s]
INFO:root:Epoch 47    loss=0.1969 [11.3 s]    dev=(HR@5:0.4385,NDCG@5:0.3223) [0.4 s]
INFO:root:Epoch 48    loss=0.1940 [11.3 s]    dev=(HR@5:0.4353,NDCG@5:0.3199) [0.4 s]
INFO:root:Epoch 49    loss=0.1931 [11.1 s]    dev=(HR@5:0.4401,NDCG@5:0.3242) [0.4 s]
INFO:root:Epoch 50    loss=0.1950 [11.1 s]    dev=(HR@5:0.4372,NDCG@5:0.3224) [0.4 s]
INFO:root:Epoch 51    loss=0.1943 [11.3 s]    dev=(HR@5:0.4404,NDCG@5:0.3242) [0.4 s]
INFO:root:Epoch 52    loss=0.1939 [11.5 s]    dev=(HR@5:0.4372,NDCG@5:0.3212) [0.4 s]
INFO:root:Epoch 53    loss=0.1936 [11.3 s]    dev=(HR@5:0.4397,NDCG@5:0.3234) [0.4 s]
INFO:root:Epoch 54    loss=0.1908 [11.1 s]    dev=(HR@5:0.4381,NDCG@5:0.3226) [0.4 s]
INFO:root:Epoch 55    loss=0.1916 [10.5 s]    dev=(HR@5:0.4413,NDCG@5:0.3237) [0.4 s]
INFO:root:Epoch 56    loss=0.1903 [11.5 s]    dev=(HR@5:0.4395,NDCG@5:0.3239) [0.4 s]
INFO:root:Epoch 57    loss=0.1913 [11.2 s]    dev=(HR@5:0.4396,NDCG@5:0.3239) [0.4 s]
INFO:root:Epoch 58    loss=0.1922 [11.5 s]    dev=(HR@5:0.4410,NDCG@5:0.3249) [0.4 s]
INFO:root:Epoch 59    loss=0.1903 [11.1 s]    dev=(HR@5:0.4379,NDCG@5:0.3221) [0.4 s]
INFO:root:Epoch 60    loss=0.1907 [11.1 s]    dev=(HR@5:0.4376,NDCG@5:0.3223) [0.4 s]
INFO:root:Epoch 61    loss=0.1905 [10.7 s]    dev=(HR@5:0.4438,NDCG@5:0.3265) [0.4 s]
INFO:root:Epoch 62    loss=0.1899 [10.5 s]    dev=(HR@5:0.4436,NDCG@5:0.3257) [0.4 s]
INFO:root:Epoch 63    loss=0.1912 [11.2 s]    dev=(HR@5:0.4419,NDCG@5:0.3250) [0.4 s]
INFO:root:Epoch 64    loss=0.1898 [11.3 s]    dev=(HR@5:0.4408,NDCG@5:0.3229) [0.4 s]
INFO:root:Epoch 65    loss=0.1905 [11.6 s]    dev=(HR@5:0.4378,NDCG@5:0.3223) [0.4 s]
INFO:root:Early stop at 65 based on dev result.
INFO:root:
Best Iter(dev)=   45	 dev=(HR@5:0.4440,NDCG@5:0.3276) [754.0 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.3929,NDCG@5:0.2825,HR@10:0.5007,NDCG@10:0.3174,HR@20:0.6247,NDCG@20:0.3487,HR@50:0.8288,NDCG@50:0.3891)
INFO:root:
--------------------------------------------- END: 2024-12-22 23:51:09 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 00:21:37 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [12.8 s]    dev=(HR@5:0.2494,NDCG@5:0.1658) [0.4 s] *
INFO:root:Epoch 2     loss=0.4341 [10.9 s]    dev=(HR@5:0.3188,NDCG@5:0.2148) [0.4 s] *
INFO:root:Epoch 3     loss=0.3989 [11.0 s]    dev=(HR@5:0.3443,NDCG@5:0.2321) [0.4 s] *
INFO:root:Epoch 4     loss=0.3779 [11.0 s]    dev=(HR@5:0.3643,NDCG@5:0.2512) [0.4 s] *
INFO:root:Epoch 5     loss=0.3548 [11.1 s]    dev=(HR@5:0.3777,NDCG@5:0.2623) [0.4 s] *
INFO:root:Epoch 6     loss=0.3322 [10.9 s]    dev=(HR@5:0.3872,NDCG@5:0.2755) [0.4 s] *
INFO:root:Epoch 7     loss=0.3140 [10.5 s]    dev=(HR@5:0.3927,NDCG@5:0.2801) [0.4 s] *
INFO:root:Epoch 8     loss=0.2974 [11.3 s]    dev=(HR@5:0.3998,NDCG@5:0.2879) [0.4 s] *
INFO:root:Epoch 9     loss=0.2822 [9.1 s]    dev=(HR@5:0.4076,NDCG@5:0.2939) [0.4 s] *
INFO:root:Epoch 10    loss=0.2708 [10.1 s]    dev=(HR@5:0.4103,NDCG@5:0.2962) [0.4 s] *
INFO:root:Epoch 11    loss=0.2603 [10.9 s]    dev=(HR@5:0.4179,NDCG@5:0.3018) [0.4 s] *
INFO:root:Epoch 12    loss=0.2508 [10.9 s]    dev=(HR@5:0.4190,NDCG@5:0.3035) [0.4 s] *
INFO:root:Epoch 13    loss=0.2461 [10.7 s]    dev=(HR@5:0.4250,NDCG@5:0.3090) [0.4 s] *
INFO:root:Epoch 14    loss=0.2398 [10.8 s]    dev=(HR@5:0.4211,NDCG@5:0.3064) [0.4 s]
INFO:root:Epoch 15    loss=0.2367 [11.1 s]    dev=(HR@5:0.4211,NDCG@5:0.3067) [0.4 s]
INFO:root:Epoch 16    loss=0.2330 [11.0 s]    dev=(HR@5:0.4207,NDCG@5:0.3047) [0.4 s]
INFO:root:Epoch 17    loss=0.2293 [11.1 s]    dev=(HR@5:0.4214,NDCG@5:0.3059) [0.4 s]
INFO:root:Epoch 18    loss=0.2252 [10.5 s]    dev=(HR@5:0.4272,NDCG@5:0.3114) [0.4 s] *
INFO:root:Epoch 19    loss=0.2223 [10.2 s]    dev=(HR@5:0.4272,NDCG@5:0.3128) [0.4 s] *
INFO:root:Epoch 20    loss=0.2202 [10.6 s]    dev=(HR@5:0.4297,NDCG@5:0.3155) [0.4 s] *
INFO:root:Epoch 21    loss=0.2163 [10.9 s]    dev=(HR@5:0.4315,NDCG@5:0.3166) [0.4 s] *
INFO:root:Epoch 22    loss=0.2140 [11.0 s]    dev=(HR@5:0.4314,NDCG@5:0.3162) [0.4 s]
INFO:root:Epoch 23    loss=0.2141 [11.3 s]    dev=(HR@5:0.4284,NDCG@5:0.3148) [0.4 s]
INFO:root:Epoch 24    loss=0.2138 [11.3 s]    dev=(HR@5:0.4322,NDCG@5:0.3161) [0.4 s]
INFO:root:Epoch 25    loss=0.2106 [11.1 s]    dev=(HR@5:0.4271,NDCG@5:0.3123) [0.4 s]
INFO:root:Epoch 26    loss=0.2107 [11.5 s]    dev=(HR@5:0.4335,NDCG@5:0.3181) [0.4 s] *
INFO:root:Epoch 27    loss=0.2097 [11.4 s]    dev=(HR@5:0.4333,NDCG@5:0.3203) [0.4 s] *
INFO:root:Epoch 28    loss=0.2096 [11.2 s]    dev=(HR@5:0.4348,NDCG@5:0.3201) [0.4 s]
INFO:root:Epoch 29    loss=0.2070 [11.2 s]    dev=(HR@5:0.4316,NDCG@5:0.3164) [0.4 s]
INFO:root:Epoch 30    loss=0.2070 [11.0 s]    dev=(HR@5:0.4325,NDCG@5:0.3183) [0.4 s]
INFO:root:Epoch 31    loss=0.2044 [11.0 s]    dev=(HR@5:0.4367,NDCG@5:0.3215) [0.4 s] *
INFO:root:Epoch 32    loss=0.2054 [11.5 s]    dev=(HR@5:0.4337,NDCG@5:0.3171) [0.4 s]
INFO:root:Epoch 33    loss=0.2051 [11.1 s]    dev=(HR@5:0.4368,NDCG@5:0.3197) [0.4 s]
INFO:root:Epoch 34    loss=0.2038 [11.1 s]    dev=(HR@5:0.4355,NDCG@5:0.3195) [0.4 s]
INFO:root:Epoch 35    loss=0.2046 [11.3 s]    dev=(HR@5:0.4366,NDCG@5:0.3185) [0.4 s]
INFO:root:Epoch 36    loss=0.2025 [11.2 s]    dev=(HR@5:0.4359,NDCG@5:0.3187) [0.4 s]
INFO:root:Epoch 37    loss=0.2021 [11.3 s]    dev=(HR@5:0.4392,NDCG@5:0.3210) [0.4 s]
INFO:root:Epoch 38    loss=0.2025 [11.2 s]    dev=(HR@5:0.4362,NDCG@5:0.3190) [0.4 s]
INFO:root:Epoch 39    loss=0.2025 [11.0 s]    dev=(HR@5:0.4321,NDCG@5:0.3151) [0.4 s]
INFO:root:Epoch 40    loss=0.2013 [11.0 s]    dev=(HR@5:0.4368,NDCG@5:0.3204) [0.4 s]
INFO:root:Epoch 41    loss=0.2015 [11.1 s]    dev=(HR@5:0.4325,NDCG@5:0.3157) [0.4 s]
INFO:root:Epoch 42    loss=0.2021 [11.1 s]    dev=(HR@5:0.4375,NDCG@5:0.3204) [0.4 s]
INFO:root:Epoch 43    loss=0.2003 [11.1 s]    dev=(HR@5:0.4386,NDCG@5:0.3222) [0.4 s] *
INFO:root:Epoch 44    loss=0.2020 [11.4 s]    dev=(HR@5:0.4382,NDCG@5:0.3202) [0.4 s]
INFO:root:Epoch 45    loss=0.1978 [10.8 s]    dev=(HR@5:0.4382,NDCG@5:0.3225) [0.4 s] *
INFO:root:Epoch 46    loss=0.1987 [10.9 s]    dev=(HR@5:0.4368,NDCG@5:0.3200) [0.4 s]
INFO:root:Epoch 47    loss=0.2002 [11.6 s]    dev=(HR@5:0.4394,NDCG@5:0.3210) [0.4 s]
INFO:root:Epoch 48    loss=0.1983 [11.3 s]    dev=(HR@5:0.4356,NDCG@5:0.3185) [0.4 s]
INFO:root:Epoch 49    loss=0.1969 [11.2 s]    dev=(HR@5:0.4400,NDCG@5:0.3219) [0.4 s]
INFO:root:Epoch 50    loss=0.1980 [11.3 s]    dev=(HR@5:0.4371,NDCG@5:0.3197) [0.4 s]
INFO:root:Epoch 51    loss=0.1966 [10.8 s]    dev=(HR@5:0.4391,NDCG@5:0.3211) [0.4 s]
INFO:root:Epoch 52    loss=0.1972 [10.9 s]    dev=(HR@5:0.4383,NDCG@5:0.3199) [0.4 s]
INFO:root:Epoch 53    loss=0.1971 [11.0 s]    dev=(HR@5:0.4373,NDCG@5:0.3199) [0.4 s]
INFO:root:Epoch 54    loss=0.1950 [10.2 s]    dev=(HR@5:0.4426,NDCG@5:0.3238) [0.4 s] *
INFO:root:Epoch 55    loss=0.1952 [11.2 s]    dev=(HR@5:0.4423,NDCG@5:0.3232) [0.4 s]
INFO:root:Epoch 56    loss=0.1941 [11.1 s]    dev=(HR@5:0.4436,NDCG@5:0.3256) [0.4 s] *
INFO:root:Epoch 57    loss=0.1953 [11.0 s]    dev=(HR@5:0.4412,NDCG@5:0.3249) [0.4 s]
INFO:root:Epoch 58    loss=0.1957 [11.0 s]    dev=(HR@5:0.4417,NDCG@5:0.3244) [0.4 s]
INFO:root:Epoch 59    loss=0.1942 [11.4 s]    dev=(HR@5:0.4407,NDCG@5:0.3234) [0.4 s]
INFO:root:Epoch 60    loss=0.1950 [9.9 s]    dev=(HR@5:0.4410,NDCG@5:0.3249) [0.4 s]
INFO:root:Epoch 61    loss=0.1946 [10.9 s]    dev=(HR@5:0.4424,NDCG@5:0.3257) [0.4 s] *
INFO:root:Epoch 62    loss=0.1940 [11.2 s]    dev=(HR@5:0.4423,NDCG@5:0.3250) [0.4 s]
INFO:root:Epoch 63    loss=0.1944 [11.4 s]    dev=(HR@5:0.4428,NDCG@5:0.3251) [0.4 s]
INFO:root:Epoch 64    loss=0.1930 [11.0 s]    dev=(HR@5:0.4372,NDCG@5:0.3202) [0.4 s]
INFO:root:Epoch 65    loss=0.1950 [11.0 s]    dev=(HR@5:0.4408,NDCG@5:0.3215) [0.4 s]
INFO:root:Epoch 66    loss=0.1929 [10.9 s]    dev=(HR@5:0.4429,NDCG@5:0.3240) [0.4 s]
INFO:root:Epoch 67    loss=0.1935 [11.0 s]    dev=(HR@5:0.4414,NDCG@5:0.3218) [0.4 s]
INFO:root:Epoch 68    loss=0.1910 [11.5 s]    dev=(HR@5:0.4441,NDCG@5:0.3245) [0.4 s]
INFO:root:Epoch 69    loss=0.1927 [11.4 s]    dev=(HR@5:0.4436,NDCG@5:0.3255) [0.4 s]
INFO:root:Epoch 70    loss=0.1926 [11.3 s]    dev=(HR@5:0.4394,NDCG@5:0.3217) [0.4 s]
INFO:root:Epoch 71    loss=0.1918 [11.1 s]    dev=(HR@5:0.4408,NDCG@5:0.3245) [0.4 s]
INFO:root:Epoch 72    loss=0.1916 [11.4 s]    dev=(HR@5:0.4437,NDCG@5:0.3262) [0.4 s] *
INFO:root:Epoch 73    loss=0.1919 [11.3 s]    dev=(HR@5:0.4402,NDCG@5:0.3239) [0.4 s]
INFO:root:Epoch 74    loss=0.1929 [10.7 s]    dev=(HR@5:0.4387,NDCG@5:0.3208) [0.4 s]
INFO:root:Epoch 75    loss=0.1939 [10.9 s]    dev=(HR@5:0.4385,NDCG@5:0.3229) [0.4 s]
INFO:root:Epoch 76    loss=0.1934 [11.5 s]    dev=(HR@5:0.4457,NDCG@5:0.3261) [0.4 s]
INFO:root:Epoch 77    loss=0.1916 [10.4 s]    dev=(HR@5:0.4431,NDCG@5:0.3251) [0.4 s]
INFO:root:Epoch 78    loss=0.1912 [9.2 s]    dev=(HR@5:0.4446,NDCG@5:0.3244) [0.4 s]
INFO:root:Epoch 79    loss=0.1921 [11.0 s]    dev=(HR@5:0.4423,NDCG@5:0.3238) [0.4 s]
INFO:root:Epoch 80    loss=0.1907 [10.2 s]    dev=(HR@5:0.4391,NDCG@5:0.3212) [0.4 s]
INFO:root:Epoch 81    loss=0.1908 [10.7 s]    dev=(HR@5:0.4359,NDCG@5:0.3181) [0.4 s]
INFO:root:Epoch 82    loss=0.1935 [10.1 s]    dev=(HR@5:0.4422,NDCG@5:0.3218) [0.4 s]
INFO:root:Epoch 83    loss=0.1909 [11.2 s]    dev=(HR@5:0.4420,NDCG@5:0.3237) [0.4 s]
INFO:root:Epoch 84    loss=0.1912 [11.3 s]    dev=(HR@5:0.4429,NDCG@5:0.3249) [0.4 s]
INFO:root:Epoch 85    loss=0.1922 [11.2 s]    dev=(HR@5:0.4432,NDCG@5:0.3239) [0.4 s]
INFO:root:Epoch 86    loss=0.1922 [11.2 s]    dev=(HR@5:0.4436,NDCG@5:0.3254) [0.4 s]
INFO:root:Epoch 87    loss=0.1910 [11.1 s]    dev=(HR@5:0.4409,NDCG@5:0.3225) [0.4 s]
INFO:root:Epoch 88    loss=0.1906 [11.1 s]    dev=(HR@5:0.4418,NDCG@5:0.3236) [0.4 s]
INFO:root:Epoch 89    loss=0.1914 [10.9 s]    dev=(HR@5:0.4393,NDCG@5:0.3218) [0.4 s]
INFO:root:Epoch 90    loss=0.1910 [11.1 s]    dev=(HR@5:0.4457,NDCG@5:0.3257) [0.4 s]
INFO:root:Epoch 91    loss=0.1901 [11.2 s]    dev=(HR@5:0.4427,NDCG@5:0.3239) [0.4 s]
INFO:root:Epoch 92    loss=0.1897 [11.5 s]    dev=(HR@5:0.4391,NDCG@5:0.3212) [0.4 s]
INFO:root:Early stop at 92 based on dev result.
INFO:root:
Best Iter(dev)=   72	 dev=(HR@5:0.4437,NDCG@5:0.3262) [1048.1 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.3905,NDCG@5:0.2782,HR@10:0.4958,NDCG@10:0.3122,HR@20:0.6148,NDCG@20:0.3422,HR@50:0.8255,NDCG@50:0.3840)
INFO:root:
--------------------------------------------- END: 2024-12-23 00:39:09 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 01:07:30 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [13.0 s]    dev=(HR@5:0.2503,NDCG@5:0.1664) [0.4 s] *
INFO:root:Epoch 2     loss=0.4323 [11.7 s]    dev=(HR@5:0.3205,NDCG@5:0.2171) [0.4 s] *
INFO:root:Epoch 3     loss=0.3952 [11.5 s]    dev=(HR@5:0.3486,NDCG@5:0.2364) [0.4 s] *
INFO:root:Epoch 4     loss=0.3721 [11.7 s]    dev=(HR@5:0.3667,NDCG@5:0.2530) [0.4 s] *
INFO:root:Epoch 5     loss=0.3489 [11.8 s]    dev=(HR@5:0.3816,NDCG@5:0.2661) [0.4 s] *
INFO:root:Epoch 6     loss=0.3259 [11.5 s]    dev=(HR@5:0.3972,NDCG@5:0.2794) [0.4 s] *
INFO:root:Epoch 7     loss=0.3075 [11.6 s]    dev=(HR@5:0.3997,NDCG@5:0.2834) [0.4 s] *
INFO:root:Epoch 8     loss=0.2921 [11.1 s]    dev=(HR@5:0.4077,NDCG@5:0.2908) [0.4 s] *
INFO:root:Epoch 9     loss=0.2767 [10.9 s]    dev=(HR@5:0.4155,NDCG@5:0.2967) [0.4 s] *
INFO:root:Epoch 10    loss=0.2670 [11.3 s]    dev=(HR@5:0.4195,NDCG@5:0.3001) [0.4 s] *
INFO:root:Epoch 11    loss=0.2568 [11.4 s]    dev=(HR@5:0.4218,NDCG@5:0.3019) [0.4 s] *
INFO:root:Epoch 12    loss=0.2491 [11.5 s]    dev=(HR@5:0.4237,NDCG@5:0.3061) [0.4 s] *
INFO:root:Epoch 13    loss=0.2451 [11.4 s]    dev=(HR@5:0.4316,NDCG@5:0.3129) [0.4 s] *
INFO:root:Epoch 14    loss=0.2394 [11.2 s]    dev=(HR@5:0.4306,NDCG@5:0.3112) [0.4 s]
INFO:root:Epoch 15    loss=0.2365 [11.3 s]    dev=(HR@5:0.4288,NDCG@5:0.3093) [0.4 s]
INFO:root:Epoch 16    loss=0.2342 [11.5 s]    dev=(HR@5:0.4328,NDCG@5:0.3130) [0.3 s] *
INFO:root:Epoch 17    loss=0.2300 [11.5 s]    dev=(HR@5:0.4276,NDCG@5:0.3093) [0.4 s]
INFO:root:Epoch 18    loss=0.2263 [11.0 s]    dev=(HR@5:0.4349,NDCG@5:0.3150) [0.4 s] *
INFO:root:Epoch 19    loss=0.2245 [9.3 s]    dev=(HR@5:0.4353,NDCG@5:0.3173) [0.4 s] *
INFO:root:Epoch 20    loss=0.2218 [11.3 s]    dev=(HR@5:0.4359,NDCG@5:0.3186) [0.4 s] *
INFO:root:Epoch 21    loss=0.2176 [11.4 s]    dev=(HR@5:0.4378,NDCG@5:0.3182) [0.4 s]
INFO:root:Epoch 22    loss=0.2159 [11.1 s]    dev=(HR@5:0.4368,NDCG@5:0.3186) [0.4 s]
INFO:root:Epoch 23    loss=0.2168 [11.2 s]    dev=(HR@5:0.4353,NDCG@5:0.3190) [0.4 s] *
INFO:root:Epoch 24    loss=0.2150 [11.2 s]    dev=(HR@5:0.4378,NDCG@5:0.3187) [0.4 s]
INFO:root:Epoch 25    loss=0.2123 [11.3 s]    dev=(HR@5:0.4368,NDCG@5:0.3190) [0.4 s]
INFO:root:Epoch 26    loss=0.2120 [11.1 s]    dev=(HR@5:0.4385,NDCG@5:0.3206) [0.4 s] *
INFO:root:Epoch 27    loss=0.2104 [11.1 s]    dev=(HR@5:0.4420,NDCG@5:0.3226) [0.4 s] *
INFO:root:Epoch 28    loss=0.2108 [11.4 s]    dev=(HR@5:0.4458,NDCG@5:0.3270) [0.4 s] *
INFO:root:Epoch 29    loss=0.2082 [11.3 s]    dev=(HR@5:0.4400,NDCG@5:0.3219) [0.4 s]
INFO:root:Epoch 30    loss=0.2078 [11.5 s]    dev=(HR@5:0.4434,NDCG@5:0.3252) [0.4 s]
INFO:root:Epoch 31    loss=0.2063 [10.7 s]    dev=(HR@5:0.4436,NDCG@5:0.3258) [0.4 s]
INFO:root:Epoch 32    loss=0.2059 [11.0 s]    dev=(HR@5:0.4457,NDCG@5:0.3262) [0.4 s]
INFO:root:Epoch 33    loss=0.2052 [11.3 s]    dev=(HR@5:0.4428,NDCG@5:0.3240) [0.4 s]
INFO:root:Epoch 34    loss=0.2041 [11.6 s]    dev=(HR@5:0.4414,NDCG@5:0.3241) [0.4 s]
INFO:root:Epoch 35    loss=0.2045 [11.4 s]    dev=(HR@5:0.4396,NDCG@5:0.3229) [0.4 s]
INFO:root:Epoch 36    loss=0.2025 [11.6 s]    dev=(HR@5:0.4415,NDCG@5:0.3234) [0.4 s]
INFO:root:Epoch 37    loss=0.2026 [11.5 s]    dev=(HR@5:0.4448,NDCG@5:0.3240) [0.4 s]
INFO:root:Epoch 38    loss=0.2022 [11.2 s]    dev=(HR@5:0.4445,NDCG@5:0.3251) [0.4 s]
INFO:root:Epoch 39    loss=0.2015 [11.4 s]    dev=(HR@5:0.4413,NDCG@5:0.3207) [0.4 s]
INFO:root:Epoch 40    loss=0.2009 [11.3 s]    dev=(HR@5:0.4452,NDCG@5:0.3250) [0.4 s]
INFO:root:Epoch 41    loss=0.2013 [11.8 s]    dev=(HR@5:0.4449,NDCG@5:0.3237) [0.4 s]
INFO:root:Epoch 42    loss=0.2003 [11.6 s]    dev=(HR@5:0.4479,NDCG@5:0.3250) [0.4 s]
INFO:root:Epoch 43    loss=0.1990 [11.4 s]    dev=(HR@5:0.4444,NDCG@5:0.3250) [0.4 s]
INFO:root:Epoch 44    loss=0.1996 [11.1 s]    dev=(HR@5:0.4464,NDCG@5:0.3249) [0.4 s]
INFO:root:Epoch 45    loss=0.1968 [11.4 s]    dev=(HR@5:0.4434,NDCG@5:0.3239) [0.4 s]
INFO:root:Epoch 46    loss=0.1980 [11.4 s]    dev=(HR@5:0.4421,NDCG@5:0.3231) [0.4 s]
INFO:root:Epoch 47    loss=0.1981 [11.3 s]    dev=(HR@5:0.4451,NDCG@5:0.3255) [0.4 s]
INFO:root:Epoch 48    loss=0.1971 [11.5 s]    dev=(HR@5:0.4434,NDCG@5:0.3238) [0.4 s]
INFO:root:Early stop at 48 based on dev result.
INFO:root:
Best Iter(dev)=   28	 dev=(HR@5:0.4458,NDCG@5:0.3270) [563.6 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.3944,NDCG@5:0.2814,HR@10:0.5077,NDCG@10:0.3181,HR@20:0.6305,NDCG@20:0.3490,HR@50:0.8354,NDCG@50:0.3896)
INFO:root:
--------------------------------------------- END: 2024-12-23 01:16:56 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 01:35:55 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [12.3 s]    dev=(HR@5:0.2519,NDCG@5:0.1675) [0.4 s] *
INFO:root:Epoch 2     loss=0.4305 [11.1 s]    dev=(HR@5:0.3265,NDCG@5:0.2222) [0.4 s] *
INFO:root:Epoch 3     loss=0.3922 [11.1 s]    dev=(HR@5:0.3564,NDCG@5:0.2439) [0.4 s] *
INFO:root:Epoch 4     loss=0.3700 [11.0 s]    dev=(HR@5:0.3701,NDCG@5:0.2561) [0.4 s] *
INFO:root:Epoch 5     loss=0.3481 [11.1 s]    dev=(HR@5:0.3880,NDCG@5:0.2701) [0.4 s] *
INFO:root:Epoch 6     loss=0.3250 [11.2 s]    dev=(HR@5:0.4049,NDCG@5:0.2860) [0.4 s] *
INFO:root:Epoch 7     loss=0.3059 [10.9 s]    dev=(HR@5:0.4098,NDCG@5:0.2910) [0.5 s] *
INFO:root:Epoch 8     loss=0.2903 [11.1 s]    dev=(HR@5:0.4160,NDCG@5:0.2979) [0.4 s] *
INFO:root:Epoch 9     loss=0.2757 [11.2 s]    dev=(HR@5:0.4194,NDCG@5:0.3014) [0.4 s] *
INFO:root:Epoch 10    loss=0.2674 [10.8 s]    dev=(HR@5:0.4207,NDCG@5:0.3030) [0.4 s] *
INFO:root:Epoch 11    loss=0.2589 [10.9 s]    dev=(HR@5:0.4267,NDCG@5:0.3070) [0.4 s] *
INFO:root:Epoch 12    loss=0.2516 [11.1 s]    dev=(HR@5:0.4251,NDCG@5:0.3070) [0.4 s]
INFO:root:Epoch 13    loss=0.2496 [11.1 s]    dev=(HR@5:0.4283,NDCG@5:0.3119) [0.4 s] *
INFO:root:Epoch 14    loss=0.2445 [11.2 s]    dev=(HR@5:0.4298,NDCG@5:0.3099) [0.4 s]
INFO:root:Epoch 15    loss=0.2418 [11.5 s]    dev=(HR@5:0.4270,NDCG@5:0.3080) [0.4 s]
INFO:root:Epoch 16    loss=0.2408 [11.4 s]    dev=(HR@5:0.4301,NDCG@5:0.3113) [0.4 s]
INFO:root:Epoch 17    loss=0.2369 [11.3 s]    dev=(HR@5:0.4269,NDCG@5:0.3077) [0.4 s]
INFO:root:Epoch 18    loss=0.2335 [11.1 s]    dev=(HR@5:0.4328,NDCG@5:0.3131) [0.4 s] *
INFO:root:Epoch 19    loss=0.2323 [11.3 s]    dev=(HR@5:0.4296,NDCG@5:0.3125) [0.4 s]
INFO:root:Epoch 20    loss=0.2304 [11.3 s]    dev=(HR@5:0.4333,NDCG@5:0.3151) [0.4 s] *
INFO:root:Epoch 21    loss=0.2273 [11.3 s]    dev=(HR@5:0.4336,NDCG@5:0.3146) [0.4 s]
INFO:root:Epoch 22    loss=0.2265 [11.7 s]    dev=(HR@5:0.4325,NDCG@5:0.3140) [0.4 s]
INFO:root:Epoch 23    loss=0.2274 [11.3 s]    dev=(HR@5:0.4310,NDCG@5:0.3136) [0.4 s]
INFO:root:Epoch 24    loss=0.2270 [11.6 s]    dev=(HR@5:0.4342,NDCG@5:0.3144) [0.4 s]
INFO:root:Epoch 25    loss=0.2237 [11.3 s]    dev=(HR@5:0.4331,NDCG@5:0.3147) [0.4 s]
INFO:root:Epoch 26    loss=0.2240 [11.5 s]    dev=(HR@5:0.4355,NDCG@5:0.3166) [0.4 s] *
INFO:root:Epoch 27    loss=0.2232 [10.0 s]    dev=(HR@5:0.4372,NDCG@5:0.3176) [0.4 s] *
INFO:root:Epoch 28    loss=0.2237 [11.2 s]    dev=(HR@5:0.4385,NDCG@5:0.3191) [0.4 s] *
INFO:root:Epoch 29    loss=0.2213 [10.8 s]    dev=(HR@5:0.4344,NDCG@5:0.3167) [0.4 s]
INFO:root:Epoch 30    loss=0.2200 [11.1 s]    dev=(HR@5:0.4377,NDCG@5:0.3197) [0.4 s] *
INFO:root:Epoch 31    loss=0.2198 [11.2 s]    dev=(HR@5:0.4383,NDCG@5:0.3204) [0.4 s] *
INFO:root:Epoch 32    loss=0.2206 [11.0 s]    dev=(HR@5:0.4350,NDCG@5:0.3185) [0.4 s]
INFO:root:Epoch 33    loss=0.2199 [11.4 s]    dev=(HR@5:0.4370,NDCG@5:0.3194) [0.4 s]
INFO:root:Epoch 34    loss=0.2201 [11.0 s]    dev=(HR@5:0.4389,NDCG@5:0.3204) [0.4 s]
INFO:root:Epoch 35    loss=0.2204 [11.4 s]    dev=(HR@5:0.4348,NDCG@5:0.3169) [0.4 s]
INFO:root:Epoch 36    loss=0.2172 [10.8 s]    dev=(HR@5:0.4354,NDCG@5:0.3170) [0.4 s]
INFO:root:Epoch 37    loss=0.2176 [11.3 s]    dev=(HR@5:0.4342,NDCG@5:0.3150) [0.4 s]
INFO:root:Epoch 38    loss=0.2180 [11.6 s]    dev=(HR@5:0.4340,NDCG@5:0.3157) [0.4 s]
INFO:root:Epoch 39    loss=0.2177 [11.1 s]    dev=(HR@5:0.4291,NDCG@5:0.3111) [0.4 s]
INFO:root:Epoch 40    loss=0.2177 [11.3 s]    dev=(HR@5:0.4306,NDCG@5:0.3134) [0.4 s]
INFO:root:Epoch 41    loss=0.2183 [11.5 s]    dev=(HR@5:0.4356,NDCG@5:0.3143) [0.4 s]
INFO:root:Epoch 42    loss=0.2171 [11.2 s]    dev=(HR@5:0.4348,NDCG@5:0.3158) [0.4 s]
INFO:root:Epoch 43    loss=0.2159 [11.2 s]    dev=(HR@5:0.4354,NDCG@5:0.3147) [0.4 s]
INFO:root:Epoch 44    loss=0.2165 [11.3 s]    dev=(HR@5:0.4329,NDCG@5:0.3132) [0.4 s]
INFO:root:Epoch 45    loss=0.2135 [11.0 s]    dev=(HR@5:0.4361,NDCG@5:0.3185) [0.4 s]
INFO:root:Epoch 46    loss=0.2150 [11.3 s]    dev=(HR@5:0.4328,NDCG@5:0.3140) [0.4 s]
INFO:root:Epoch 47    loss=0.2147 [11.4 s]    dev=(HR@5:0.4361,NDCG@5:0.3163) [0.4 s]
INFO:root:Epoch 48    loss=0.2143 [11.2 s]    dev=(HR@5:0.4293,NDCG@5:0.3125) [0.4 s]
INFO:root:Epoch 49    loss=0.2129 [11.3 s]    dev=(HR@5:0.4363,NDCG@5:0.3163) [0.4 s]
INFO:root:Epoch 50    loss=0.2140 [11.2 s]    dev=(HR@5:0.4343,NDCG@5:0.3166) [0.4 s]
INFO:root:Epoch 51    loss=0.2134 [11.2 s]    dev=(HR@5:0.4348,NDCG@5:0.3155) [0.4 s]
INFO:root:Early stop at 51 based on dev result.
INFO:root:
Best Iter(dev)=   31	 dev=(HR@5:0.4383,NDCG@5:0.3204) [591.7 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.3886,NDCG@5:0.2756,HR@10:0.5015,NDCG@10:0.3122,HR@20:0.6250,NDCG@20:0.3433,HR@50:0.8356,NDCG@50:0.3851)
INFO:root:
--------------------------------------------- END: 2024-12-23 01:45:49 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 02:05:08 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5165 [13.3 s]    dev=(HR@5:0.2528,NDCG@5:0.1683) [0.4 s] *
INFO:root:Epoch 2     loss=0.4298 [12.0 s]    dev=(HR@5:0.3267,NDCG@5:0.2228) [0.4 s] *
INFO:root:Epoch 3     loss=0.3926 [12.0 s]    dev=(HR@5:0.3545,NDCG@5:0.2425) [0.4 s] *
INFO:root:Epoch 4     loss=0.3713 [11.8 s]    dev=(HR@5:0.3712,NDCG@5:0.2564) [0.4 s] *
INFO:root:Epoch 5     loss=0.3490 [12.1 s]    dev=(HR@5:0.3889,NDCG@5:0.2709) [0.4 s] *
INFO:root:Epoch 6     loss=0.3257 [11.9 s]    dev=(HR@5:0.4034,NDCG@5:0.2852) [0.4 s] *
INFO:root:Epoch 7     loss=0.3068 [11.5 s]    dev=(HR@5:0.4088,NDCG@5:0.2898) [0.4 s] *
INFO:root:Epoch 8     loss=0.2919 [11.9 s]    dev=(HR@5:0.4161,NDCG@5:0.2978) [0.4 s] *
INFO:root:Epoch 9     loss=0.2776 [11.9 s]    dev=(HR@5:0.4201,NDCG@5:0.3012) [0.4 s] *
INFO:root:Epoch 10    loss=0.2693 [12.1 s]    dev=(HR@5:0.4220,NDCG@5:0.3041) [0.4 s] *
INFO:root:Epoch 11    loss=0.2605 [12.3 s]    dev=(HR@5:0.4227,NDCG@5:0.3052) [0.4 s] *
INFO:root:Epoch 12    loss=0.2528 [11.9 s]    dev=(HR@5:0.4292,NDCG@5:0.3092) [0.4 s] *
INFO:root:Epoch 13    loss=0.2505 [11.9 s]    dev=(HR@5:0.4312,NDCG@5:0.3131) [0.4 s] *
INFO:root:Epoch 14    loss=0.2453 [11.7 s]    dev=(HR@5:0.4297,NDCG@5:0.3105) [0.4 s]
INFO:root:Epoch 15    loss=0.2422 [10.6 s]    dev=(HR@5:0.4313,NDCG@5:0.3103) [0.4 s]
INFO:root:Epoch 16    loss=0.2411 [11.7 s]    dev=(HR@5:0.4317,NDCG@5:0.3129) [0.4 s]
INFO:root:Epoch 17    loss=0.2369 [12.0 s]    dev=(HR@5:0.4265,NDCG@5:0.3086) [0.4 s]
INFO:root:Epoch 18    loss=0.2333 [12.1 s]    dev=(HR@5:0.4336,NDCG@5:0.3144) [0.4 s] *
INFO:root:Epoch 19    loss=0.2322 [11.5 s]    dev=(HR@5:0.4310,NDCG@5:0.3138) [0.4 s]
INFO:root:Epoch 20    loss=0.2298 [11.1 s]    dev=(HR@5:0.4329,NDCG@5:0.3163) [0.4 s] *
INFO:root:Epoch 21    loss=0.2264 [11.8 s]    dev=(HR@5:0.4343,NDCG@5:0.3160) [0.4 s]
INFO:root:Epoch 22    loss=0.2259 [11.8 s]    dev=(HR@5:0.4315,NDCG@5:0.3143) [0.4 s]
INFO:root:Epoch 23    loss=0.2269 [12.0 s]    dev=(HR@5:0.4305,NDCG@5:0.3131) [0.4 s]
INFO:root:Epoch 24    loss=0.2263 [11.8 s]    dev=(HR@5:0.4323,NDCG@5:0.3140) [0.4 s]
INFO:root:Epoch 25    loss=0.2229 [10.2 s]    dev=(HR@5:0.4321,NDCG@5:0.3146) [0.4 s]
INFO:root:Epoch 26    loss=0.2228 [11.1 s]    dev=(HR@5:0.4355,NDCG@5:0.3169) [0.4 s] *
INFO:root:Epoch 27    loss=0.2227 [11.6 s]    dev=(HR@5:0.4348,NDCG@5:0.3160) [0.4 s]
INFO:root:Epoch 28    loss=0.2225 [11.7 s]    dev=(HR@5:0.4376,NDCG@5:0.3197) [0.4 s] *
INFO:root:Epoch 29    loss=0.2200 [11.7 s]    dev=(HR@5:0.4351,NDCG@5:0.3172) [0.4 s]
INFO:root:Epoch 30    loss=0.2192 [11.6 s]    dev=(HR@5:0.4381,NDCG@5:0.3203) [0.4 s] *
INFO:root:Epoch 31    loss=0.2186 [12.0 s]    dev=(HR@5:0.4368,NDCG@5:0.3205) [0.4 s] *
INFO:root:Epoch 32    loss=0.2196 [12.2 s]    dev=(HR@5:0.4338,NDCG@5:0.3171) [0.4 s]
INFO:root:Epoch 33    loss=0.2185 [11.9 s]    dev=(HR@5:0.4357,NDCG@5:0.3188) [0.4 s]
INFO:root:Epoch 34    loss=0.2185 [12.0 s]    dev=(HR@5:0.4366,NDCG@5:0.3192) [0.4 s]
INFO:root:Epoch 35    loss=0.2188 [11.8 s]    dev=(HR@5:0.4338,NDCG@5:0.3165) [0.4 s]
INFO:root:Epoch 36    loss=0.2158 [12.0 s]    dev=(HR@5:0.4348,NDCG@5:0.3158) [0.4 s]
INFO:root:Epoch 37    loss=0.2161 [11.9 s]    dev=(HR@5:0.4326,NDCG@5:0.3142) [0.4 s]
INFO:root:Epoch 38    loss=0.2169 [11.6 s]    dev=(HR@5:0.4325,NDCG@5:0.3150) [0.3 s]
INFO:root:Epoch 39    loss=0.2164 [11.9 s]    dev=(HR@5:0.4293,NDCG@5:0.3113) [0.4 s]
INFO:root:Epoch 40    loss=0.2160 [11.9 s]    dev=(HR@5:0.4299,NDCG@5:0.3125) [0.4 s]
INFO:root:Epoch 41    loss=0.2172 [12.0 s]    dev=(HR@5:0.4328,NDCG@5:0.3136) [0.4 s]
INFO:root:Epoch 42    loss=0.2163 [12.1 s]    dev=(HR@5:0.4351,NDCG@5:0.3155) [0.4 s]
INFO:root:Epoch 43    loss=0.2143 [11.5 s]    dev=(HR@5:0.4343,NDCG@5:0.3152) [0.4 s]
INFO:root:Epoch 44    loss=0.2151 [11.9 s]    dev=(HR@5:0.4345,NDCG@5:0.3145) [0.4 s]
INFO:root:Epoch 45    loss=0.2127 [12.0 s]    dev=(HR@5:0.4389,NDCG@5:0.3198) [0.4 s]
INFO:root:Epoch 46    loss=0.2139 [11.7 s]    dev=(HR@5:0.4330,NDCG@5:0.3148) [0.4 s]
INFO:root:Epoch 47    loss=0.2141 [11.8 s]    dev=(HR@5:0.4348,NDCG@5:0.3155) [0.4 s]
INFO:root:Epoch 48    loss=0.2136 [12.1 s]    dev=(HR@5:0.4305,NDCG@5:0.3126) [0.4 s]
INFO:root:Epoch 49    loss=0.2122 [11.3 s]    dev=(HR@5:0.4328,NDCG@5:0.3150) [0.4 s]
INFO:root:Epoch 50    loss=0.2135 [11.4 s]    dev=(HR@5:0.4312,NDCG@5:0.3154) [0.4 s]
INFO:root:Epoch 51    loss=0.2127 [10.6 s]    dev=(HR@5:0.4342,NDCG@5:0.3168) [0.4 s]
INFO:root:Early stop at 51 based on dev result.
INFO:root:
Best Iter(dev)=   31	 dev=(HR@5:0.4368,NDCG@5:0.3205) [620.3 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.3891,NDCG@5:0.2765,HR@10:0.4970,NDCG@10:0.3115,HR@20:0.6224,NDCG@20:0.3431,HR@50:0.8352,NDCG@50:0.3853)
INFO:root:
--------------------------------------------- END: 2024-12-23 02:15:32 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 02:34:44 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5165 [12.5 s]    dev=(HR@5:0.2522,NDCG@5:0.1679) [0.4 s] *
INFO:root:Epoch 2     loss=0.4303 [11.4 s]    dev=(HR@5:0.3240,NDCG@5:0.2207) [0.4 s] *
INFO:root:Epoch 3     loss=0.3943 [11.2 s]    dev=(HR@5:0.3496,NDCG@5:0.2382) [0.4 s] *
INFO:root:Epoch 4     loss=0.3739 [11.3 s]    dev=(HR@5:0.3669,NDCG@5:0.2537) [0.4 s] *
INFO:root:Epoch 5     loss=0.3505 [11.2 s]    dev=(HR@5:0.3859,NDCG@5:0.2678) [0.4 s] *
INFO:root:Epoch 6     loss=0.3264 [11.3 s]    dev=(HR@5:0.4026,NDCG@5:0.2842) [0.4 s] *
INFO:root:Epoch 7     loss=0.3072 [11.2 s]    dev=(HR@5:0.4089,NDCG@5:0.2900) [0.4 s] *
INFO:root:Epoch 8     loss=0.2925 [11.1 s]    dev=(HR@5:0.4178,NDCG@5:0.2979) [0.4 s] *
INFO:root:Epoch 9     loss=0.2788 [11.3 s]    dev=(HR@5:0.4168,NDCG@5:0.2987) [0.4 s] *
INFO:root:Epoch 10    loss=0.2707 [11.2 s]    dev=(HR@5:0.4256,NDCG@5:0.3052) [0.3 s] *
INFO:root:Epoch 11    loss=0.2618 [10.9 s]    dev=(HR@5:0.4234,NDCG@5:0.3055) [0.4 s] *
INFO:root:Epoch 12    loss=0.2541 [11.1 s]    dev=(HR@5:0.4291,NDCG@5:0.3094) [0.4 s] *
INFO:root:Epoch 13    loss=0.2512 [11.2 s]    dev=(HR@5:0.4319,NDCG@5:0.3136) [0.4 s] *
INFO:root:Epoch 14    loss=0.2462 [10.7 s]    dev=(HR@5:0.4319,NDCG@5:0.3120) [0.4 s]
INFO:root:Epoch 15    loss=0.2423 [11.4 s]    dev=(HR@5:0.4302,NDCG@5:0.3097) [0.4 s]
INFO:root:Epoch 16    loss=0.2406 [11.2 s]    dev=(HR@5:0.4334,NDCG@5:0.3149) [0.4 s] *
INFO:root:Epoch 17    loss=0.2366 [11.1 s]    dev=(HR@5:0.4327,NDCG@5:0.3127) [0.4 s]
INFO:root:Epoch 18    loss=0.2325 [10.2 s]    dev=(HR@5:0.4347,NDCG@5:0.3154) [0.4 s] *
INFO:root:Epoch 19    loss=0.2309 [11.0 s]    dev=(HR@5:0.4339,NDCG@5:0.3162) [0.4 s] *
INFO:root:Epoch 20    loss=0.2284 [11.2 s]    dev=(HR@5:0.4349,NDCG@5:0.3168) [0.4 s] *
INFO:root:Epoch 21    loss=0.2246 [11.3 s]    dev=(HR@5:0.4374,NDCG@5:0.3180) [0.4 s] *
INFO:root:Epoch 22    loss=0.2241 [11.1 s]    dev=(HR@5:0.4369,NDCG@5:0.3176) [0.4 s]
INFO:root:Epoch 23    loss=0.2243 [11.4 s]    dev=(HR@5:0.4325,NDCG@5:0.3159) [0.4 s]
INFO:root:Epoch 24    loss=0.2242 [11.2 s]    dev=(HR@5:0.4373,NDCG@5:0.3177) [0.4 s]
INFO:root:Epoch 25    loss=0.2206 [11.3 s]    dev=(HR@5:0.4319,NDCG@5:0.3149) [0.4 s]
INFO:root:Epoch 26    loss=0.2206 [11.1 s]    dev=(HR@5:0.4354,NDCG@5:0.3175) [0.4 s]
INFO:root:Epoch 27    loss=0.2208 [11.0 s]    dev=(HR@5:0.4331,NDCG@5:0.3155) [0.4 s]
INFO:root:Epoch 28    loss=0.2196 [11.3 s]    dev=(HR@5:0.4376,NDCG@5:0.3202) [0.4 s] *
INFO:root:Epoch 29    loss=0.2179 [11.4 s]    dev=(HR@5:0.4343,NDCG@5:0.3172) [0.4 s]
INFO:root:Epoch 30    loss=0.2172 [11.3 s]    dev=(HR@5:0.4375,NDCG@5:0.3198) [0.4 s]
INFO:root:Epoch 31    loss=0.2165 [11.2 s]    dev=(HR@5:0.4381,NDCG@5:0.3206) [0.4 s] *
INFO:root:Epoch 32    loss=0.2176 [11.0 s]    dev=(HR@5:0.4338,NDCG@5:0.3180) [0.4 s]
INFO:root:Epoch 33    loss=0.2162 [11.2 s]    dev=(HR@5:0.4345,NDCG@5:0.3188) [0.4 s]
INFO:root:Epoch 34    loss=0.2161 [10.1 s]    dev=(HR@5:0.4361,NDCG@5:0.3195) [0.4 s]
INFO:root:Epoch 35    loss=0.2163 [10.9 s]    dev=(HR@5:0.4354,NDCG@5:0.3169) [0.4 s]
INFO:root:Epoch 36    loss=0.2134 [11.3 s]    dev=(HR@5:0.4333,NDCG@5:0.3159) [0.4 s]
INFO:root:Epoch 37    loss=0.2141 [11.2 s]    dev=(HR@5:0.4336,NDCG@5:0.3172) [0.4 s]
INFO:root:Epoch 38    loss=0.2147 [11.0 s]    dev=(HR@5:0.4363,NDCG@5:0.3172) [0.4 s]
INFO:root:Epoch 39    loss=0.2145 [10.7 s]    dev=(HR@5:0.4294,NDCG@5:0.3116) [0.4 s]
INFO:root:Epoch 40    loss=0.2143 [11.4 s]    dev=(HR@5:0.4327,NDCG@5:0.3138) [0.4 s]
INFO:root:Epoch 41    loss=0.2154 [11.0 s]    dev=(HR@5:0.4330,NDCG@5:0.3135) [0.4 s]
INFO:root:Epoch 42    loss=0.2145 [10.5 s]    dev=(HR@5:0.4368,NDCG@5:0.3169) [0.4 s]
INFO:root:Epoch 43    loss=0.2125 [11.3 s]    dev=(HR@5:0.4389,NDCG@5:0.3184) [0.4 s]
INFO:root:Epoch 44    loss=0.2133 [11.3 s]    dev=(HR@5:0.4355,NDCG@5:0.3161) [0.4 s]
INFO:root:Epoch 45    loss=0.2109 [11.4 s]    dev=(HR@5:0.4397,NDCG@5:0.3203) [0.4 s]
INFO:root:Epoch 46    loss=0.2124 [11.3 s]    dev=(HR@5:0.4328,NDCG@5:0.3154) [0.4 s]
INFO:root:Epoch 47    loss=0.2128 [11.2 s]    dev=(HR@5:0.4360,NDCG@5:0.3175) [0.4 s]
INFO:root:Epoch 48    loss=0.2113 [11.3 s]    dev=(HR@5:0.4319,NDCG@5:0.3123) [0.4 s]
INFO:root:Epoch 49    loss=0.2102 [10.7 s]    dev=(HR@5:0.4364,NDCG@5:0.3173) [0.4 s]
INFO:root:Epoch 50    loss=0.2121 [11.5 s]    dev=(HR@5:0.4352,NDCG@5:0.3188) [0.4 s]
INFO:root:Epoch 51    loss=0.2107 [11.3 s]    dev=(HR@5:0.4379,NDCG@5:0.3180) [0.4 s]
INFO:root:Early stop at 51 based on dev result.
INFO:root:
Best Iter(dev)=   31	 dev=(HR@5:0.4381,NDCG@5:0.3206) [589.0 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.3882,NDCG@5:0.2762,HR@10:0.4988,NDCG@10:0.3120,HR@20:0.6207,NDCG@20:0.3427,HR@50:0.8341,NDCG@50:0.3850)
INFO:root:
--------------------------------------------- END: 2024-12-23 02:44:36 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 03:09:58 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5159 [12.4 s]    dev=(HR@5:0.2505,NDCG@5:0.1666) [0.4 s] *
INFO:root:Epoch 2     loss=0.4334 [11.6 s]    dev=(HR@5:0.3178,NDCG@5:0.2142) [0.4 s] *
INFO:root:Epoch 3     loss=0.3982 [11.4 s]    dev=(HR@5:0.3434,NDCG@5:0.2310) [0.4 s] *
INFO:root:Epoch 4     loss=0.3759 [11.3 s]    dev=(HR@5:0.3637,NDCG@5:0.2507) [0.4 s] *
INFO:root:Epoch 5     loss=0.3509 [11.2 s]    dev=(HR@5:0.3799,NDCG@5:0.2650) [0.4 s] *
INFO:root:Epoch 6     loss=0.3261 [10.7 s]    dev=(HR@5:0.3975,NDCG@5:0.2816) [0.4 s] *
INFO:root:Epoch 7     loss=0.3059 [11.2 s]    dev=(HR@5:0.3968,NDCG@5:0.2843) [0.4 s] *
INFO:root:Epoch 8     loss=0.2894 [10.8 s]    dev=(HR@5:0.4077,NDCG@5:0.2928) [0.4 s] *
INFO:root:Epoch 9     loss=0.2745 [10.3 s]    dev=(HR@5:0.4084,NDCG@5:0.2956) [0.4 s] *
INFO:root:Epoch 10    loss=0.2642 [11.2 s]    dev=(HR@5:0.4124,NDCG@5:0.2983) [0.4 s] *
INFO:root:Epoch 11    loss=0.2550 [11.2 s]    dev=(HR@5:0.4209,NDCG@5:0.3031) [0.4 s] *
INFO:root:Epoch 12    loss=0.2461 [11.1 s]    dev=(HR@5:0.4244,NDCG@5:0.3064) [0.3 s] *
INFO:root:Epoch 13    loss=0.2433 [10.9 s]    dev=(HR@5:0.4248,NDCG@5:0.3096) [0.4 s] *
INFO:root:Epoch 14    loss=0.2371 [11.0 s]    dev=(HR@5:0.4252,NDCG@5:0.3085) [0.4 s]
INFO:root:Epoch 15    loss=0.2350 [11.0 s]    dev=(HR@5:0.4248,NDCG@5:0.3064) [0.4 s]
INFO:root:Epoch 16    loss=0.2313 [11.3 s]    dev=(HR@5:0.4251,NDCG@5:0.3087) [0.4 s]
INFO:root:Epoch 17    loss=0.2287 [11.1 s]    dev=(HR@5:0.4220,NDCG@5:0.3070) [0.4 s]
INFO:root:Epoch 18    loss=0.2245 [11.3 s]    dev=(HR@5:0.4279,NDCG@5:0.3121) [0.4 s] *
INFO:root:Epoch 19    loss=0.2224 [11.1 s]    dev=(HR@5:0.4276,NDCG@5:0.3120) [0.4 s]
INFO:root:Epoch 20    loss=0.2209 [11.4 s]    dev=(HR@5:0.4286,NDCG@5:0.3126) [0.4 s] *
INFO:root:Epoch 21    loss=0.2170 [10.9 s]    dev=(HR@5:0.4308,NDCG@5:0.3144) [0.4 s] *
INFO:root:Epoch 22    loss=0.2154 [11.4 s]    dev=(HR@5:0.4323,NDCG@5:0.3157) [0.4 s] *
INFO:root:Epoch 23    loss=0.2158 [11.2 s]    dev=(HR@5:0.4257,NDCG@5:0.3125) [0.4 s]
INFO:root:Epoch 24    loss=0.2143 [11.3 s]    dev=(HR@5:0.4340,NDCG@5:0.3163) [0.4 s] *
INFO:root:Epoch 25    loss=0.2123 [11.1 s]    dev=(HR@5:0.4311,NDCG@5:0.3162) [0.4 s]
INFO:root:Epoch 26    loss=0.2130 [11.5 s]    dev=(HR@5:0.4329,NDCG@5:0.3169) [0.4 s] *
INFO:root:Epoch 27    loss=0.2112 [11.3 s]    dev=(HR@5:0.4360,NDCG@5:0.3190) [0.4 s] *
INFO:root:Epoch 28    loss=0.2118 [11.0 s]    dev=(HR@5:0.4385,NDCG@5:0.3215) [0.4 s] *
INFO:root:Epoch 29    loss=0.2085 [11.0 s]    dev=(HR@5:0.4335,NDCG@5:0.3171) [0.4 s]
INFO:root:Epoch 30    loss=0.2080 [10.2 s]    dev=(HR@5:0.4329,NDCG@5:0.3183) [0.4 s]
INFO:root:Epoch 31    loss=0.2057 [11.4 s]    dev=(HR@5:0.4382,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 32    loss=0.2069 [11.1 s]    dev=(HR@5:0.4344,NDCG@5:0.3181) [0.4 s]
INFO:root:Epoch 33    loss=0.2061 [11.2 s]    dev=(HR@5:0.4362,NDCG@5:0.3190) [0.4 s]
INFO:root:Epoch 34    loss=0.2053 [11.1 s]    dev=(HR@5:0.4395,NDCG@5:0.3207) [0.3 s]
INFO:root:Epoch 35    loss=0.2051 [11.1 s]    dev=(HR@5:0.4355,NDCG@5:0.3162) [0.4 s]
INFO:root:Epoch 36    loss=0.2035 [11.3 s]    dev=(HR@5:0.4403,NDCG@5:0.3190) [0.4 s]
INFO:root:Epoch 37    loss=0.2032 [11.4 s]    dev=(HR@5:0.4366,NDCG@5:0.3187) [0.4 s]
INFO:root:Epoch 38    loss=0.2031 [11.3 s]    dev=(HR@5:0.4378,NDCG@5:0.3190) [0.4 s]
INFO:root:Epoch 39    loss=0.2027 [11.2 s]    dev=(HR@5:0.4333,NDCG@5:0.3142) [0.4 s]
INFO:root:Epoch 40    loss=0.2021 [11.5 s]    dev=(HR@5:0.4378,NDCG@5:0.3198) [0.4 s]
INFO:root:Epoch 41    loss=0.2034 [10.5 s]    dev=(HR@5:0.4370,NDCG@5:0.3165) [0.4 s]
INFO:root:Epoch 42    loss=0.2031 [10.8 s]    dev=(HR@5:0.4427,NDCG@5:0.3226) [0.4 s] *
INFO:root:Epoch 43    loss=0.2001 [11.2 s]    dev=(HR@5:0.4394,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 44    loss=0.2021 [9.2 s]    dev=(HR@5:0.4418,NDCG@5:0.3216) [0.4 s]
INFO:root:Epoch 45    loss=0.1977 [10.9 s]    dev=(HR@5:0.4418,NDCG@5:0.3243) [0.4 s] *
INFO:root:Epoch 46    loss=0.1993 [11.2 s]    dev=(HR@5:0.4396,NDCG@5:0.3203) [0.4 s]
INFO:root:Epoch 47    loss=0.1995 [11.0 s]    dev=(HR@5:0.4428,NDCG@5:0.3246) [0.4 s] *
INFO:root:Epoch 48    loss=0.1989 [11.2 s]    dev=(HR@5:0.4384,NDCG@5:0.3202) [0.4 s]
INFO:root:Epoch 49    loss=0.1973 [11.1 s]    dev=(HR@5:0.4433,NDCG@5:0.3245) [0.4 s]
INFO:root:Epoch 50    loss=0.1988 [11.3 s]    dev=(HR@5:0.4363,NDCG@5:0.3185) [0.4 s]
INFO:root:Epoch 51    loss=0.1979 [11.5 s]    dev=(HR@5:0.4383,NDCG@5:0.3193) [0.4 s]
INFO:root:Epoch 52    loss=0.1971 [11.2 s]    dev=(HR@5:0.4416,NDCG@5:0.3200) [0.4 s]
INFO:root:Epoch 53    loss=0.1975 [11.6 s]    dev=(HR@5:0.4411,NDCG@5:0.3226) [0.4 s]
INFO:root:Epoch 54    loss=0.1958 [11.1 s]    dev=(HR@5:0.4429,NDCG@5:0.3236) [0.4 s]
INFO:root:Epoch 55    loss=0.1953 [11.1 s]    dev=(HR@5:0.4455,NDCG@5:0.3243) [0.4 s]
INFO:root:Epoch 56    loss=0.1946 [11.4 s]    dev=(HR@5:0.4455,NDCG@5:0.3257) [0.4 s] *
INFO:root:Epoch 57    loss=0.1954 [11.2 s]    dev=(HR@5:0.4449,NDCG@5:0.3256) [0.4 s]
INFO:root:Epoch 58    loss=0.1965 [11.2 s]    dev=(HR@5:0.4460,NDCG@5:0.3270) [0.4 s] *
INFO:root:Epoch 59    loss=0.1953 [11.2 s]    dev=(HR@5:0.4430,NDCG@5:0.3238) [0.4 s]
INFO:root:Epoch 60    loss=0.1958 [10.1 s]    dev=(HR@5:0.4421,NDCG@5:0.3241) [0.4 s]
INFO:root:Epoch 61    loss=0.1954 [11.4 s]    dev=(HR@5:0.4465,NDCG@5:0.3285) [0.4 s] *
INFO:root:Epoch 62    loss=0.1944 [11.4 s]    dev=(HR@5:0.4445,NDCG@5:0.3268) [0.4 s]
INFO:root:Epoch 63    loss=0.1952 [11.4 s]    dev=(HR@5:0.4488,NDCG@5:0.3272) [0.4 s]
INFO:root:Epoch 64    loss=0.1942 [11.3 s]    dev=(HR@5:0.4413,NDCG@5:0.3220) [0.4 s]
INFO:root:Epoch 65    loss=0.1948 [10.6 s]    dev=(HR@5:0.4426,NDCG@5:0.3241) [0.4 s]
INFO:root:Epoch 66    loss=0.1933 [10.9 s]    dev=(HR@5:0.4438,NDCG@5:0.3231) [0.4 s]
INFO:root:Epoch 67    loss=0.1946 [10.4 s]    dev=(HR@5:0.4449,NDCG@5:0.3243) [0.4 s]
INFO:root:Epoch 68    loss=0.1920 [11.3 s]    dev=(HR@5:0.4438,NDCG@5:0.3258) [0.4 s]
INFO:root:Epoch 69    loss=0.1943 [11.2 s]    dev=(HR@5:0.4427,NDCG@5:0.3242) [0.4 s]
INFO:root:Epoch 70    loss=0.1936 [11.2 s]    dev=(HR@5:0.4482,NDCG@5:0.3286) [0.4 s] *
INFO:root:Epoch 71    loss=0.1931 [11.5 s]    dev=(HR@5:0.4437,NDCG@5:0.3264) [0.4 s]
INFO:root:Epoch 72    loss=0.1923 [11.1 s]    dev=(HR@5:0.4431,NDCG@5:0.3257) [0.4 s]
INFO:root:Epoch 73    loss=0.1926 [10.9 s]    dev=(HR@5:0.4445,NDCG@5:0.3256) [0.4 s]
INFO:root:Epoch 74    loss=0.1935 [11.3 s]    dev=(HR@5:0.4442,NDCG@5:0.3239) [0.4 s]
INFO:root:Epoch 75    loss=0.1945 [11.2 s]    dev=(HR@5:0.4403,NDCG@5:0.3228) [0.4 s]
INFO:root:Epoch 76    loss=0.1938 [11.2 s]    dev=(HR@5:0.4479,NDCG@5:0.3278) [0.4 s]
INFO:root:Epoch 77    loss=0.1918 [10.6 s]    dev=(HR@5:0.4464,NDCG@5:0.3275) [0.4 s]
INFO:root:Epoch 78    loss=0.1919 [11.2 s]    dev=(HR@5:0.4445,NDCG@5:0.3259) [0.4 s]
INFO:root:Epoch 79    loss=0.1926 [11.2 s]    dev=(HR@5:0.4460,NDCG@5:0.3269) [0.4 s]
INFO:root:Epoch 80    loss=0.1914 [11.3 s]    dev=(HR@5:0.4472,NDCG@5:0.3273) [0.4 s]
INFO:root:Epoch 81    loss=0.1916 [11.6 s]    dev=(HR@5:0.4440,NDCG@5:0.3231) [0.4 s]
INFO:root:Epoch 82    loss=0.1934 [11.3 s]    dev=(HR@5:0.4470,NDCG@5:0.3279) [0.4 s]
INFO:root:Epoch 83    loss=0.1919 [11.3 s]    dev=(HR@5:0.4483,NDCG@5:0.3277) [0.4 s]
INFO:root:Epoch 84    loss=0.1921 [11.4 s]    dev=(HR@5:0.4464,NDCG@5:0.3267) [0.4 s]
INFO:root:Epoch 85    loss=0.1928 [11.4 s]    dev=(HR@5:0.4526,NDCG@5:0.3310) [0.4 s] *
INFO:root:Epoch 86    loss=0.1932 [10.5 s]    dev=(HR@5:0.4470,NDCG@5:0.3277) [0.4 s]
INFO:root:Epoch 87    loss=0.1919 [11.5 s]    dev=(HR@5:0.4445,NDCG@5:0.3245) [0.4 s]
INFO:root:Epoch 88    loss=0.1919 [11.3 s]    dev=(HR@5:0.4460,NDCG@5:0.3264) [0.4 s]
INFO:root:Epoch 89    loss=0.1915 [10.8 s]    dev=(HR@5:0.4419,NDCG@5:0.3255) [0.4 s]
INFO:root:Epoch 90    loss=0.1910 [11.4 s]    dev=(HR@5:0.4504,NDCG@5:0.3301) [0.4 s]
INFO:root:Epoch 91    loss=0.1910 [10.6 s]    dev=(HR@5:0.4475,NDCG@5:0.3294) [0.4 s]
INFO:root:Epoch 92    loss=0.1905 [11.1 s]    dev=(HR@5:0.4471,NDCG@5:0.3268) [0.4 s]
INFO:root:Epoch 93    loss=0.1915 [11.5 s]    dev=(HR@5:0.4470,NDCG@5:0.3262) [0.4 s]
INFO:root:Epoch 94    loss=0.1919 [9.7 s]    dev=(HR@5:0.4476,NDCG@5:0.3265) [0.4 s]
INFO:root:Epoch 95    loss=0.1915 [11.3 s]    dev=(HR@5:0.4519,NDCG@5:0.3293) [0.4 s]
INFO:root:Epoch 96    loss=0.1903 [11.3 s]    dev=(HR@5:0.4496,NDCG@5:0.3303) [0.4 s]
INFO:root:Epoch 97    loss=0.1911 [10.9 s]    dev=(HR@5:0.4479,NDCG@5:0.3275) [0.4 s]
INFO:root:Epoch 98    loss=0.1901 [10.8 s]    dev=(HR@5:0.4430,NDCG@5:0.3227) [0.4 s]
INFO:root:Epoch 99    loss=0.1908 [11.3 s]    dev=(HR@5:0.4472,NDCG@5:0.3267) [0.4 s]
INFO:root:Epoch 100   loss=0.1909 [11.0 s]    dev=(HR@5:0.4506,NDCG@5:0.3297) [0.4 s]
INFO:root:Epoch 101   loss=0.1929 [11.1 s]    dev=(HR@5:0.4459,NDCG@5:0.3257) [0.4 s]
INFO:root:Epoch 102   loss=0.1922 [11.1 s]    dev=(HR@5:0.4477,NDCG@5:0.3283) [0.4 s]
INFO:root:Epoch 103   loss=0.1906 [11.1 s]    dev=(HR@5:0.4472,NDCG@5:0.3268) [0.4 s]
INFO:root:Epoch 104   loss=0.1914 [11.1 s]    dev=(HR@5:0.4475,NDCG@5:0.3261) [0.4 s]
INFO:root:Epoch 105   loss=0.1911 [10.0 s]    dev=(HR@5:0.4473,NDCG@5:0.3255) [0.4 s]
INFO:root:Early stop at 105 based on dev result.
INFO:root:
Best Iter(dev)=   85	 dev=(HR@5:0.4526,NDCG@5:0.3310) [1206.1 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.3989,NDCG@5:0.2840,HR@10:0.5049,NDCG@10:0.3183,HR@20:0.6262,NDCG@20:0.3489,HR@50:0.8377,NDCG@50:0.3908)
INFO:root:
--------------------------------------------- END: 2024-12-23 03:30:06 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 03:55:42 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5162 [12.7 s]    dev=(HR@5:0.2515,NDCG@5:0.1674) [0.4 s] *
INFO:root:Epoch 2     loss=0.4303 [11.3 s]    dev=(HR@5:0.3233,NDCG@5:0.2196) [0.4 s] *
INFO:root:Epoch 3     loss=0.3928 [11.4 s]    dev=(HR@5:0.3522,NDCG@5:0.2391) [0.4 s] *
INFO:root:Epoch 4     loss=0.3687 [11.2 s]    dev=(HR@5:0.3729,NDCG@5:0.2578) [0.4 s] *
INFO:root:Epoch 5     loss=0.3426 [11.6 s]    dev=(HR@5:0.3927,NDCG@5:0.2757) [0.4 s] *
INFO:root:Epoch 6     loss=0.3170 [11.5 s]    dev=(HR@5:0.4106,NDCG@5:0.2916) [0.4 s] *
INFO:root:Epoch 7     loss=0.2975 [11.3 s]    dev=(HR@5:0.4169,NDCG@5:0.2971) [0.4 s] *
INFO:root:Epoch 8     loss=0.2818 [11.3 s]    dev=(HR@5:0.4223,NDCG@5:0.3042) [0.4 s] *
INFO:root:Epoch 9     loss=0.2673 [11.1 s]    dev=(HR@5:0.4248,NDCG@5:0.3082) [0.4 s] *
INFO:root:Epoch 10    loss=0.2587 [11.2 s]    dev=(HR@5:0.4272,NDCG@5:0.3094) [0.4 s] *
INFO:root:Epoch 11    loss=0.2491 [11.4 s]    dev=(HR@5:0.4338,NDCG@5:0.3138) [0.4 s] *
INFO:root:Epoch 12    loss=0.2415 [11.4 s]    dev=(HR@5:0.4351,NDCG@5:0.3160) [0.3 s] *
INFO:root:Epoch 13    loss=0.2378 [11.4 s]    dev=(HR@5:0.4380,NDCG@5:0.3196) [0.4 s] *
INFO:root:Epoch 14    loss=0.2330 [11.5 s]    dev=(HR@5:0.4370,NDCG@5:0.3177) [0.4 s]
INFO:root:Epoch 15    loss=0.2305 [10.6 s]    dev=(HR@5:0.4366,NDCG@5:0.3165) [0.4 s]
INFO:root:Epoch 16    loss=0.2276 [11.0 s]    dev=(HR@5:0.4402,NDCG@5:0.3210) [0.4 s] *
INFO:root:Epoch 17    loss=0.2239 [11.1 s]    dev=(HR@5:0.4387,NDCG@5:0.3167) [0.4 s]
INFO:root:Epoch 18    loss=0.2198 [11.4 s]    dev=(HR@5:0.4420,NDCG@5:0.3216) [0.4 s] *
INFO:root:Epoch 19    loss=0.2183 [11.3 s]    dev=(HR@5:0.4420,NDCG@5:0.3216) [0.4 s] *
INFO:root:Epoch 20    loss=0.2147 [11.1 s]    dev=(HR@5:0.4447,NDCG@5:0.3265) [0.3 s] *
INFO:root:Epoch 21    loss=0.2113 [11.3 s]    dev=(HR@5:0.4416,NDCG@5:0.3231) [0.4 s]
INFO:root:Epoch 22    loss=0.2102 [11.1 s]    dev=(HR@5:0.4425,NDCG@5:0.3246) [0.4 s]
INFO:root:Epoch 23    loss=0.2105 [11.5 s]    dev=(HR@5:0.4417,NDCG@5:0.3245) [0.4 s]
INFO:root:Epoch 24    loss=0.2091 [11.5 s]    dev=(HR@5:0.4448,NDCG@5:0.3239) [0.4 s]
INFO:root:Epoch 25    loss=0.2065 [10.8 s]    dev=(HR@5:0.4418,NDCG@5:0.3235) [0.4 s]
INFO:root:Epoch 26    loss=0.2061 [11.4 s]    dev=(HR@5:0.4457,NDCG@5:0.3259) [0.4 s]
INFO:root:Epoch 27    loss=0.2051 [10.9 s]    dev=(HR@5:0.4487,NDCG@5:0.3276) [0.3 s] *
INFO:root:Epoch 28    loss=0.2056 [11.2 s]    dev=(HR@5:0.4487,NDCG@5:0.3291) [0.4 s] *
INFO:root:Epoch 29    loss=0.2029 [11.3 s]    dev=(HR@5:0.4449,NDCG@5:0.3257) [0.4 s]
INFO:root:Epoch 30    loss=0.2018 [10.9 s]    dev=(HR@5:0.4423,NDCG@5:0.3245) [0.4 s]
INFO:root:Epoch 31    loss=0.2016 [10.3 s]    dev=(HR@5:0.4477,NDCG@5:0.3287) [0.4 s]
INFO:root:Epoch 32    loss=0.2008 [10.3 s]    dev=(HR@5:0.4453,NDCG@5:0.3251) [0.4 s]
INFO:root:Epoch 33    loss=0.2004 [10.4 s]    dev=(HR@5:0.4452,NDCG@5:0.3262) [0.4 s]
INFO:root:Epoch 34    loss=0.1993 [11.2 s]    dev=(HR@5:0.4474,NDCG@5:0.3280) [0.4 s]
INFO:root:Epoch 35    loss=0.1997 [11.2 s]    dev=(HR@5:0.4402,NDCG@5:0.3230) [0.4 s]
INFO:root:Epoch 36    loss=0.1979 [10.3 s]    dev=(HR@5:0.4453,NDCG@5:0.3251) [0.4 s]
INFO:root:Epoch 37    loss=0.1986 [11.4 s]    dev=(HR@5:0.4481,NDCG@5:0.3265) [0.4 s]
INFO:root:Epoch 38    loss=0.1978 [11.5 s]    dev=(HR@5:0.4458,NDCG@5:0.3261) [0.4 s]
INFO:root:Epoch 39    loss=0.1979 [11.6 s]    dev=(HR@5:0.4409,NDCG@5:0.3217) [0.4 s]
INFO:root:Epoch 40    loss=0.1968 [11.2 s]    dev=(HR@5:0.4453,NDCG@5:0.3244) [0.4 s]
INFO:root:Epoch 41    loss=0.1985 [11.5 s]    dev=(HR@5:0.4426,NDCG@5:0.3234) [0.4 s]
INFO:root:Epoch 42    loss=0.1972 [11.4 s]    dev=(HR@5:0.4472,NDCG@5:0.3264) [0.4 s]
INFO:root:Epoch 43    loss=0.1957 [11.2 s]    dev=(HR@5:0.4465,NDCG@5:0.3276) [0.4 s]
INFO:root:Epoch 44    loss=0.1976 [11.3 s]    dev=(HR@5:0.4432,NDCG@5:0.3243) [0.4 s]
INFO:root:Epoch 45    loss=0.1937 [11.1 s]    dev=(HR@5:0.4459,NDCG@5:0.3280) [0.4 s]
INFO:root:Epoch 46    loss=0.1956 [11.2 s]    dev=(HR@5:0.4432,NDCG@5:0.3252) [0.4 s]
INFO:root:Epoch 47    loss=0.1956 [11.1 s]    dev=(HR@5:0.4450,NDCG@5:0.3248) [0.4 s]
INFO:root:Epoch 48    loss=0.1955 [11.3 s]    dev=(HR@5:0.4428,NDCG@5:0.3220) [0.4 s]
INFO:root:Early stop at 48 based on dev result.
INFO:root:
Best Iter(dev)=   28	 dev=(HR@5:0.4487,NDCG@5:0.3291) [556.7 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.3941,NDCG@5:0.2807,HR@10:0.5049,NDCG@10:0.3166,HR@20:0.6297,NDCG@20:0.3480,HR@50:0.8321,NDCG@50:0.3881)
INFO:root:
--------------------------------------------- END: 2024-12-23 04:05:02 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 04:33:40 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5163 [13.1 s]    dev=(HR@5:0.2544,NDCG@5:0.1700) [0.4 s] *
INFO:root:Epoch 2     loss=0.4279 [11.7 s]    dev=(HR@5:0.3289,NDCG@5:0.2242) [0.4 s] *
INFO:root:Epoch 3     loss=0.3904 [11.2 s]    dev=(HR@5:0.3567,NDCG@5:0.2450) [0.4 s] *
INFO:root:Epoch 4     loss=0.3663 [11.5 s]    dev=(HR@5:0.3786,NDCG@5:0.2628) [0.4 s] *
INFO:root:Epoch 5     loss=0.3415 [11.3 s]    dev=(HR@5:0.3948,NDCG@5:0.2765) [0.4 s] *
INFO:root:Epoch 6     loss=0.3174 [11.1 s]    dev=(HR@5:0.4109,NDCG@5:0.2906) [0.4 s] *
INFO:root:Epoch 7     loss=0.2988 [11.1 s]    dev=(HR@5:0.4158,NDCG@5:0.2952) [0.4 s] *
INFO:root:Epoch 8     loss=0.2839 [11.3 s]    dev=(HR@5:0.4212,NDCG@5:0.3031) [0.4 s] *
INFO:root:Epoch 9     loss=0.2701 [11.2 s]    dev=(HR@5:0.4235,NDCG@5:0.3057) [0.4 s] *
INFO:root:Epoch 10    loss=0.2620 [11.3 s]    dev=(HR@5:0.4257,NDCG@5:0.3074) [0.4 s] *
INFO:root:Epoch 11    loss=0.2538 [11.6 s]    dev=(HR@5:0.4316,NDCG@5:0.3109) [0.4 s] *
INFO:root:Epoch 12    loss=0.2458 [11.3 s]    dev=(HR@5:0.4302,NDCG@5:0.3124) [0.4 s] *
INFO:root:Epoch 13    loss=0.2424 [11.5 s]    dev=(HR@5:0.4332,NDCG@5:0.3152) [0.4 s] *
INFO:root:Epoch 14    loss=0.2378 [11.6 s]    dev=(HR@5:0.4378,NDCG@5:0.3163) [0.4 s] *
INFO:root:Epoch 15    loss=0.2351 [10.9 s]    dev=(HR@5:0.4353,NDCG@5:0.3140) [0.4 s]
INFO:root:Epoch 16    loss=0.2329 [11.5 s]    dev=(HR@5:0.4356,NDCG@5:0.3158) [0.4 s]
INFO:root:Epoch 17    loss=0.2294 [11.2 s]    dev=(HR@5:0.4361,NDCG@5:0.3149) [0.4 s]
INFO:root:Epoch 18    loss=0.2246 [11.5 s]    dev=(HR@5:0.4376,NDCG@5:0.3186) [0.4 s] *
INFO:root:Epoch 19    loss=0.2234 [11.4 s]    dev=(HR@5:0.4402,NDCG@5:0.3209) [0.4 s] *
INFO:root:Epoch 20    loss=0.2199 [11.3 s]    dev=(HR@5:0.4425,NDCG@5:0.3229) [0.4 s] *
INFO:root:Epoch 21    loss=0.2166 [11.2 s]    dev=(HR@5:0.4443,NDCG@5:0.3218) [0.4 s]
INFO:root:Epoch 22    loss=0.2151 [11.1 s]    dev=(HR@5:0.4395,NDCG@5:0.3202) [0.4 s]
INFO:root:Epoch 23    loss=0.2158 [11.0 s]    dev=(HR@5:0.4390,NDCG@5:0.3205) [0.4 s]
INFO:root:Epoch 24    loss=0.2148 [11.2 s]    dev=(HR@5:0.4423,NDCG@5:0.3220) [0.4 s]
INFO:root:Epoch 25    loss=0.2111 [11.3 s]    dev=(HR@5:0.4413,NDCG@5:0.3229) [0.4 s] *
INFO:root:Epoch 26    loss=0.2105 [10.9 s]    dev=(HR@5:0.4440,NDCG@5:0.3247) [0.4 s] *
INFO:root:Epoch 27    loss=0.2102 [10.9 s]    dev=(HR@5:0.4441,NDCG@5:0.3249) [0.4 s] *
INFO:root:Epoch 28    loss=0.2110 [11.5 s]    dev=(HR@5:0.4481,NDCG@5:0.3281) [0.4 s] *
INFO:root:Epoch 29    loss=0.2076 [11.0 s]    dev=(HR@5:0.4431,NDCG@5:0.3243) [0.4 s]
INFO:root:Epoch 30    loss=0.2063 [11.1 s]    dev=(HR@5:0.4439,NDCG@5:0.3248) [0.4 s]
INFO:root:Epoch 31    loss=0.2060 [11.4 s]    dev=(HR@5:0.4481,NDCG@5:0.3261) [0.4 s]
INFO:root:Epoch 32    loss=0.2061 [11.3 s]    dev=(HR@5:0.4428,NDCG@5:0.3228) [0.4 s]
INFO:root:Epoch 33    loss=0.2049 [11.5 s]    dev=(HR@5:0.4475,NDCG@5:0.3285) [0.4 s] *
INFO:root:Epoch 34    loss=0.2043 [11.3 s]    dev=(HR@5:0.4465,NDCG@5:0.3266) [0.4 s]
INFO:root:Epoch 35    loss=0.2050 [11.1 s]    dev=(HR@5:0.4456,NDCG@5:0.3251) [0.4 s]
INFO:root:Epoch 36    loss=0.2020 [11.3 s]    dev=(HR@5:0.4430,NDCG@5:0.3229) [0.4 s]
INFO:root:Epoch 37    loss=0.2028 [11.2 s]    dev=(HR@5:0.4455,NDCG@5:0.3240) [0.4 s]
INFO:root:Epoch 38    loss=0.2032 [11.1 s]    dev=(HR@5:0.4457,NDCG@5:0.3235) [0.4 s]
INFO:root:Epoch 39    loss=0.2031 [11.1 s]    dev=(HR@5:0.4385,NDCG@5:0.3187) [0.4 s]
INFO:root:Epoch 40    loss=0.2024 [11.2 s]    dev=(HR@5:0.4405,NDCG@5:0.3217) [0.4 s]
INFO:root:Epoch 41    loss=0.2026 [11.5 s]    dev=(HR@5:0.4440,NDCG@5:0.3228) [0.4 s]
INFO:root:Epoch 42    loss=0.2018 [11.4 s]    dev=(HR@5:0.4484,NDCG@5:0.3256) [0.4 s]
INFO:root:Epoch 43    loss=0.2001 [11.2 s]    dev=(HR@5:0.4469,NDCG@5:0.3253) [0.4 s]
INFO:root:Epoch 44    loss=0.2020 [11.5 s]    dev=(HR@5:0.4447,NDCG@5:0.3244) [0.4 s]
INFO:root:Epoch 45    loss=0.1987 [11.5 s]    dev=(HR@5:0.4486,NDCG@5:0.3284) [0.4 s]
INFO:root:Epoch 46    loss=0.1997 [11.3 s]    dev=(HR@5:0.4427,NDCG@5:0.3227) [0.4 s]
INFO:root:Epoch 47    loss=0.1999 [11.4 s]    dev=(HR@5:0.4420,NDCG@5:0.3225) [0.4 s]
INFO:root:Epoch 48    loss=0.1998 [11.4 s]    dev=(HR@5:0.4390,NDCG@5:0.3206) [0.4 s]
INFO:root:Epoch 49    loss=0.1978 [11.3 s]    dev=(HR@5:0.4444,NDCG@5:0.3256) [0.4 s]
INFO:root:Epoch 50    loss=0.1994 [11.1 s]    dev=(HR@5:0.4402,NDCG@5:0.3240) [0.4 s]
INFO:root:Epoch 51    loss=0.1981 [11.1 s]    dev=(HR@5:0.4421,NDCG@5:0.3227) [0.4 s]
INFO:root:Epoch 52    loss=0.1990 [11.4 s]    dev=(HR@5:0.4436,NDCG@5:0.3238) [0.4 s]
INFO:root:Epoch 53    loss=0.1989 [11.3 s]    dev=(HR@5:0.4418,NDCG@5:0.3235) [0.4 s]
INFO:root:Early stop at 53 based on dev result.
INFO:root:
Best Iter(dev)=   33	 dev=(HR@5:0.4475,NDCG@5:0.3285) [620.5 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.3973,NDCG@5:0.2821,HR@10:0.5053,NDCG@10:0.3172,HR@20:0.6282,NDCG@20:0.3481,HR@50:0.8384,NDCG@50:0.3898)
INFO:root:
--------------------------------------------- END: 2024-12-23 04:44:04 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 05:08:00 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5165 [12.2 s]    dev=(HR@5:0.2533,NDCG@5:0.1690) [0.3 s] *
INFO:root:Epoch 2     loss=0.4283 [11.2 s]    dev=(HR@5:0.3295,NDCG@5:0.2243) [0.4 s] *
INFO:root:Epoch 3     loss=0.3902 [11.8 s]    dev=(HR@5:0.3575,NDCG@5:0.2443) [0.4 s] *
INFO:root:Epoch 4     loss=0.3654 [10.5 s]    dev=(HR@5:0.3810,NDCG@5:0.2642) [0.4 s] *
INFO:root:Epoch 5     loss=0.3389 [11.2 s]    dev=(HR@5:0.3995,NDCG@5:0.2813) [0.4 s] *
INFO:root:Epoch 6     loss=0.3136 [11.1 s]    dev=(HR@5:0.4148,NDCG@5:0.2976) [0.4 s] *
INFO:root:Epoch 7     loss=0.2954 [11.1 s]    dev=(HR@5:0.4235,NDCG@5:0.3014) [0.4 s] *
INFO:root:Epoch 8     loss=0.2823 [11.1 s]    dev=(HR@5:0.4242,NDCG@5:0.3066) [0.4 s] *
INFO:root:Epoch 9     loss=0.2695 [11.1 s]    dev=(HR@5:0.4266,NDCG@5:0.3099) [0.4 s] *
INFO:root:Epoch 10    loss=0.2619 [11.1 s]    dev=(HR@5:0.4292,NDCG@5:0.3108) [0.4 s] *
INFO:root:Epoch 11    loss=0.2534 [10.8 s]    dev=(HR@5:0.4321,NDCG@5:0.3119) [0.4 s] *
INFO:root:Epoch 12    loss=0.2469 [11.4 s]    dev=(HR@5:0.4326,NDCG@5:0.3133) [0.4 s] *
INFO:root:Epoch 13    loss=0.2436 [11.5 s]    dev=(HR@5:0.4389,NDCG@5:0.3184) [0.4 s] *
INFO:root:Epoch 14    loss=0.2392 [10.9 s]    dev=(HR@5:0.4382,NDCG@5:0.3178) [0.4 s]
INFO:root:Epoch 15    loss=0.2364 [10.8 s]    dev=(HR@5:0.4351,NDCG@5:0.3164) [0.4 s]
INFO:root:Epoch 16    loss=0.2346 [11.1 s]    dev=(HR@5:0.4367,NDCG@5:0.3182) [0.4 s]
INFO:root:Epoch 17    loss=0.2312 [10.2 s]    dev=(HR@5:0.4338,NDCG@5:0.3147) [0.4 s]
INFO:root:Epoch 18    loss=0.2273 [11.3 s]    dev=(HR@5:0.4405,NDCG@5:0.3208) [0.4 s] *
INFO:root:Epoch 19    loss=0.2262 [11.2 s]    dev=(HR@5:0.4377,NDCG@5:0.3192) [0.4 s]
INFO:root:Epoch 20    loss=0.2229 [11.3 s]    dev=(HR@5:0.4398,NDCG@5:0.3221) [0.4 s] *
INFO:root:Epoch 21    loss=0.2199 [11.0 s]    dev=(HR@5:0.4393,NDCG@5:0.3205) [0.4 s]
INFO:root:Epoch 22    loss=0.2200 [11.1 s]    dev=(HR@5:0.4387,NDCG@5:0.3216) [0.4 s]
INFO:root:Epoch 23    loss=0.2205 [10.9 s]    dev=(HR@5:0.4375,NDCG@5:0.3204) [0.4 s]
INFO:root:Epoch 24    loss=0.2201 [10.6 s]    dev=(HR@5:0.4387,NDCG@5:0.3206) [0.4 s]
INFO:root:Epoch 25    loss=0.2165 [10.5 s]    dev=(HR@5:0.4389,NDCG@5:0.3204) [0.4 s]
INFO:root:Epoch 26    loss=0.2172 [10.6 s]    dev=(HR@5:0.4410,NDCG@5:0.3212) [0.4 s]
INFO:root:Epoch 27    loss=0.2173 [10.7 s]    dev=(HR@5:0.4395,NDCG@5:0.3215) [0.3 s]
INFO:root:Epoch 28    loss=0.2166 [9.4 s]    dev=(HR@5:0.4416,NDCG@5:0.3248) [0.3 s] *
INFO:root:Epoch 29    loss=0.2145 [10.6 s]    dev=(HR@5:0.4405,NDCG@5:0.3222) [0.4 s]
INFO:root:Epoch 30    loss=0.2141 [10.8 s]    dev=(HR@5:0.4407,NDCG@5:0.3217) [0.4 s]
INFO:root:Epoch 31    loss=0.2138 [10.4 s]    dev=(HR@5:0.4400,NDCG@5:0.3231) [0.3 s]
INFO:root:Epoch 32    loss=0.2139 [9.4 s]    dev=(HR@5:0.4386,NDCG@5:0.3201) [0.4 s]
INFO:root:Epoch 33    loss=0.2136 [10.8 s]    dev=(HR@5:0.4390,NDCG@5:0.3215) [0.4 s]
INFO:root:Epoch 34    loss=0.2131 [9.9 s]    dev=(HR@5:0.4417,NDCG@5:0.3239) [0.4 s]
INFO:root:Epoch 35    loss=0.2135 [10.3 s]    dev=(HR@5:0.4367,NDCG@5:0.3186) [0.4 s]
INFO:root:Epoch 36    loss=0.2107 [11.2 s]    dev=(HR@5:0.4396,NDCG@5:0.3203) [0.4 s]
INFO:root:Epoch 37    loss=0.2123 [10.9 s]    dev=(HR@5:0.4383,NDCG@5:0.3186) [0.4 s]
INFO:root:Epoch 38    loss=0.2123 [11.1 s]    dev=(HR@5:0.4409,NDCG@5:0.3219) [0.4 s]
INFO:root:Epoch 39    loss=0.2129 [11.1 s]    dev=(HR@5:0.4372,NDCG@5:0.3170) [0.4 s]
INFO:root:Epoch 40    loss=0.2119 [11.2 s]    dev=(HR@5:0.4402,NDCG@5:0.3194) [0.4 s]
INFO:root:Epoch 41    loss=0.2128 [11.0 s]    dev=(HR@5:0.4342,NDCG@5:0.3166) [0.4 s]
INFO:root:Epoch 42    loss=0.2118 [11.2 s]    dev=(HR@5:0.4408,NDCG@5:0.3203) [0.4 s]
INFO:root:Epoch 43    loss=0.2103 [11.2 s]    dev=(HR@5:0.4411,NDCG@5:0.3220) [0.4 s]
INFO:root:Epoch 44    loss=0.2116 [11.2 s]    dev=(HR@5:0.4396,NDCG@5:0.3189) [0.4 s]
INFO:root:Epoch 45    loss=0.2091 [11.4 s]    dev=(HR@5:0.4399,NDCG@5:0.3229) [0.4 s]
INFO:root:Epoch 46    loss=0.2101 [11.3 s]    dev=(HR@5:0.4370,NDCG@5:0.3207) [0.4 s]
INFO:root:Epoch 47    loss=0.2099 [11.0 s]    dev=(HR@5:0.4400,NDCG@5:0.3206) [0.4 s]
INFO:root:Epoch 48    loss=0.2102 [11.2 s]    dev=(HR@5:0.4357,NDCG@5:0.3182) [0.4 s]
INFO:root:Early stop at 48 based on dev result.
INFO:root:
Best Iter(dev)=   28	 dev=(HR@5:0.4416,NDCG@5:0.3248) [543.4 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.3957,NDCG@5:0.2826,HR@10:0.5055,NDCG@10:0.3182,HR@20:0.6274,NDCG@20:0.3491,HR@50:0.8414,NDCG@50:0.3914)
INFO:root:
--------------------------------------------- END: 2024-12-23 05:17:06 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 05:36:58 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5166 [11.7 s]    dev=(HR@5:0.2538,NDCG@5:0.1695) [0.4 s] *
INFO:root:Epoch 2     loss=0.4280 [11.1 s]    dev=(HR@5:0.3310,NDCG@5:0.2249) [0.4 s] *
INFO:root:Epoch 3     loss=0.3891 [11.5 s]    dev=(HR@5:0.3619,NDCG@5:0.2472) [0.4 s] *
INFO:root:Epoch 4     loss=0.3632 [11.5 s]    dev=(HR@5:0.3860,NDCG@5:0.2674) [0.4 s] *
INFO:root:Epoch 5     loss=0.3367 [11.2 s]    dev=(HR@5:0.4058,NDCG@5:0.2863) [0.4 s] *
INFO:root:Epoch 6     loss=0.3116 [10.7 s]    dev=(HR@5:0.4193,NDCG@5:0.3010) [0.4 s] *
INFO:root:Epoch 7     loss=0.2937 [10.9 s]    dev=(HR@5:0.4238,NDCG@5:0.3047) [0.4 s] *
INFO:root:Epoch 8     loss=0.2799 [11.1 s]    dev=(HR@5:0.4323,NDCG@5:0.3126) [0.4 s] *
INFO:root:Epoch 9     loss=0.2661 [10.6 s]    dev=(HR@5:0.4323,NDCG@5:0.3151) [0.4 s] *
INFO:root:Epoch 10    loss=0.2570 [11.3 s]    dev=(HR@5:0.4370,NDCG@5:0.3173) [0.4 s] *
INFO:root:Epoch 11    loss=0.2477 [11.5 s]    dev=(HR@5:0.4398,NDCG@5:0.3190) [0.4 s] *
INFO:root:Epoch 12    loss=0.2398 [11.4 s]    dev=(HR@5:0.4423,NDCG@5:0.3213) [0.4 s] *
INFO:root:Epoch 13    loss=0.2361 [11.5 s]    dev=(HR@5:0.4460,NDCG@5:0.3263) [0.4 s] *
INFO:root:Epoch 14    loss=0.2314 [11.3 s]    dev=(HR@5:0.4451,NDCG@5:0.3243) [0.4 s]
INFO:root:Epoch 15    loss=0.2276 [11.5 s]    dev=(HR@5:0.4431,NDCG@5:0.3225) [0.4 s]
INFO:root:Epoch 16    loss=0.2262 [11.0 s]    dev=(HR@5:0.4419,NDCG@5:0.3229) [0.4 s]
INFO:root:Epoch 17    loss=0.2224 [10.5 s]    dev=(HR@5:0.4382,NDCG@5:0.3198) [0.4 s]
INFO:root:Epoch 18    loss=0.2186 [11.6 s]    dev=(HR@5:0.4448,NDCG@5:0.3262) [0.4 s]
INFO:root:Epoch 19    loss=0.2182 [11.5 s]    dev=(HR@5:0.4425,NDCG@5:0.3254) [0.4 s]
INFO:root:Epoch 20    loss=0.2149 [11.3 s]    dev=(HR@5:0.4421,NDCG@5:0.3252) [0.3 s]
INFO:root:Epoch 21    loss=0.2113 [11.3 s]    dev=(HR@5:0.4457,NDCG@5:0.3271) [0.4 s] *
INFO:root:Epoch 22    loss=0.2117 [11.2 s]    dev=(HR@5:0.4423,NDCG@5:0.3252) [0.4 s]
INFO:root:Epoch 23    loss=0.2116 [11.2 s]    dev=(HR@5:0.4425,NDCG@5:0.3253) [0.4 s]
INFO:root:Epoch 24    loss=0.2112 [11.2 s]    dev=(HR@5:0.4460,NDCG@5:0.3248) [0.4 s]
INFO:root:Epoch 25    loss=0.2084 [11.1 s]    dev=(HR@5:0.4437,NDCG@5:0.3252) [0.4 s]
INFO:root:Epoch 26    loss=0.2085 [11.2 s]    dev=(HR@5:0.4436,NDCG@5:0.3249) [0.4 s]
INFO:root:Epoch 27    loss=0.2088 [11.3 s]    dev=(HR@5:0.4447,NDCG@5:0.3273) [0.4 s] *
INFO:root:Epoch 28    loss=0.2079 [11.4 s]    dev=(HR@5:0.4477,NDCG@5:0.3301) [0.4 s] *
INFO:root:Epoch 29    loss=0.2066 [11.4 s]    dev=(HR@5:0.4455,NDCG@5:0.3272) [0.4 s]
INFO:root:Epoch 30    loss=0.2056 [11.1 s]    dev=(HR@5:0.4452,NDCG@5:0.3266) [0.4 s]
INFO:root:Epoch 31    loss=0.2051 [11.4 s]    dev=(HR@5:0.4461,NDCG@5:0.3291) [0.4 s]
INFO:root:Epoch 32    loss=0.2048 [11.5 s]    dev=(HR@5:0.4434,NDCG@5:0.3251) [0.4 s]
INFO:root:Epoch 33    loss=0.2055 [11.1 s]    dev=(HR@5:0.4438,NDCG@5:0.3273) [0.4 s]
INFO:root:Epoch 34    loss=0.2044 [11.4 s]    dev=(HR@5:0.4447,NDCG@5:0.3263) [0.4 s]
INFO:root:Epoch 35    loss=0.2046 [11.1 s]    dev=(HR@5:0.4411,NDCG@5:0.3240) [0.4 s]
INFO:root:Epoch 36    loss=0.2025 [11.3 s]    dev=(HR@5:0.4436,NDCG@5:0.3252) [0.4 s]
INFO:root:Epoch 37    loss=0.2032 [10.6 s]    dev=(HR@5:0.4436,NDCG@5:0.3247) [0.4 s]
INFO:root:Epoch 38    loss=0.2039 [11.5 s]    dev=(HR@5:0.4430,NDCG@5:0.3246) [0.4 s]
INFO:root:Epoch 39    loss=0.2038 [11.3 s]    dev=(HR@5:0.4377,NDCG@5:0.3192) [0.4 s]
INFO:root:Epoch 40    loss=0.2027 [11.3 s]    dev=(HR@5:0.4421,NDCG@5:0.3233) [0.4 s]
INFO:root:Epoch 41    loss=0.2029 [11.5 s]    dev=(HR@5:0.4402,NDCG@5:0.3223) [0.4 s]
INFO:root:Epoch 42    loss=0.2028 [10.8 s]    dev=(HR@5:0.4453,NDCG@5:0.3247) [0.4 s]
INFO:root:Epoch 43    loss=0.2018 [10.9 s]    dev=(HR@5:0.4466,NDCG@5:0.3282) [0.4 s]
INFO:root:Epoch 44    loss=0.2029 [10.5 s]    dev=(HR@5:0.4405,NDCG@5:0.3229) [0.4 s]
INFO:root:Epoch 45    loss=0.1995 [11.3 s]    dev=(HR@5:0.4455,NDCG@5:0.3276) [0.4 s]
INFO:root:Epoch 46    loss=0.2016 [10.5 s]    dev=(HR@5:0.4409,NDCG@5:0.3249) [0.4 s]
INFO:root:Epoch 47    loss=0.2021 [11.3 s]    dev=(HR@5:0.4444,NDCG@5:0.3255) [0.4 s]
INFO:root:Epoch 48    loss=0.2010 [11.3 s]    dev=(HR@5:0.4425,NDCG@5:0.3222) [0.4 s]
INFO:root:Early stop at 48 based on dev result.
INFO:root:
Best Iter(dev)=   28	 dev=(HR@5:0.4477,NDCG@5:0.3301) [556.1 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.4002,NDCG@5:0.2864,HR@10:0.5115,NDCG@10:0.3223,HR@20:0.6301,NDCG@20:0.3523,HR@50:0.8403,NDCG@50:0.3938)
INFO:root:
--------------------------------------------- END: 2024-12-23 05:46:16 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 06:10:51 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5153 [12.4 s]    dev=(HR@5:0.2516,NDCG@5:0.1673) [0.4 s] *
INFO:root:Epoch 2     loss=0.4317 [10.9 s]    dev=(HR@5:0.3187,NDCG@5:0.2156) [0.4 s] *
INFO:root:Epoch 3     loss=0.3972 [11.7 s]    dev=(HR@5:0.3442,NDCG@5:0.2310) [0.4 s] *
INFO:root:Epoch 4     loss=0.3758 [11.1 s]    dev=(HR@5:0.3619,NDCG@5:0.2476) [0.4 s] *
INFO:root:Epoch 5     loss=0.3524 [9.8 s]    dev=(HR@5:0.3786,NDCG@5:0.2649) [0.4 s] *
INFO:root:Epoch 6     loss=0.3293 [11.4 s]    dev=(HR@5:0.3922,NDCG@5:0.2784) [0.4 s] *
INFO:root:Epoch 7     loss=0.3105 [11.3 s]    dev=(HR@5:0.4009,NDCG@5:0.2852) [0.4 s] *
INFO:root:Epoch 8     loss=0.2956 [11.2 s]    dev=(HR@5:0.4019,NDCG@5:0.2878) [0.4 s] *
INFO:root:Epoch 9     loss=0.2805 [11.1 s]    dev=(HR@5:0.4065,NDCG@5:0.2923) [0.4 s] *
INFO:root:Epoch 10    loss=0.2706 [11.2 s]    dev=(HR@5:0.4102,NDCG@5:0.2964) [0.4 s] *
INFO:root:Epoch 11    loss=0.2615 [11.2 s]    dev=(HR@5:0.4139,NDCG@5:0.2982) [0.4 s] *
INFO:root:Epoch 12    loss=0.2520 [11.1 s]    dev=(HR@5:0.4193,NDCG@5:0.3033) [0.4 s] *
INFO:root:Epoch 13    loss=0.2491 [11.5 s]    dev=(HR@5:0.4225,NDCG@5:0.3058) [0.4 s] *
INFO:root:Epoch 14    loss=0.2443 [11.5 s]    dev=(HR@5:0.4202,NDCG@5:0.3032) [0.4 s]
INFO:root:Epoch 15    loss=0.2407 [11.0 s]    dev=(HR@5:0.4203,NDCG@5:0.3035) [0.4 s]
INFO:root:Epoch 16    loss=0.2376 [10.2 s]    dev=(HR@5:0.4191,NDCG@5:0.3027) [0.4 s]
INFO:root:Epoch 17    loss=0.2345 [11.5 s]    dev=(HR@5:0.4181,NDCG@5:0.3028) [0.4 s]
INFO:root:Epoch 18    loss=0.2293 [11.3 s]    dev=(HR@5:0.4208,NDCG@5:0.3042) [0.4 s]
INFO:root:Epoch 19    loss=0.2275 [11.3 s]    dev=(HR@5:0.4265,NDCG@5:0.3104) [0.4 s] *
INFO:root:Epoch 20    loss=0.2252 [11.1 s]    dev=(HR@5:0.4276,NDCG@5:0.3091) [0.4 s]
INFO:root:Epoch 21    loss=0.2214 [11.1 s]    dev=(HR@5:0.4291,NDCG@5:0.3112) [0.3 s] *
INFO:root:Epoch 22    loss=0.2204 [10.2 s]    dev=(HR@5:0.4284,NDCG@5:0.3113) [0.4 s] *
INFO:root:Epoch 23    loss=0.2210 [10.9 s]    dev=(HR@5:0.4222,NDCG@5:0.3078) [0.4 s]
INFO:root:Epoch 24    loss=0.2197 [11.3 s]    dev=(HR@5:0.4337,NDCG@5:0.3142) [0.4 s] *
INFO:root:Epoch 25    loss=0.2160 [11.2 s]    dev=(HR@5:0.4274,NDCG@5:0.3122) [0.4 s]
INFO:root:Epoch 26    loss=0.2169 [11.3 s]    dev=(HR@5:0.4327,NDCG@5:0.3143) [0.4 s] *
INFO:root:Epoch 27    loss=0.2155 [10.7 s]    dev=(HR@5:0.4306,NDCG@5:0.3143) [0.4 s]
INFO:root:Epoch 28    loss=0.2159 [9.9 s]    dev=(HR@5:0.4335,NDCG@5:0.3171) [0.4 s] *
INFO:root:Epoch 29    loss=0.2130 [10.9 s]    dev=(HR@5:0.4279,NDCG@5:0.3128) [0.4 s]
INFO:root:Epoch 30    loss=0.2125 [11.2 s]    dev=(HR@5:0.4280,NDCG@5:0.3138) [0.4 s]
INFO:root:Epoch 31    loss=0.2113 [9.6 s]    dev=(HR@5:0.4310,NDCG@5:0.3178) [0.4 s] *
INFO:root:Epoch 32    loss=0.2123 [10.7 s]    dev=(HR@5:0.4334,NDCG@5:0.3172) [0.4 s]
INFO:root:Epoch 33    loss=0.2116 [10.5 s]    dev=(HR@5:0.4321,NDCG@5:0.3164) [0.4 s]
INFO:root:Epoch 34    loss=0.2106 [10.0 s]    dev=(HR@5:0.4342,NDCG@5:0.3167) [0.4 s]
INFO:root:Epoch 35    loss=0.2111 [11.3 s]    dev=(HR@5:0.4308,NDCG@5:0.3134) [0.4 s]
INFO:root:Epoch 36    loss=0.2087 [11.5 s]    dev=(HR@5:0.4340,NDCG@5:0.3162) [0.4 s]
INFO:root:Epoch 37    loss=0.2097 [11.2 s]    dev=(HR@5:0.4333,NDCG@5:0.3164) [0.4 s]
INFO:root:Epoch 38    loss=0.2085 [10.1 s]    dev=(HR@5:0.4366,NDCG@5:0.3173) [0.4 s]
INFO:root:Epoch 39    loss=0.2095 [11.5 s]    dev=(HR@5:0.4278,NDCG@5:0.3117) [0.4 s]
INFO:root:Epoch 40    loss=0.2090 [11.1 s]    dev=(HR@5:0.4325,NDCG@5:0.3152) [0.4 s]
INFO:root:Epoch 41    loss=0.2093 [11.1 s]    dev=(HR@5:0.4307,NDCG@5:0.3127) [0.4 s]
INFO:root:Epoch 42    loss=0.2095 [10.4 s]    dev=(HR@5:0.4355,NDCG@5:0.3155) [0.4 s]
INFO:root:Epoch 43    loss=0.2076 [11.1 s]    dev=(HR@5:0.4355,NDCG@5:0.3186) [0.4 s] *
INFO:root:Epoch 44    loss=0.2085 [11.4 s]    dev=(HR@5:0.4340,NDCG@5:0.3161) [0.4 s]
INFO:root:Epoch 45    loss=0.2054 [11.3 s]    dev=(HR@5:0.4365,NDCG@5:0.3205) [0.4 s] *
INFO:root:Epoch 46    loss=0.2069 [11.1 s]    dev=(HR@5:0.4313,NDCG@5:0.3144) [0.4 s]
INFO:root:Epoch 47    loss=0.2071 [11.0 s]    dev=(HR@5:0.4339,NDCG@5:0.3167) [0.4 s]
INFO:root:Epoch 48    loss=0.2068 [11.1 s]    dev=(HR@5:0.4321,NDCG@5:0.3154) [0.4 s]
INFO:root:Epoch 49    loss=0.2048 [11.2 s]    dev=(HR@5:0.4371,NDCG@5:0.3199) [0.4 s]
INFO:root:Epoch 50    loss=0.2062 [11.3 s]    dev=(HR@5:0.4323,NDCG@5:0.3173) [0.4 s]
INFO:root:Epoch 51    loss=0.2051 [11.3 s]    dev=(HR@5:0.4357,NDCG@5:0.3167) [0.4 s]
INFO:root:Epoch 52    loss=0.2051 [10.9 s]    dev=(HR@5:0.4355,NDCG@5:0.3160) [0.4 s]
INFO:root:Epoch 53    loss=0.2049 [11.2 s]    dev=(HR@5:0.4362,NDCG@5:0.3181) [0.4 s]
INFO:root:Epoch 54    loss=0.2034 [11.1 s]    dev=(HR@5:0.4350,NDCG@5:0.3179) [0.4 s]
INFO:root:Epoch 55    loss=0.2030 [9.5 s]    dev=(HR@5:0.4391,NDCG@5:0.3188) [0.4 s]
INFO:root:Epoch 56    loss=0.2034 [11.1 s]    dev=(HR@5:0.4370,NDCG@5:0.3200) [0.4 s]
INFO:root:Epoch 57    loss=0.2041 [11.4 s]    dev=(HR@5:0.4359,NDCG@5:0.3181) [0.4 s]
INFO:root:Epoch 58    loss=0.2044 [11.0 s]    dev=(HR@5:0.4427,NDCG@5:0.3250) [0.4 s] *
INFO:root:Epoch 59    loss=0.2042 [11.2 s]    dev=(HR@5:0.4354,NDCG@5:0.3186) [0.4 s]
INFO:root:Epoch 60    loss=0.2039 [11.0 s]    dev=(HR@5:0.4383,NDCG@5:0.3195) [0.4 s]
INFO:root:Epoch 61    loss=0.2033 [11.1 s]    dev=(HR@5:0.4447,NDCG@5:0.3254) [0.4 s] *
INFO:root:Epoch 62    loss=0.2030 [11.2 s]    dev=(HR@5:0.4423,NDCG@5:0.3233) [0.4 s]
INFO:root:Epoch 63    loss=0.2049 [11.1 s]    dev=(HR@5:0.4428,NDCG@5:0.3229) [0.4 s]
INFO:root:Epoch 64    loss=0.2028 [11.3 s]    dev=(HR@5:0.4419,NDCG@5:0.3215) [0.4 s]
INFO:root:Epoch 65    loss=0.2027 [10.7 s]    dev=(HR@5:0.4395,NDCG@5:0.3205) [0.4 s]
INFO:root:Epoch 66    loss=0.2024 [11.4 s]    dev=(HR@5:0.4378,NDCG@5:0.3194) [0.4 s]
INFO:root:Epoch 67    loss=0.2025 [10.9 s]    dev=(HR@5:0.4384,NDCG@5:0.3208) [0.4 s]
INFO:root:Epoch 68    loss=0.2011 [11.3 s]    dev=(HR@5:0.4400,NDCG@5:0.3209) [0.4 s]
INFO:root:Epoch 69    loss=0.2031 [11.5 s]    dev=(HR@5:0.4354,NDCG@5:0.3173) [0.4 s]
INFO:root:Epoch 70    loss=0.2021 [10.1 s]    dev=(HR@5:0.4386,NDCG@5:0.3205) [0.4 s]
INFO:root:Epoch 71    loss=0.2005 [11.0 s]    dev=(HR@5:0.4359,NDCG@5:0.3197) [0.4 s]
INFO:root:Epoch 72    loss=0.2004 [11.0 s]    dev=(HR@5:0.4393,NDCG@5:0.3215) [0.4 s]
INFO:root:Epoch 73    loss=0.2022 [11.1 s]    dev=(HR@5:0.4380,NDCG@5:0.3188) [0.4 s]
INFO:root:Epoch 74    loss=0.2022 [11.0 s]    dev=(HR@5:0.4374,NDCG@5:0.3176) [0.4 s]
INFO:root:Epoch 75    loss=0.2035 [11.0 s]    dev=(HR@5:0.4390,NDCG@5:0.3191) [0.4 s]
INFO:root:Epoch 76    loss=0.2023 [10.6 s]    dev=(HR@5:0.4457,NDCG@5:0.3240) [0.4 s]
INFO:root:Epoch 77    loss=0.2014 [11.0 s]    dev=(HR@5:0.4400,NDCG@5:0.3217) [0.4 s]
INFO:root:Epoch 78    loss=0.2018 [11.1 s]    dev=(HR@5:0.4425,NDCG@5:0.3222) [0.4 s]
INFO:root:Epoch 79    loss=0.2017 [10.7 s]    dev=(HR@5:0.4419,NDCG@5:0.3216) [0.4 s]
INFO:root:Epoch 80    loss=0.2003 [11.6 s]    dev=(HR@5:0.4447,NDCG@5:0.3224) [0.4 s]
INFO:root:Epoch 81    loss=0.2001 [11.4 s]    dev=(HR@5:0.4376,NDCG@5:0.3176) [0.4 s]
INFO:root:Early stop at 81 based on dev result.
INFO:root:
Best Iter(dev)=   61	 dev=(HR@5:0.4447,NDCG@5:0.3254) [924.0 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.3932,NDCG@5:0.2804,HR@10:0.5026,NDCG@10:0.3159,HR@20:0.6237,NDCG@20:0.3463,HR@50:0.8324,NDCG@50:0.3875)
INFO:root:
--------------------------------------------- END: 2024-12-23 06:26:18 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 06:57:39 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5150 [12.7 s]    dev=(HR@5:0.2560,NDCG@5:0.1712) [0.4 s] *
INFO:root:Epoch 2     loss=0.4257 [11.3 s]    dev=(HR@5:0.3303,NDCG@5:0.2248) [0.4 s] *
INFO:root:Epoch 3     loss=0.3885 [11.1 s]    dev=(HR@5:0.3589,NDCG@5:0.2439) [0.4 s] *
INFO:root:Epoch 4     loss=0.3651 [11.3 s]    dev=(HR@5:0.3772,NDCG@5:0.2620) [0.4 s] *
INFO:root:Epoch 5     loss=0.3412 [11.1 s]    dev=(HR@5:0.3981,NDCG@5:0.2802) [0.4 s] *
INFO:root:Epoch 6     loss=0.3169 [11.0 s]    dev=(HR@5:0.4105,NDCG@5:0.2933) [0.4 s] *
INFO:root:Epoch 7     loss=0.2996 [10.9 s]    dev=(HR@5:0.4163,NDCG@5:0.2975) [0.4 s] *
INFO:root:Epoch 8     loss=0.2847 [11.5 s]    dev=(HR@5:0.4230,NDCG@5:0.3059) [0.4 s] *
INFO:root:Epoch 9     loss=0.2708 [11.0 s]    dev=(HR@5:0.4263,NDCG@5:0.3072) [0.4 s] *
INFO:root:Epoch 10    loss=0.2618 [11.0 s]    dev=(HR@5:0.4282,NDCG@5:0.3089) [0.4 s] *
INFO:root:Epoch 11    loss=0.2518 [11.1 s]    dev=(HR@5:0.4325,NDCG@5:0.3133) [0.4 s] *
INFO:root:Epoch 12    loss=0.2447 [11.2 s]    dev=(HR@5:0.4321,NDCG@5:0.3143) [0.4 s] *
INFO:root:Epoch 13    loss=0.2406 [10.4 s]    dev=(HR@5:0.4380,NDCG@5:0.3188) [0.4 s] *
INFO:root:Epoch 14    loss=0.2366 [10.6 s]    dev=(HR@5:0.4379,NDCG@5:0.3181) [0.4 s]
INFO:root:Epoch 15    loss=0.2332 [11.4 s]    dev=(HR@5:0.4367,NDCG@5:0.3173) [0.4 s]
INFO:root:Epoch 16    loss=0.2305 [11.3 s]    dev=(HR@5:0.4394,NDCG@5:0.3188) [0.4 s]
INFO:root:Epoch 17    loss=0.2275 [11.2 s]    dev=(HR@5:0.4397,NDCG@5:0.3182) [0.4 s]
INFO:root:Epoch 18    loss=0.2230 [11.3 s]    dev=(HR@5:0.4366,NDCG@5:0.3185) [0.4 s]
INFO:root:Epoch 19    loss=0.2210 [10.6 s]    dev=(HR@5:0.4379,NDCG@5:0.3185) [0.4 s]
INFO:root:Epoch 20    loss=0.2188 [10.7 s]    dev=(HR@5:0.4423,NDCG@5:0.3227) [0.4 s] *
INFO:root:Epoch 21    loss=0.2151 [10.8 s]    dev=(HR@5:0.4413,NDCG@5:0.3211) [0.4 s]
INFO:root:Epoch 22    loss=0.2147 [10.9 s]    dev=(HR@5:0.4408,NDCG@5:0.3223) [0.4 s]
INFO:root:Epoch 23    loss=0.2155 [10.8 s]    dev=(HR@5:0.4397,NDCG@5:0.3218) [0.4 s]
INFO:root:Epoch 24    loss=0.2151 [10.6 s]    dev=(HR@5:0.4410,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 25    loss=0.2108 [10.5 s]    dev=(HR@5:0.4376,NDCG@5:0.3180) [0.4 s]
INFO:root:Epoch 26    loss=0.2119 [11.1 s]    dev=(HR@5:0.4405,NDCG@5:0.3222) [0.4 s]
INFO:root:Epoch 27    loss=0.2117 [11.0 s]    dev=(HR@5:0.4408,NDCG@5:0.3221) [0.4 s]
INFO:root:Epoch 28    loss=0.2110 [10.5 s]    dev=(HR@5:0.4442,NDCG@5:0.3248) [0.4 s] *
INFO:root:Epoch 29    loss=0.2096 [11.1 s]    dev=(HR@5:0.4392,NDCG@5:0.3205) [0.4 s]
INFO:root:Epoch 30    loss=0.2091 [10.8 s]    dev=(HR@5:0.4400,NDCG@5:0.3223) [0.4 s]
INFO:root:Epoch 31    loss=0.2079 [11.2 s]    dev=(HR@5:0.4414,NDCG@5:0.3244) [0.4 s]
INFO:root:Epoch 32    loss=0.2082 [11.2 s]    dev=(HR@5:0.4415,NDCG@5:0.3220) [0.4 s]
INFO:root:Epoch 33    loss=0.2079 [11.4 s]    dev=(HR@5:0.4427,NDCG@5:0.3245) [0.4 s]
INFO:root:Epoch 34    loss=0.2066 [11.3 s]    dev=(HR@5:0.4411,NDCG@5:0.3239) [0.4 s]
INFO:root:Epoch 35    loss=0.2076 [11.0 s]    dev=(HR@5:0.4314,NDCG@5:0.3151) [0.4 s]
INFO:root:Epoch 36    loss=0.2055 [11.3 s]    dev=(HR@5:0.4359,NDCG@5:0.3173) [0.4 s]
INFO:root:Epoch 37    loss=0.2068 [11.5 s]    dev=(HR@5:0.4398,NDCG@5:0.3205) [0.4 s]
INFO:root:Epoch 38    loss=0.2064 [11.3 s]    dev=(HR@5:0.4394,NDCG@5:0.3203) [0.4 s]
INFO:root:Epoch 39    loss=0.2074 [11.4 s]    dev=(HR@5:0.4363,NDCG@5:0.3166) [0.4 s]
INFO:root:Epoch 40    loss=0.2061 [9.9 s]    dev=(HR@5:0.4381,NDCG@5:0.3193) [0.4 s]
INFO:root:Epoch 41    loss=0.2071 [10.7 s]    dev=(HR@5:0.4375,NDCG@5:0.3178) [0.4 s]
INFO:root:Epoch 42    loss=0.2062 [11.0 s]    dev=(HR@5:0.4417,NDCG@5:0.3209) [0.4 s]
INFO:root:Epoch 43    loss=0.2052 [11.2 s]    dev=(HR@5:0.4427,NDCG@5:0.3238) [0.4 s]
INFO:root:Epoch 44    loss=0.2064 [11.2 s]    dev=(HR@5:0.4376,NDCG@5:0.3184) [0.4 s]
INFO:root:Epoch 45    loss=0.2031 [11.2 s]    dev=(HR@5:0.4398,NDCG@5:0.3212) [0.4 s]
INFO:root:Epoch 46    loss=0.2047 [11.0 s]    dev=(HR@5:0.4363,NDCG@5:0.3180) [0.4 s]
INFO:root:Epoch 47    loss=0.2047 [11.2 s]    dev=(HR@5:0.4392,NDCG@5:0.3196) [0.4 s]
INFO:root:Epoch 48    loss=0.2042 [10.8 s]    dev=(HR@5:0.4389,NDCG@5:0.3199) [0.4 s]
INFO:root:Early stop at 48 based on dev result.
INFO:root:
Best Iter(dev)=   28	 dev=(HR@5:0.4442,NDCG@5:0.3248) [549.1 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.3947,NDCG@5:0.2817,HR@10:0.5047,NDCG@10:0.3174,HR@20:0.6241,NDCG@20:0.3474,HR@50:0.8350,NDCG@50:0.3892)
INFO:root:
--------------------------------------------- END: 2024-12-23 07:06:51 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 07:34:21 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5153 [12.4 s]    dev=(HR@5:0.2565,NDCG@5:0.1718) [0.4 s] *
INFO:root:Epoch 2     loss=0.4249 [12.1 s]    dev=(HR@5:0.3330,NDCG@5:0.2264) [0.4 s] *
INFO:root:Epoch 3     loss=0.3866 [12.0 s]    dev=(HR@5:0.3633,NDCG@5:0.2482) [0.4 s] *
INFO:root:Epoch 4     loss=0.3611 [12.0 s]    dev=(HR@5:0.3852,NDCG@5:0.2692) [0.4 s] *
INFO:root:Epoch 5     loss=0.3359 [12.0 s]    dev=(HR@5:0.4040,NDCG@5:0.2865) [0.4 s] *
INFO:root:Epoch 6     loss=0.3119 [11.7 s]    dev=(HR@5:0.4178,NDCG@5:0.2983) [0.4 s] *
INFO:root:Epoch 7     loss=0.2951 [11.8 s]    dev=(HR@5:0.4194,NDCG@5:0.2996) [0.4 s] *
INFO:root:Epoch 8     loss=0.2814 [11.8 s]    dev=(HR@5:0.4256,NDCG@5:0.3077) [0.4 s] *
INFO:root:Epoch 9     loss=0.2688 [12.0 s]    dev=(HR@5:0.4298,NDCG@5:0.3110) [0.4 s] *
INFO:root:Epoch 10    loss=0.2591 [11.8 s]    dev=(HR@5:0.4323,NDCG@5:0.3146) [0.4 s] *
INFO:root:Epoch 11    loss=0.2497 [12.0 s]    dev=(HR@5:0.4353,NDCG@5:0.3157) [0.4 s] *
INFO:root:Epoch 12    loss=0.2415 [12.0 s]    dev=(HR@5:0.4391,NDCG@5:0.3207) [0.4 s] *
INFO:root:Epoch 13    loss=0.2372 [12.0 s]    dev=(HR@5:0.4417,NDCG@5:0.3234) [0.4 s] *
INFO:root:Epoch 14    loss=0.2331 [12.1 s]    dev=(HR@5:0.4427,NDCG@5:0.3225) [0.4 s]
INFO:root:Epoch 15    loss=0.2286 [12.0 s]    dev=(HR@5:0.4404,NDCG@5:0.3210) [0.4 s]
INFO:root:Epoch 16    loss=0.2259 [11.9 s]    dev=(HR@5:0.4432,NDCG@5:0.3246) [0.4 s] *
INFO:root:Epoch 17    loss=0.2225 [11.9 s]    dev=(HR@5:0.4420,NDCG@5:0.3224) [0.4 s]
INFO:root:Epoch 18    loss=0.2178 [11.7 s]    dev=(HR@5:0.4448,NDCG@5:0.3259) [0.4 s] *
INFO:root:Epoch 19    loss=0.2156 [11.8 s]    dev=(HR@5:0.4439,NDCG@5:0.3243) [0.4 s]
INFO:root:Epoch 20    loss=0.2130 [11.9 s]    dev=(HR@5:0.4487,NDCG@5:0.3289) [0.4 s] *
INFO:root:Epoch 21    loss=0.2104 [11.9 s]    dev=(HR@5:0.4471,NDCG@5:0.3277) [0.4 s]
INFO:root:Epoch 22    loss=0.2093 [11.8 s]    dev=(HR@5:0.4455,NDCG@5:0.3266) [0.4 s]
INFO:root:Epoch 23    loss=0.2101 [11.7 s]    dev=(HR@5:0.4430,NDCG@5:0.3256) [0.4 s]
INFO:root:Epoch 24    loss=0.2094 [11.6 s]    dev=(HR@5:0.4443,NDCG@5:0.3265) [0.4 s]
INFO:root:Epoch 25    loss=0.2055 [11.8 s]    dev=(HR@5:0.4428,NDCG@5:0.3239) [0.4 s]
INFO:root:Epoch 26    loss=0.2054 [11.7 s]    dev=(HR@5:0.4431,NDCG@5:0.3259) [0.4 s]
INFO:root:Epoch 27    loss=0.2047 [11.7 s]    dev=(HR@5:0.4457,NDCG@5:0.3281) [0.4 s]
INFO:root:Epoch 28    loss=0.2049 [10.4 s]    dev=(HR@5:0.4492,NDCG@5:0.3300) [0.3 s] *
INFO:root:Epoch 29    loss=0.2029 [11.2 s]    dev=(HR@5:0.4447,NDCG@5:0.3272) [0.4 s]
INFO:root:Epoch 30    loss=0.2028 [11.7 s]    dev=(HR@5:0.4494,NDCG@5:0.3290) [0.4 s]
INFO:root:Epoch 31    loss=0.2018 [11.9 s]    dev=(HR@5:0.4492,NDCG@5:0.3297) [0.4 s]
INFO:root:Epoch 32    loss=0.2015 [11.9 s]    dev=(HR@5:0.4496,NDCG@5:0.3282) [0.4 s]
INFO:root:Epoch 33    loss=0.2021 [11.9 s]    dev=(HR@5:0.4489,NDCG@5:0.3312) [0.4 s] *
INFO:root:Epoch 34    loss=0.2010 [12.0 s]    dev=(HR@5:0.4486,NDCG@5:0.3287) [0.4 s]
INFO:root:Epoch 35    loss=0.2014 [11.6 s]    dev=(HR@5:0.4421,NDCG@5:0.3251) [0.4 s]
INFO:root:Epoch 36    loss=0.1988 [11.3 s]    dev=(HR@5:0.4434,NDCG@5:0.3256) [0.4 s]
INFO:root:Epoch 37    loss=0.2004 [11.6 s]    dev=(HR@5:0.4470,NDCG@5:0.3267) [0.4 s]
INFO:root:Epoch 38    loss=0.1996 [11.7 s]    dev=(HR@5:0.4462,NDCG@5:0.3250) [0.3 s]
INFO:root:Epoch 39    loss=0.2002 [11.7 s]    dev=(HR@5:0.4418,NDCG@5:0.3226) [0.4 s]
INFO:root:Epoch 40    loss=0.1996 [11.3 s]    dev=(HR@5:0.4465,NDCG@5:0.3270) [0.4 s]
INFO:root:Epoch 41    loss=0.2002 [11.5 s]    dev=(HR@5:0.4457,NDCG@5:0.3257) [0.4 s]
INFO:root:Epoch 42    loss=0.2001 [11.8 s]    dev=(HR@5:0.4490,NDCG@5:0.3277) [0.4 s]
INFO:root:Epoch 43    loss=0.1982 [11.9 s]    dev=(HR@5:0.4491,NDCG@5:0.3280) [0.4 s]
INFO:root:Epoch 44    loss=0.1991 [11.7 s]    dev=(HR@5:0.4451,NDCG@5:0.3247) [0.4 s]
INFO:root:Epoch 45    loss=0.1964 [12.1 s]    dev=(HR@5:0.4512,NDCG@5:0.3300) [0.4 s]
INFO:root:Epoch 46    loss=0.1974 [12.1 s]    dev=(HR@5:0.4404,NDCG@5:0.3243) [0.4 s]
INFO:root:Epoch 47    loss=0.1983 [11.1 s]    dev=(HR@5:0.4454,NDCG@5:0.3266) [0.4 s]
INFO:root:Epoch 48    loss=0.1977 [11.9 s]    dev=(HR@5:0.4430,NDCG@5:0.3244) [0.4 s]
INFO:root:Epoch 49    loss=0.1957 [11.8 s]    dev=(HR@5:0.4477,NDCG@5:0.3280) [0.4 s]
INFO:root:Epoch 50    loss=0.1985 [11.9 s]    dev=(HR@5:0.4472,NDCG@5:0.3272) [0.4 s]
INFO:root:Epoch 51    loss=0.1973 [10.7 s]    dev=(HR@5:0.4449,NDCG@5:0.3273) [0.4 s]
INFO:root:Epoch 52    loss=0.1970 [10.8 s]    dev=(HR@5:0.4469,NDCG@5:0.3272) [0.4 s]
INFO:root:Epoch 53    loss=0.1965 [12.0 s]    dev=(HR@5:0.4469,NDCG@5:0.3270) [0.4 s]
INFO:root:Early stop at 53 based on dev result.
INFO:root:
Best Iter(dev)=   33	 dev=(HR@5:0.4489,NDCG@5:0.3312) [643.5 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.4004,NDCG@5:0.2844,HR@10:0.5077,NDCG@10:0.3191,HR@20:0.6328,NDCG@20:0.3507,HR@50:0.8374,NDCG@50:0.3912)
INFO:root:
--------------------------------------------- END: 2024-12-23 07:45:07 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 08:04:36 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5155 [12.1 s]    dev=(HR@5:0.2592,NDCG@5:0.1737) [0.4 s] *
INFO:root:Epoch 2     loss=0.4238 [11.2 s]    dev=(HR@5:0.3363,NDCG@5:0.2281) [0.4 s] *
INFO:root:Epoch 3     loss=0.3860 [11.0 s]    dev=(HR@5:0.3634,NDCG@5:0.2495) [0.4 s] *
INFO:root:Epoch 4     loss=0.3605 [11.1 s]    dev=(HR@5:0.3863,NDCG@5:0.2707) [0.4 s] *
INFO:root:Epoch 5     loss=0.3351 [11.1 s]    dev=(HR@5:0.4041,NDCG@5:0.2871) [0.4 s] *
INFO:root:Epoch 6     loss=0.3114 [10.7 s]    dev=(HR@5:0.4194,NDCG@5:0.3001) [0.4 s] *
INFO:root:Epoch 7     loss=0.2935 [11.3 s]    dev=(HR@5:0.4245,NDCG@5:0.3039) [0.4 s] *
INFO:root:Epoch 8     loss=0.2786 [11.4 s]    dev=(HR@5:0.4315,NDCG@5:0.3127) [0.4 s] *
INFO:root:Epoch 9     loss=0.2645 [11.4 s]    dev=(HR@5:0.4356,NDCG@5:0.3168) [0.4 s] *
INFO:root:Epoch 10    loss=0.2547 [11.2 s]    dev=(HR@5:0.4391,NDCG@5:0.3209) [0.4 s] *
INFO:root:Epoch 11    loss=0.2441 [11.2 s]    dev=(HR@5:0.4422,NDCG@5:0.3232) [0.4 s] *
INFO:root:Epoch 12    loss=0.2355 [11.2 s]    dev=(HR@5:0.4468,NDCG@5:0.3263) [0.4 s] *
INFO:root:Epoch 13    loss=0.2307 [11.2 s]    dev=(HR@5:0.4493,NDCG@5:0.3303) [0.4 s] *
INFO:root:Epoch 14    loss=0.2261 [11.3 s]    dev=(HR@5:0.4509,NDCG@5:0.3308) [0.4 s] *
INFO:root:Epoch 15    loss=0.2222 [11.1 s]    dev=(HR@5:0.4487,NDCG@5:0.3287) [0.4 s]
INFO:root:Epoch 16    loss=0.2193 [11.2 s]    dev=(HR@5:0.4517,NDCG@5:0.3313) [0.4 s] *
INFO:root:Epoch 17    loss=0.2155 [11.4 s]    dev=(HR@5:0.4504,NDCG@5:0.3302) [0.4 s]
INFO:root:Epoch 18    loss=0.2114 [11.0 s]    dev=(HR@5:0.4527,NDCG@5:0.3332) [0.4 s] *
INFO:root:Epoch 19    loss=0.2097 [11.1 s]    dev=(HR@5:0.4528,NDCG@5:0.3330) [0.4 s]
INFO:root:Epoch 20    loss=0.2070 [10.4 s]    dev=(HR@5:0.4540,NDCG@5:0.3352) [0.4 s] *
INFO:root:Epoch 21    loss=0.2035 [11.2 s]    dev=(HR@5:0.4536,NDCG@5:0.3341) [0.4 s]
INFO:root:Epoch 22    loss=0.2034 [11.2 s]    dev=(HR@5:0.4517,NDCG@5:0.3346) [0.4 s]
INFO:root:Epoch 23    loss=0.2041 [11.4 s]    dev=(HR@5:0.4522,NDCG@5:0.3340) [0.4 s]
INFO:root:Epoch 24    loss=0.2031 [11.3 s]    dev=(HR@5:0.4520,NDCG@5:0.3319) [0.4 s]
INFO:root:Epoch 25    loss=0.1990 [11.4 s]    dev=(HR@5:0.4519,NDCG@5:0.3323) [0.4 s]
INFO:root:Epoch 26    loss=0.1998 [10.9 s]    dev=(HR@5:0.4519,NDCG@5:0.3339) [0.4 s]
INFO:root:Epoch 27    loss=0.1994 [11.4 s]    dev=(HR@5:0.4526,NDCG@5:0.3355) [0.4 s] *
INFO:root:Epoch 28    loss=0.1991 [11.3 s]    dev=(HR@5:0.4554,NDCG@5:0.3363) [0.4 s] *
INFO:root:Epoch 29    loss=0.1977 [11.0 s]    dev=(HR@5:0.4535,NDCG@5:0.3348) [0.4 s]
INFO:root:Epoch 30    loss=0.1977 [11.4 s]    dev=(HR@5:0.4572,NDCG@5:0.3374) [0.4 s] *
INFO:root:Epoch 31    loss=0.1954 [11.1 s]    dev=(HR@5:0.4548,NDCG@5:0.3383) [0.4 s] *
INFO:root:Epoch 32    loss=0.1959 [11.3 s]    dev=(HR@5:0.4558,NDCG@5:0.3364) [0.4 s]
INFO:root:Epoch 33    loss=0.1966 [11.4 s]    dev=(HR@5:0.4584,NDCG@5:0.3409) [0.4 s] *
INFO:root:Epoch 34    loss=0.1956 [11.5 s]    dev=(HR@5:0.4562,NDCG@5:0.3368) [0.4 s]
INFO:root:Epoch 35    loss=0.1951 [11.0 s]    dev=(HR@5:0.4541,NDCG@5:0.3357) [0.4 s]
INFO:root:Epoch 36    loss=0.1933 [11.1 s]    dev=(HR@5:0.4577,NDCG@5:0.3364) [0.4 s]
INFO:root:Epoch 37    loss=0.1938 [11.1 s]    dev=(HR@5:0.4568,NDCG@5:0.3360) [0.4 s]
INFO:root:Epoch 38    loss=0.1944 [11.2 s]    dev=(HR@5:0.4557,NDCG@5:0.3362) [0.4 s]
INFO:root:Epoch 39    loss=0.1944 [11.2 s]    dev=(HR@5:0.4489,NDCG@5:0.3301) [0.4 s]
INFO:root:Epoch 40    loss=0.1935 [11.4 s]    dev=(HR@5:0.4512,NDCG@5:0.3329) [0.4 s]
INFO:root:Epoch 41    loss=0.1946 [11.2 s]    dev=(HR@5:0.4529,NDCG@5:0.3346) [0.4 s]
INFO:root:Epoch 42    loss=0.1935 [11.1 s]    dev=(HR@5:0.4543,NDCG@5:0.3327) [0.4 s]
INFO:root:Epoch 43    loss=0.1921 [11.3 s]    dev=(HR@5:0.4575,NDCG@5:0.3364) [0.4 s]
INFO:root:Epoch 44    loss=0.1935 [11.5 s]    dev=(HR@5:0.4559,NDCG@5:0.3352) [0.4 s]
INFO:root:Epoch 45    loss=0.1905 [11.0 s]    dev=(HR@5:0.4588,NDCG@5:0.3397) [0.4 s]
INFO:root:Epoch 46    loss=0.1915 [11.1 s]    dev=(HR@5:0.4556,NDCG@5:0.3354) [0.4 s]
INFO:root:Epoch 47    loss=0.1919 [11.0 s]    dev=(HR@5:0.4526,NDCG@5:0.3336) [0.4 s]
INFO:root:Epoch 48    loss=0.1915 [11.0 s]    dev=(HR@5:0.4547,NDCG@5:0.3340) [0.4 s]
INFO:root:Epoch 49    loss=0.1898 [11.0 s]    dev=(HR@5:0.4566,NDCG@5:0.3364) [0.4 s]
INFO:root:Epoch 50    loss=0.1926 [10.9 s]    dev=(HR@5:0.4528,NDCG@5:0.3341) [0.4 s]
INFO:root:Epoch 51    loss=0.1904 [11.1 s]    dev=(HR@5:0.4535,NDCG@5:0.3344) [0.4 s]
INFO:root:Epoch 52    loss=0.1918 [11.1 s]    dev=(HR@5:0.4538,NDCG@5:0.3328) [0.4 s]
INFO:root:Epoch 53    loss=0.1906 [11.5 s]    dev=(HR@5:0.4509,NDCG@5:0.3331) [0.4 s]
INFO:root:Early stop at 53 based on dev result.
INFO:root:
Best Iter(dev)=   33	 dev=(HR@5:0.4584,NDCG@5:0.3409) [613.6 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.4080,NDCG@5:0.2938,HR@10:0.5164,NDCG@10:0.3290,HR@20:0.6385,NDCG@20:0.3597,HR@50:0.8417,NDCG@50:0.3999)
INFO:root:
--------------------------------------------- END: 2024-12-23 08:14:52 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 08:35:32 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5157 [12.6 s]    dev=(HR@5:0.2601,NDCG@5:0.1744) [0.4 s] *
INFO:root:Epoch 2     loss=0.4234 [11.1 s]    dev=(HR@5:0.3381,NDCG@5:0.2304) [0.4 s] *
INFO:root:Epoch 3     loss=0.3848 [11.5 s]    dev=(HR@5:0.3686,NDCG@5:0.2546) [0.4 s] *
INFO:root:Epoch 4     loss=0.3581 [11.0 s]    dev=(HR@5:0.3922,NDCG@5:0.2758) [0.4 s] *
INFO:root:Epoch 5     loss=0.3311 [11.2 s]    dev=(HR@5:0.4124,NDCG@5:0.2935) [0.4 s] *
INFO:root:Epoch 6     loss=0.3054 [10.4 s]    dev=(HR@5:0.4265,NDCG@5:0.3064) [0.4 s] *
INFO:root:Epoch 7     loss=0.2870 [10.9 s]    dev=(HR@5:0.4306,NDCG@5:0.3108) [0.4 s] *
INFO:root:Epoch 8     loss=0.2712 [11.2 s]    dev=(HR@5:0.4385,NDCG@5:0.3184) [0.4 s] *
INFO:root:Epoch 9     loss=0.2583 [10.6 s]    dev=(HR@5:0.4392,NDCG@5:0.3199) [0.4 s] *
INFO:root:Epoch 10    loss=0.2489 [11.2 s]    dev=(HR@5:0.4430,NDCG@5:0.3233) [0.4 s] *
INFO:root:Epoch 11    loss=0.2393 [11.3 s]    dev=(HR@5:0.4453,NDCG@5:0.3259) [0.4 s] *
INFO:root:Epoch 12    loss=0.2312 [11.3 s]    dev=(HR@5:0.4469,NDCG@5:0.3273) [0.4 s] *
INFO:root:Epoch 13    loss=0.2275 [10.4 s]    dev=(HR@5:0.4517,NDCG@5:0.3324) [0.4 s] *
INFO:root:Epoch 14    loss=0.2231 [11.5 s]    dev=(HR@5:0.4536,NDCG@5:0.3332) [0.4 s] *
INFO:root:Epoch 15    loss=0.2195 [11.2 s]    dev=(HR@5:0.4487,NDCG@5:0.3297) [0.4 s]
INFO:root:Epoch 16    loss=0.2167 [10.5 s]    dev=(HR@5:0.4497,NDCG@5:0.3317) [0.4 s]
INFO:root:Epoch 17    loss=0.2130 [10.3 s]    dev=(HR@5:0.4526,NDCG@5:0.3338) [0.4 s] *
INFO:root:Epoch 18    loss=0.2095 [11.4 s]    dev=(HR@5:0.4539,NDCG@5:0.3340) [0.4 s] *
INFO:root:Epoch 19    loss=0.2081 [11.0 s]    dev=(HR@5:0.4509,NDCG@5:0.3337) [0.4 s]
INFO:root:Epoch 20    loss=0.2053 [11.4 s]    dev=(HR@5:0.4529,NDCG@5:0.3353) [0.4 s] *
INFO:root:Epoch 21    loss=0.2019 [11.2 s]    dev=(HR@5:0.4539,NDCG@5:0.3349) [0.4 s]
INFO:root:Epoch 22    loss=0.2023 [10.8 s]    dev=(HR@5:0.4530,NDCG@5:0.3355) [0.4 s] *
INFO:root:Epoch 23    loss=0.2027 [11.3 s]    dev=(HR@5:0.4511,NDCG@5:0.3348) [0.4 s]
INFO:root:Epoch 24    loss=0.2016 [11.0 s]    dev=(HR@5:0.4511,NDCG@5:0.3339) [0.4 s]
INFO:root:Epoch 25    loss=0.1983 [11.5 s]    dev=(HR@5:0.4492,NDCG@5:0.3324) [0.4 s]
INFO:root:Epoch 26    loss=0.1987 [11.5 s]    dev=(HR@5:0.4507,NDCG@5:0.3358) [0.4 s] *
INFO:root:Epoch 27    loss=0.1985 [11.3 s]    dev=(HR@5:0.4507,NDCG@5:0.3342) [0.4 s]
INFO:root:Epoch 28    loss=0.1986 [11.2 s]    dev=(HR@5:0.4534,NDCG@5:0.3371) [0.4 s] *
INFO:root:Epoch 29    loss=0.1965 [10.5 s]    dev=(HR@5:0.4517,NDCG@5:0.3354) [0.4 s]
INFO:root:Epoch 30    loss=0.1971 [10.5 s]    dev=(HR@5:0.4539,NDCG@5:0.3372) [0.4 s] *
INFO:root:Epoch 31    loss=0.1944 [11.5 s]    dev=(HR@5:0.4584,NDCG@5:0.3404) [0.4 s] *
INFO:root:Epoch 32    loss=0.1953 [11.4 s]    dev=(HR@5:0.4564,NDCG@5:0.3355) [0.4 s]
INFO:root:Epoch 33    loss=0.1960 [11.0 s]    dev=(HR@5:0.4560,NDCG@5:0.3399) [0.4 s]
INFO:root:Epoch 34    loss=0.1950 [11.3 s]    dev=(HR@5:0.4591,NDCG@5:0.3395) [0.4 s]
INFO:root:Epoch 35    loss=0.1950 [11.5 s]    dev=(HR@5:0.4549,NDCG@5:0.3371) [0.4 s]
INFO:root:Epoch 36    loss=0.1932 [11.3 s]    dev=(HR@5:0.4532,NDCG@5:0.3343) [0.4 s]
INFO:root:Epoch 37    loss=0.1939 [11.4 s]    dev=(HR@5:0.4554,NDCG@5:0.3367) [0.4 s]
INFO:root:Epoch 38    loss=0.1950 [11.1 s]    dev=(HR@5:0.4542,NDCG@5:0.3358) [0.4 s]
INFO:root:Epoch 39    loss=0.1943 [11.4 s]    dev=(HR@5:0.4530,NDCG@5:0.3343) [0.4 s]
INFO:root:Epoch 40    loss=0.1943 [11.3 s]    dev=(HR@5:0.4552,NDCG@5:0.3368) [0.4 s]
INFO:root:Epoch 41    loss=0.1948 [11.3 s]    dev=(HR@5:0.4564,NDCG@5:0.3365) [0.4 s]
INFO:root:Epoch 42    loss=0.1940 [10.7 s]    dev=(HR@5:0.4567,NDCG@5:0.3358) [0.4 s]
INFO:root:Epoch 43    loss=0.1926 [10.7 s]    dev=(HR@5:0.4578,NDCG@5:0.3387) [0.4 s]
INFO:root:Epoch 44    loss=0.1941 [10.7 s]    dev=(HR@5:0.4549,NDCG@5:0.3357) [0.4 s]
INFO:root:Epoch 45    loss=0.1914 [11.1 s]    dev=(HR@5:0.4588,NDCG@5:0.3411) [0.4 s] *
INFO:root:Epoch 46    loss=0.1926 [11.2 s]    dev=(HR@5:0.4545,NDCG@5:0.3384) [0.4 s]
INFO:root:Epoch 47    loss=0.1923 [11.1 s]    dev=(HR@5:0.4550,NDCG@5:0.3358) [0.4 s]
INFO:root:Epoch 48    loss=0.1913 [11.4 s]    dev=(HR@5:0.4549,NDCG@5:0.3367) [0.4 s]
INFO:root:Epoch 49    loss=0.1906 [11.4 s]    dev=(HR@5:0.4568,NDCG@5:0.3372) [0.4 s]
INFO:root:Epoch 50    loss=0.1926 [11.5 s]    dev=(HR@5:0.4525,NDCG@5:0.3341) [0.4 s]
INFO:root:Epoch 51    loss=0.1906 [11.2 s]    dev=(HR@5:0.4573,NDCG@5:0.3385) [0.4 s]
INFO:root:Epoch 52    loss=0.1915 [11.3 s]    dev=(HR@5:0.4544,NDCG@5:0.3358) [0.4 s]
INFO:root:Epoch 53    loss=0.1911 [11.3 s]    dev=(HR@5:0.4526,NDCG@5:0.3354) [0.4 s]
INFO:root:Epoch 54    loss=0.1884 [11.2 s]    dev=(HR@5:0.4587,NDCG@5:0.3382) [0.4 s]
INFO:root:Epoch 55    loss=0.1898 [11.3 s]    dev=(HR@5:0.4577,NDCG@5:0.3373) [0.4 s]
INFO:root:Epoch 56    loss=0.1894 [11.2 s]    dev=(HR@5:0.4583,NDCG@5:0.3379) [0.4 s]
INFO:root:Epoch 57    loss=0.1900 [11.3 s]    dev=(HR@5:0.4551,NDCG@5:0.3368) [0.4 s]
INFO:root:Epoch 58    loss=0.1908 [11.4 s]    dev=(HR@5:0.4582,NDCG@5:0.3389) [0.4 s]
INFO:root:Epoch 59    loss=0.1901 [11.2 s]    dev=(HR@5:0.4537,NDCG@5:0.3355) [0.4 s]
INFO:root:Epoch 60    loss=0.1903 [11.5 s]    dev=(HR@5:0.4570,NDCG@5:0.3375) [0.4 s]
INFO:root:Epoch 61    loss=0.1896 [11.4 s]    dev=(HR@5:0.4577,NDCG@5:0.3393) [0.4 s]
INFO:root:Epoch 62    loss=0.1881 [11.0 s]    dev=(HR@5:0.4586,NDCG@5:0.3383) [0.4 s]
INFO:root:Epoch 63    loss=0.1895 [11.3 s]    dev=(HR@5:0.4606,NDCG@5:0.3391) [0.4 s]
INFO:root:Epoch 64    loss=0.1875 [11.3 s]    dev=(HR@5:0.4550,NDCG@5:0.3351) [0.4 s]
INFO:root:Epoch 65    loss=0.1879 [11.5 s]    dev=(HR@5:0.4504,NDCG@5:0.3334) [0.4 s]
INFO:root:Early stop at 65 based on dev result.
INFO:root:
Best Iter(dev)=   45	 dev=(HR@5:0.4588,NDCG@5:0.3411) [751.4 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.4136,NDCG@5:0.2990,HR@10:0.5184,NDCG@10:0.3328,HR@20:0.6388,NDCG@20:0.3632,HR@50:0.8394,NDCG@50:0.4029)
INFO:root:
--------------------------------------------- END: 2024-12-23 08:48:06 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 09:13:45 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5143 [12.0 s]    dev=(HR@5:0.2522,NDCG@5:0.1676) [0.4 s] *
INFO:root:Epoch 2     loss=0.4311 [11.4 s]    dev=(HR@5:0.3159,NDCG@5:0.2135) [0.4 s] *
INFO:root:Epoch 3     loss=0.3977 [11.2 s]    dev=(HR@5:0.3404,NDCG@5:0.2286) [0.4 s] *
INFO:root:Epoch 4     loss=0.3761 [11.3 s]    dev=(HR@5:0.3581,NDCG@5:0.2447) [0.4 s] *
INFO:root:Epoch 5     loss=0.3520 [9.9 s]    dev=(HR@5:0.3736,NDCG@5:0.2598) [0.4 s] *
INFO:root:Epoch 6     loss=0.3285 [10.9 s]    dev=(HR@5:0.3929,NDCG@5:0.2786) [0.4 s] *
INFO:root:Epoch 7     loss=0.3116 [11.0 s]    dev=(HR@5:0.3970,NDCG@5:0.2804) [0.4 s] *
INFO:root:Epoch 8     loss=0.2998 [11.3 s]    dev=(HR@5:0.4008,NDCG@5:0.2858) [0.4 s] *
INFO:root:Epoch 9     loss=0.2876 [11.3 s]    dev=(HR@5:0.3975,NDCG@5:0.2849) [0.4 s]
INFO:root:Epoch 10    loss=0.2804 [11.1 s]    dev=(HR@5:0.4041,NDCG@5:0.2882) [0.4 s] *
INFO:root:Epoch 11    loss=0.2725 [11.3 s]    dev=(HR@5:0.4059,NDCG@5:0.2885) [0.4 s] *
INFO:root:Epoch 12    loss=0.2654 [11.4 s]    dev=(HR@5:0.4107,NDCG@5:0.2947) [0.4 s] *
INFO:root:Epoch 13    loss=0.2617 [11.5 s]    dev=(HR@5:0.4165,NDCG@5:0.2992) [0.4 s] *
INFO:root:Epoch 14    loss=0.2575 [11.4 s]    dev=(HR@5:0.4131,NDCG@5:0.2960) [0.4 s]
INFO:root:Epoch 15    loss=0.2545 [11.2 s]    dev=(HR@5:0.4135,NDCG@5:0.2962) [0.4 s]
INFO:root:Epoch 16    loss=0.2523 [11.2 s]    dev=(HR@5:0.4173,NDCG@5:0.2999) [0.4 s] *
INFO:root:Epoch 17    loss=0.2482 [11.4 s]    dev=(HR@5:0.4130,NDCG@5:0.2973) [0.4 s]
INFO:root:Epoch 18    loss=0.2439 [11.1 s]    dev=(HR@5:0.4169,NDCG@5:0.2993) [0.4 s]
INFO:root:Epoch 19    loss=0.2406 [11.0 s]    dev=(HR@5:0.4196,NDCG@5:0.3033) [0.4 s] *
INFO:root:Epoch 20    loss=0.2385 [11.2 s]    dev=(HR@5:0.4249,NDCG@5:0.3064) [0.4 s] *
INFO:root:Epoch 21    loss=0.2343 [11.6 s]    dev=(HR@5:0.4269,NDCG@5:0.3075) [0.4 s] *
INFO:root:Epoch 22    loss=0.2322 [11.5 s]    dev=(HR@5:0.4254,NDCG@5:0.3085) [0.4 s] *
INFO:root:Epoch 23    loss=0.2333 [10.7 s]    dev=(HR@5:0.4218,NDCG@5:0.3064) [0.4 s]
INFO:root:Epoch 24    loss=0.2315 [11.2 s]    dev=(HR@5:0.4330,NDCG@5:0.3122) [0.4 s] *
INFO:root:Epoch 25    loss=0.2281 [11.0 s]    dev=(HR@5:0.4273,NDCG@5:0.3092) [0.4 s]
INFO:root:Epoch 26    loss=0.2285 [10.4 s]    dev=(HR@5:0.4297,NDCG@5:0.3110) [0.4 s]
INFO:root:Epoch 27    loss=0.2275 [10.8 s]    dev=(HR@5:0.4306,NDCG@5:0.3120) [0.4 s]
INFO:root:Epoch 28    loss=0.2278 [11.1 s]    dev=(HR@5:0.4317,NDCG@5:0.3139) [0.4 s] *
INFO:root:Epoch 29    loss=0.2249 [10.6 s]    dev=(HR@5:0.4275,NDCG@5:0.3109) [0.4 s]
INFO:root:Epoch 30    loss=0.2242 [10.3 s]    dev=(HR@5:0.4288,NDCG@5:0.3123) [0.4 s]
INFO:root:Epoch 31    loss=0.2225 [11.3 s]    dev=(HR@5:0.4319,NDCG@5:0.3148) [0.4 s] *
INFO:root:Epoch 32    loss=0.2236 [11.2 s]    dev=(HR@5:0.4307,NDCG@5:0.3113) [0.4 s]
INFO:root:Epoch 33    loss=0.2232 [11.2 s]    dev=(HR@5:0.4336,NDCG@5:0.3149) [0.4 s] *
INFO:root:Epoch 34    loss=0.2219 [11.1 s]    dev=(HR@5:0.4345,NDCG@5:0.3143) [0.4 s]
INFO:root:Epoch 35    loss=0.2218 [11.3 s]    dev=(HR@5:0.4327,NDCG@5:0.3121) [0.4 s]
INFO:root:Epoch 36    loss=0.2196 [11.1 s]    dev=(HR@5:0.4280,NDCG@5:0.3075) [0.4 s]
INFO:root:Epoch 37    loss=0.2208 [11.2 s]    dev=(HR@5:0.4291,NDCG@5:0.3110) [0.4 s]
INFO:root:Epoch 38    loss=0.2199 [11.4 s]    dev=(HR@5:0.4314,NDCG@5:0.3126) [0.4 s]
INFO:root:Epoch 39    loss=0.2202 [11.3 s]    dev=(HR@5:0.4281,NDCG@5:0.3097) [0.4 s]
INFO:root:Epoch 40    loss=0.2195 [10.9 s]    dev=(HR@5:0.4312,NDCG@5:0.3120) [0.4 s]
INFO:root:Epoch 41    loss=0.2201 [11.1 s]    dev=(HR@5:0.4299,NDCG@5:0.3090) [0.4 s]
INFO:root:Epoch 42    loss=0.2200 [10.9 s]    dev=(HR@5:0.4353,NDCG@5:0.3156) [0.4 s] *
INFO:root:Epoch 43    loss=0.2190 [11.3 s]    dev=(HR@5:0.4358,NDCG@5:0.3173) [0.4 s] *
INFO:root:Epoch 44    loss=0.2194 [11.1 s]    dev=(HR@5:0.4378,NDCG@5:0.3156) [0.4 s]
INFO:root:Epoch 45    loss=0.2156 [11.1 s]    dev=(HR@5:0.4386,NDCG@5:0.3183) [0.4 s] *
INFO:root:Epoch 46    loss=0.2180 [10.6 s]    dev=(HR@5:0.4299,NDCG@5:0.3100) [0.4 s]
INFO:root:Epoch 47    loss=0.2182 [11.2 s]    dev=(HR@5:0.4339,NDCG@5:0.3134) [0.4 s]
INFO:root:Epoch 48    loss=0.2167 [11.0 s]    dev=(HR@5:0.4335,NDCG@5:0.3135) [0.4 s]
INFO:root:Epoch 49    loss=0.2153 [11.1 s]    dev=(HR@5:0.4415,NDCG@5:0.3177) [0.4 s]
INFO:root:Epoch 50    loss=0.2163 [11.3 s]    dev=(HR@5:0.4334,NDCG@5:0.3156) [0.4 s]
INFO:root:Epoch 51    loss=0.2156 [11.2 s]    dev=(HR@5:0.4373,NDCG@5:0.3156) [0.4 s]
INFO:root:Epoch 52    loss=0.2155 [11.2 s]    dev=(HR@5:0.4368,NDCG@5:0.3158) [0.4 s]
INFO:root:Epoch 53    loss=0.2153 [10.4 s]    dev=(HR@5:0.4329,NDCG@5:0.3136) [0.4 s]
INFO:root:Epoch 54    loss=0.2132 [11.2 s]    dev=(HR@5:0.4349,NDCG@5:0.3142) [0.4 s]
INFO:root:Epoch 55    loss=0.2146 [11.4 s]    dev=(HR@5:0.4370,NDCG@5:0.3168) [0.4 s]
INFO:root:Epoch 56    loss=0.2143 [11.5 s]    dev=(HR@5:0.4349,NDCG@5:0.3174) [0.4 s]
INFO:root:Epoch 57    loss=0.2146 [11.2 s]    dev=(HR@5:0.4382,NDCG@5:0.3177) [0.4 s]
INFO:root:Epoch 58    loss=0.2155 [11.4 s]    dev=(HR@5:0.4371,NDCG@5:0.3193) [0.4 s] *
INFO:root:Epoch 59    loss=0.2144 [11.5 s]    dev=(HR@5:0.4401,NDCG@5:0.3199) [0.4 s] *
INFO:root:Epoch 60    loss=0.2144 [11.2 s]    dev=(HR@5:0.4372,NDCG@5:0.3172) [0.4 s]
INFO:root:Epoch 61    loss=0.2138 [11.2 s]    dev=(HR@5:0.4417,NDCG@5:0.3204) [0.4 s] *
INFO:root:Epoch 62    loss=0.2129 [11.2 s]    dev=(HR@5:0.4396,NDCG@5:0.3184) [0.4 s]
INFO:root:Epoch 63    loss=0.2148 [11.4 s]    dev=(HR@5:0.4416,NDCG@5:0.3201) [0.4 s]
INFO:root:Epoch 64    loss=0.2125 [11.2 s]    dev=(HR@5:0.4383,NDCG@5:0.3189) [0.4 s]
INFO:root:Epoch 65    loss=0.2136 [11.3 s]    dev=(HR@5:0.4344,NDCG@5:0.3150) [0.4 s]
INFO:root:Epoch 66    loss=0.2122 [11.3 s]    dev=(HR@5:0.4357,NDCG@5:0.3152) [0.4 s]
INFO:root:Epoch 67    loss=0.2120 [11.3 s]    dev=(HR@5:0.4383,NDCG@5:0.3182) [0.4 s]
INFO:root:Epoch 68    loss=0.2109 [10.8 s]    dev=(HR@5:0.4353,NDCG@5:0.3176) [0.4 s]
INFO:root:Epoch 69    loss=0.2131 [9.9 s]    dev=(HR@5:0.4345,NDCG@5:0.3160) [0.4 s]
INFO:root:Epoch 70    loss=0.2117 [11.3 s]    dev=(HR@5:0.4329,NDCG@5:0.3166) [0.4 s]
INFO:root:Epoch 71    loss=0.2105 [11.1 s]    dev=(HR@5:0.4323,NDCG@5:0.3146) [0.4 s]
INFO:root:Epoch 72    loss=0.2104 [11.5 s]    dev=(HR@5:0.4338,NDCG@5:0.3164) [0.4 s]
INFO:root:Epoch 73    loss=0.2114 [11.3 s]    dev=(HR@5:0.4344,NDCG@5:0.3147) [0.4 s]
INFO:root:Epoch 74    loss=0.2112 [9.8 s]    dev=(HR@5:0.4336,NDCG@5:0.3117) [0.4 s]
INFO:root:Epoch 75    loss=0.2132 [10.4 s]    dev=(HR@5:0.4385,NDCG@5:0.3170) [0.4 s]
INFO:root:Epoch 76    loss=0.2113 [10.4 s]    dev=(HR@5:0.4402,NDCG@5:0.3194) [0.4 s]
INFO:root:Epoch 77    loss=0.2099 [11.5 s]    dev=(HR@5:0.4387,NDCG@5:0.3173) [0.4 s]
INFO:root:Epoch 78    loss=0.2101 [11.3 s]    dev=(HR@5:0.4398,NDCG@5:0.3177) [0.4 s]
INFO:root:Epoch 79    loss=0.2108 [11.6 s]    dev=(HR@5:0.4377,NDCG@5:0.3172) [0.4 s]
INFO:root:Epoch 80    loss=0.2072 [11.3 s]    dev=(HR@5:0.4375,NDCG@5:0.3158) [0.4 s]
INFO:root:Epoch 81    loss=0.2092 [11.3 s]    dev=(HR@5:0.4351,NDCG@5:0.3144) [0.4 s]
INFO:root:Early stop at 81 based on dev result.
INFO:root:
Best Iter(dev)=   61	 dev=(HR@5:0.4417,NDCG@5:0.3204) [932.2 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.3888,NDCG@5:0.2745,HR@10:0.5048,NDCG@10:0.3122,HR@20:0.6276,NDCG@20:0.3431,HR@50:0.8337,NDCG@50:0.3840)
INFO:root:
--------------------------------------------- END: 2024-12-23 09:29:20 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 09:54:07 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5140 [12.6 s]    dev=(HR@5:0.2615,NDCG@5:0.1751) [0.4 s] *
INFO:root:Epoch 2     loss=0.4228 [11.2 s]    dev=(HR@5:0.3350,NDCG@5:0.2289) [0.4 s] *
INFO:root:Epoch 3     loss=0.3870 [12.0 s]    dev=(HR@5:0.3633,NDCG@5:0.2491) [0.4 s] *
INFO:root:Epoch 4     loss=0.3635 [11.6 s]    dev=(HR@5:0.3826,NDCG@5:0.2665) [0.4 s] *
INFO:root:Epoch 5     loss=0.3385 [11.4 s]    dev=(HR@5:0.4004,NDCG@5:0.2826) [0.4 s] *
INFO:root:Epoch 6     loss=0.3131 [11.3 s]    dev=(HR@5:0.4127,NDCG@5:0.2942) [0.4 s] *
INFO:root:Epoch 7     loss=0.2950 [11.2 s]    dev=(HR@5:0.4165,NDCG@5:0.2974) [0.4 s] *
INFO:root:Epoch 8     loss=0.2809 [11.9 s]    dev=(HR@5:0.4245,NDCG@5:0.3061) [0.4 s] *
INFO:root:Epoch 9     loss=0.2683 [11.9 s]    dev=(HR@5:0.4267,NDCG@5:0.3075) [0.4 s] *
INFO:root:Epoch 10    loss=0.2602 [11.7 s]    dev=(HR@5:0.4278,NDCG@5:0.3085) [0.4 s] *
INFO:root:Epoch 11    loss=0.2523 [11.9 s]    dev=(HR@5:0.4293,NDCG@5:0.3103) [0.4 s] *
INFO:root:Epoch 12    loss=0.2454 [11.8 s]    dev=(HR@5:0.4325,NDCG@5:0.3126) [0.4 s] *
INFO:root:Epoch 13    loss=0.2417 [11.9 s]    dev=(HR@5:0.4355,NDCG@5:0.3159) [0.4 s] *
INFO:root:Epoch 14    loss=0.2384 [11.6 s]    dev=(HR@5:0.4348,NDCG@5:0.3141) [0.4 s]
INFO:root:Epoch 15    loss=0.2351 [11.0 s]    dev=(HR@5:0.4329,NDCG@5:0.3146) [0.4 s]
INFO:root:Epoch 16    loss=0.2326 [11.4 s]    dev=(HR@5:0.4343,NDCG@5:0.3153) [0.4 s]
INFO:root:Epoch 17    loss=0.2296 [11.9 s]    dev=(HR@5:0.4353,NDCG@5:0.3146) [0.4 s]
INFO:root:Epoch 18    loss=0.2253 [11.9 s]    dev=(HR@5:0.4352,NDCG@5:0.3150) [0.4 s]
INFO:root:Epoch 19    loss=0.2235 [11.8 s]    dev=(HR@5:0.4340,NDCG@5:0.3159) [0.4 s] *
INFO:root:Epoch 20    loss=0.2217 [12.0 s]    dev=(HR@5:0.4383,NDCG@5:0.3192) [0.4 s] *
INFO:root:Epoch 21    loss=0.2176 [11.1 s]    dev=(HR@5:0.4404,NDCG@5:0.3190) [0.4 s]
INFO:root:Epoch 22    loss=0.2169 [10.4 s]    dev=(HR@5:0.4383,NDCG@5:0.3189) [0.4 s]
INFO:root:Epoch 23    loss=0.2181 [12.0 s]    dev=(HR@5:0.4378,NDCG@5:0.3196) [0.4 s] *
INFO:root:Epoch 24    loss=0.2167 [11.7 s]    dev=(HR@5:0.4433,NDCG@5:0.3220) [0.4 s] *
INFO:root:Epoch 25    loss=0.2136 [11.9 s]    dev=(HR@5:0.4353,NDCG@5:0.3171) [0.4 s]
INFO:root:Epoch 26    loss=0.2141 [11.4 s]    dev=(HR@5:0.4373,NDCG@5:0.3180) [0.4 s]
INFO:root:Epoch 27    loss=0.2131 [11.3 s]    dev=(HR@5:0.4374,NDCG@5:0.3194) [0.4 s]
INFO:root:Epoch 28    loss=0.2127 [11.1 s]    dev=(HR@5:0.4398,NDCG@5:0.3220) [0.4 s]
INFO:root:Epoch 29    loss=0.2112 [11.9 s]    dev=(HR@5:0.4370,NDCG@5:0.3182) [0.4 s]
INFO:root:Epoch 30    loss=0.2102 [11.8 s]    dev=(HR@5:0.4370,NDCG@5:0.3186) [0.4 s]
INFO:root:Epoch 31    loss=0.2103 [11.9 s]    dev=(HR@5:0.4399,NDCG@5:0.3228) [0.4 s] *
INFO:root:Epoch 32    loss=0.2106 [12.1 s]    dev=(HR@5:0.4383,NDCG@5:0.3190) [0.4 s]
INFO:root:Epoch 33    loss=0.2108 [11.9 s]    dev=(HR@5:0.4426,NDCG@5:0.3238) [0.4 s] *
INFO:root:Epoch 34    loss=0.2091 [11.9 s]    dev=(HR@5:0.4419,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 35    loss=0.2102 [11.8 s]    dev=(HR@5:0.4368,NDCG@5:0.3178) [0.4 s]
INFO:root:Epoch 36    loss=0.2076 [11.8 s]    dev=(HR@5:0.4383,NDCG@5:0.3186) [0.4 s]
INFO:root:Epoch 37    loss=0.2078 [11.9 s]    dev=(HR@5:0.4375,NDCG@5:0.3186) [0.4 s]
INFO:root:Epoch 38    loss=0.2082 [10.7 s]    dev=(HR@5:0.4394,NDCG@5:0.3192) [0.4 s]
INFO:root:Epoch 39    loss=0.2088 [12.0 s]    dev=(HR@5:0.4328,NDCG@5:0.3146) [0.4 s]
INFO:root:Epoch 40    loss=0.2077 [11.4 s]    dev=(HR@5:0.4386,NDCG@5:0.3191) [0.4 s]
INFO:root:Epoch 41    loss=0.2081 [11.4 s]    dev=(HR@5:0.4404,NDCG@5:0.3197) [0.4 s]
INFO:root:Epoch 42    loss=0.2069 [11.6 s]    dev=(HR@5:0.4439,NDCG@5:0.3225) [0.4 s]
INFO:root:Epoch 43    loss=0.2061 [11.7 s]    dev=(HR@5:0.4445,NDCG@5:0.3242) [0.4 s] *
INFO:root:Epoch 44    loss=0.2084 [10.2 s]    dev=(HR@5:0.4411,NDCG@5:0.3220) [0.4 s]
INFO:root:Epoch 45    loss=0.2046 [9.9 s]    dev=(HR@5:0.4445,NDCG@5:0.3240) [0.4 s]
INFO:root:Epoch 46    loss=0.2066 [11.4 s]    dev=(HR@5:0.4383,NDCG@5:0.3175) [0.4 s]
INFO:root:Epoch 47    loss=0.2060 [11.3 s]    dev=(HR@5:0.4402,NDCG@5:0.3205) [0.4 s]
INFO:root:Epoch 48    loss=0.2057 [11.3 s]    dev=(HR@5:0.4392,NDCG@5:0.3194) [0.4 s]
INFO:root:Epoch 49    loss=0.2041 [11.2 s]    dev=(HR@5:0.4447,NDCG@5:0.3252) [0.4 s] *
INFO:root:Epoch 50    loss=0.2060 [11.5 s]    dev=(HR@5:0.4410,NDCG@5:0.3223) [0.4 s]
INFO:root:Epoch 51    loss=0.2045 [11.1 s]    dev=(HR@5:0.4380,NDCG@5:0.3201) [0.4 s]
INFO:root:Epoch 52    loss=0.2050 [11.0 s]    dev=(HR@5:0.4412,NDCG@5:0.3224) [0.4 s]
INFO:root:Epoch 53    loss=0.2043 [10.7 s]    dev=(HR@5:0.4408,NDCG@5:0.3224) [0.4 s]
INFO:root:Epoch 54    loss=0.2034 [11.5 s]    dev=(HR@5:0.4408,NDCG@5:0.3206) [0.4 s]
INFO:root:Epoch 55    loss=0.2035 [11.5 s]    dev=(HR@5:0.4402,NDCG@5:0.3224) [0.4 s]
INFO:root:Epoch 56    loss=0.2037 [11.3 s]    dev=(HR@5:0.4425,NDCG@5:0.3237) [0.4 s]
INFO:root:Epoch 57    loss=0.2036 [11.2 s]    dev=(HR@5:0.4413,NDCG@5:0.3218) [0.3 s]
INFO:root:Epoch 58    loss=0.2051 [11.4 s]    dev=(HR@5:0.4453,NDCG@5:0.3263) [0.4 s] *
INFO:root:Epoch 59    loss=0.2041 [11.6 s]    dev=(HR@5:0.4437,NDCG@5:0.3249) [0.4 s]
INFO:root:Epoch 60    loss=0.2042 [11.3 s]    dev=(HR@5:0.4423,NDCG@5:0.3236) [0.4 s]
INFO:root:Epoch 61    loss=0.2045 [11.3 s]    dev=(HR@5:0.4457,NDCG@5:0.3271) [0.4 s] *
INFO:root:Epoch 62    loss=0.2031 [11.5 s]    dev=(HR@5:0.4413,NDCG@5:0.3228) [0.4 s]
INFO:root:Epoch 63    loss=0.2050 [11.1 s]    dev=(HR@5:0.4444,NDCG@5:0.3246) [0.4 s]
INFO:root:Epoch 64    loss=0.2025 [11.0 s]    dev=(HR@5:0.4415,NDCG@5:0.3223) [0.4 s]
INFO:root:Epoch 65    loss=0.2042 [11.1 s]    dev=(HR@5:0.4419,NDCG@5:0.3222) [0.4 s]
INFO:root:Epoch 66    loss=0.2023 [10.9 s]    dev=(HR@5:0.4419,NDCG@5:0.3235) [0.4 s]
INFO:root:Epoch 67    loss=0.2027 [11.0 s]    dev=(HR@5:0.4442,NDCG@5:0.3239) [0.4 s]
INFO:root:Epoch 68    loss=0.2014 [10.6 s]    dev=(HR@5:0.4441,NDCG@5:0.3253) [0.4 s]
INFO:root:Epoch 69    loss=0.2034 [10.0 s]    dev=(HR@5:0.4436,NDCG@5:0.3232) [0.4 s]
INFO:root:Epoch 70    loss=0.2025 [10.2 s]    dev=(HR@5:0.4403,NDCG@5:0.3223) [0.4 s]
INFO:root:Epoch 71    loss=0.2024 [11.1 s]    dev=(HR@5:0.4460,NDCG@5:0.3259) [0.4 s]
INFO:root:Epoch 72    loss=0.2019 [11.1 s]    dev=(HR@5:0.4477,NDCG@5:0.3272) [0.4 s] *
INFO:root:Epoch 73    loss=0.2030 [11.0 s]    dev=(HR@5:0.4423,NDCG@5:0.3223) [0.4 s]
INFO:root:Epoch 74    loss=0.2036 [10.9 s]    dev=(HR@5:0.4400,NDCG@5:0.3216) [0.4 s]
INFO:root:Epoch 75    loss=0.2051 [11.4 s]    dev=(HR@5:0.4457,NDCG@5:0.3260) [0.4 s]
INFO:root:Epoch 76    loss=0.2040 [11.4 s]    dev=(HR@5:0.4464,NDCG@5:0.3267) [0.4 s]
INFO:root:Epoch 77    loss=0.2022 [11.2 s]    dev=(HR@5:0.4449,NDCG@5:0.3235) [0.4 s]
INFO:root:Epoch 78    loss=0.2024 [11.1 s]    dev=(HR@5:0.4485,NDCG@5:0.3273) [0.4 s] *
INFO:root:Epoch 79    loss=0.2036 [10.6 s]    dev=(HR@5:0.4471,NDCG@5:0.3243) [0.4 s]
INFO:root:Epoch 80    loss=0.2009 [11.6 s]    dev=(HR@5:0.4432,NDCG@5:0.3217) [0.4 s]
INFO:root:Epoch 81    loss=0.2011 [10.6 s]    dev=(HR@5:0.4412,NDCG@5:0.3188) [0.4 s]
INFO:root:Epoch 82    loss=0.2039 [11.3 s]    dev=(HR@5:0.4427,NDCG@5:0.3231) [0.4 s]
INFO:root:Epoch 83    loss=0.2018 [11.3 s]    dev=(HR@5:0.4445,NDCG@5:0.3232) [0.4 s]
INFO:root:Epoch 84    loss=0.2015 [11.4 s]    dev=(HR@5:0.4457,NDCG@5:0.3240) [0.4 s]
INFO:root:Epoch 85    loss=0.2035 [11.4 s]    dev=(HR@5:0.4472,NDCG@5:0.3260) [0.4 s]
INFO:root:Epoch 86    loss=0.2034 [11.5 s]    dev=(HR@5:0.4449,NDCG@5:0.3239) [0.4 s]
INFO:root:Epoch 87    loss=0.2028 [10.2 s]    dev=(HR@5:0.4450,NDCG@5:0.3248) [0.4 s]
INFO:root:Epoch 88    loss=0.2029 [11.5 s]    dev=(HR@5:0.4436,NDCG@5:0.3234) [0.4 s]
INFO:root:Epoch 89    loss=0.2019 [11.1 s]    dev=(HR@5:0.4429,NDCG@5:0.3236) [0.4 s]
INFO:root:Epoch 90    loss=0.2023 [11.0 s]    dev=(HR@5:0.4464,NDCG@5:0.3262) [0.4 s]
INFO:root:Epoch 91    loss=0.2015 [11.2 s]    dev=(HR@5:0.4483,NDCG@5:0.3281) [0.4 s] *
INFO:root:Epoch 92    loss=0.2003 [10.6 s]    dev=(HR@5:0.4485,NDCG@5:0.3266) [0.4 s]
INFO:root:Epoch 93    loss=0.2029 [10.5 s]    dev=(HR@5:0.4475,NDCG@5:0.3270) [0.4 s]
INFO:root:Epoch 94    loss=0.2020 [10.5 s]    dev=(HR@5:0.4469,NDCG@5:0.3265) [0.4 s]
INFO:root:Epoch 95    loss=0.2025 [11.0 s]    dev=(HR@5:0.4449,NDCG@5:0.3248) [0.4 s]
INFO:root:Epoch 96    loss=0.2005 [11.0 s]    dev=(HR@5:0.4449,NDCG@5:0.3251) [0.4 s]
INFO:root:Epoch 97    loss=0.2019 [10.9 s]    dev=(HR@5:0.4447,NDCG@5:0.3229) [0.4 s]
INFO:root:Epoch 98    loss=0.2003 [10.5 s]    dev=(HR@5:0.4444,NDCG@5:0.3217) [0.4 s]
INFO:root:Epoch 99    loss=0.2016 [10.6 s]    dev=(HR@5:0.4472,NDCG@5:0.3259) [0.4 s]
INFO:root:Epoch 100   loss=0.2010 [11.0 s]    dev=(HR@5:0.4452,NDCG@5:0.3254) [0.4 s]
INFO:root:Epoch 101   loss=0.2022 [11.1 s]    dev=(HR@5:0.4453,NDCG@5:0.3233) [0.4 s]
INFO:root:Epoch 102   loss=0.2032 [11.0 s]    dev=(HR@5:0.4467,NDCG@5:0.3255) [0.4 s]
INFO:root:Epoch 103   loss=0.2016 [10.4 s]    dev=(HR@5:0.4415,NDCG@5:0.3221) [0.4 s]
INFO:root:Epoch 104   loss=0.2016 [11.5 s]    dev=(HR@5:0.4455,NDCG@5:0.3241) [0.4 s]
INFO:root:Epoch 105   loss=0.2011 [11.0 s]    dev=(HR@5:0.4443,NDCG@5:0.3222) [0.4 s]
INFO:root:Epoch 106   loss=0.2005 [11.4 s]    dev=(HR@5:0.4419,NDCG@5:0.3209) [0.4 s]
INFO:root:Epoch 107   loss=0.2015 [10.9 s]    dev=(HR@5:0.4411,NDCG@5:0.3203) [0.4 s]
INFO:root:Epoch 108   loss=0.2015 [11.2 s]    dev=(HR@5:0.4453,NDCG@5:0.3244) [0.4 s]
INFO:root:Epoch 109   loss=0.2004 [11.6 s]    dev=(HR@5:0.4441,NDCG@5:0.3250) [0.4 s]
INFO:root:Epoch 110   loss=0.2001 [11.4 s]    dev=(HR@5:0.4441,NDCG@5:0.3269) [0.4 s]
INFO:root:Epoch 111   loss=0.1999 [11.5 s]    dev=(HR@5:0.4463,NDCG@5:0.3252) [0.4 s]
INFO:root:Early stop at 111 based on dev result.
INFO:root:
Best Iter(dev)=   91	 dev=(HR@5:0.4483,NDCG@5:0.3281) [1295.4 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.4009,NDCG@5:0.2855,HR@10:0.5080,NDCG@10:0.3201,HR@20:0.6315,NDCG@20:0.3513,HR@50:0.8338,NDCG@50:0.3913)
INFO:root:
--------------------------------------------- END: 2024-12-23 10:15:45 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 10:40:37 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5140 [12.7 s]    dev=(HR@5:0.2683,NDCG@5:0.1798) [0.4 s] *
INFO:root:Epoch 2     loss=0.4202 [11.3 s]    dev=(HR@5:0.3399,NDCG@5:0.2327) [0.4 s] *
INFO:root:Epoch 3     loss=0.3835 [11.3 s]    dev=(HR@5:0.3710,NDCG@5:0.2557) [0.4 s] *
INFO:root:Epoch 4     loss=0.3597 [11.5 s]    dev=(HR@5:0.3920,NDCG@5:0.2732) [0.4 s] *
INFO:root:Epoch 5     loss=0.3356 [11.1 s]    dev=(HR@5:0.4065,NDCG@5:0.2885) [0.4 s] *
INFO:root:Epoch 6     loss=0.3099 [11.1 s]    dev=(HR@5:0.4230,NDCG@5:0.3036) [0.4 s] *
INFO:root:Epoch 7     loss=0.2908 [11.5 s]    dev=(HR@5:0.4277,NDCG@5:0.3083) [0.4 s] *
INFO:root:Epoch 8     loss=0.2752 [11.2 s]    dev=(HR@5:0.4336,NDCG@5:0.3144) [0.4 s] *
INFO:root:Epoch 9     loss=0.2617 [11.4 s]    dev=(HR@5:0.4384,NDCG@5:0.3178) [0.4 s] *
INFO:root:Epoch 10    loss=0.2529 [11.4 s]    dev=(HR@5:0.4392,NDCG@5:0.3211) [0.4 s] *
INFO:root:Epoch 11    loss=0.2440 [10.6 s]    dev=(HR@5:0.4434,NDCG@5:0.3235) [0.4 s] *
INFO:root:Epoch 12    loss=0.2365 [11.5 s]    dev=(HR@5:0.4457,NDCG@5:0.3254) [0.4 s] *
INFO:root:Epoch 13    loss=0.2320 [11.4 s]    dev=(HR@5:0.4478,NDCG@5:0.3282) [0.4 s] *
INFO:root:Epoch 14    loss=0.2281 [11.0 s]    dev=(HR@5:0.4489,NDCG@5:0.3285) [0.4 s] *
INFO:root:Epoch 15    loss=0.2249 [11.1 s]    dev=(HR@5:0.4463,NDCG@5:0.3272) [0.4 s]
INFO:root:Epoch 16    loss=0.2223 [11.3 s]    dev=(HR@5:0.4476,NDCG@5:0.3292) [0.4 s] *
INFO:root:Epoch 17    loss=0.2193 [11.3 s]    dev=(HR@5:0.4468,NDCG@5:0.3283) [0.4 s]
INFO:root:Epoch 18    loss=0.2148 [11.1 s]    dev=(HR@5:0.4493,NDCG@5:0.3299) [0.4 s] *
INFO:root:Epoch 19    loss=0.2137 [11.2 s]    dev=(HR@5:0.4511,NDCG@5:0.3316) [0.4 s] *
INFO:root:Epoch 20    loss=0.2107 [11.2 s]    dev=(HR@5:0.4501,NDCG@5:0.3313) [0.4 s]
INFO:root:Epoch 21    loss=0.2068 [11.4 s]    dev=(HR@5:0.4474,NDCG@5:0.3300) [0.4 s]
INFO:root:Epoch 22    loss=0.2071 [11.5 s]    dev=(HR@5:0.4470,NDCG@5:0.3312) [0.4 s]
INFO:root:Epoch 23    loss=0.2071 [11.1 s]    dev=(HR@5:0.4438,NDCG@5:0.3300) [0.4 s]
INFO:root:Epoch 24    loss=0.2058 [11.1 s]    dev=(HR@5:0.4471,NDCG@5:0.3296) [0.4 s]
INFO:root:Epoch 25    loss=0.2032 [11.1 s]    dev=(HR@5:0.4467,NDCG@5:0.3292) [0.4 s]
INFO:root:Epoch 26    loss=0.2037 [11.1 s]    dev=(HR@5:0.4465,NDCG@5:0.3290) [0.4 s]
INFO:root:Epoch 27    loss=0.2032 [11.6 s]    dev=(HR@5:0.4466,NDCG@5:0.3307) [0.4 s]
INFO:root:Epoch 28    loss=0.2019 [11.3 s]    dev=(HR@5:0.4515,NDCG@5:0.3328) [0.4 s] *
INFO:root:Epoch 29    loss=0.2008 [11.2 s]    dev=(HR@5:0.4479,NDCG@5:0.3315) [0.4 s]
INFO:root:Epoch 30    loss=0.2011 [11.5 s]    dev=(HR@5:0.4477,NDCG@5:0.3303) [0.4 s]
INFO:root:Epoch 31    loss=0.2003 [11.4 s]    dev=(HR@5:0.4524,NDCG@5:0.3348) [0.4 s] *
INFO:root:Epoch 32    loss=0.2005 [11.1 s]    dev=(HR@5:0.4498,NDCG@5:0.3317) [0.4 s]
INFO:root:Epoch 33    loss=0.2006 [11.0 s]    dev=(HR@5:0.4490,NDCG@5:0.3327) [0.4 s]
INFO:root:Epoch 34    loss=0.1999 [10.9 s]    dev=(HR@5:0.4505,NDCG@5:0.3331) [0.4 s]
INFO:root:Epoch 35    loss=0.2004 [11.0 s]    dev=(HR@5:0.4460,NDCG@5:0.3289) [0.4 s]
INFO:root:Epoch 36    loss=0.1978 [11.3 s]    dev=(HR@5:0.4487,NDCG@5:0.3296) [0.4 s]
INFO:root:Epoch 37    loss=0.1978 [9.9 s]    dev=(HR@5:0.4500,NDCG@5:0.3320) [0.4 s]
INFO:root:Epoch 38    loss=0.1984 [10.1 s]    dev=(HR@5:0.4515,NDCG@5:0.3320) [0.4 s]
INFO:root:Epoch 39    loss=0.1993 [11.3 s]    dev=(HR@5:0.4451,NDCG@5:0.3267) [0.4 s]
INFO:root:Epoch 40    loss=0.1976 [10.9 s]    dev=(HR@5:0.4490,NDCG@5:0.3301) [0.3 s]
INFO:root:Epoch 41    loss=0.1992 [11.4 s]    dev=(HR@5:0.4487,NDCG@5:0.3298) [0.4 s]
INFO:root:Epoch 42    loss=0.1981 [11.2 s]    dev=(HR@5:0.4514,NDCG@5:0.3305) [0.4 s]
INFO:root:Epoch 43    loss=0.1964 [10.8 s]    dev=(HR@5:0.4537,NDCG@5:0.3329) [0.4 s]
INFO:root:Epoch 44    loss=0.1987 [11.5 s]    dev=(HR@5:0.4489,NDCG@5:0.3296) [0.4 s]
INFO:root:Epoch 45    loss=0.1951 [11.1 s]    dev=(HR@5:0.4512,NDCG@5:0.3330) [0.4 s]
INFO:root:Epoch 46    loss=0.1966 [10.8 s]    dev=(HR@5:0.4479,NDCG@5:0.3297) [0.4 s]
INFO:root:Epoch 47    loss=0.1968 [11.1 s]    dev=(HR@5:0.4477,NDCG@5:0.3297) [0.4 s]
INFO:root:Epoch 48    loss=0.1970 [11.2 s]    dev=(HR@5:0.4474,NDCG@5:0.3294) [0.4 s]
INFO:root:Epoch 49    loss=0.1961 [11.6 s]    dev=(HR@5:0.4504,NDCG@5:0.3313) [0.4 s]
INFO:root:Epoch 50    loss=0.1976 [11.5 s]    dev=(HR@5:0.4484,NDCG@5:0.3299) [0.4 s]
INFO:root:Epoch 51    loss=0.1959 [11.1 s]    dev=(HR@5:0.4496,NDCG@5:0.3322) [0.4 s]
INFO:root:Early stop at 51 based on dev result.
INFO:root:
Best Iter(dev)=   31	 dev=(HR@5:0.4524,NDCG@5:0.3348) [591.1 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.4029,NDCG@5:0.2894,HR@10:0.5092,NDCG@10:0.3238,HR@20:0.6320,NDCG@20:0.3547,HR@50:0.8345,NDCG@50:0.3948)
INFO:root:
--------------------------------------------- END: 2024-12-23 10:50:31 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 11:13:01 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5143 [12.9 s]    dev=(HR@5:0.2597,NDCG@5:0.1742) [0.4 s] *
INFO:root:Epoch 2     loss=0.4232 [11.1 s]    dev=(HR@5:0.3353,NDCG@5:0.2278) [0.4 s] *
INFO:root:Epoch 3     loss=0.3857 [11.0 s]    dev=(HR@5:0.3639,NDCG@5:0.2482) [0.4 s] *
INFO:root:Epoch 4     loss=0.3601 [11.2 s]    dev=(HR@5:0.3870,NDCG@5:0.2691) [0.4 s] *
INFO:root:Epoch 5     loss=0.3336 [10.7 s]    dev=(HR@5:0.4061,NDCG@5:0.2888) [0.4 s] *
INFO:root:Epoch 6     loss=0.3080 [10.2 s]    dev=(HR@5:0.4219,NDCG@5:0.3018) [0.4 s] *
INFO:root:Epoch 7     loss=0.2903 [11.1 s]    dev=(HR@5:0.4277,NDCG@5:0.3067) [0.4 s] *
INFO:root:Epoch 8     loss=0.2765 [11.3 s]    dev=(HR@5:0.4338,NDCG@5:0.3130) [0.4 s] *
INFO:root:Epoch 9     loss=0.2639 [11.0 s]    dev=(HR@5:0.4352,NDCG@5:0.3150) [0.4 s] *
INFO:root:Epoch 10    loss=0.2558 [11.9 s]    dev=(HR@5:0.4362,NDCG@5:0.3176) [0.4 s] *
INFO:root:Epoch 11    loss=0.2467 [11.1 s]    dev=(HR@5:0.4377,NDCG@5:0.3179) [0.4 s] *
INFO:root:Epoch 12    loss=0.2398 [11.9 s]    dev=(HR@5:0.4393,NDCG@5:0.3209) [0.4 s] *
INFO:root:Epoch 13    loss=0.2364 [11.1 s]    dev=(HR@5:0.4446,NDCG@5:0.3258) [0.4 s] *
INFO:root:Epoch 14    loss=0.2320 [12.0 s]    dev=(HR@5:0.4440,NDCG@5:0.3248) [0.4 s]
INFO:root:Epoch 15    loss=0.2278 [11.1 s]    dev=(HR@5:0.4421,NDCG@5:0.3238) [0.4 s]
INFO:root:Epoch 16    loss=0.2253 [11.7 s]    dev=(HR@5:0.4448,NDCG@5:0.3254) [0.4 s]
INFO:root:Epoch 17    loss=0.2221 [11.7 s]    dev=(HR@5:0.4389,NDCG@5:0.3229) [0.4 s]
INFO:root:Epoch 18    loss=0.2174 [11.6 s]    dev=(HR@5:0.4461,NDCG@5:0.3277) [0.4 s] *
INFO:root:Epoch 19    loss=0.2165 [11.5 s]    dev=(HR@5:0.4434,NDCG@5:0.3258) [0.4 s]
INFO:root:Epoch 20    loss=0.2130 [11.6 s]    dev=(HR@5:0.4442,NDCG@5:0.3279) [0.4 s] *
INFO:root:Epoch 21    loss=0.2104 [11.6 s]    dev=(HR@5:0.4442,NDCG@5:0.3265) [0.4 s]
INFO:root:Epoch 22    loss=0.2095 [10.7 s]    dev=(HR@5:0.4413,NDCG@5:0.3269) [0.4 s]
INFO:root:Epoch 23    loss=0.2099 [11.0 s]    dev=(HR@5:0.4434,NDCG@5:0.3285) [0.4 s] *
INFO:root:Epoch 24    loss=0.2088 [11.7 s]    dev=(HR@5:0.4438,NDCG@5:0.3283) [0.4 s]
INFO:root:Epoch 25    loss=0.2059 [11.5 s]    dev=(HR@5:0.4424,NDCG@5:0.3263) [0.4 s]
INFO:root:Epoch 26    loss=0.2061 [11.2 s]    dev=(HR@5:0.4429,NDCG@5:0.3283) [0.5 s]
INFO:root:Epoch 27    loss=0.2058 [11.6 s]    dev=(HR@5:0.4468,NDCG@5:0.3297) [0.4 s] *
INFO:root:Epoch 28    loss=0.2058 [11.2 s]    dev=(HR@5:0.4451,NDCG@5:0.3299) [0.4 s] *
INFO:root:Epoch 29    loss=0.2036 [11.6 s]    dev=(HR@5:0.4417,NDCG@5:0.3274) [0.4 s]
INFO:root:Epoch 30    loss=0.2039 [9.9 s]    dev=(HR@5:0.4441,NDCG@5:0.3300) [0.4 s] *
INFO:root:Epoch 31    loss=0.2018 [11.5 s]    dev=(HR@5:0.4438,NDCG@5:0.3310) [0.4 s] *
INFO:root:Epoch 32    loss=0.2027 [11.1 s]    dev=(HR@5:0.4445,NDCG@5:0.3283) [0.4 s]
INFO:root:Epoch 33    loss=0.2023 [10.8 s]    dev=(HR@5:0.4435,NDCG@5:0.3291) [0.4 s]
INFO:root:Epoch 34    loss=0.2028 [11.4 s]    dev=(HR@5:0.4434,NDCG@5:0.3282) [0.4 s]
INFO:root:Epoch 35    loss=0.2026 [11.6 s]    dev=(HR@5:0.4413,NDCG@5:0.3273) [0.4 s]
INFO:root:Epoch 36    loss=0.2002 [11.0 s]    dev=(HR@5:0.4402,NDCG@5:0.3256) [0.4 s]
INFO:root:Epoch 37    loss=0.2006 [11.6 s]    dev=(HR@5:0.4434,NDCG@5:0.3280) [0.4 s]
INFO:root:Epoch 38    loss=0.2015 [11.4 s]    dev=(HR@5:0.4432,NDCG@5:0.3287) [0.4 s]
INFO:root:Epoch 39    loss=0.2009 [11.3 s]    dev=(HR@5:0.4383,NDCG@5:0.3250) [0.4 s]
INFO:root:Epoch 40    loss=0.2001 [11.4 s]    dev=(HR@5:0.4419,NDCG@5:0.3274) [0.4 s]
INFO:root:Epoch 41    loss=0.2009 [11.5 s]    dev=(HR@5:0.4429,NDCG@5:0.3268) [0.4 s]
INFO:root:Epoch 42    loss=0.2001 [11.5 s]    dev=(HR@5:0.4451,NDCG@5:0.3273) [0.4 s]
INFO:root:Epoch 43    loss=0.1990 [11.7 s]    dev=(HR@5:0.4483,NDCG@5:0.3304) [0.4 s]
INFO:root:Epoch 44    loss=0.1998 [11.6 s]    dev=(HR@5:0.4419,NDCG@5:0.3270) [0.4 s]
INFO:root:Epoch 45    loss=0.1975 [10.6 s]    dev=(HR@5:0.4480,NDCG@5:0.3324) [0.4 s] *
INFO:root:Epoch 46    loss=0.1986 [10.5 s]    dev=(HR@5:0.4440,NDCG@5:0.3297) [0.4 s]
INFO:root:Epoch 47    loss=0.1990 [11.3 s]    dev=(HR@5:0.4434,NDCG@5:0.3274) [0.4 s]
INFO:root:Epoch 48    loss=0.1980 [11.5 s]    dev=(HR@5:0.4450,NDCG@5:0.3294) [0.4 s]
INFO:root:Epoch 49    loss=0.1969 [11.4 s]    dev=(HR@5:0.4494,NDCG@5:0.3305) [0.4 s]
INFO:root:Epoch 50    loss=0.1989 [11.3 s]    dev=(HR@5:0.4417,NDCG@5:0.3260) [0.4 s]
INFO:root:Epoch 51    loss=0.1969 [11.4 s]    dev=(HR@5:0.4434,NDCG@5:0.3287) [0.4 s]
INFO:root:Epoch 52    loss=0.1984 [11.4 s]    dev=(HR@5:0.4453,NDCG@5:0.3295) [0.4 s]
INFO:root:Epoch 53    loss=0.1973 [11.2 s]    dev=(HR@5:0.4414,NDCG@5:0.3268) [0.4 s]
INFO:root:Epoch 54    loss=0.1957 [11.2 s]    dev=(HR@5:0.4429,NDCG@5:0.3269) [0.4 s]
INFO:root:Epoch 55    loss=0.1968 [11.2 s]    dev=(HR@5:0.4453,NDCG@5:0.3295) [0.4 s]
INFO:root:Epoch 56    loss=0.1965 [11.5 s]    dev=(HR@5:0.4440,NDCG@5:0.3283) [0.4 s]
INFO:root:Epoch 57    loss=0.1967 [11.1 s]    dev=(HR@5:0.4425,NDCG@5:0.3282) [0.4 s]
INFO:root:Epoch 58    loss=0.1978 [11.1 s]    dev=(HR@5:0.4474,NDCG@5:0.3312) [0.4 s]
INFO:root:Epoch 59    loss=0.1966 [11.5 s]    dev=(HR@5:0.4467,NDCG@5:0.3300) [0.4 s]
INFO:root:Epoch 60    loss=0.1972 [11.4 s]    dev=(HR@5:0.4496,NDCG@5:0.3322) [0.4 s]
INFO:root:Epoch 61    loss=0.1964 [11.5 s]    dev=(HR@5:0.4479,NDCG@5:0.3308) [0.4 s]
INFO:root:Epoch 62    loss=0.1961 [11.7 s]    dev=(HR@5:0.4442,NDCG@5:0.3275) [0.4 s]
INFO:root:Epoch 63    loss=0.1974 [11.6 s]    dev=(HR@5:0.4482,NDCG@5:0.3309) [0.4 s]
INFO:root:Epoch 64    loss=0.1947 [11.6 s]    dev=(HR@5:0.4450,NDCG@5:0.3278) [0.4 s]
INFO:root:Epoch 65    loss=0.1959 [11.4 s]    dev=(HR@5:0.4418,NDCG@5:0.3262) [0.4 s]
INFO:root:Early stop at 65 based on dev result.
INFO:root:
Best Iter(dev)=   45	 dev=(HR@5:0.4480,NDCG@5:0.3324) [762.0 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.4012,NDCG@5:0.2892,HR@10:0.5072,NDCG@10:0.3235,HR@20:0.6275,NDCG@20:0.3538,HR@50:0.8333,NDCG@50:0.3946)
INFO:root:
--------------------------------------------- END: 2024-12-23 11:25:46 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 11:49:04 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 2                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5147 [12.6 s]    dev=(HR@5:0.2585,NDCG@5:0.1732) [0.4 s] *
INFO:root:Epoch 2     loss=0.4244 [11.2 s]    dev=(HR@5:0.3327,NDCG@5:0.2256) [0.4 s] *
INFO:root:Epoch 3     loss=0.3869 [11.4 s]    dev=(HR@5:0.3613,NDCG@5:0.2466) [0.4 s] *
INFO:root:Epoch 4     loss=0.3608 [10.5 s]    dev=(HR@5:0.3889,NDCG@5:0.2703) [0.4 s] *
INFO:root:Epoch 5     loss=0.3335 [11.5 s]    dev=(HR@5:0.4057,NDCG@5:0.2882) [0.4 s] *
INFO:root:Epoch 6     loss=0.3078 [11.5 s]    dev=(HR@5:0.4205,NDCG@5:0.3022) [0.4 s] *
INFO:root:Epoch 7     loss=0.2899 [11.0 s]    dev=(HR@5:0.4267,NDCG@5:0.3070) [0.4 s] *
INFO:root:Epoch 8     loss=0.2746 [11.5 s]    dev=(HR@5:0.4361,NDCG@5:0.3152) [0.4 s] *
INFO:root:Epoch 9     loss=0.2608 [11.1 s]    dev=(HR@5:0.4386,NDCG@5:0.3195) [0.4 s] *
INFO:root:Epoch 10    loss=0.2512 [11.1 s]    dev=(HR@5:0.4413,NDCG@5:0.3221) [0.4 s] *
INFO:root:Epoch 11    loss=0.2409 [10.6 s]    dev=(HR@5:0.4440,NDCG@5:0.3247) [0.4 s] *
INFO:root:Epoch 12    loss=0.2324 [11.2 s]    dev=(HR@5:0.4509,NDCG@5:0.3302) [0.4 s] *
INFO:root:Epoch 13    loss=0.2283 [11.1 s]    dev=(HR@5:0.4554,NDCG@5:0.3342) [0.4 s] *
INFO:root:Epoch 14    loss=0.2233 [11.4 s]    dev=(HR@5:0.4542,NDCG@5:0.3327) [0.4 s]
INFO:root:Epoch 15    loss=0.2189 [11.3 s]    dev=(HR@5:0.4489,NDCG@5:0.3305) [0.4 s]
INFO:root:Epoch 16    loss=0.2157 [11.5 s]    dev=(HR@5:0.4521,NDCG@5:0.3330) [0.4 s]
INFO:root:Epoch 17    loss=0.2124 [11.1 s]    dev=(HR@5:0.4522,NDCG@5:0.3338) [0.4 s]
INFO:root:Epoch 18    loss=0.2079 [10.9 s]    dev=(HR@5:0.4534,NDCG@5:0.3347) [0.4 s] *
INFO:root:Epoch 19    loss=0.2063 [11.1 s]    dev=(HR@5:0.4526,NDCG@5:0.3346) [0.4 s]
INFO:root:Epoch 20    loss=0.2037 [11.3 s]    dev=(HR@5:0.4530,NDCG@5:0.3371) [0.4 s] *
INFO:root:Epoch 21    loss=0.2005 [11.2 s]    dev=(HR@5:0.4524,NDCG@5:0.3357) [0.4 s]
INFO:root:Epoch 22    loss=0.1999 [11.2 s]    dev=(HR@5:0.4514,NDCG@5:0.3361) [0.4 s]
INFO:root:Epoch 23    loss=0.2007 [11.1 s]    dev=(HR@5:0.4509,NDCG@5:0.3362) [0.4 s]
INFO:root:Epoch 24    loss=0.1994 [10.9 s]    dev=(HR@5:0.4545,NDCG@5:0.3371) [0.4 s]
INFO:root:Epoch 25    loss=0.1962 [11.1 s]    dev=(HR@5:0.4534,NDCG@5:0.3358) [0.4 s]
INFO:root:Epoch 26    loss=0.1968 [10.7 s]    dev=(HR@5:0.4498,NDCG@5:0.3352) [0.4 s]
INFO:root:Epoch 27    loss=0.1966 [11.0 s]    dev=(HR@5:0.4566,NDCG@5:0.3395) [0.4 s] *
INFO:root:Epoch 28    loss=0.1967 [11.2 s]    dev=(HR@5:0.4547,NDCG@5:0.3387) [0.4 s]
INFO:root:Epoch 29    loss=0.1947 [10.9 s]    dev=(HR@5:0.4533,NDCG@5:0.3382) [0.4 s]
INFO:root:Epoch 30    loss=0.1950 [11.1 s]    dev=(HR@5:0.4556,NDCG@5:0.3392) [0.4 s]
INFO:root:Epoch 31    loss=0.1923 [11.1 s]    dev=(HR@5:0.4561,NDCG@5:0.3402) [0.4 s] *
INFO:root:Epoch 32    loss=0.1933 [10.9 s]    dev=(HR@5:0.4548,NDCG@5:0.3368) [0.4 s]
INFO:root:Epoch 33    loss=0.1938 [10.8 s]    dev=(HR@5:0.4566,NDCG@5:0.3405) [0.4 s] *
INFO:root:Epoch 34    loss=0.1925 [11.4 s]    dev=(HR@5:0.4547,NDCG@5:0.3385) [0.4 s]
INFO:root:Epoch 35    loss=0.1932 [11.3 s]    dev=(HR@5:0.4530,NDCG@5:0.3377) [0.4 s]
INFO:root:Epoch 36    loss=0.1912 [11.4 s]    dev=(HR@5:0.4549,NDCG@5:0.3365) [0.4 s]
INFO:root:Epoch 37    loss=0.1913 [11.5 s]    dev=(HR@5:0.4565,NDCG@5:0.3377) [0.4 s]
INFO:root:Epoch 38    loss=0.1916 [11.3 s]    dev=(HR@5:0.4559,NDCG@5:0.3367) [0.4 s]
INFO:root:Epoch 39    loss=0.1918 [11.4 s]    dev=(HR@5:0.4527,NDCG@5:0.3353) [0.3 s]
INFO:root:Epoch 40    loss=0.1915 [10.9 s]    dev=(HR@5:0.4531,NDCG@5:0.3354) [0.4 s]
INFO:root:Epoch 41    loss=0.1919 [11.0 s]    dev=(HR@5:0.4571,NDCG@5:0.3384) [0.4 s]
INFO:root:Epoch 42    loss=0.1910 [11.0 s]    dev=(HR@5:0.4577,NDCG@5:0.3373) [0.4 s]
INFO:root:Epoch 43    loss=0.1899 [11.0 s]    dev=(HR@5:0.4580,NDCG@5:0.3391) [0.4 s]
INFO:root:Epoch 44    loss=0.1911 [11.0 s]    dev=(HR@5:0.4551,NDCG@5:0.3377) [0.4 s]
INFO:root:Epoch 45    loss=0.1885 [10.1 s]    dev=(HR@5:0.4588,NDCG@5:0.3416) [0.4 s] *
INFO:root:Epoch 46    loss=0.1899 [10.9 s]    dev=(HR@5:0.4591,NDCG@5:0.3409) [0.4 s]
INFO:root:Epoch 47    loss=0.1902 [11.0 s]    dev=(HR@5:0.4557,NDCG@5:0.3372) [0.4 s]
INFO:root:Epoch 48    loss=0.1891 [11.3 s]    dev=(HR@5:0.4556,NDCG@5:0.3372) [0.4 s]
INFO:root:Epoch 49    loss=0.1884 [11.1 s]    dev=(HR@5:0.4603,NDCG@5:0.3396) [0.4 s]
INFO:root:Epoch 50    loss=0.1909 [11.1 s]    dev=(HR@5:0.4525,NDCG@5:0.3366) [0.4 s]
INFO:root:Epoch 51    loss=0.1882 [11.0 s]    dev=(HR@5:0.4547,NDCG@5:0.3387) [0.4 s]
INFO:root:Epoch 52    loss=0.1887 [11.2 s]    dev=(HR@5:0.4548,NDCG@5:0.3369) [0.4 s]
INFO:root:Epoch 53    loss=0.1891 [11.3 s]    dev=(HR@5:0.4510,NDCG@5:0.3341) [0.4 s]
INFO:root:Epoch 54    loss=0.1872 [11.1 s]    dev=(HR@5:0.4547,NDCG@5:0.3357) [0.4 s]
INFO:root:Epoch 55    loss=0.1881 [11.1 s]    dev=(HR@5:0.4568,NDCG@5:0.3393) [0.4 s]
INFO:root:Epoch 56    loss=0.1879 [11.2 s]    dev=(HR@5:0.4551,NDCG@5:0.3380) [0.4 s]
INFO:root:Epoch 57    loss=0.1888 [11.2 s]    dev=(HR@5:0.4541,NDCG@5:0.3365) [0.4 s]
INFO:root:Epoch 58    loss=0.1897 [10.2 s]    dev=(HR@5:0.4545,NDCG@5:0.3386) [0.4 s]
INFO:root:Epoch 59    loss=0.1886 [10.9 s]    dev=(HR@5:0.4554,NDCG@5:0.3367) [0.4 s]
INFO:root:Epoch 60    loss=0.1891 [11.2 s]    dev=(HR@5:0.4554,NDCG@5:0.3385) [0.4 s]
INFO:root:Epoch 61    loss=0.1888 [11.1 s]    dev=(HR@5:0.4597,NDCG@5:0.3407) [0.4 s]
INFO:root:Epoch 62    loss=0.1879 [11.1 s]    dev=(HR@5:0.4583,NDCG@5:0.3379) [0.4 s]
INFO:root:Epoch 63    loss=0.1894 [11.1 s]    dev=(HR@5:0.4586,NDCG@5:0.3407) [0.4 s]
INFO:root:Epoch 64    loss=0.1876 [11.0 s]    dev=(HR@5:0.4545,NDCG@5:0.3374) [0.4 s]
INFO:root:Epoch 65    loss=0.1879 [11.1 s]    dev=(HR@5:0.4518,NDCG@5:0.3373) [0.4 s]
INFO:root:Early stop at 65 based on dev result.
INFO:root:
Best Iter(dev)=   45	 dev=(HR@5:0.4588,NDCG@5:0.3416) [748.1 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=2.pt
INFO:root:
Test After Training: (HR@5:0.4101,NDCG@5:0.2973,HR@10:0.5179,NDCG@10:0.3322,HR@20:0.6401,NDCG@20:0.3630,HR@50:0.8356,NDCG@50:0.4017)
INFO:root:
--------------------------------------------- END: 2024-12-23 12:01:35 ---------------------------------------------
