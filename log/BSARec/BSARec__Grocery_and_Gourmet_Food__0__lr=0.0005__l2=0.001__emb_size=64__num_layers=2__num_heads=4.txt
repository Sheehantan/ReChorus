INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-04 12:30:52 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5165 [22.9 s]    dev=(HR@5:0.2500,NDCG@5:0.1661) [1.0 s] *
INFO:root:Epoch 2     loss=0.4338 [21.1 s]    dev=(HR@5:0.3183,NDCG@5:0.2150) [0.9 s] *
INFO:root:Epoch 3     loss=0.3986 [20.7 s]    dev=(HR@5:0.3446,NDCG@5:0.2316) [0.9 s] *
INFO:root:Epoch 4     loss=0.3764 [20.7 s]    dev=(HR@5:0.3688,NDCG@5:0.2541) [0.9 s] *
INFO:root:Epoch 5     loss=0.3502 [20.8 s]    dev=(HR@5:0.3838,NDCG@5:0.2678) [0.9 s] *
INFO:root:Epoch 6     loss=0.3244 [20.7 s]    dev=(HR@5:0.3979,NDCG@5:0.2813) [1.0 s] *
INFO:root:Epoch 7     loss=0.3046 [21.5 s]    dev=(HR@5:0.4023,NDCG@5:0.2869) [0.9 s] *
INFO:root:Epoch 8     loss=0.2870 [20.8 s]    dev=(HR@5:0.4113,NDCG@5:0.2955) [0.9 s] *
INFO:root:Epoch 9     loss=0.2726 [20.6 s]    dev=(HR@5:0.4130,NDCG@5:0.2978) [1.0 s] *
INFO:root:Epoch 10    loss=0.2621 [20.6 s]    dev=(HR@5:0.4171,NDCG@5:0.3015) [1.0 s] *
INFO:root:Epoch 11    loss=0.2521 [22.0 s]    dev=(HR@5:0.4195,NDCG@5:0.3029) [1.0 s] *
INFO:root:Epoch 12    loss=0.2433 [21.3 s]    dev=(HR@5:0.4229,NDCG@5:0.3061) [1.0 s] *
INFO:root:Epoch 13    loss=0.2399 [21.1 s]    dev=(HR@5:0.4268,NDCG@5:0.3105) [1.0 s] *
INFO:root:Epoch 14    loss=0.2335 [21.5 s]    dev=(HR@5:0.4257,NDCG@5:0.3090) [1.0 s]
INFO:root:Epoch 15    loss=0.2310 [21.5 s]    dev=(HR@5:0.4263,NDCG@5:0.3092) [1.0 s]
INFO:root:Epoch 16    loss=0.2272 [21.4 s]    dev=(HR@5:0.4250,NDCG@5:0.3090) [1.0 s]
INFO:root:Epoch 17    loss=0.2240 [21.2 s]    dev=(HR@5:0.4233,NDCG@5:0.3066) [1.0 s]
INFO:root:Epoch 18    loss=0.2200 [21.0 s]    dev=(HR@5:0.4268,NDCG@5:0.3113) [0.9 s] *
INFO:root:Epoch 19    loss=0.2179 [21.0 s]    dev=(HR@5:0.4302,NDCG@5:0.3144) [0.9 s] *
INFO:root:Epoch 20    loss=0.2156 [21.1 s]    dev=(HR@5:0.4327,NDCG@5:0.3167) [1.0 s] *
INFO:root:Epoch 21    loss=0.2116 [20.7 s]    dev=(HR@5:0.4322,NDCG@5:0.3160) [1.0 s]
INFO:root:Epoch 22    loss=0.2106 [21.2 s]    dev=(HR@5:0.4344,NDCG@5:0.3172) [1.0 s] *
INFO:root:Epoch 23    loss=0.2110 [20.6 s]    dev=(HR@5:0.4263,NDCG@5:0.3135) [1.0 s]
INFO:root:Epoch 24    loss=0.2097 [20.7 s]    dev=(HR@5:0.4338,NDCG@5:0.3180) [1.0 s] *
INFO:root:Epoch 25    loss=0.2071 [20.7 s]    dev=(HR@5:0.4323,NDCG@5:0.3157) [0.9 s]
INFO:root:Epoch 26    loss=0.2073 [20.6 s]    dev=(HR@5:0.4333,NDCG@5:0.3182) [0.9 s] *
INFO:root:Epoch 27    loss=0.2059 [20.7 s]    dev=(HR@5:0.4365,NDCG@5:0.3201) [1.0 s] *
INFO:root:Epoch 28    loss=0.2060 [20.7 s]    dev=(HR@5:0.4380,NDCG@5:0.3212) [0.9 s] *
INFO:root:Epoch 29    loss=0.2036 [20.9 s]    dev=(HR@5:0.4335,NDCG@5:0.3188) [0.9 s]
INFO:root:Epoch 30    loss=0.2034 [20.7 s]    dev=(HR@5:0.4353,NDCG@5:0.3204) [0.9 s]
INFO:root:Epoch 31    loss=0.2012 [20.7 s]    dev=(HR@5:0.4385,NDCG@5:0.3214) [1.0 s] *
INFO:root:Epoch 32    loss=0.2027 [20.7 s]    dev=(HR@5:0.4351,NDCG@5:0.3195) [1.0 s]
INFO:root:Epoch 33    loss=0.2018 [20.7 s]    dev=(HR@5:0.4397,NDCG@5:0.3215) [0.9 s] *
INFO:root:Epoch 34    loss=0.2007 [20.6 s]    dev=(HR@5:0.4364,NDCG@5:0.3206) [0.9 s]
INFO:root:Epoch 35    loss=0.2012 [20.7 s]    dev=(HR@5:0.4371,NDCG@5:0.3196) [0.9 s]
INFO:root:Epoch 36    loss=0.1994 [20.6 s]    dev=(HR@5:0.4374,NDCG@5:0.3186) [0.9 s]
INFO:root:Epoch 37    loss=0.1997 [20.8 s]    dev=(HR@5:0.4401,NDCG@5:0.3215) [0.9 s] *
INFO:root:Epoch 38    loss=0.1994 [20.6 s]    dev=(HR@5:0.4383,NDCG@5:0.3200) [1.0 s]
INFO:root:Epoch 39    loss=0.1994 [21.1 s]    dev=(HR@5:0.4346,NDCG@5:0.3158) [0.9 s]
INFO:root:Epoch 40    loss=0.1989 [20.7 s]    dev=(HR@5:0.4368,NDCG@5:0.3198) [0.9 s]
INFO:root:Epoch 41    loss=0.1997 [20.6 s]    dev=(HR@5:0.4370,NDCG@5:0.3178) [0.9 s]
INFO:root:Epoch 42    loss=0.2000 [20.7 s]    dev=(HR@5:0.4423,NDCG@5:0.3219) [0.9 s] *
INFO:root:Epoch 43    loss=0.1975 [20.6 s]    dev=(HR@5:0.4393,NDCG@5:0.3236) [0.9 s] *
INFO:root:Epoch 44    loss=0.1987 [20.7 s]    dev=(HR@5:0.4377,NDCG@5:0.3210) [1.0 s]
INFO:root:Epoch 45    loss=0.1958 [20.9 s]    dev=(HR@5:0.4395,NDCG@5:0.3229) [0.9 s]
INFO:root:Epoch 46    loss=0.1965 [20.8 s]    dev=(HR@5:0.4408,NDCG@5:0.3226) [0.9 s]
INFO:root:Epoch 47    loss=0.1981 [20.6 s]    dev=(HR@5:0.4403,NDCG@5:0.3202) [0.9 s]
INFO:root:Epoch 48    loss=0.1969 [20.5 s]    dev=(HR@5:0.4395,NDCG@5:0.3204) [0.9 s]
INFO:root:Epoch 49    loss=0.1958 [20.7 s]    dev=(HR@5:0.4444,NDCG@5:0.3247) [0.9 s] *
INFO:root:Epoch 50    loss=0.1965 [20.6 s]    dev=(HR@5:0.4382,NDCG@5:0.3216) [0.9 s]
INFO:root:Epoch 51    loss=0.1959 [20.7 s]    dev=(HR@5:0.4431,NDCG@5:0.3243) [0.9 s]
INFO:root:Epoch 52    loss=0.1959 [20.8 s]    dev=(HR@5:0.4402,NDCG@5:0.3219) [1.0 s]
INFO:root:Epoch 53    loss=0.1956 [20.7 s]    dev=(HR@5:0.4423,NDCG@5:0.3226) [0.9 s]
INFO:root:Epoch 54    loss=0.1929 [20.7 s]    dev=(HR@5:0.4447,NDCG@5:0.3256) [0.9 s] *
INFO:root:Epoch 55    loss=0.1938 [20.7 s]    dev=(HR@5:0.4435,NDCG@5:0.3241) [1.0 s]
INFO:root:Epoch 56    loss=0.1935 [20.6 s]    dev=(HR@5:0.4460,NDCG@5:0.3267) [0.9 s] *
INFO:root:Epoch 57    loss=0.1937 [20.7 s]    dev=(HR@5:0.4445,NDCG@5:0.3271) [0.9 s] *
INFO:root:Epoch 58    loss=0.1950 [20.7 s]    dev=(HR@5:0.4455,NDCG@5:0.3286) [0.9 s] *
INFO:root:Epoch 59    loss=0.1936 [20.8 s]    dev=(HR@5:0.4433,NDCG@5:0.3263) [0.9 s]
INFO:root:Epoch 60    loss=0.1939 [20.6 s]    dev=(HR@5:0.4413,NDCG@5:0.3240) [0.9 s]
INFO:root:Epoch 61    loss=0.1936 [20.6 s]    dev=(HR@5:0.4458,NDCG@5:0.3274) [0.9 s]
INFO:root:Epoch 62    loss=0.1932 [20.6 s]    dev=(HR@5:0.4467,NDCG@5:0.3265) [1.0 s]
INFO:root:Epoch 63    loss=0.1937 [20.6 s]    dev=(HR@5:0.4452,NDCG@5:0.3266) [0.9 s]
INFO:root:Epoch 64    loss=0.1924 [21.1 s]    dev=(HR@5:0.4418,NDCG@5:0.3229) [0.9 s]
INFO:root:Epoch 65    loss=0.1941 [20.7 s]    dev=(HR@5:0.4402,NDCG@5:0.3238) [1.0 s]
INFO:root:Epoch 66    loss=0.1928 [20.6 s]    dev=(HR@5:0.4436,NDCG@5:0.3249) [0.9 s]
INFO:root:Epoch 67    loss=0.1930 [20.9 s]    dev=(HR@5:0.4439,NDCG@5:0.3242) [0.9 s]
INFO:root:Epoch 68    loss=0.1910 [20.7 s]    dev=(HR@5:0.4471,NDCG@5:0.3263) [1.0 s]
INFO:root:Epoch 69    loss=0.1935 [20.7 s]    dev=(HR@5:0.4462,NDCG@5:0.3266) [0.9 s]
INFO:root:Epoch 70    loss=0.1925 [20.7 s]    dev=(HR@5:0.4455,NDCG@5:0.3271) [1.0 s]
INFO:root:Epoch 71    loss=0.1922 [20.7 s]    dev=(HR@5:0.4404,NDCG@5:0.3248) [1.0 s]
INFO:root:Epoch 72    loss=0.1902 [20.7 s]    dev=(HR@5:0.4415,NDCG@5:0.3238) [1.0 s]
INFO:root:Epoch 73    loss=0.1912 [20.7 s]    dev=(HR@5:0.4447,NDCG@5:0.3263) [0.9 s]
INFO:root:Epoch 74    loss=0.1912 [20.6 s]    dev=(HR@5:0.4416,NDCG@5:0.3228) [0.9 s]
INFO:root:Epoch 75    loss=0.1919 [21.7 s]    dev=(HR@5:0.4429,NDCG@5:0.3256) [0.9 s]
INFO:root:Epoch 76    loss=0.1914 [20.7 s]    dev=(HR@5:0.4416,NDCG@5:0.3233) [0.9 s]
INFO:root:Epoch 77    loss=0.1901 [20.6 s]    dev=(HR@5:0.4460,NDCG@5:0.3263) [0.9 s]
INFO:root:Epoch 78    loss=0.1900 [20.6 s]    dev=(HR@5:0.4400,NDCG@5:0.3210) [0.9 s]
INFO:root:Early stop at 78 based on dev result.
INFO:root:
Best Iter(dev)=   58	 dev=(HR@5:0.4455,NDCG@5:0.3286) [1699.7 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.3936,NDCG@5:0.2809,HR@10:0.5017,NDCG@10:0.3160,HR@20:0.6229,NDCG@20:0.3465,HR@50:0.8230,NDCG@50:0.3861)
INFO:root:
--------------------------------------------- END: 2024-12-04 12:59:14 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-04 13:09:41 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5142 [23.2 s]    dev=(HR@5:0.2589,NDCG@5:0.1734) [1.0 s] *
INFO:root:Epoch 2     loss=0.4235 [21.8 s]    dev=(HR@5:0.3338,NDCG@5:0.2278) [0.9 s] *
INFO:root:Epoch 3     loss=0.3864 [21.4 s]    dev=(HR@5:0.3645,NDCG@5:0.2498) [1.0 s] *
INFO:root:Epoch 4     loss=0.3629 [21.0 s]    dev=(HR@5:0.3819,NDCG@5:0.2653) [1.0 s] *
INFO:root:Epoch 5     loss=0.3382 [20.9 s]    dev=(HR@5:0.3998,NDCG@5:0.2796) [1.0 s] *
INFO:root:Epoch 6     loss=0.3133 [20.8 s]    dev=(HR@5:0.4120,NDCG@5:0.2920) [1.0 s] *
INFO:root:Epoch 7     loss=0.2951 [20.8 s]    dev=(HR@5:0.4176,NDCG@5:0.2978) [1.0 s] *
INFO:root:Epoch 8     loss=0.2802 [20.9 s]    dev=(HR@5:0.4264,NDCG@5:0.3071) [0.9 s] *
INFO:root:Epoch 9     loss=0.2660 [20.8 s]    dev=(HR@5:0.4281,NDCG@5:0.3086) [0.9 s] *
INFO:root:Epoch 10    loss=0.2566 [20.8 s]    dev=(HR@5:0.4335,NDCG@5:0.3128) [0.9 s] *
INFO:root:Epoch 11    loss=0.2475 [20.9 s]    dev=(HR@5:0.4343,NDCG@5:0.3143) [0.9 s] *
INFO:root:Epoch 12    loss=0.2405 [20.8 s]    dev=(HR@5:0.4361,NDCG@5:0.3161) [1.0 s] *
INFO:root:Epoch 13    loss=0.2364 [20.8 s]    dev=(HR@5:0.4415,NDCG@5:0.3201) [0.9 s] *
INFO:root:Epoch 14    loss=0.2324 [20.9 s]    dev=(HR@5:0.4405,NDCG@5:0.3190) [0.9 s]
INFO:root:Epoch 15    loss=0.2295 [20.9 s]    dev=(HR@5:0.4396,NDCG@5:0.3186) [1.0 s]
INFO:root:Epoch 16    loss=0.2271 [21.0 s]    dev=(HR@5:0.4388,NDCG@5:0.3187) [0.9 s]
INFO:root:Epoch 17    loss=0.2240 [20.8 s]    dev=(HR@5:0.4394,NDCG@5:0.3192) [0.9 s]
INFO:root:Epoch 18    loss=0.2195 [20.9 s]    dev=(HR@5:0.4385,NDCG@5:0.3197) [1.0 s]
INFO:root:Epoch 19    loss=0.2182 [20.9 s]    dev=(HR@5:0.4387,NDCG@5:0.3193) [1.0 s]
INFO:root:Epoch 20    loss=0.2165 [21.4 s]    dev=(HR@5:0.4427,NDCG@5:0.3229) [1.0 s] *
INFO:root:Epoch 21    loss=0.2125 [21.6 s]    dev=(HR@5:0.4430,NDCG@5:0.3219) [1.0 s]
INFO:root:Epoch 22    loss=0.2121 [20.9 s]    dev=(HR@5:0.4435,NDCG@5:0.3225) [1.0 s]
INFO:root:Epoch 23    loss=0.2129 [20.9 s]    dev=(HR@5:0.4388,NDCG@5:0.3202) [1.0 s]
INFO:root:Epoch 24    loss=0.2127 [20.8 s]    dev=(HR@5:0.4443,NDCG@5:0.3217) [1.0 s]
INFO:root:Epoch 25    loss=0.2093 [20.8 s]    dev=(HR@5:0.4395,NDCG@5:0.3197) [1.0 s]
INFO:root:Epoch 26    loss=0.2098 [20.7 s]    dev=(HR@5:0.4391,NDCG@5:0.3190) [1.0 s]
INFO:root:Epoch 27    loss=0.2090 [21.0 s]    dev=(HR@5:0.4380,NDCG@5:0.3182) [0.9 s]
INFO:root:Epoch 28    loss=0.2094 [20.7 s]    dev=(HR@5:0.4430,NDCG@5:0.3250) [1.0 s] *
INFO:root:Epoch 29    loss=0.2078 [20.8 s]    dev=(HR@5:0.4418,NDCG@5:0.3216) [0.9 s]
INFO:root:Epoch 30    loss=0.2067 [20.8 s]    dev=(HR@5:0.4405,NDCG@5:0.3228) [1.0 s]
INFO:root:Epoch 31    loss=0.2068 [20.9 s]    dev=(HR@5:0.4408,NDCG@5:0.3226) [0.9 s]
INFO:root:Epoch 32    loss=0.2065 [20.8 s]    dev=(HR@5:0.4393,NDCG@5:0.3204) [1.0 s]
INFO:root:Epoch 33    loss=0.2070 [20.8 s]    dev=(HR@5:0.4410,NDCG@5:0.3231) [0.9 s]
INFO:root:Epoch 34    loss=0.2057 [20.8 s]    dev=(HR@5:0.4432,NDCG@5:0.3232) [0.9 s]
INFO:root:Epoch 35    loss=0.2065 [20.8 s]    dev=(HR@5:0.4353,NDCG@5:0.3179) [1.0 s]
INFO:root:Epoch 36    loss=0.2051 [21.2 s]    dev=(HR@5:0.4384,NDCG@5:0.3188) [0.9 s]
INFO:root:Epoch 37    loss=0.2058 [21.4 s]    dev=(HR@5:0.4393,NDCG@5:0.3205) [1.0 s]
INFO:root:Epoch 38    loss=0.2056 [21.3 s]    dev=(HR@5:0.4412,NDCG@5:0.3222) [1.0 s]
INFO:root:Epoch 39    loss=0.2064 [21.3 s]    dev=(HR@5:0.4338,NDCG@5:0.3141) [1.0 s]
INFO:root:Epoch 40    loss=0.2055 [21.3 s]    dev=(HR@5:0.4395,NDCG@5:0.3186) [1.0 s]
INFO:root:Epoch 41    loss=0.2059 [21.1 s]    dev=(HR@5:0.4398,NDCG@5:0.3205) [0.9 s]
INFO:root:Epoch 42    loss=0.2056 [20.8 s]    dev=(HR@5:0.4442,NDCG@5:0.3226) [0.9 s]
INFO:root:Epoch 43    loss=0.2046 [20.8 s]    dev=(HR@5:0.4447,NDCG@5:0.3248) [1.0 s]
INFO:root:Epoch 44    loss=0.2056 [20.8 s]    dev=(HR@5:0.4408,NDCG@5:0.3217) [0.9 s]
INFO:root:Epoch 45    loss=0.2030 [20.8 s]    dev=(HR@5:0.4436,NDCG@5:0.3244) [0.9 s]
INFO:root:Epoch 46    loss=0.2042 [20.9 s]    dev=(HR@5:0.4370,NDCG@5:0.3180) [0.9 s]
INFO:root:Epoch 47    loss=0.2042 [20.9 s]    dev=(HR@5:0.4387,NDCG@5:0.3191) [1.0 s]
INFO:root:Epoch 48    loss=0.2038 [20.8 s]    dev=(HR@5:0.4370,NDCG@5:0.3192) [1.0 s]
INFO:root:Early stop at 48 based on dev result.
INFO:root:
Best Iter(dev)=   28	 dev=(HR@5:0.4430,NDCG@5:0.3250) [1054.1 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.3966,NDCG@5:0.2813,HR@10:0.5070,NDCG@10:0.3170,HR@20:0.6284,NDCG@20:0.3475,HR@50:0.8341,NDCG@50:0.3882)
INFO:root:
--------------------------------------------- END: 2024-12-04 13:27:17 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-04 15:49:24 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Evaluating with parameters: {'L': 2, 'alpha': 0.1, 'c': 1, 'h': 1}
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-04 15:58:49 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Evaluating with parameters: {'L': 2, 'alpha': 0.1, 'c': 1, 'h': 1}
INFO:root:Optimizer: Adam
INFO:root:Epoch 1 loss=0.5142 [27.9 s] dev=(HR@5:0.2589,NDCG@5:0.1734)
INFO:root:Epoch 2 loss=0.4235 [22.2 s] dev=(HR@5:0.3338,NDCG@5:0.2278)
INFO:root:Epoch 3 loss=0.3864 [22.0 s] dev=(HR@5:0.3645,NDCG@5:0.2498)
INFO:root:Epoch 4 loss=0.3629 [22.0 s] dev=(HR@5:0.3819,NDCG@5:0.2653)
INFO:root:Epoch 5 loss=0.3382 [21.4 s] dev=(HR@5:0.3998,NDCG@5:0.2796)
INFO:root:Epoch 6 loss=0.3133 [21.4 s] dev=(HR@5:0.4120,NDCG@5:0.2920)
INFO:root:Epoch 7 loss=0.2951 [21.5 s] dev=(HR@5:0.4176,NDCG@5:0.2978)
INFO:root:Epoch 8 loss=0.2802 [21.4 s] dev=(HR@5:0.4264,NDCG@5:0.3071)
INFO:root:Epoch 9 loss=0.2660 [21.4 s] dev=(HR@5:0.4281,NDCG@5:0.3086)
INFO:root:Epoch 10 loss=0.2566 [21.4 s] dev=(HR@5:0.4335,NDCG@5:0.3128)
INFO:root:Epoch 11 loss=0.2475 [21.4 s] dev=(HR@5:0.4343,NDCG@5:0.3143)
INFO:root:Epoch 12 loss=0.2405 [21.4 s] dev=(HR@5:0.4361,NDCG@5:0.3161)
INFO:root:Epoch 13 loss=0.2364 [21.3 s] dev=(HR@5:0.4415,NDCG@5:0.3201)
INFO:root:Epoch 14 loss=0.2324 [21.5 s] dev=(HR@5:0.4405,NDCG@5:0.3190)
INFO:root:Epoch 15 loss=0.2295 [21.4 s] dev=(HR@5:0.4396,NDCG@5:0.3186)
INFO:root:Epoch 16 loss=0.2271 [22.4 s] dev=(HR@5:0.4388,NDCG@5:0.3187)
INFO:root:Epoch 17 loss=0.2240 [21.5 s] dev=(HR@5:0.4394,NDCG@5:0.3192)
INFO:root:Epoch 18 loss=0.2195 [21.4 s] dev=(HR@5:0.4385,NDCG@5:0.3197)
INFO:root:Epoch 19 loss=0.2182 [21.5 s] dev=(HR@5:0.4387,NDCG@5:0.3193)
INFO:root:Epoch 20 loss=0.2165 [21.4 s] dev=(HR@5:0.4427,NDCG@5:0.3229)
INFO:root:Epoch 21 loss=0.2125 [21.4 s] dev=(HR@5:0.4430,NDCG@5:0.3219)
INFO:root:Epoch 22 loss=0.2121 [21.3 s] dev=(HR@5:0.4435,NDCG@5:0.3225)
INFO:root:Epoch 23 loss=0.2129 [21.5 s] dev=(HR@5:0.4388,NDCG@5:0.3202)
INFO:root:Epoch 24 loss=0.2127 [21.3 s] dev=(HR@5:0.4443,NDCG@5:0.3217)
INFO:root:Epoch 25 loss=0.2093 [21.4 s] dev=(HR@5:0.4395,NDCG@5:0.3197)
INFO:root:Epoch 26 loss=0.2098 [21.4 s] dev=(HR@5:0.4391,NDCG@5:0.3190)
INFO:root:Epoch 27 loss=0.2090 [21.4 s] dev=(HR@5:0.4380,NDCG@5:0.3182)
INFO:root:Epoch 28 loss=0.2094 [21.5 s] dev=(HR@5:0.4430,NDCG@5:0.3250)
INFO:root:Epoch 29 loss=0.2078 [21.4 s] dev=(HR@5:0.4418,NDCG@5:0.3216)
INFO:root:Epoch 30 loss=0.2067 [21.3 s] dev=(HR@5:0.4405,NDCG@5:0.3228)
INFO:root:Epoch 31 loss=0.2068 [21.4 s] dev=(HR@5:0.4408,NDCG@5:0.3226)
INFO:root:Epoch 32 loss=0.2065 [21.3 s] dev=(HR@5:0.4393,NDCG@5:0.3204)
INFO:root:Epoch 33 loss=0.2070 [21.4 s] dev=(HR@5:0.4410,NDCG@5:0.3231)
INFO:root:Epoch 34 loss=0.2057 [21.4 s] dev=(HR@5:0.4432,NDCG@5:0.3232)
INFO:root:Epoch 35 loss=0.2065 [21.3 s] dev=(HR@5:0.4353,NDCG@5:0.3179)
INFO:root:Epoch 36 loss=0.2051 [21.3 s] dev=(HR@5:0.4384,NDCG@5:0.3188)
INFO:root:Epoch 37 loss=0.2058 [21.7 s] dev=(HR@5:0.4393,NDCG@5:0.3205)
INFO:root:Epoch 38 loss=0.2056 [21.3 s] dev=(HR@5:0.4412,NDCG@5:0.3222)
INFO:root:Epoch 39 loss=0.2064 [21.4 s] dev=(HR@5:0.4338,NDCG@5:0.3141)
INFO:root:Epoch 40 loss=0.2055 [21.4 s] dev=(HR@5:0.4395,NDCG@5:0.3186)
INFO:root:Epoch 41 loss=0.2059 [21.4 s] dev=(HR@5:0.4398,NDCG@5:0.3205)
INFO:root:Epoch 42 loss=0.2056 [21.4 s] dev=(HR@5:0.4442,NDCG@5:0.3226)
INFO:root:Epoch 43 loss=0.2046 [21.3 s] dev=(HR@5:0.4447,NDCG@5:0.3248)
INFO:root:Epoch 44 loss=0.2056 [21.3 s] dev=(HR@5:0.4408,NDCG@5:0.3217)
INFO:root:Epoch 45 loss=0.2030 [21.4 s] dev=(HR@5:0.4436,NDCG@5:0.3244)
INFO:root:Epoch 46 loss=0.2042 [21.4 s] dev=(HR@5:0.4370,NDCG@5:0.3180)
INFO:root:Epoch 47 loss=0.2042 [21.4 s] dev=(HR@5:0.4387,NDCG@5:0.3191)
INFO:root:Epoch 48 loss=0.2038 [21.3 s] dev=(HR@5:0.4370,NDCG@5:0.3192)
INFO:root:Early stop at 48 based on dev result.
INFO:root:Evaluating with parameters: {'L': 2, 'alpha': 0.1, 'c': 1, 'h': 2}
INFO:root:Epoch 1 loss=0.2021 [20.4 s] dev=(HR@5:0.4416,NDCG@5:0.3228)
INFO:root:Epoch 2 loss=0.2042 [22.5 s] dev=(HR@5:0.4410,NDCG@5:0.3226)
INFO:root:Early stop manually
INFO:root:Best parameters found: {'L': 2, 'alpha': 0.1, 'c': 1, 'h': 1} with score: 0.32496644423299614
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-04 16:40:03 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-04 16:42:00 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-04 16:45:44 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-04 16:49:14 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-04 21:57:55 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5165 [23.4 s]    dev=(HR@5:0.2511,NDCG@5:0.1669) [1.0 s] *
INFO:root:Epoch 2     loss=0.4328 [21.2 s]    dev=(HR@5:0.3219,NDCG@5:0.2184) [0.9 s] *
INFO:root:Epoch 3     loss=0.4003 [21.2 s]    dev=(HR@5:0.3389,NDCG@5:0.2287) [0.9 s] *
INFO:root:Epoch 4     loss=0.3845 [21.2 s]    dev=(HR@5:0.3562,NDCG@5:0.2448) [1.0 s] *
INFO:root:Epoch 5     loss=0.3640 [21.1 s]    dev=(HR@5:0.3701,NDCG@5:0.2554) [0.9 s] *
INFO:root:Epoch 6     loss=0.3417 [21.2 s]    dev=(HR@5:0.3824,NDCG@5:0.2703) [1.0 s] *
INFO:root:Epoch 7     loss=0.3236 [21.1 s]    dev=(HR@5:0.3922,NDCG@5:0.2767) [0.9 s] *
INFO:root:Epoch 8     loss=0.3066 [21.1 s]    dev=(HR@5:0.3958,NDCG@5:0.2820) [0.9 s] *
INFO:root:Epoch 9     loss=0.2909 [21.1 s]    dev=(HR@5:0.4018,NDCG@5:0.2884) [0.9 s] *
INFO:root:Epoch 10    loss=0.2800 [21.1 s]    dev=(HR@5:0.4071,NDCG@5:0.2935) [0.9 s] *
INFO:root:Epoch 11    loss=0.2675 [21.1 s]    dev=(HR@5:0.4116,NDCG@5:0.2969) [0.9 s] *
INFO:root:Epoch 12    loss=0.2589 [21.2 s]    dev=(HR@5:0.4184,NDCG@5:0.3022) [0.9 s] *
INFO:root:Epoch 13    loss=0.2544 [21.1 s]    dev=(HR@5:0.4223,NDCG@5:0.3056) [0.9 s] *
INFO:root:Epoch 14    loss=0.2478 [21.2 s]    dev=(HR@5:0.4219,NDCG@5:0.3050) [0.9 s]
INFO:root:Epoch 15    loss=0.2440 [21.2 s]    dev=(HR@5:0.4225,NDCG@5:0.3045) [0.9 s]
INFO:root:Epoch 16    loss=0.2406 [21.1 s]    dev=(HR@5:0.4261,NDCG@5:0.3093) [0.9 s] *
INFO:root:Epoch 17    loss=0.2365 [21.2 s]    dev=(HR@5:0.4226,NDCG@5:0.3063) [0.9 s]
INFO:root:Epoch 18    loss=0.2317 [21.0 s]    dev=(HR@5:0.4254,NDCG@5:0.3093) [0.9 s] *
INFO:root:Epoch 19    loss=0.2283 [21.2 s]    dev=(HR@5:0.4282,NDCG@5:0.3128) [0.9 s] *
INFO:root:Epoch 20    loss=0.2254 [21.0 s]    dev=(HR@5:0.4295,NDCG@5:0.3133) [0.9 s] *
INFO:root:Epoch 21    loss=0.2210 [21.1 s]    dev=(HR@5:0.4311,NDCG@5:0.3144) [0.9 s] *
INFO:root:Epoch 22    loss=0.2195 [21.2 s]    dev=(HR@5:0.4316,NDCG@5:0.3148) [0.9 s] *
INFO:root:Epoch 23    loss=0.2179 [21.1 s]    dev=(HR@5:0.4278,NDCG@5:0.3132) [0.9 s]
INFO:root:Epoch 24    loss=0.2168 [21.2 s]    dev=(HR@5:0.4329,NDCG@5:0.3167) [0.9 s] *
INFO:root:Epoch 25    loss=0.2130 [21.2 s]    dev=(HR@5:0.4306,NDCG@5:0.3141) [0.9 s]
INFO:root:Epoch 26    loss=0.2129 [21.2 s]    dev=(HR@5:0.4366,NDCG@5:0.3185) [0.9 s] *
INFO:root:Epoch 27    loss=0.2128 [21.1 s]    dev=(HR@5:0.4369,NDCG@5:0.3186) [0.9 s] *
INFO:root:Epoch 28    loss=0.2120 [21.2 s]    dev=(HR@5:0.4361,NDCG@5:0.3187) [0.9 s] *
INFO:root:Epoch 29    loss=0.2094 [21.2 s]    dev=(HR@5:0.4342,NDCG@5:0.3178) [0.9 s]
INFO:root:Epoch 30    loss=0.2085 [21.8 s]    dev=(HR@5:0.4348,NDCG@5:0.3186) [1.0 s]
INFO:root:Epoch 31    loss=0.2065 [21.8 s]    dev=(HR@5:0.4356,NDCG@5:0.3207) [1.0 s] *
INFO:root:Epoch 32    loss=0.2067 [21.8 s]    dev=(HR@5:0.4332,NDCG@5:0.3200) [1.0 s]
INFO:root:Epoch 33    loss=0.2058 [21.7 s]    dev=(HR@5:0.4352,NDCG@5:0.3193) [1.0 s]
INFO:root:Epoch 34    loss=0.2038 [21.5 s]    dev=(HR@5:0.4359,NDCG@5:0.3198) [1.0 s]
INFO:root:Epoch 35    loss=0.2056 [21.3 s]    dev=(HR@5:0.4316,NDCG@5:0.3161) [1.0 s]
INFO:root:Epoch 36    loss=0.2030 [21.5 s]    dev=(HR@5:0.4356,NDCG@5:0.3204) [1.0 s]
INFO:root:Epoch 37    loss=0.2026 [21.4 s]    dev=(HR@5:0.4389,NDCG@5:0.3209) [1.0 s] *
INFO:root:Epoch 38    loss=0.2021 [21.4 s]    dev=(HR@5:0.4366,NDCG@5:0.3193) [1.0 s]
INFO:root:Epoch 39    loss=0.2017 [21.5 s]    dev=(HR@5:0.4352,NDCG@5:0.3182) [1.0 s]
INFO:root:Epoch 40    loss=0.2004 [22.2 s]    dev=(HR@5:0.4308,NDCG@5:0.3150) [1.0 s]
INFO:root:Epoch 41    loss=0.2007 [21.7 s]    dev=(HR@5:0.4272,NDCG@5:0.3127) [1.0 s]
INFO:root:Epoch 42    loss=0.2007 [22.0 s]    dev=(HR@5:0.4353,NDCG@5:0.3194) [1.0 s]
INFO:root:Epoch 43    loss=0.1988 [22.0 s]    dev=(HR@5:0.4374,NDCG@5:0.3230) [1.0 s] *
INFO:root:Epoch 44    loss=0.2000 [22.0 s]    dev=(HR@5:0.4391,NDCG@5:0.3216) [1.0 s]
INFO:root:Epoch 45    loss=0.1966 [22.0 s]    dev=(HR@5:0.4391,NDCG@5:0.3233) [1.0 s] *
INFO:root:Epoch 46    loss=0.1963 [22.0 s]    dev=(HR@5:0.4338,NDCG@5:0.3189) [1.0 s]
INFO:root:Epoch 47    loss=0.1972 [21.9 s]    dev=(HR@5:0.4366,NDCG@5:0.3183) [1.0 s]
INFO:root:Epoch 48    loss=0.1946 [22.3 s]    dev=(HR@5:0.4254,NDCG@5:0.3114) [1.2 s]
INFO:root:Epoch 49    loss=0.1955 [23.8 s]    dev=(HR@5:0.4383,NDCG@5:0.3217) [1.2 s]
INFO:root:Epoch 50    loss=0.1957 [23.6 s]    dev=(HR@5:0.4372,NDCG@5:0.3208) [1.0 s]
INFO:root:Epoch 51    loss=0.1939 [22.1 s]    dev=(HR@5:0.4386,NDCG@5:0.3209) [1.0 s]
INFO:root:Epoch 52    loss=0.1947 [21.4 s]    dev=(HR@5:0.4346,NDCG@5:0.3193) [0.9 s]
INFO:root:Epoch 53    loss=0.1938 [21.1 s]    dev=(HR@5:0.4336,NDCG@5:0.3185) [1.0 s]
INFO:root:Epoch 54    loss=0.1915 [21.1 s]    dev=(HR@5:0.4391,NDCG@5:0.3226) [0.9 s]
INFO:root:Epoch 55    loss=0.1912 [21.2 s]    dev=(HR@5:0.4394,NDCG@5:0.3223) [0.9 s]
INFO:root:Epoch 56    loss=0.1910 [21.2 s]    dev=(HR@5:0.4382,NDCG@5:0.3218) [0.9 s]
INFO:root:Epoch 57    loss=0.1906 [21.2 s]    dev=(HR@5:0.4361,NDCG@5:0.3212) [0.9 s]
INFO:root:Epoch 58    loss=0.1920 [21.2 s]    dev=(HR@5:0.4356,NDCG@5:0.3198) [1.0 s]
INFO:root:Epoch 59    loss=0.1905 [21.2 s]    dev=(HR@5:0.4367,NDCG@5:0.3192) [0.9 s]
INFO:root:Epoch 60    loss=0.1920 [21.3 s]    dev=(HR@5:0.4339,NDCG@5:0.3169) [0.9 s]
INFO:root:Epoch 61    loss=0.1904 [21.2 s]    dev=(HR@5:0.4377,NDCG@5:0.3210) [0.9 s]
INFO:root:Epoch 62    loss=0.1895 [21.2 s]    dev=(HR@5:0.4361,NDCG@5:0.3209) [0.9 s]
INFO:root:Epoch 63    loss=0.1908 [21.2 s]    dev=(HR@5:0.4354,NDCG@5:0.3199) [0.9 s]
INFO:root:Epoch 64    loss=0.1891 [21.1 s]    dev=(HR@5:0.4356,NDCG@5:0.3187) [1.0 s]
INFO:root:Epoch 65    loss=0.1902 [21.1 s]    dev=(HR@5:0.4343,NDCG@5:0.3172) [0.9 s]
INFO:root:Early stop at 65 based on dev result.
INFO:root:
Best Iter(dev)=   45	 dev=(HR@5:0.4391,NDCG@5:0.3233) [1458.1 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.3870,NDCG@5:0.2786,HR@10:0.4929,NDCG@10:0.3128,HR@20:0.6186,NDCG@20:0.3445,HR@50:0.8236,NDCG@50:0.3851)
INFO:root:
--------------------------------------------- END: 2024-12-04 22:22:15 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-05 20:28:41 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5165 [26.1 s]    dev=(HR@5:0.2511,NDCG@5:0.1669) [1.0 s] *
INFO:root:Epoch 2     loss=0.4328 [21.9 s]    dev=(HR@5:0.3219,NDCG@5:0.2184) [0.9 s] *
INFO:root:Epoch 3     loss=0.4003 [22.0 s]    dev=(HR@5:0.3389,NDCG@5:0.2287) [1.0 s] *
INFO:root:Epoch 4     loss=0.3845 [21.7 s]    dev=(HR@5:0.3562,NDCG@5:0.2448) [0.9 s] *
INFO:root:Epoch 5     loss=0.3640 [21.4 s]    dev=(HR@5:0.3701,NDCG@5:0.2554) [0.9 s] *
INFO:root:Epoch 6     loss=0.3417 [21.7 s]    dev=(HR@5:0.3824,NDCG@5:0.2703) [1.0 s] *
INFO:root:Epoch 7     loss=0.3236 [23.1 s]    dev=(HR@5:0.3922,NDCG@5:0.2767) [1.2 s] *
INFO:root:Epoch 8     loss=0.3066 [22.6 s]    dev=(HR@5:0.3958,NDCG@5:0.2820) [1.0 s] *
INFO:root:Epoch 9     loss=0.2909 [21.8 s]    dev=(HR@5:0.4018,NDCG@5:0.2884) [1.0 s] *
INFO:root:Epoch 10    loss=0.2800 [21.6 s]    dev=(HR@5:0.4071,NDCG@5:0.2935) [0.9 s] *
INFO:root:Epoch 11    loss=0.2675 [21.5 s]    dev=(HR@5:0.4116,NDCG@5:0.2969) [1.0 s] *
INFO:root:Epoch 12    loss=0.2589 [55.4 s]    dev=(HR@5:0.4184,NDCG@5:0.3022) [1.6 s] *
INFO:root:Epoch 13    loss=0.2544 [32.4 s]    dev=(HR@5:0.4223,NDCG@5:0.3056) [1.0 s] *
INFO:root:Epoch 14    loss=0.2478 [21.6 s]    dev=(HR@5:0.4219,NDCG@5:0.3050) [1.0 s]
INFO:root:Epoch 15    loss=0.2440 [32.5 s]    dev=(HR@5:0.4225,NDCG@5:0.3045) [1.6 s]
INFO:root:Epoch 16    loss=0.2406 [37.1 s]    dev=(HR@5:0.4261,NDCG@5:0.3093) [1.6 s] *
INFO:root:Epoch 17    loss=0.2365 [36.6 s]    dev=(HR@5:0.4226,NDCG@5:0.3063) [1.6 s]
INFO:root:Epoch 18    loss=0.2317 [36.7 s]    dev=(HR@5:0.4254,NDCG@5:0.3093) [1.6 s] *
INFO:root:Epoch 19    loss=0.2283 [36.9 s]    dev=(HR@5:0.4282,NDCG@5:0.3128) [1.6 s] *
INFO:root:Epoch 20    loss=0.2254 [56.8 s]    dev=(HR@5:0.4295,NDCG@5:0.3133) [1.6 s] *
INFO:root:Epoch 21    loss=0.2210 [36.9 s]    dev=(HR@5:0.4311,NDCG@5:0.3144) [1.7 s] *
INFO:root:Epoch 22    loss=0.2195 [36.5 s]    dev=(HR@5:0.4316,NDCG@5:0.3148) [1.6 s] *
INFO:root:Epoch 23    loss=0.2179 [37.3 s]    dev=(HR@5:0.4278,NDCG@5:0.3132) [1.6 s]
INFO:root:Epoch 24    loss=0.2168 [36.7 s]    dev=(HR@5:0.4329,NDCG@5:0.3167) [1.6 s] *
INFO:root:Epoch 25    loss=0.2130 [37.0 s]    dev=(HR@5:0.4306,NDCG@5:0.3141) [1.6 s]
INFO:root:Epoch 26    loss=0.2129 [36.5 s]    dev=(HR@5:0.4366,NDCG@5:0.3185) [1.6 s] *
INFO:root:Epoch 27    loss=0.2128 [33.6 s]    dev=(HR@5:0.4369,NDCG@5:0.3186) [1.2 s] *
INFO:root:Epoch 28    loss=0.2120 [36.9 s]    dev=(HR@5:0.4361,NDCG@5:0.3187) [1.6 s] *
INFO:root:Epoch 29    loss=0.2094 [36.9 s]    dev=(HR@5:0.4342,NDCG@5:0.3178) [1.6 s]
INFO:root:Epoch 30    loss=0.2085 [36.9 s]    dev=(HR@5:0.4348,NDCG@5:0.3186) [1.6 s]
INFO:root:Epoch 31    loss=0.2065 [36.9 s]    dev=(HR@5:0.4356,NDCG@5:0.3207) [1.6 s] *
INFO:root:Epoch 32    loss=0.2067 [37.1 s]    dev=(HR@5:0.4332,NDCG@5:0.3200) [1.6 s]
INFO:root:Epoch 33    loss=0.2058 [36.6 s]    dev=(HR@5:0.4352,NDCG@5:0.3193) [1.7 s]
INFO:root:Epoch 34    loss=0.2038 [36.4 s]    dev=(HR@5:0.4359,NDCG@5:0.3198) [1.6 s]
INFO:root:Epoch 35    loss=0.2056 [35.4 s]    dev=(HR@5:0.4316,NDCG@5:0.3161) [1.0 s]
INFO:root:Epoch 36    loss=0.2030 [22.2 s]    dev=(HR@5:0.4356,NDCG@5:0.3204) [0.9 s]
INFO:root:Epoch 37    loss=0.2026 [21.5 s]    dev=(HR@5:0.4389,NDCG@5:0.3209) [0.9 s] *
INFO:root:Epoch 38    loss=0.2021 [21.5 s]    dev=(HR@5:0.4366,NDCG@5:0.3193) [0.9 s]
INFO:root:Epoch 39    loss=0.2017 [21.4 s]    dev=(HR@5:0.4352,NDCG@5:0.3182) [0.9 s]
INFO:root:Epoch 40    loss=0.2004 [21.4 s]    dev=(HR@5:0.4308,NDCG@5:0.3150) [0.9 s]
INFO:root:Epoch 41    loss=0.2007 [21.4 s]    dev=(HR@5:0.4272,NDCG@5:0.3127) [0.9 s]
INFO:root:Epoch 42    loss=0.2007 [21.4 s]    dev=(HR@5:0.4353,NDCG@5:0.3194) [0.9 s]
INFO:root:Epoch 43    loss=0.1988 [21.4 s]    dev=(HR@5:0.4374,NDCG@5:0.3230) [0.9 s] *
INFO:root:Epoch 44    loss=0.2000 [21.5 s]    dev=(HR@5:0.4391,NDCG@5:0.3216) [0.9 s]
INFO:root:Epoch 45    loss=0.1966 [22.3 s]    dev=(HR@5:0.4391,NDCG@5:0.3233) [1.0 s] *
INFO:root:Epoch 46    loss=0.1963 [21.8 s]    dev=(HR@5:0.4338,NDCG@5:0.3189) [0.9 s]
INFO:root:Epoch 47    loss=0.1972 [21.6 s]    dev=(HR@5:0.4366,NDCG@5:0.3183) [0.9 s]
INFO:root:Epoch 48    loss=0.1946 [21.8 s]    dev=(HR@5:0.4254,NDCG@5:0.3114) [1.0 s]
INFO:root:Epoch 49    loss=0.1955 [22.1 s]    dev=(HR@5:0.4383,NDCG@5:0.3217) [1.0 s]
INFO:root:Epoch 50    loss=0.1957 [22.0 s]    dev=(HR@5:0.4372,NDCG@5:0.3208) [1.0 s]
INFO:root:Epoch 51    loss=0.1939 [22.4 s]    dev=(HR@5:0.4386,NDCG@5:0.3209) [1.0 s]
INFO:root:Epoch 52    loss=0.1947 [21.9 s]    dev=(HR@5:0.4346,NDCG@5:0.3193) [1.0 s]
INFO:root:Epoch 53    loss=0.1938 [21.8 s]    dev=(HR@5:0.4336,NDCG@5:0.3185) [0.9 s]
INFO:root:Epoch 54    loss=0.1915 [21.8 s]    dev=(HR@5:0.4391,NDCG@5:0.3226) [1.0 s]
INFO:root:Epoch 55    loss=0.1912 [21.8 s]    dev=(HR@5:0.4394,NDCG@5:0.3223) [0.9 s]
INFO:root:Epoch 56    loss=0.1910 [21.9 s]    dev=(HR@5:0.4382,NDCG@5:0.3218) [1.0 s]
INFO:root:Epoch 57    loss=0.1906 [22.3 s]    dev=(HR@5:0.4361,NDCG@5:0.3212) [1.0 s]
INFO:root:Epoch 58    loss=0.1920 [22.2 s]    dev=(HR@5:0.4356,NDCG@5:0.3198) [1.0 s]
INFO:root:Epoch 59    loss=0.1905 [22.7 s]    dev=(HR@5:0.4367,NDCG@5:0.3192) [1.2 s]
INFO:root:Epoch 60    loss=0.1920 [22.6 s]    dev=(HR@5:0.4339,NDCG@5:0.3169) [1.0 s]
INFO:root:Epoch 61    loss=0.1904 [22.6 s]    dev=(HR@5:0.4377,NDCG@5:0.3210) [1.0 s]
INFO:root:Epoch 62    loss=0.1895 [22.4 s]    dev=(HR@5:0.4361,NDCG@5:0.3209) [1.0 s]
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-05 21:29:54 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5166 [27.9 s]    dev=(HR@5:0.2513,NDCG@5:0.1671) [1.0 s] *
INFO:root:Epoch 2     loss=0.4327 [21.7 s]    dev=(HR@5:0.3227,NDCG@5:0.2188) [1.0 s] *
INFO:root:Epoch 3     loss=0.4004 [22.0 s]    dev=(HR@5:0.3390,NDCG@5:0.2285) [1.0 s] *
INFO:root:Epoch 4     loss=0.3850 [21.8 s]    dev=(HR@5:0.3546,NDCG@5:0.2428) [1.0 s] *
INFO:root:Epoch 5     loss=0.3639 [21.9 s]    dev=(HR@5:0.3688,NDCG@5:0.2552) [1.0 s] *
INFO:root:Epoch 6     loss=0.3399 [21.9 s]    dev=(HR@5:0.3833,NDCG@5:0.2705) [1.0 s] *
INFO:root:Epoch 7     loss=0.3213 [21.7 s]    dev=(HR@5:0.3910,NDCG@5:0.2756) [1.0 s] *
INFO:root:Epoch 8     loss=0.3040 [21.8 s]    dev=(HR@5:0.3960,NDCG@5:0.2814) [1.0 s] *
INFO:root:Epoch 9     loss=0.2888 [21.9 s]    dev=(HR@5:0.3987,NDCG@5:0.2857) [1.0 s] *
INFO:root:Epoch 10    loss=0.2785 [21.9 s]    dev=(HR@5:0.4056,NDCG@5:0.2906) [1.0 s] *
INFO:root:Epoch 11    loss=0.2674 [21.8 s]    dev=(HR@5:0.4082,NDCG@5:0.2928) [1.0 s] *
INFO:root:Epoch 12    loss=0.2599 [21.8 s]    dev=(HR@5:0.4135,NDCG@5:0.2973) [1.0 s] *
INFO:root:Epoch 13    loss=0.2566 [21.8 s]    dev=(HR@5:0.4198,NDCG@5:0.3027) [1.0 s] *
INFO:root:Epoch 14    loss=0.2494 [21.9 s]    dev=(HR@5:0.4180,NDCG@5:0.3005) [1.0 s]
INFO:root:Epoch 15    loss=0.2463 [22.1 s]    dev=(HR@5:0.4190,NDCG@5:0.3005) [1.3 s]
INFO:root:Epoch 16    loss=0.2433 [31.5 s]    dev=(HR@5:0.4195,NDCG@5:0.3037) [1.4 s] *
INFO:root:Epoch 17    loss=0.2393 [32.3 s]    dev=(HR@5:0.4158,NDCG@5:0.3008) [1.4 s]
INFO:root:Epoch 18    loss=0.2347 [32.4 s]    dev=(HR@5:0.4213,NDCG@5:0.3058) [1.4 s] *
INFO:root:Epoch 19    loss=0.2318 [32.3 s]    dev=(HR@5:0.4248,NDCG@5:0.3087) [1.4 s] *
INFO:root:Epoch 20    loss=0.2299 [32.4 s]    dev=(HR@5:0.4264,NDCG@5:0.3092) [1.4 s] *
INFO:root:Epoch 21    loss=0.2255 [32.2 s]    dev=(HR@5:0.4263,NDCG@5:0.3103) [1.4 s] *
INFO:root:Epoch 22    loss=0.2241 [32.2 s]    dev=(HR@5:0.4250,NDCG@5:0.3086) [1.4 s]
INFO:root:Epoch 23    loss=0.2237 [32.4 s]    dev=(HR@5:0.4213,NDCG@5:0.3070) [1.4 s]
INFO:root:Epoch 24    loss=0.2216 [32.3 s]    dev=(HR@5:0.4264,NDCG@5:0.3130) [1.4 s] *
INFO:root:Epoch 25    loss=0.2190 [32.5 s]    dev=(HR@5:0.4215,NDCG@5:0.3088) [1.4 s]
INFO:root:Epoch 26    loss=0.2181 [32.5 s]    dev=(HR@5:0.4261,NDCG@5:0.3122) [1.4 s]
INFO:root:Epoch 27    loss=0.2168 [32.3 s]    dev=(HR@5:0.4256,NDCG@5:0.3116) [1.4 s]
INFO:root:Epoch 28    loss=0.2161 [32.3 s]    dev=(HR@5:0.4284,NDCG@5:0.3143) [1.4 s] *
INFO:root:Epoch 29    loss=0.2140 [32.3 s]    dev=(HR@5:0.4258,NDCG@5:0.3108) [1.4 s]
INFO:root:Epoch 30    loss=0.2132 [33.0 s]    dev=(HR@5:0.4308,NDCG@5:0.3156) [1.5 s] *
INFO:root:Epoch 31    loss=0.2113 [32.8 s]    dev=(HR@5:0.4274,NDCG@5:0.3134) [1.4 s]
INFO:root:Epoch 32    loss=0.2119 [32.7 s]    dev=(HR@5:0.4274,NDCG@5:0.3133) [1.4 s]
INFO:root:Epoch 33    loss=0.2097 [32.4 s]    dev=(HR@5:0.4299,NDCG@5:0.3146) [1.4 s]
INFO:root:Epoch 34    loss=0.2095 [32.2 s]    dev=(HR@5:0.4311,NDCG@5:0.3123) [1.4 s]
INFO:root:Epoch 35    loss=0.2105 [32.3 s]    dev=(HR@5:0.4308,NDCG@5:0.3128) [1.4 s]
INFO:root:Epoch 36    loss=0.2070 [32.3 s]    dev=(HR@5:0.4315,NDCG@5:0.3153) [1.4 s]
INFO:root:Epoch 37    loss=0.2066 [32.2 s]    dev=(HR@5:0.4333,NDCG@5:0.3163) [1.4 s] *
INFO:root:Epoch 38    loss=0.2064 [32.5 s]    dev=(HR@5:0.4318,NDCG@5:0.3139) [1.4 s]
INFO:root:Epoch 39    loss=0.2059 [23.1 s]    dev=(HR@5:0.4283,NDCG@5:0.3112) [0.9 s]
INFO:root:Epoch 40    loss=0.2060 [21.8 s]    dev=(HR@5:0.4282,NDCG@5:0.3134) [1.0 s]
INFO:root:Epoch 41    loss=0.2061 [21.7 s]    dev=(HR@5:0.4302,NDCG@5:0.3118) [1.0 s]
INFO:root:Epoch 42    loss=0.2058 [21.8 s]    dev=(HR@5:0.4306,NDCG@5:0.3132) [1.0 s]
INFO:root:Epoch 43    loss=0.2039 [21.7 s]    dev=(HR@5:0.4336,NDCG@5:0.3187) [1.0 s] *
INFO:root:Epoch 44    loss=0.2039 [21.8 s]    dev=(HR@5:0.4329,NDCG@5:0.3180) [1.0 s]
INFO:root:Epoch 45    loss=0.2010 [21.7 s]    dev=(HR@5:0.4348,NDCG@5:0.3200) [1.0 s] *
INFO:root:Epoch 46    loss=0.2012 [21.8 s]    dev=(HR@5:0.4300,NDCG@5:0.3141) [1.0 s]
INFO:root:Epoch 47    loss=0.2023 [21.8 s]    dev=(HR@5:0.4285,NDCG@5:0.3132) [1.0 s]
INFO:root:Epoch 48    loss=0.1999 [21.8 s]    dev=(HR@5:0.4222,NDCG@5:0.3081) [1.0 s]
INFO:root:Epoch 49    loss=0.1988 [21.6 s]    dev=(HR@5:0.4295,NDCG@5:0.3158) [1.0 s]
INFO:root:Epoch 50    loss=0.1994 [21.7 s]    dev=(HR@5:0.4254,NDCG@5:0.3121) [1.0 s]
INFO:root:Epoch 51    loss=0.1992 [21.8 s]    dev=(HR@5:0.4332,NDCG@5:0.3173) [1.0 s]
INFO:root:Epoch 52    loss=0.1992 [21.9 s]    dev=(HR@5:0.4326,NDCG@5:0.3162) [1.0 s]
INFO:root:Epoch 53    loss=0.1973 [21.8 s]    dev=(HR@5:0.4288,NDCG@5:0.3156) [1.0 s]
INFO:root:Epoch 54    loss=0.1952 [21.8 s]    dev=(HR@5:0.4336,NDCG@5:0.3183) [1.0 s]
INFO:root:Epoch 55    loss=0.1956 [21.8 s]    dev=(HR@5:0.4358,NDCG@5:0.3199) [1.0 s]
INFO:root:Epoch 56    loss=0.1954 [21.7 s]    dev=(HR@5:0.4289,NDCG@5:0.3174) [1.0 s]
INFO:root:Epoch 57    loss=0.1945 [21.8 s]    dev=(HR@5:0.4357,NDCG@5:0.3213) [1.0 s] *
INFO:root:Epoch 58    loss=0.1960 [21.8 s]    dev=(HR@5:0.4346,NDCG@5:0.3202) [1.0 s]
INFO:root:Epoch 59    loss=0.1940 [21.8 s]    dev=(HR@5:0.4333,NDCG@5:0.3177) [1.0 s]
INFO:root:Epoch 60    loss=0.1946 [21.8 s]    dev=(HR@5:0.4273,NDCG@5:0.3130) [1.0 s]
INFO:root:Epoch 61    loss=0.1938 [21.8 s]    dev=(HR@5:0.4383,NDCG@5:0.3232) [1.0 s] *
INFO:root:Epoch 62    loss=0.1935 [21.8 s]    dev=(HR@5:0.4353,NDCG@5:0.3201) [1.0 s]
INFO:root:Epoch 63    loss=0.1943 [21.8 s]    dev=(HR@5:0.4353,NDCG@5:0.3205) [1.0 s]
INFO:root:Epoch 64    loss=0.1934 [21.8 s]    dev=(HR@5:0.4341,NDCG@5:0.3172) [1.0 s]
INFO:root:Epoch 65    loss=0.1934 [21.8 s]    dev=(HR@5:0.4357,NDCG@5:0.3198) [1.0 s]
INFO:root:Epoch 66    loss=0.1924 [21.8 s]    dev=(HR@5:0.4360,NDCG@5:0.3169) [1.0 s]
INFO:root:Epoch 67    loss=0.1932 [21.7 s]    dev=(HR@5:0.4347,NDCG@5:0.3198) [1.0 s]
INFO:root:Epoch 68    loss=0.1899 [21.8 s]    dev=(HR@5:0.4353,NDCG@5:0.3190) [1.0 s]
INFO:root:Epoch 69    loss=0.1915 [21.8 s]    dev=(HR@5:0.4351,NDCG@5:0.3200) [1.0 s]
INFO:root:Epoch 70    loss=0.1915 [21.8 s]    dev=(HR@5:0.4299,NDCG@5:0.3168) [0.9 s]
INFO:root:Epoch 71    loss=0.1905 [21.8 s]    dev=(HR@5:0.4355,NDCG@5:0.3192) [1.0 s]
INFO:root:Epoch 72    loss=0.1896 [21.7 s]    dev=(HR@5:0.4312,NDCG@5:0.3172) [0.9 s]
INFO:root:Epoch 73    loss=0.1908 [21.8 s]    dev=(HR@5:0.4348,NDCG@5:0.3182) [1.0 s]
INFO:root:Epoch 74    loss=0.1904 [21.8 s]    dev=(HR@5:0.4300,NDCG@5:0.3150) [1.0 s]
INFO:root:Epoch 75    loss=0.1923 [21.8 s]    dev=(HR@5:0.4340,NDCG@5:0.3183) [1.0 s]
INFO:root:Epoch 76    loss=0.1900 [21.8 s]    dev=(HR@5:0.4348,NDCG@5:0.3193) [1.0 s]
INFO:root:Epoch 77    loss=0.1889 [21.8 s]    dev=(HR@5:0.4294,NDCG@5:0.3161) [1.0 s]
INFO:root:Epoch 78    loss=0.1897 [21.9 s]    dev=(HR@5:0.4352,NDCG@5:0.3195) [1.0 s]
INFO:root:Epoch 79    loss=0.1895 [21.8 s]    dev=(HR@5:0.4358,NDCG@5:0.3203) [1.0 s]
INFO:root:Epoch 80    loss=0.1878 [21.7 s]    dev=(HR@5:0.4280,NDCG@5:0.3137) [1.0 s]
INFO:root:Epoch 81    loss=0.1891 [21.8 s]    dev=(HR@5:0.4270,NDCG@5:0.3116) [1.0 s]
INFO:root:Early stop at 81 based on dev result.
INFO:root:
Best Iter(dev)=   61	 dev=(HR@5:0.4383,NDCG@5:0.3232) [2105.2 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.3844,NDCG@5:0.2751,HR@10:0.4917,NDCG@10:0.3099,HR@20:0.6116,NDCG@20:0.3400,HR@50:0.8243,NDCG@50:0.3822)
INFO:root:
--------------------------------------------- END: 2024-12-05 22:05:02 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-05 23:02:59 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5166 [22.8 s]    dev=(HR@5:0.2513,NDCG@5:0.1671) [0.9 s] *
INFO:root:Epoch 2     loss=0.4327 [20.9 s]    dev=(HR@5:0.3222,NDCG@5:0.2185) [0.9 s] *
INFO:root:Epoch 3     loss=0.4006 [21.0 s]    dev=(HR@5:0.3389,NDCG@5:0.2286) [0.9 s] *
INFO:root:Epoch 4     loss=0.3864 [20.9 s]    dev=(HR@5:0.3500,NDCG@5:0.2398) [0.9 s] *
INFO:root:Epoch 5     loss=0.3665 [20.9 s]    dev=(HR@5:0.3667,NDCG@5:0.2528) [0.9 s] *
INFO:root:Epoch 6     loss=0.3423 [21.2 s]    dev=(HR@5:0.3825,NDCG@5:0.2697) [1.1 s] *
INFO:root:Epoch 7     loss=0.3224 [21.6 s]    dev=(HR@5:0.3910,NDCG@5:0.2758) [1.0 s] *
INFO:root:Epoch 8     loss=0.3041 [21.8 s]    dev=(HR@5:0.3954,NDCG@5:0.2816) [1.0 s] *
INFO:root:Epoch 9     loss=0.2888 [22.1 s]    dev=(HR@5:0.4002,NDCG@5:0.2866) [1.0 s] *
INFO:root:Epoch 10    loss=0.2782 [21.2 s]    dev=(HR@5:0.4054,NDCG@5:0.2902) [0.9 s] *
INFO:root:Epoch 11    loss=0.2673 [21.0 s]    dev=(HR@5:0.4107,NDCG@5:0.2943) [0.9 s] *
INFO:root:Epoch 12    loss=0.2596 [20.9 s]    dev=(HR@5:0.4141,NDCG@5:0.2982) [1.0 s] *
INFO:root:Epoch 13    loss=0.2558 [21.1 s]    dev=(HR@5:0.4217,NDCG@5:0.3044) [0.9 s] *
INFO:root:Epoch 14    loss=0.2487 [21.1 s]    dev=(HR@5:0.4199,NDCG@5:0.3025) [0.9 s]
INFO:root:Epoch 15    loss=0.2454 [21.7 s]    dev=(HR@5:0.4201,NDCG@5:0.3024) [1.0 s]
INFO:root:Epoch 16    loss=0.2419 [21.5 s]    dev=(HR@5:0.4228,NDCG@5:0.3065) [0.9 s] *
INFO:root:Epoch 17    loss=0.2380 [21.0 s]    dev=(HR@5:0.4175,NDCG@5:0.3028) [0.9 s]
INFO:root:Epoch 18    loss=0.2330 [21.1 s]    dev=(HR@5:0.4237,NDCG@5:0.3084) [0.9 s] *
INFO:root:Epoch 19    loss=0.2297 [20.9 s]    dev=(HR@5:0.4259,NDCG@5:0.3110) [1.0 s] *
INFO:root:Epoch 20    loss=0.2273 [21.5 s]    dev=(HR@5:0.4280,NDCG@5:0.3125) [1.0 s] *
INFO:root:Epoch 21    loss=0.2227 [21.7 s]    dev=(HR@5:0.4294,NDCG@5:0.3134) [1.0 s] *
INFO:root:Epoch 22    loss=0.2218 [29.3 s]    dev=(HR@5:0.4275,NDCG@5:0.3121) [0.9 s]
INFO:root:Epoch 23    loss=0.2215 [21.5 s]    dev=(HR@5:0.4257,NDCG@5:0.3119) [1.0 s]
INFO:root:Epoch 24    loss=0.2198 [21.6 s]    dev=(HR@5:0.4315,NDCG@5:0.3155) [1.0 s] *
INFO:root:Epoch 25    loss=0.2167 [21.6 s]    dev=(HR@5:0.4253,NDCG@5:0.3105) [1.0 s]
INFO:root:Epoch 26    loss=0.2163 [21.2 s]    dev=(HR@5:0.4301,NDCG@5:0.3168) [1.0 s] *
INFO:root:Epoch 27    loss=0.2156 [21.6 s]    dev=(HR@5:0.4286,NDCG@5:0.3145) [0.9 s]
INFO:root:Epoch 28    loss=0.2146 [21.2 s]    dev=(HR@5:0.4338,NDCG@5:0.3181) [1.0 s] *
INFO:root:Epoch 29    loss=0.2129 [21.5 s]    dev=(HR@5:0.4280,NDCG@5:0.3137) [0.9 s]
INFO:root:Epoch 30    loss=0.2121 [21.4 s]    dev=(HR@5:0.4316,NDCG@5:0.3169) [1.0 s]
INFO:root:Epoch 31    loss=0.2107 [21.6 s]    dev=(HR@5:0.4308,NDCG@5:0.3160) [0.9 s]
INFO:root:Epoch 32    loss=0.2113 [21.6 s]    dev=(HR@5:0.4297,NDCG@5:0.3159) [1.0 s]
INFO:root:Epoch 33    loss=0.2096 [21.6 s]    dev=(HR@5:0.4310,NDCG@5:0.3164) [1.0 s]
INFO:root:Epoch 34    loss=0.2085 [21.9 s]    dev=(HR@5:0.4338,NDCG@5:0.3149) [1.0 s]
INFO:root:Epoch 35    loss=0.2100 [21.5 s]    dev=(HR@5:0.4331,NDCG@5:0.3152) [1.0 s]
INFO:root:Epoch 36    loss=0.2065 [21.1 s]    dev=(HR@5:0.4329,NDCG@5:0.3176) [0.9 s]
INFO:root:Epoch 37    loss=0.2070 [21.0 s]    dev=(HR@5:0.4357,NDCG@5:0.3182) [0.9 s] *
INFO:root:Epoch 38    loss=0.2069 [21.0 s]    dev=(HR@5:0.4348,NDCG@5:0.3165) [0.9 s]
INFO:root:Epoch 39    loss=0.2063 [21.0 s]    dev=(HR@5:0.4324,NDCG@5:0.3153) [0.9 s]
INFO:root:Epoch 40    loss=0.2059 [21.0 s]    dev=(HR@5:0.4319,NDCG@5:0.3178) [1.0 s]
INFO:root:Epoch 41    loss=0.2063 [21.7 s]    dev=(HR@5:0.4323,NDCG@5:0.3146) [1.0 s]
INFO:root:Epoch 42    loss=0.2067 [21.5 s]    dev=(HR@5:0.4368,NDCG@5:0.3195) [1.0 s] *
INFO:root:Epoch 43    loss=0.2056 [21.7 s]    dev=(HR@5:0.4378,NDCG@5:0.3221) [1.0 s] *
INFO:root:Epoch 44    loss=0.2059 [21.4 s]    dev=(HR@5:0.4386,NDCG@5:0.3213) [1.0 s]
INFO:root:Epoch 45    loss=0.2026 [21.2 s]    dev=(HR@5:0.4398,NDCG@5:0.3242) [0.9 s] *
INFO:root:Epoch 46    loss=0.2033 [21.0 s]    dev=(HR@5:0.4369,NDCG@5:0.3187) [0.9 s]
INFO:root:Epoch 47    loss=0.2040 [21.0 s]    dev=(HR@5:0.4366,NDCG@5:0.3209) [0.9 s]
INFO:root:Epoch 48    loss=0.2020 [20.9 s]    dev=(HR@5:0.4319,NDCG@5:0.3149) [0.9 s]
INFO:root:Epoch 49    loss=0.2008 [21.0 s]    dev=(HR@5:0.4357,NDCG@5:0.3197) [0.9 s]
INFO:root:Epoch 50    loss=0.2021 [20.8 s]    dev=(HR@5:0.4375,NDCG@5:0.3216) [0.9 s]
INFO:root:Epoch 51    loss=0.2018 [20.9 s]    dev=(HR@5:0.4405,NDCG@5:0.3233) [0.9 s]
INFO:root:Epoch 52    loss=0.2016 [21.2 s]    dev=(HR@5:0.4380,NDCG@5:0.3200) [1.0 s]
INFO:root:Epoch 53    loss=0.2000 [22.0 s]    dev=(HR@5:0.4363,NDCG@5:0.3200) [1.0 s]
INFO:root:Epoch 54    loss=0.1979 [20.9 s]    dev=(HR@5:0.4387,NDCG@5:0.3211) [0.9 s]
INFO:root:Epoch 55    loss=0.1987 [21.0 s]    dev=(HR@5:0.4390,NDCG@5:0.3219) [0.9 s]
INFO:root:Epoch 56    loss=0.1989 [20.9 s]    dev=(HR@5:0.4398,NDCG@5:0.3231) [0.9 s]
INFO:root:Epoch 57    loss=0.1982 [20.9 s]    dev=(HR@5:0.4428,NDCG@5:0.3251) [0.9 s] *
INFO:root:Epoch 58    loss=0.1999 [21.0 s]    dev=(HR@5:0.4400,NDCG@5:0.3242) [0.9 s]
INFO:root:Epoch 59    loss=0.1981 [21.0 s]    dev=(HR@5:0.4377,NDCG@5:0.3212) [0.9 s]
INFO:root:Epoch 60    loss=0.1982 [20.9 s]    dev=(HR@5:0.4352,NDCG@5:0.3185) [0.9 s]
INFO:root:Epoch 61    loss=0.1980 [20.9 s]    dev=(HR@5:0.4422,NDCG@5:0.3254) [0.9 s] *
INFO:root:Epoch 62    loss=0.1975 [21.0 s]    dev=(HR@5:0.4418,NDCG@5:0.3252) [0.9 s]
INFO:root:Epoch 63    loss=0.1982 [20.9 s]    dev=(HR@5:0.4409,NDCG@5:0.3247) [0.9 s]
INFO:root:Epoch 64    loss=0.1968 [20.9 s]    dev=(HR@5:0.4385,NDCG@5:0.3209) [1.0 s]
INFO:root:Epoch 65    loss=0.1978 [21.0 s]    dev=(HR@5:0.4389,NDCG@5:0.3205) [0.9 s]
INFO:root:Epoch 66    loss=0.1964 [21.1 s]    dev=(HR@5:0.4395,NDCG@5:0.3210) [0.9 s]
INFO:root:Epoch 67    loss=0.1967 [21.0 s]    dev=(HR@5:0.4425,NDCG@5:0.3240) [0.9 s]
INFO:root:Epoch 68    loss=0.1948 [20.9 s]    dev=(HR@5:0.4431,NDCG@5:0.3248) [0.9 s]
INFO:root:Epoch 69    loss=0.1963 [20.9 s]    dev=(HR@5:0.4434,NDCG@5:0.3252) [0.9 s]
INFO:root:Epoch 70    loss=0.1964 [20.9 s]    dev=(HR@5:0.4425,NDCG@5:0.3253) [0.9 s]
INFO:root:Epoch 71    loss=0.1957 [20.9 s]    dev=(HR@5:0.4420,NDCG@5:0.3259) [1.0 s] *
INFO:root:Epoch 72    loss=0.1943 [21.8 s]    dev=(HR@5:0.4386,NDCG@5:0.3246) [0.9 s]
INFO:root:Epoch 73    loss=0.1958 [43.3 s]    dev=(HR@5:0.4427,NDCG@5:0.3247) [1.0 s]
INFO:root:Epoch 74    loss=0.1953 [21.5 s]    dev=(HR@5:0.4366,NDCG@5:0.3197) [0.9 s]
INFO:root:Epoch 75    loss=0.1969 [21.1 s]    dev=(HR@5:0.4400,NDCG@5:0.3243) [0.9 s]
INFO:root:Epoch 76    loss=0.1944 [21.6 s]    dev=(HR@5:0.4425,NDCG@5:0.3261) [0.9 s] *
INFO:root:Epoch 77    loss=0.1940 [21.4 s]    dev=(HR@5:0.4395,NDCG@5:0.3201) [1.0 s]
INFO:root:Epoch 78    loss=0.1933 [21.0 s]    dev=(HR@5:0.4417,NDCG@5:0.3228) [0.9 s]
INFO:root:Epoch 79    loss=0.1941 [21.0 s]    dev=(HR@5:0.4417,NDCG@5:0.3238) [0.9 s]
INFO:root:Epoch 80    loss=0.1926 [21.6 s]    dev=(HR@5:0.4386,NDCG@5:0.3206) [1.0 s]
INFO:root:Epoch 81    loss=0.1930 [21.7 s]    dev=(HR@5:0.4338,NDCG@5:0.3175) [1.0 s]
INFO:root:Epoch 82    loss=0.1951 [21.7 s]    dev=(HR@5:0.4384,NDCG@5:0.3226) [0.9 s]
INFO:root:Epoch 83    loss=0.1919 [21.8 s]    dev=(HR@5:0.4416,NDCG@5:0.3226) [1.0 s]
INFO:root:Epoch 84    loss=0.1920 [21.8 s]    dev=(HR@5:0.4383,NDCG@5:0.3221) [0.9 s]
INFO:root:Epoch 85    loss=0.1933 [21.6 s]    dev=(HR@5:0.4395,NDCG@5:0.3222) [1.0 s]
INFO:root:Epoch 86    loss=0.1934 [21.6 s]    dev=(HR@5:0.4377,NDCG@5:0.3209) [1.0 s]
INFO:root:Epoch 87    loss=0.1925 [21.8 s]    dev=(HR@5:0.4406,NDCG@5:0.3246) [1.0 s]
INFO:root:Epoch 88    loss=0.1919 [22.2 s]    dev=(HR@5:0.4390,NDCG@5:0.3226) [1.0 s]
INFO:root:Epoch 89    loss=0.1913 [21.8 s]    dev=(HR@5:0.4331,NDCG@5:0.3210) [1.1 s]
INFO:root:Epoch 90    loss=0.1900 [22.5 s]    dev=(HR@5:0.4413,NDCG@5:0.3244) [0.9 s]
INFO:root:Epoch 91    loss=0.1918 [21.2 s]    dev=(HR@5:0.4408,NDCG@5:0.3250) [1.0 s]
INFO:root:Epoch 92    loss=0.1892 [22.0 s]    dev=(HR@5:0.4388,NDCG@5:0.3212) [1.0 s]
INFO:root:Epoch 93    loss=0.1917 [22.4 s]    dev=(HR@5:0.4389,NDCG@5:0.3223) [1.0 s]
INFO:root:Epoch 94    loss=0.1916 [21.7 s]    dev=(HR@5:0.4425,NDCG@5:0.3256) [1.0 s]
INFO:root:Epoch 95    loss=0.1913 [21.8 s]    dev=(HR@5:0.4420,NDCG@5:0.3247) [1.0 s]
INFO:root:Epoch 96    loss=0.1900 [22.1 s]    dev=(HR@5:0.4405,NDCG@5:0.3253) [1.0 s]
INFO:root:Early stop at 96 based on dev result.
INFO:root:
Best Iter(dev)=   76	 dev=(HR@5:0.4425,NDCG@5:0.3261) [2171.5 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.3943,NDCG@5:0.2814,HR@10:0.4973,NDCG@10:0.3147,HR@20:0.6293,NDCG@20:0.3480,HR@50:0.8348,NDCG@50:0.3886)
INFO:root:
--------------------------------------------- END: 2024-12-05 23:39:13 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 00:37:45 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5166 [24.1 s]    dev=(HR@5:0.2515,NDCG@5:0.1672) [1.0 s] *
INFO:root:Epoch 2     loss=0.4326 [21.6 s]    dev=(HR@5:0.3224,NDCG@5:0.2186) [1.0 s] *
INFO:root:Epoch 3     loss=0.4004 [21.7 s]    dev=(HR@5:0.3389,NDCG@5:0.2287) [0.9 s] *
INFO:root:Epoch 4     loss=0.3864 [21.5 s]    dev=(HR@5:0.3499,NDCG@5:0.2393) [1.0 s] *
INFO:root:Epoch 5     loss=0.3677 [21.6 s]    dev=(HR@5:0.3631,NDCG@5:0.2499) [0.9 s] *
INFO:root:Epoch 6     loss=0.3442 [21.5 s]    dev=(HR@5:0.3802,NDCG@5:0.2680) [1.0 s] *
INFO:root:Epoch 7     loss=0.3234 [21.6 s]    dev=(HR@5:0.3898,NDCG@5:0.2748) [0.9 s] *
INFO:root:Epoch 8     loss=0.3040 [21.5 s]    dev=(HR@5:0.3978,NDCG@5:0.2836) [1.0 s] *
INFO:root:Epoch 9     loss=0.2883 [21.6 s]    dev=(HR@5:0.3994,NDCG@5:0.2860) [0.9 s] *
INFO:root:Epoch 10    loss=0.2781 [21.7 s]    dev=(HR@5:0.4061,NDCG@5:0.2906) [1.0 s] *
INFO:root:Epoch 11    loss=0.2669 [21.6 s]    dev=(HR@5:0.4122,NDCG@5:0.2939) [1.0 s] *
INFO:root:Epoch 12    loss=0.2594 [21.5 s]    dev=(HR@5:0.4165,NDCG@5:0.2991) [1.0 s] *
INFO:root:Epoch 13    loss=0.2553 [21.6 s]    dev=(HR@5:0.4219,NDCG@5:0.3036) [0.9 s] *
INFO:root:Epoch 14    loss=0.2487 [21.5 s]    dev=(HR@5:0.4192,NDCG@5:0.3019) [1.0 s]
INFO:root:Epoch 15    loss=0.2454 [21.6 s]    dev=(HR@5:0.4189,NDCG@5:0.3019) [0.9 s]
INFO:root:Epoch 16    loss=0.2422 [21.7 s]    dev=(HR@5:0.4226,NDCG@5:0.3061) [1.0 s] *
INFO:root:Epoch 17    loss=0.2385 [21.6 s]    dev=(HR@5:0.4186,NDCG@5:0.3027) [0.9 s]
INFO:root:Epoch 18    loss=0.2338 [21.6 s]    dev=(HR@5:0.4235,NDCG@5:0.3074) [1.0 s] *
INFO:root:Epoch 19    loss=0.2307 [21.6 s]    dev=(HR@5:0.4258,NDCG@5:0.3104) [1.0 s] *
INFO:root:Epoch 20    loss=0.2291 [21.5 s]    dev=(HR@5:0.4270,NDCG@5:0.3112) [0.9 s] *
INFO:root:Epoch 21    loss=0.2244 [21.6 s]    dev=(HR@5:0.4290,NDCG@5:0.3129) [0.9 s] *
INFO:root:Epoch 22    loss=0.2238 [21.5 s]    dev=(HR@5:0.4263,NDCG@5:0.3106) [1.0 s]
INFO:root:Epoch 23    loss=0.2236 [21.7 s]    dev=(HR@5:0.4237,NDCG@5:0.3106) [0.9 s]
INFO:root:Epoch 24    loss=0.2223 [21.6 s]    dev=(HR@5:0.4298,NDCG@5:0.3143) [0.9 s] *
INFO:root:Epoch 25    loss=0.2194 [21.7 s]    dev=(HR@5:0.4274,NDCG@5:0.3114) [0.9 s]
INFO:root:Epoch 26    loss=0.2190 [21.6 s]    dev=(HR@5:0.4272,NDCG@5:0.3131) [0.9 s]
INFO:root:Epoch 27    loss=0.2184 [21.6 s]    dev=(HR@5:0.4279,NDCG@5:0.3132) [0.9 s]
INFO:root:Epoch 28    loss=0.2179 [21.6 s]    dev=(HR@5:0.4295,NDCG@5:0.3161) [0.9 s] *
INFO:root:Epoch 29    loss=0.2163 [21.6 s]    dev=(HR@5:0.4288,NDCG@5:0.3131) [0.9 s]
INFO:root:Epoch 30    loss=0.2150 [21.6 s]    dev=(HR@5:0.4323,NDCG@5:0.3161) [1.0 s] *
INFO:root:Epoch 31    loss=0.2143 [21.6 s]    dev=(HR@5:0.4299,NDCG@5:0.3158) [1.0 s]
INFO:root:Epoch 32    loss=0.2146 [21.5 s]    dev=(HR@5:0.4294,NDCG@5:0.3151) [0.9 s]
INFO:root:Epoch 33    loss=0.2135 [21.5 s]    dev=(HR@5:0.4304,NDCG@5:0.3147) [0.9 s]
INFO:root:Epoch 34    loss=0.2121 [21.6 s]    dev=(HR@5:0.4330,NDCG@5:0.3151) [0.9 s]
INFO:root:Epoch 35    loss=0.2134 [21.5 s]    dev=(HR@5:0.4323,NDCG@5:0.3135) [0.9 s]
INFO:root:Epoch 36    loss=0.2103 [21.6 s]    dev=(HR@5:0.4327,NDCG@5:0.3159) [1.0 s]
INFO:root:Epoch 37    loss=0.2109 [21.6 s]    dev=(HR@5:0.4365,NDCG@5:0.3185) [1.0 s] *
INFO:root:Epoch 38    loss=0.2102 [21.5 s]    dev=(HR@5:0.4327,NDCG@5:0.3146) [0.9 s]
INFO:root:Epoch 39    loss=0.2102 [21.6 s]    dev=(HR@5:0.4333,NDCG@5:0.3152) [1.0 s]
INFO:root:Epoch 40    loss=0.2092 [21.5 s]    dev=(HR@5:0.4332,NDCG@5:0.3173) [0.9 s]
INFO:root:Epoch 41    loss=0.2099 [21.5 s]    dev=(HR@5:0.4317,NDCG@5:0.3135) [0.9 s]
INFO:root:Epoch 42    loss=0.2100 [21.5 s]    dev=(HR@5:0.4361,NDCG@5:0.3177) [1.0 s]
INFO:root:Epoch 43    loss=0.2086 [21.6 s]    dev=(HR@5:0.4381,NDCG@5:0.3218) [1.0 s] *
INFO:root:Epoch 44    loss=0.2093 [21.6 s]    dev=(HR@5:0.4361,NDCG@5:0.3202) [0.9 s]
INFO:root:Epoch 45    loss=0.2060 [21.5 s]    dev=(HR@5:0.4374,NDCG@5:0.3222) [0.9 s] *
INFO:root:Epoch 46    loss=0.2063 [21.6 s]    dev=(HR@5:0.4357,NDCG@5:0.3190) [1.0 s]
INFO:root:Epoch 47    loss=0.2073 [21.6 s]    dev=(HR@5:0.4368,NDCG@5:0.3203) [0.9 s]
INFO:root:Epoch 48    loss=0.2052 [21.6 s]    dev=(HR@5:0.4334,NDCG@5:0.3161) [1.0 s]
INFO:root:Epoch 49    loss=0.2037 [21.6 s]    dev=(HR@5:0.4363,NDCG@5:0.3204) [0.9 s]
INFO:root:Epoch 50    loss=0.2053 [21.6 s]    dev=(HR@5:0.4386,NDCG@5:0.3237) [0.9 s] *
INFO:root:Epoch 51    loss=0.2045 [21.6 s]    dev=(HR@5:0.4387,NDCG@5:0.3221) [0.9 s]
INFO:root:Epoch 52    loss=0.2042 [21.6 s]    dev=(HR@5:0.4354,NDCG@5:0.3185) [0.9 s]
INFO:root:Epoch 53    loss=0.2029 [21.6 s]    dev=(HR@5:0.4362,NDCG@5:0.3212) [0.9 s]
INFO:root:Epoch 54    loss=0.2003 [21.6 s]    dev=(HR@5:0.4410,NDCG@5:0.3227) [0.9 s]
INFO:root:Epoch 55    loss=0.2012 [21.6 s]    dev=(HR@5:0.4389,NDCG@5:0.3220) [0.9 s]
INFO:root:Epoch 56    loss=0.2007 [21.6 s]    dev=(HR@5:0.4391,NDCG@5:0.3237) [0.9 s] *
INFO:root:Epoch 57    loss=0.2007 [21.7 s]    dev=(HR@5:0.4399,NDCG@5:0.3242) [1.0 s] *
INFO:root:Epoch 58    loss=0.2018 [21.7 s]    dev=(HR@5:0.4395,NDCG@5:0.3231) [1.0 s]
INFO:root:Epoch 59    loss=0.2001 [21.6 s]    dev=(HR@5:0.4392,NDCG@5:0.3221) [1.0 s]
INFO:root:Epoch 60    loss=0.2005 [21.6 s]    dev=(HR@5:0.4359,NDCG@5:0.3192) [1.0 s]
INFO:root:Epoch 61    loss=0.2002 [21.6 s]    dev=(HR@5:0.4421,NDCG@5:0.3262) [1.0 s] *
INFO:root:Epoch 62    loss=0.1994 [21.6 s]    dev=(HR@5:0.4400,NDCG@5:0.3239) [1.0 s]
INFO:root:Epoch 63    loss=0.2004 [21.6 s]    dev=(HR@5:0.4409,NDCG@5:0.3242) [1.0 s]
INFO:root:Epoch 64    loss=0.1988 [21.5 s]    dev=(HR@5:0.4404,NDCG@5:0.3224) [1.0 s]
INFO:root:Epoch 65    loss=0.1995 [21.7 s]    dev=(HR@5:0.4393,NDCG@5:0.3217) [1.0 s]
INFO:root:Epoch 66    loss=0.1984 [21.5 s]    dev=(HR@5:0.4416,NDCG@5:0.3224) [1.0 s]
INFO:root:Epoch 67    loss=0.1983 [21.5 s]    dev=(HR@5:0.4435,NDCG@5:0.3243) [1.0 s]
INFO:root:Epoch 68    loss=0.1966 [21.7 s]    dev=(HR@5:0.4427,NDCG@5:0.3225) [0.9 s]
INFO:root:Epoch 69    loss=0.1977 [21.6 s]    dev=(HR@5:0.4419,NDCG@5:0.3246) [1.0 s]
INFO:root:Epoch 70    loss=0.1981 [21.6 s]    dev=(HR@5:0.4413,NDCG@5:0.3243) [0.9 s]
INFO:root:Epoch 71    loss=0.1969 [21.6 s]    dev=(HR@5:0.4435,NDCG@5:0.3272) [1.0 s] *
INFO:root:Epoch 72    loss=0.1961 [21.7 s]    dev=(HR@5:0.4423,NDCG@5:0.3258) [0.9 s]
INFO:root:Epoch 73    loss=0.1979 [21.7 s]    dev=(HR@5:0.4420,NDCG@5:0.3255) [1.0 s]
INFO:root:Epoch 74    loss=0.1973 [21.6 s]    dev=(HR@5:0.4374,NDCG@5:0.3191) [0.9 s]
INFO:root:Epoch 75    loss=0.1983 [21.6 s]    dev=(HR@5:0.4412,NDCG@5:0.3248) [1.0 s]
INFO:root:Epoch 76    loss=0.1963 [21.6 s]    dev=(HR@5:0.4421,NDCG@5:0.3247) [0.9 s]
INFO:root:Epoch 77    loss=0.1960 [21.6 s]    dev=(HR@5:0.4393,NDCG@5:0.3228) [1.0 s]
INFO:root:Epoch 78    loss=0.1962 [21.6 s]    dev=(HR@5:0.4398,NDCG@5:0.3220) [0.9 s]
INFO:root:Epoch 79    loss=0.1970 [21.5 s]    dev=(HR@5:0.4410,NDCG@5:0.3233) [1.0 s]
INFO:root:Epoch 80    loss=0.1954 [21.6 s]    dev=(HR@5:0.4393,NDCG@5:0.3212) [1.0 s]
INFO:root:Epoch 81    loss=0.1956 [21.6 s]    dev=(HR@5:0.4376,NDCG@5:0.3197) [1.0 s]
INFO:root:Epoch 82    loss=0.1973 [21.6 s]    dev=(HR@5:0.4385,NDCG@5:0.3230) [0.9 s]
INFO:root:Epoch 83    loss=0.1948 [21.6 s]    dev=(HR@5:0.4428,NDCG@5:0.3235) [1.0 s]
INFO:root:Epoch 84    loss=0.1946 [21.6 s]    dev=(HR@5:0.4427,NDCG@5:0.3255) [0.9 s]
INFO:root:Epoch 85    loss=0.1969 [21.6 s]    dev=(HR@5:0.4430,NDCG@5:0.3254) [0.9 s]
INFO:root:Epoch 86    loss=0.1957 [21.5 s]    dev=(HR@5:0.4410,NDCG@5:0.3237) [0.9 s]
INFO:root:Epoch 87    loss=0.1953 [21.5 s]    dev=(HR@5:0.4385,NDCG@5:0.3232) [1.0 s]
INFO:root:Epoch 88    loss=0.1950 [21.6 s]    dev=(HR@5:0.4409,NDCG@5:0.3233) [0.9 s]
INFO:root:Epoch 89    loss=0.1942 [21.9 s]    dev=(HR@5:0.4392,NDCG@5:0.3235) [0.9 s]
INFO:root:Epoch 90    loss=0.1937 [21.6 s]    dev=(HR@5:0.4397,NDCG@5:0.3253) [0.9 s]
INFO:root:Epoch 91    loss=0.1946 [21.6 s]    dev=(HR@5:0.4391,NDCG@5:0.3237) [1.0 s]
INFO:root:Early stop at 91 based on dev result.
INFO:root:
Best Iter(dev)=   71	 dev=(HR@5:0.4435,NDCG@5:0.3272) [2053.8 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.3898,NDCG@5:0.2801,HR@10:0.4956,NDCG@10:0.3143,HR@20:0.6195,NDCG@20:0.3456,HR@50:0.8328,NDCG@50:0.3878)
INFO:root:
--------------------------------------------- END: 2024-12-06 01:12:01 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 02:12:16 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5167 [23.1 s]    dev=(HR@5:0.2513,NDCG@5:0.1669) [1.0 s] *
INFO:root:Epoch 2     loss=0.4327 [21.2 s]    dev=(HR@5:0.3218,NDCG@5:0.2184) [0.9 s] *
INFO:root:Epoch 3     loss=0.4003 [21.1 s]    dev=(HR@5:0.3394,NDCG@5:0.2285) [0.9 s] *
INFO:root:Epoch 4     loss=0.3860 [21.1 s]    dev=(HR@5:0.3500,NDCG@5:0.2395) [0.9 s] *
INFO:root:Epoch 5     loss=0.3669 [21.2 s]    dev=(HR@5:0.3635,NDCG@5:0.2502) [0.9 s] *
INFO:root:Epoch 6     loss=0.3439 [21.1 s]    dev=(HR@5:0.3810,NDCG@5:0.2685) [0.9 s] *
INFO:root:Epoch 7     loss=0.3231 [21.1 s]    dev=(HR@5:0.3891,NDCG@5:0.2755) [1.0 s] *
INFO:root:Epoch 8     loss=0.3033 [21.1 s]    dev=(HR@5:0.3999,NDCG@5:0.2855) [0.9 s] *
INFO:root:Epoch 9     loss=0.2869 [21.2 s]    dev=(HR@5:0.4012,NDCG@5:0.2885) [0.9 s] *
INFO:root:Epoch 10    loss=0.2759 [21.2 s]    dev=(HR@5:0.4084,NDCG@5:0.2924) [1.0 s] *
INFO:root:Epoch 11    loss=0.2644 [21.2 s]    dev=(HR@5:0.4150,NDCG@5:0.2967) [0.9 s] *
INFO:root:Epoch 12    loss=0.2563 [21.2 s]    dev=(HR@5:0.4208,NDCG@5:0.3019) [0.9 s] *
INFO:root:Epoch 13    loss=0.2521 [21.1 s]    dev=(HR@5:0.4238,NDCG@5:0.3057) [0.9 s] *
INFO:root:Epoch 14    loss=0.2454 [21.1 s]    dev=(HR@5:0.4226,NDCG@5:0.3047) [0.9 s]
INFO:root:Epoch 15    loss=0.2419 [21.1 s]    dev=(HR@5:0.4222,NDCG@5:0.3041) [0.9 s]
INFO:root:Epoch 16    loss=0.2386 [21.2 s]    dev=(HR@5:0.4257,NDCG@5:0.3094) [0.9 s] *
INFO:root:Epoch 17    loss=0.2339 [21.2 s]    dev=(HR@5:0.4217,NDCG@5:0.3049) [0.9 s]
INFO:root:Epoch 18    loss=0.2295 [21.5 s]    dev=(HR@5:0.4282,NDCG@5:0.3112) [1.0 s] *
INFO:root:Epoch 19    loss=0.2262 [21.3 s]    dev=(HR@5:0.4299,NDCG@5:0.3138) [0.9 s] *
INFO:root:Epoch 20    loss=0.2235 [21.3 s]    dev=(HR@5:0.4291,NDCG@5:0.3145) [0.9 s] *
INFO:root:Epoch 21    loss=0.2190 [21.2 s]    dev=(HR@5:0.4310,NDCG@5:0.3151) [0.9 s] *
INFO:root:Epoch 22    loss=0.2187 [21.1 s]    dev=(HR@5:0.4298,NDCG@5:0.3142) [0.9 s]
INFO:root:Epoch 23    loss=0.2179 [21.1 s]    dev=(HR@5:0.4278,NDCG@5:0.3146) [0.9 s]
INFO:root:Epoch 24    loss=0.2166 [21.1 s]    dev=(HR@5:0.4322,NDCG@5:0.3167) [0.9 s] *
INFO:root:Epoch 25    loss=0.2135 [21.3 s]    dev=(HR@5:0.4288,NDCG@5:0.3124) [1.0 s]
INFO:root:Epoch 26    loss=0.2130 [21.3 s]    dev=(HR@5:0.4357,NDCG@5:0.3188) [0.9 s] *
INFO:root:Epoch 27    loss=0.2121 [21.1 s]    dev=(HR@5:0.4331,NDCG@5:0.3182) [0.9 s]
INFO:root:Epoch 28    loss=0.2115 [21.1 s]    dev=(HR@5:0.4378,NDCG@5:0.3215) [1.0 s] *
INFO:root:Epoch 29    loss=0.2099 [21.1 s]    dev=(HR@5:0.4343,NDCG@5:0.3172) [0.9 s]
INFO:root:Epoch 30    loss=0.2095 [21.2 s]    dev=(HR@5:0.4356,NDCG@5:0.3202) [0.9 s]
INFO:root:Epoch 31    loss=0.2082 [21.2 s]    dev=(HR@5:0.4355,NDCG@5:0.3211) [0.9 s]
INFO:root:Epoch 32    loss=0.2084 [21.3 s]    dev=(HR@5:0.4367,NDCG@5:0.3200) [0.9 s]
INFO:root:Epoch 33    loss=0.2070 [21.3 s]    dev=(HR@5:0.4370,NDCG@5:0.3199) [0.9 s]
INFO:root:Epoch 34    loss=0.2054 [21.1 s]    dev=(HR@5:0.4404,NDCG@5:0.3213) [0.9 s]
INFO:root:Epoch 35    loss=0.2070 [21.2 s]    dev=(HR@5:0.4353,NDCG@5:0.3174) [1.0 s]
INFO:root:Epoch 36    loss=0.2040 [21.1 s]    dev=(HR@5:0.4366,NDCG@5:0.3196) [0.9 s]
INFO:root:Epoch 37    loss=0.2046 [21.1 s]    dev=(HR@5:0.4363,NDCG@5:0.3195) [0.9 s]
INFO:root:Epoch 38    loss=0.2041 [21.2 s]    dev=(HR@5:0.4350,NDCG@5:0.3190) [0.9 s]
INFO:root:Epoch 39    loss=0.2034 [21.1 s]    dev=(HR@5:0.4323,NDCG@5:0.3162) [0.9 s]
INFO:root:Epoch 40    loss=0.2028 [21.1 s]    dev=(HR@5:0.4361,NDCG@5:0.3195) [1.0 s]
INFO:root:Epoch 41    loss=0.2030 [21.2 s]    dev=(HR@5:0.4323,NDCG@5:0.3149) [0.9 s]
INFO:root:Epoch 42    loss=0.2036 [21.2 s]    dev=(HR@5:0.4410,NDCG@5:0.3221) [1.0 s] *
INFO:root:Epoch 43    loss=0.2017 [21.1 s]    dev=(HR@5:0.4412,NDCG@5:0.3239) [0.9 s] *
INFO:root:Epoch 44    loss=0.2022 [21.1 s]    dev=(HR@5:0.4376,NDCG@5:0.3222) [1.0 s]
INFO:root:Epoch 45    loss=0.1995 [21.2 s]    dev=(HR@5:0.4411,NDCG@5:0.3248) [0.9 s] *
INFO:root:Epoch 46    loss=0.1995 [21.2 s]    dev=(HR@5:0.4427,NDCG@5:0.3238) [0.9 s]
INFO:root:Epoch 47    loss=0.2007 [21.3 s]    dev=(HR@5:0.4413,NDCG@5:0.3233) [1.0 s]
INFO:root:Epoch 48    loss=0.1986 [21.3 s]    dev=(HR@5:0.4370,NDCG@5:0.3191) [0.9 s]
INFO:root:Epoch 49    loss=0.1970 [21.2 s]    dev=(HR@5:0.4394,NDCG@5:0.3227) [0.9 s]
INFO:root:Epoch 50    loss=0.1990 [21.2 s]    dev=(HR@5:0.4376,NDCG@5:0.3218) [0.9 s]
INFO:root:Epoch 51    loss=0.1984 [21.2 s]    dev=(HR@5:0.4421,NDCG@5:0.3247) [0.9 s]
INFO:root:Epoch 52    loss=0.1980 [21.1 s]    dev=(HR@5:0.4389,NDCG@5:0.3219) [0.9 s]
INFO:root:Epoch 53    loss=0.1971 [21.2 s]    dev=(HR@5:0.4402,NDCG@5:0.3251) [0.9 s] *
INFO:root:Epoch 54    loss=0.1947 [21.2 s]    dev=(HR@5:0.4421,NDCG@5:0.3249) [1.0 s]
INFO:root:Epoch 55    loss=0.1956 [21.1 s]    dev=(HR@5:0.4422,NDCG@5:0.3249) [1.0 s]
INFO:root:Epoch 56    loss=0.1953 [21.2 s]    dev=(HR@5:0.4428,NDCG@5:0.3255) [0.9 s] *
INFO:root:Epoch 57    loss=0.1955 [21.2 s]    dev=(HR@5:0.4424,NDCG@5:0.3257) [0.9 s] *
INFO:root:Epoch 58    loss=0.1963 [21.2 s]    dev=(HR@5:0.4426,NDCG@5:0.3259) [0.9 s] *
INFO:root:Epoch 59    loss=0.1945 [21.3 s]    dev=(HR@5:0.4422,NDCG@5:0.3244) [0.9 s]
INFO:root:Epoch 60    loss=0.1950 [21.2 s]    dev=(HR@5:0.4441,NDCG@5:0.3248) [0.9 s]
INFO:root:Epoch 61    loss=0.1945 [21.2 s]    dev=(HR@5:0.4460,NDCG@5:0.3276) [1.0 s] *
INFO:root:Epoch 62    loss=0.1937 [21.1 s]    dev=(HR@5:0.4444,NDCG@5:0.3268) [0.9 s]
INFO:root:Epoch 63    loss=0.1949 [21.2 s]    dev=(HR@5:0.4438,NDCG@5:0.3270) [1.0 s]
INFO:root:Epoch 64    loss=0.1933 [21.2 s]    dev=(HR@5:0.4436,NDCG@5:0.3252) [0.9 s]
INFO:root:Epoch 65    loss=0.1939 [21.2 s]    dev=(HR@5:0.4432,NDCG@5:0.3241) [0.9 s]
INFO:root:Epoch 66    loss=0.1923 [21.1 s]    dev=(HR@5:0.4435,NDCG@5:0.3236) [0.9 s]
INFO:root:Epoch 67    loss=0.1930 [21.2 s]    dev=(HR@5:0.4470,NDCG@5:0.3272) [0.9 s]
INFO:root:Epoch 68    loss=0.1910 [21.1 s]    dev=(HR@5:0.4460,NDCG@5:0.3263) [1.0 s]
INFO:root:Epoch 69    loss=0.1930 [21.2 s]    dev=(HR@5:0.4445,NDCG@5:0.3259) [0.9 s]
INFO:root:Epoch 70    loss=0.1923 [21.2 s]    dev=(HR@5:0.4440,NDCG@5:0.3259) [0.9 s]
INFO:root:Epoch 71    loss=0.1917 [21.2 s]    dev=(HR@5:0.4464,NDCG@5:0.3274) [0.9 s]
INFO:root:Epoch 72    loss=0.1908 [21.1 s]    dev=(HR@5:0.4442,NDCG@5:0.3267) [0.9 s]
INFO:root:Epoch 73    loss=0.1915 [21.2 s]    dev=(HR@5:0.4463,NDCG@5:0.3272) [0.9 s]
INFO:root:Epoch 74    loss=0.1911 [21.1 s]    dev=(HR@5:0.4410,NDCG@5:0.3218) [0.9 s]
INFO:root:Epoch 75    loss=0.1934 [21.1 s]    dev=(HR@5:0.4402,NDCG@5:0.3236) [0.9 s]
INFO:root:Epoch 76    loss=0.1917 [21.1 s]    dev=(HR@5:0.4448,NDCG@5:0.3267) [0.9 s]
INFO:root:Epoch 77    loss=0.1905 [21.2 s]    dev=(HR@5:0.4442,NDCG@5:0.3247) [0.9 s]
INFO:root:Epoch 78    loss=0.1907 [21.3 s]    dev=(HR@5:0.4441,NDCG@5:0.3233) [0.9 s]
INFO:root:Epoch 79    loss=0.1918 [21.2 s]    dev=(HR@5:0.4433,NDCG@5:0.3242) [0.9 s]
INFO:root:Epoch 80    loss=0.1899 [21.1 s]    dev=(HR@5:0.4434,NDCG@5:0.3233) [0.9 s]
INFO:root:Epoch 81    loss=0.1897 [21.2 s]    dev=(HR@5:0.4370,NDCG@5:0.3197) [0.9 s]
INFO:root:Early stop at 81 based on dev result.
INFO:root:
Best Iter(dev)=   61	 dev=(HR@5:0.4460,NDCG@5:0.3276) [1794.4 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.3953,NDCG@5:0.2828,HR@10:0.5058,NDCG@10:0.3187,HR@20:0.6242,NDCG@20:0.3485,HR@50:0.8350,NDCG@50:0.3902)
INFO:root:
--------------------------------------------- END: 2024-12-06 02:42:12 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 03:56:22 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5165 [23.3 s]    dev=(HR@5:0.2500,NDCG@5:0.1661) [0.9 s] *
INFO:root:Epoch 2     loss=0.4338 [21.4 s]    dev=(HR@5:0.3183,NDCG@5:0.2150) [0.9 s] *
INFO:root:Epoch 3     loss=0.3986 [21.4 s]    dev=(HR@5:0.3446,NDCG@5:0.2316) [0.9 s] *
INFO:root:Epoch 4     loss=0.3764 [21.4 s]    dev=(HR@5:0.3688,NDCG@5:0.2541) [0.9 s] *
INFO:root:Epoch 5     loss=0.3502 [21.3 s]    dev=(HR@5:0.3838,NDCG@5:0.2678) [0.9 s] *
INFO:root:Epoch 6     loss=0.3244 [21.3 s]    dev=(HR@5:0.3979,NDCG@5:0.2813) [0.9 s] *
INFO:root:Epoch 7     loss=0.3046 [21.2 s]    dev=(HR@5:0.4023,NDCG@5:0.2869) [0.9 s] *
INFO:root:Epoch 8     loss=0.2870 [21.4 s]    dev=(HR@5:0.4113,NDCG@5:0.2955) [1.0 s] *
INFO:root:Epoch 9     loss=0.2726 [21.2 s]    dev=(HR@5:0.4130,NDCG@5:0.2978) [0.9 s] *
INFO:root:Epoch 10    loss=0.2621 [21.4 s]    dev=(HR@5:0.4171,NDCG@5:0.3015) [0.9 s] *
INFO:root:Epoch 11    loss=0.2521 [21.3 s]    dev=(HR@5:0.4195,NDCG@5:0.3029) [0.9 s] *
INFO:root:Epoch 12    loss=0.2433 [21.2 s]    dev=(HR@5:0.4229,NDCG@5:0.3061) [0.9 s] *
INFO:root:Epoch 13    loss=0.2399 [21.5 s]    dev=(HR@5:0.4268,NDCG@5:0.3105) [1.0 s] *
INFO:root:Epoch 14    loss=0.2335 [21.4 s]    dev=(HR@5:0.4257,NDCG@5:0.3090) [0.9 s]
INFO:root:Epoch 15    loss=0.2310 [21.2 s]    dev=(HR@5:0.4263,NDCG@5:0.3092) [1.0 s]
INFO:root:Epoch 16    loss=0.2272 [21.2 s]    dev=(HR@5:0.4250,NDCG@5:0.3090) [0.9 s]
INFO:root:Epoch 17    loss=0.2240 [21.2 s]    dev=(HR@5:0.4233,NDCG@5:0.3066) [0.9 s]
INFO:root:Epoch 18    loss=0.2200 [21.3 s]    dev=(HR@5:0.4268,NDCG@5:0.3113) [0.9 s] *
INFO:root:Epoch 19    loss=0.2179 [21.3 s]    dev=(HR@5:0.4302,NDCG@5:0.3144) [0.9 s] *
INFO:root:Epoch 20    loss=0.2156 [21.3 s]    dev=(HR@5:0.4327,NDCG@5:0.3167) [0.9 s] *
INFO:root:Epoch 21    loss=0.2116 [21.4 s]    dev=(HR@5:0.4322,NDCG@5:0.3160) [0.9 s]
INFO:root:Epoch 22    loss=0.2106 [21.3 s]    dev=(HR@5:0.4344,NDCG@5:0.3172) [0.9 s] *
INFO:root:Epoch 23    loss=0.2110 [21.4 s]    dev=(HR@5:0.4263,NDCG@5:0.3135) [0.9 s]
INFO:root:Epoch 24    loss=0.2097 [21.4 s]    dev=(HR@5:0.4338,NDCG@5:0.3180) [0.9 s] *
INFO:root:Epoch 25    loss=0.2071 [21.3 s]    dev=(HR@5:0.4323,NDCG@5:0.3157) [0.9 s]
INFO:root:Epoch 26    loss=0.2073 [21.4 s]    dev=(HR@5:0.4333,NDCG@5:0.3182) [0.9 s] *
INFO:root:Epoch 27    loss=0.2059 [21.3 s]    dev=(HR@5:0.4365,NDCG@5:0.3201) [0.9 s] *
INFO:root:Epoch 28    loss=0.2060 [21.3 s]    dev=(HR@5:0.4380,NDCG@5:0.3212) [0.9 s] *
INFO:root:Epoch 29    loss=0.2036 [21.4 s]    dev=(HR@5:0.4335,NDCG@5:0.3188) [0.9 s]
INFO:root:Epoch 30    loss=0.2034 [21.2 s]    dev=(HR@5:0.4353,NDCG@5:0.3204) [1.0 s]
INFO:root:Epoch 31    loss=0.2012 [21.3 s]    dev=(HR@5:0.4385,NDCG@5:0.3214) [0.9 s] *
INFO:root:Epoch 32    loss=0.2027 [21.3 s]    dev=(HR@5:0.4351,NDCG@5:0.3195) [1.0 s]
INFO:root:Epoch 33    loss=0.2018 [21.2 s]    dev=(HR@5:0.4397,NDCG@5:0.3215) [0.9 s] *
INFO:root:Epoch 34    loss=0.2007 [21.4 s]    dev=(HR@5:0.4364,NDCG@5:0.3206) [0.9 s]
INFO:root:Epoch 35    loss=0.2012 [21.3 s]    dev=(HR@5:0.4371,NDCG@5:0.3196) [0.9 s]
INFO:root:Epoch 36    loss=0.1994 [21.4 s]    dev=(HR@5:0.4374,NDCG@5:0.3186) [0.9 s]
INFO:root:Epoch 37    loss=0.1997 [21.2 s]    dev=(HR@5:0.4401,NDCG@5:0.3215) [0.9 s] *
INFO:root:Epoch 38    loss=0.1994 [21.3 s]    dev=(HR@5:0.4383,NDCG@5:0.3200) [0.9 s]
INFO:root:Epoch 39    loss=0.1994 [21.3 s]    dev=(HR@5:0.4346,NDCG@5:0.3158) [1.0 s]
INFO:root:Epoch 40    loss=0.1989 [21.3 s]    dev=(HR@5:0.4368,NDCG@5:0.3198) [0.9 s]
INFO:root:Epoch 41    loss=0.1997 [21.3 s]    dev=(HR@5:0.4370,NDCG@5:0.3178) [0.9 s]
INFO:root:Epoch 42    loss=0.2000 [21.3 s]    dev=(HR@5:0.4423,NDCG@5:0.3219) [0.9 s] *
INFO:root:Epoch 43    loss=0.1975 [21.2 s]    dev=(HR@5:0.4393,NDCG@5:0.3236) [0.9 s] *
INFO:root:Epoch 44    loss=0.1987 [21.3 s]    dev=(HR@5:0.4377,NDCG@5:0.3210) [0.9 s]
INFO:root:Epoch 45    loss=0.1958 [21.3 s]    dev=(HR@5:0.4395,NDCG@5:0.3229) [0.9 s]
INFO:root:Epoch 46    loss=0.1965 [21.3 s]    dev=(HR@5:0.4408,NDCG@5:0.3226) [0.9 s]
INFO:root:Epoch 47    loss=0.1981 [21.2 s]    dev=(HR@5:0.4403,NDCG@5:0.3202) [0.9 s]
INFO:root:Epoch 48    loss=0.1969 [21.3 s]    dev=(HR@5:0.4395,NDCG@5:0.3204) [1.0 s]
INFO:root:Epoch 49    loss=0.1958 [21.4 s]    dev=(HR@5:0.4444,NDCG@5:0.3247) [0.9 s] *
INFO:root:Epoch 50    loss=0.1965 [21.2 s]    dev=(HR@5:0.4382,NDCG@5:0.3216) [1.0 s]
INFO:root:Epoch 51    loss=0.1959 [21.5 s]    dev=(HR@5:0.4431,NDCG@5:0.3243) [1.0 s]
INFO:root:Epoch 52    loss=0.1959 [21.6 s]    dev=(HR@5:0.4402,NDCG@5:0.3219) [0.9 s]
INFO:root:Epoch 53    loss=0.1956 [21.3 s]    dev=(HR@5:0.4423,NDCG@5:0.3226) [0.9 s]
INFO:root:Epoch 54    loss=0.1929 [21.3 s]    dev=(HR@5:0.4447,NDCG@5:0.3256) [0.9 s] *
INFO:root:Epoch 55    loss=0.1938 [21.4 s]    dev=(HR@5:0.4435,NDCG@5:0.3241) [0.9 s]
INFO:root:Epoch 56    loss=0.1935 [21.4 s]    dev=(HR@5:0.4460,NDCG@5:0.3267) [0.9 s] *
INFO:root:Epoch 57    loss=0.1937 [21.3 s]    dev=(HR@5:0.4445,NDCG@5:0.3271) [0.9 s] *
INFO:root:Epoch 58    loss=0.1950 [21.4 s]    dev=(HR@5:0.4455,NDCG@5:0.3286) [0.9 s] *
INFO:root:Epoch 59    loss=0.1936 [21.3 s]    dev=(HR@5:0.4433,NDCG@5:0.3263) [0.9 s]
INFO:root:Epoch 60    loss=0.1939 [21.2 s]    dev=(HR@5:0.4413,NDCG@5:0.3240) [0.9 s]
INFO:root:Epoch 61    loss=0.1936 [21.3 s]    dev=(HR@5:0.4458,NDCG@5:0.3274) [1.0 s]
INFO:root:Epoch 62    loss=0.1932 [21.4 s]    dev=(HR@5:0.4467,NDCG@5:0.3265) [0.9 s]
INFO:root:Epoch 63    loss=0.1937 [21.3 s]    dev=(HR@5:0.4452,NDCG@5:0.3266) [1.0 s]
INFO:root:Epoch 64    loss=0.1924 [21.3 s]    dev=(HR@5:0.4418,NDCG@5:0.3229) [0.9 s]
INFO:root:Epoch 65    loss=0.1941 [21.2 s]    dev=(HR@5:0.4402,NDCG@5:0.3238) [1.0 s]
INFO:root:Epoch 66    loss=0.1928 [21.4 s]    dev=(HR@5:0.4436,NDCG@5:0.3249) [0.9 s]
INFO:root:Epoch 67    loss=0.1930 [21.3 s]    dev=(HR@5:0.4439,NDCG@5:0.3242) [0.9 s]
INFO:root:Epoch 68    loss=0.1910 [21.4 s]    dev=(HR@5:0.4471,NDCG@5:0.3263) [0.9 s]
INFO:root:Epoch 69    loss=0.1935 [21.4 s]    dev=(HR@5:0.4462,NDCG@5:0.3266) [0.9 s]
INFO:root:Epoch 70    loss=0.1925 [21.4 s]    dev=(HR@5:0.4455,NDCG@5:0.3271) [0.9 s]
INFO:root:Epoch 71    loss=0.1922 [21.3 s]    dev=(HR@5:0.4404,NDCG@5:0.3248) [0.9 s]
INFO:root:Epoch 72    loss=0.1902 [21.4 s]    dev=(HR@5:0.4415,NDCG@5:0.3238) [1.0 s]
INFO:root:Epoch 73    loss=0.1912 [21.3 s]    dev=(HR@5:0.4447,NDCG@5:0.3263) [0.9 s]
INFO:root:Epoch 74    loss=0.1912 [21.3 s]    dev=(HR@5:0.4416,NDCG@5:0.3228) [1.0 s]
INFO:root:Epoch 75    loss=0.1919 [21.5 s]    dev=(HR@5:0.4429,NDCG@5:0.3256) [0.9 s]
INFO:root:Epoch 76    loss=0.1914 [21.4 s]    dev=(HR@5:0.4416,NDCG@5:0.3233) [1.0 s]
INFO:root:Epoch 77    loss=0.1901 [21.4 s]    dev=(HR@5:0.4460,NDCG@5:0.3263) [0.9 s]
INFO:root:Epoch 78    loss=0.1900 [21.3 s]    dev=(HR@5:0.4400,NDCG@5:0.3210) [1.0 s]
INFO:root:Early stop at 78 based on dev result.
INFO:root:
Best Iter(dev)=   58	 dev=(HR@5:0.4455,NDCG@5:0.3286) [1739.5 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.3936,NDCG@5:0.2809,HR@10:0.5017,NDCG@10:0.3160,HR@20:0.6229,NDCG@20:0.3465,HR@50:0.8230,NDCG@50:0.3861)
INFO:root:
--------------------------------------------- END: 2024-12-06 04:25:24 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 05:21:11 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5165 [23.2 s]    dev=(HR@5:0.2516,NDCG@5:0.1672) [0.9 s] *
INFO:root:Epoch 2     loss=0.4315 [21.2 s]    dev=(HR@5:0.3223,NDCG@5:0.2185) [1.0 s] *
INFO:root:Epoch 3     loss=0.3955 [21.3 s]    dev=(HR@5:0.3483,NDCG@5:0.2352) [0.9 s] *
INFO:root:Epoch 4     loss=0.3731 [21.2 s]    dev=(HR@5:0.3669,NDCG@5:0.2531) [0.9 s] *
INFO:root:Epoch 5     loss=0.3480 [21.3 s]    dev=(HR@5:0.3831,NDCG@5:0.2673) [0.9 s] *
INFO:root:Epoch 6     loss=0.3227 [21.1 s]    dev=(HR@5:0.4027,NDCG@5:0.2840) [0.9 s] *
INFO:root:Epoch 7     loss=0.3028 [21.2 s]    dev=(HR@5:0.4073,NDCG@5:0.2897) [0.9 s] *
INFO:root:Epoch 8     loss=0.2869 [21.2 s]    dev=(HR@5:0.4113,NDCG@5:0.2953) [0.9 s] *
INFO:root:Epoch 9     loss=0.2725 [21.2 s]    dev=(HR@5:0.4184,NDCG@5:0.3001) [1.0 s] *
INFO:root:Epoch 10    loss=0.2635 [21.1 s]    dev=(HR@5:0.4204,NDCG@5:0.3026) [0.9 s] *
INFO:root:Epoch 11    loss=0.2534 [21.1 s]    dev=(HR@5:0.4251,NDCG@5:0.3057) [0.9 s] *
INFO:root:Epoch 12    loss=0.2454 [21.2 s]    dev=(HR@5:0.4276,NDCG@5:0.3090) [0.9 s] *
INFO:root:Epoch 13    loss=0.2417 [21.1 s]    dev=(HR@5:0.4320,NDCG@5:0.3135) [0.9 s] *
INFO:root:Epoch 14    loss=0.2356 [21.2 s]    dev=(HR@5:0.4344,NDCG@5:0.3131) [0.9 s]
INFO:root:Epoch 15    loss=0.2320 [21.1 s]    dev=(HR@5:0.4295,NDCG@5:0.3113) [0.9 s]
INFO:root:Epoch 16    loss=0.2301 [21.1 s]    dev=(HR@5:0.4364,NDCG@5:0.3169) [0.9 s] *
INFO:root:Epoch 17    loss=0.2256 [21.1 s]    dev=(HR@5:0.4313,NDCG@5:0.3132) [0.9 s]
INFO:root:Epoch 18    loss=0.2218 [21.1 s]    dev=(HR@5:0.4370,NDCG@5:0.3167) [0.9 s]
INFO:root:Epoch 19    loss=0.2200 [21.2 s]    dev=(HR@5:0.4345,NDCG@5:0.3166) [0.9 s]
INFO:root:Epoch 20    loss=0.2174 [21.0 s]    dev=(HR@5:0.4370,NDCG@5:0.3186) [0.9 s] *
INFO:root:Epoch 21    loss=0.2137 [21.1 s]    dev=(HR@5:0.4399,NDCG@5:0.3202) [1.0 s] *
INFO:root:Epoch 22    loss=0.2122 [21.1 s]    dev=(HR@5:0.4372,NDCG@5:0.3205) [0.9 s] *
INFO:root:Epoch 23    loss=0.2126 [21.2 s]    dev=(HR@5:0.4371,NDCG@5:0.3197) [0.9 s]
INFO:root:Epoch 24    loss=0.2116 [21.2 s]    dev=(HR@5:0.4417,NDCG@5:0.3208) [0.9 s] *
INFO:root:Epoch 25    loss=0.2085 [21.1 s]    dev=(HR@5:0.4381,NDCG@5:0.3202) [0.9 s]
INFO:root:Epoch 26    loss=0.2081 [21.1 s]    dev=(HR@5:0.4415,NDCG@5:0.3218) [1.0 s] *
INFO:root:Epoch 27    loss=0.2080 [21.3 s]    dev=(HR@5:0.4452,NDCG@5:0.3245) [0.9 s] *
INFO:root:Epoch 28    loss=0.2078 [21.2 s]    dev=(HR@5:0.4462,NDCG@5:0.3274) [0.9 s] *
INFO:root:Epoch 29    loss=0.2048 [21.1 s]    dev=(HR@5:0.4417,NDCG@5:0.3231) [0.9 s]
INFO:root:Epoch 30    loss=0.2043 [21.3 s]    dev=(HR@5:0.4421,NDCG@5:0.3239) [0.9 s]
INFO:root:Epoch 31    loss=0.2029 [21.1 s]    dev=(HR@5:0.4486,NDCG@5:0.3290) [0.9 s] *
INFO:root:Epoch 32    loss=0.2034 [21.1 s]    dev=(HR@5:0.4421,NDCG@5:0.3243) [0.9 s]
INFO:root:Epoch 33    loss=0.2026 [21.2 s]    dev=(HR@5:0.4443,NDCG@5:0.3259) [0.9 s]
INFO:root:Epoch 34    loss=0.2011 [21.3 s]    dev=(HR@5:0.4429,NDCG@5:0.3248) [0.9 s]
INFO:root:Epoch 35    loss=0.2016 [21.2 s]    dev=(HR@5:0.4388,NDCG@5:0.3214) [0.9 s]
INFO:root:Epoch 36    loss=0.1999 [21.3 s]    dev=(HR@5:0.4410,NDCG@5:0.3227) [0.9 s]
INFO:root:Epoch 37    loss=0.2002 [21.3 s]    dev=(HR@5:0.4417,NDCG@5:0.3227) [0.9 s]
INFO:root:Epoch 38    loss=0.1995 [21.2 s]    dev=(HR@5:0.4415,NDCG@5:0.3226) [0.9 s]
INFO:root:Epoch 39    loss=0.1992 [21.2 s]    dev=(HR@5:0.4425,NDCG@5:0.3222) [0.9 s]
INFO:root:Epoch 40    loss=0.1991 [21.2 s]    dev=(HR@5:0.4428,NDCG@5:0.3237) [0.9 s]
INFO:root:Epoch 41    loss=0.1992 [21.2 s]    dev=(HR@5:0.4432,NDCG@5:0.3227) [0.9 s]
INFO:root:Epoch 42    loss=0.1990 [21.2 s]    dev=(HR@5:0.4470,NDCG@5:0.3255) [1.0 s]
INFO:root:Epoch 43    loss=0.1981 [21.2 s]    dev=(HR@5:0.4474,NDCG@5:0.3271) [0.9 s]
INFO:root:Epoch 44    loss=0.1984 [21.2 s]    dev=(HR@5:0.4452,NDCG@5:0.3248) [0.9 s]
INFO:root:Epoch 45    loss=0.1959 [21.2 s]    dev=(HR@5:0.4460,NDCG@5:0.3269) [0.9 s]
INFO:root:Epoch 46    loss=0.1964 [21.2 s]    dev=(HR@5:0.4440,NDCG@5:0.3238) [0.9 s]
INFO:root:Epoch 47    loss=0.1968 [21.1 s]    dev=(HR@5:0.4461,NDCG@5:0.3253) [0.9 s]
INFO:root:Epoch 48    loss=0.1961 [21.2 s]    dev=(HR@5:0.4410,NDCG@5:0.3222) [0.9 s]
INFO:root:Epoch 49    loss=0.1951 [21.2 s]    dev=(HR@5:0.4499,NDCG@5:0.3291) [0.9 s] *
INFO:root:Epoch 50    loss=0.1962 [21.2 s]    dev=(HR@5:0.4443,NDCG@5:0.3259) [0.9 s]
INFO:root:Epoch 51    loss=0.1946 [21.2 s]    dev=(HR@5:0.4442,NDCG@5:0.3253) [0.9 s]
INFO:root:Epoch 52    loss=0.1947 [21.2 s]    dev=(HR@5:0.4445,NDCG@5:0.3232) [0.9 s]
INFO:root:Epoch 53    loss=0.1951 [21.2 s]    dev=(HR@5:0.4449,NDCG@5:0.3259) [1.0 s]
INFO:root:Epoch 54    loss=0.1934 [21.1 s]    dev=(HR@5:0.4466,NDCG@5:0.3266) [0.9 s]
INFO:root:Epoch 55    loss=0.1934 [21.1 s]    dev=(HR@5:0.4460,NDCG@5:0.3245) [0.9 s]
INFO:root:Epoch 56    loss=0.1925 [21.2 s]    dev=(HR@5:0.4471,NDCG@5:0.3272) [0.9 s]
INFO:root:Epoch 57    loss=0.1930 [21.2 s]    dev=(HR@5:0.4464,NDCG@5:0.3279) [0.9 s]
INFO:root:Epoch 58    loss=0.1942 [21.2 s]    dev=(HR@5:0.4491,NDCG@5:0.3292) [0.9 s] *
INFO:root:Epoch 59    loss=0.1936 [21.1 s]    dev=(HR@5:0.4454,NDCG@5:0.3271) [0.9 s]
INFO:root:Epoch 60    loss=0.1935 [21.1 s]    dev=(HR@5:0.4440,NDCG@5:0.3254) [0.9 s]
INFO:root:Epoch 61    loss=0.1929 [21.2 s]    dev=(HR@5:0.4502,NDCG@5:0.3307) [1.0 s] *
INFO:root:Epoch 62    loss=0.1938 [21.0 s]    dev=(HR@5:0.4478,NDCG@5:0.3281) [0.9 s]
INFO:root:Epoch 63    loss=0.1941 [21.3 s]    dev=(HR@5:0.4511,NDCG@5:0.3294) [0.9 s]
INFO:root:Epoch 64    loss=0.1916 [21.2 s]    dev=(HR@5:0.4436,NDCG@5:0.3255) [0.9 s]
INFO:root:Epoch 65    loss=0.1929 [21.2 s]    dev=(HR@5:0.4477,NDCG@5:0.3274) [0.9 s]
INFO:root:Epoch 66    loss=0.1913 [21.2 s]    dev=(HR@5:0.4475,NDCG@5:0.3266) [0.9 s]
INFO:root:Epoch 67    loss=0.1919 [21.2 s]    dev=(HR@5:0.4466,NDCG@5:0.3258) [0.9 s]
INFO:root:Epoch 68    loss=0.1906 [21.2 s]    dev=(HR@5:0.4462,NDCG@5:0.3249) [0.9 s]
INFO:root:Epoch 69    loss=0.1922 [21.2 s]    dev=(HR@5:0.4481,NDCG@5:0.3282) [0.9 s]
INFO:root:Epoch 70    loss=0.1911 [21.2 s]    dev=(HR@5:0.4456,NDCG@5:0.3276) [0.9 s]
INFO:root:Epoch 71    loss=0.1911 [21.2 s]    dev=(HR@5:0.4467,NDCG@5:0.3276) [0.9 s]
INFO:root:Epoch 72    loss=0.1901 [21.1 s]    dev=(HR@5:0.4453,NDCG@5:0.3269) [1.0 s]
INFO:root:Epoch 73    loss=0.1911 [21.2 s]    dev=(HR@5:0.4494,NDCG@5:0.3285) [0.9 s]
INFO:root:Epoch 74    loss=0.1919 [21.3 s]    dev=(HR@5:0.4475,NDCG@5:0.3262) [0.9 s]
INFO:root:Epoch 75    loss=0.1923 [21.1 s]    dev=(HR@5:0.4439,NDCG@5:0.3259) [0.9 s]
INFO:root:Epoch 76    loss=0.1915 [21.2 s]    dev=(HR@5:0.4484,NDCG@5:0.3283) [0.9 s]
INFO:root:Epoch 77    loss=0.1902 [21.3 s]    dev=(HR@5:0.4464,NDCG@5:0.3273) [0.9 s]
INFO:root:Epoch 78    loss=0.1903 [21.2 s]    dev=(HR@5:0.4517,NDCG@5:0.3273) [0.9 s]
INFO:root:Epoch 79    loss=0.1907 [21.2 s]    dev=(HR@5:0.4506,NDCG@5:0.3310) [0.9 s] *
INFO:root:Epoch 80    loss=0.1888 [21.2 s]    dev=(HR@5:0.4487,NDCG@5:0.3278) [1.0 s]
INFO:root:Epoch 81    loss=0.1898 [21.3 s]    dev=(HR@5:0.4474,NDCG@5:0.3251) [0.9 s]
INFO:root:Epoch 82    loss=0.1908 [21.2 s]    dev=(HR@5:0.4502,NDCG@5:0.3288) [1.0 s]
INFO:root:Epoch 83    loss=0.1893 [21.1 s]    dev=(HR@5:0.4504,NDCG@5:0.3298) [0.9 s]
INFO:root:Epoch 84    loss=0.1893 [21.2 s]    dev=(HR@5:0.4509,NDCG@5:0.3287) [0.9 s]
INFO:root:Epoch 85    loss=0.1921 [21.2 s]    dev=(HR@5:0.4495,NDCG@5:0.3312) [0.9 s] *
INFO:root:Epoch 86    loss=0.1913 [21.1 s]    dev=(HR@5:0.4468,NDCG@5:0.3269) [0.9 s]
INFO:root:Epoch 87    loss=0.1904 [21.1 s]    dev=(HR@5:0.4470,NDCG@5:0.3272) [1.0 s]
INFO:root:Epoch 88    loss=0.1913 [21.1 s]    dev=(HR@5:0.4519,NDCG@5:0.3307) [0.9 s]
INFO:root:Epoch 89    loss=0.1903 [21.2 s]    dev=(HR@5:0.4487,NDCG@5:0.3289) [0.9 s]
INFO:root:Epoch 90    loss=0.1889 [21.2 s]    dev=(HR@5:0.4504,NDCG@5:0.3307) [0.9 s]
INFO:root:Epoch 91    loss=0.1898 [21.1 s]    dev=(HR@5:0.4501,NDCG@5:0.3302) [0.9 s]
INFO:root:Epoch 92    loss=0.1880 [21.2 s]    dev=(HR@5:0.4497,NDCG@5:0.3268) [0.9 s]
INFO:root:Epoch 93    loss=0.1907 [21.2 s]    dev=(HR@5:0.4424,NDCG@5:0.3251) [0.9 s]
INFO:root:Epoch 94    loss=0.1899 [21.1 s]    dev=(HR@5:0.4459,NDCG@5:0.3260) [1.0 s]
INFO:root:Epoch 95    loss=0.1905 [21.3 s]    dev=(HR@5:0.4485,NDCG@5:0.3273) [0.9 s]
INFO:root:Epoch 96    loss=0.1878 [21.2 s]    dev=(HR@5:0.4466,NDCG@5:0.3287) [0.9 s]
INFO:root:Epoch 97    loss=0.1897 [21.1 s]    dev=(HR@5:0.4469,NDCG@5:0.3266) [1.0 s]
INFO:root:Epoch 98    loss=0.1885 [21.1 s]    dev=(HR@5:0.4413,NDCG@5:0.3218) [0.9 s]
INFO:root:Epoch 99    loss=0.1890 [21.1 s]    dev=(HR@5:0.4509,NDCG@5:0.3300) [1.0 s]
INFO:root:Epoch 100   loss=0.1889 [21.2 s]    dev=(HR@5:0.4517,NDCG@5:0.3306) [0.9 s]
INFO:root:Epoch 101   loss=0.1899 [21.2 s]    dev=(HR@5:0.4472,NDCG@5:0.3257) [1.0 s]
INFO:root:Epoch 102   loss=0.1907 [21.1 s]    dev=(HR@5:0.4506,NDCG@5:0.3312) [0.9 s] *
INFO:root:Epoch 103   loss=0.1890 [21.2 s]    dev=(HR@5:0.4472,NDCG@5:0.3258) [0.9 s]
INFO:root:Epoch 104   loss=0.1891 [21.3 s]    dev=(HR@5:0.4464,NDCG@5:0.3256) [0.9 s]
INFO:root:Epoch 105   loss=0.1879 [21.2 s]    dev=(HR@5:0.4452,NDCG@5:0.3246) [0.9 s]
INFO:root:Epoch 106   loss=0.1887 [21.2 s]    dev=(HR@5:0.4489,NDCG@5:0.3274) [0.9 s]
INFO:root:Epoch 107   loss=0.1889 [21.2 s]    dev=(HR@5:0.4468,NDCG@5:0.3264) [0.9 s]
INFO:root:Epoch 108   loss=0.1891 [21.3 s]    dev=(HR@5:0.4507,NDCG@5:0.3296) [1.0 s]
INFO:root:Epoch 109   loss=0.1883 [21.3 s]    dev=(HR@5:0.4500,NDCG@5:0.3322) [0.9 s] *
INFO:root:Epoch 110   loss=0.1875 [21.2 s]    dev=(HR@5:0.4504,NDCG@5:0.3307) [0.9 s]
INFO:root:Epoch 111   loss=0.1880 [21.2 s]    dev=(HR@5:0.4494,NDCG@5:0.3274) [0.9 s]
INFO:root:Epoch 112   loss=0.1903 [21.2 s]    dev=(HR@5:0.4483,NDCG@5:0.3301) [0.9 s]
INFO:root:Epoch 113   loss=0.1892 [21.3 s]    dev=(HR@5:0.4477,NDCG@5:0.3290) [1.0 s]
INFO:root:Epoch 114   loss=0.1889 [21.3 s]    dev=(HR@5:0.4445,NDCG@5:0.3236) [0.9 s]
INFO:root:Epoch 115   loss=0.1879 [21.2 s]    dev=(HR@5:0.4453,NDCG@5:0.3260) [1.0 s]
INFO:root:Epoch 116   loss=0.1872 [21.2 s]    dev=(HR@5:0.4440,NDCG@5:0.3263) [0.9 s]
INFO:root:Epoch 117   loss=0.1886 [21.2 s]    dev=(HR@5:0.4478,NDCG@5:0.3266) [0.9 s]
INFO:root:Epoch 118   loss=0.1889 [21.2 s]    dev=(HR@5:0.4514,NDCG@5:0.3305) [0.9 s]
INFO:root:Epoch 119   loss=0.1881 [21.2 s]    dev=(HR@5:0.4524,NDCG@5:0.3299) [0.9 s]
INFO:root:Epoch 120   loss=0.1876 [21.3 s]    dev=(HR@5:0.4526,NDCG@5:0.3310) [0.9 s]
INFO:root:Epoch 121   loss=0.1861 [21.0 s]    dev=(HR@5:0.4530,NDCG@5:0.3311) [0.9 s]
INFO:root:Epoch 122   loss=0.1885 [21.1 s]    dev=(HR@5:0.4524,NDCG@5:0.3296) [1.0 s]
INFO:root:Epoch 123   loss=0.1880 [21.2 s]    dev=(HR@5:0.4492,NDCG@5:0.3292) [0.9 s]
INFO:root:Epoch 124   loss=0.1873 [21.1 s]    dev=(HR@5:0.4509,NDCG@5:0.3295) [0.9 s]
INFO:root:Epoch 125   loss=0.1877 [21.3 s]    dev=(HR@5:0.4453,NDCG@5:0.3251) [0.9 s]
INFO:root:Epoch 126   loss=0.1895 [21.2 s]    dev=(HR@5:0.4477,NDCG@5:0.3276) [0.9 s]
INFO:root:Epoch 127   loss=0.1865 [21.2 s]    dev=(HR@5:0.4513,NDCG@5:0.3287) [0.9 s]
INFO:root:Epoch 128   loss=0.1869 [21.2 s]    dev=(HR@5:0.4436,NDCG@5:0.3241) [0.9 s]
INFO:root:Epoch 129   loss=0.1892 [21.2 s]    dev=(HR@5:0.4460,NDCG@5:0.3233) [1.0 s]
INFO:root:Early stop at 129 based on dev result.
INFO:root:
Best Iter(dev)=  109	 dev=(HR@5:0.4500,NDCG@5:0.3322) [2856.1 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.4041,NDCG@5:0.2896,HR@10:0.5125,NDCG@10:0.3247,HR@20:0.6339,NDCG@20:0.3553,HR@50:0.8342,NDCG@50:0.3950)
INFO:root:
--------------------------------------------- END: 2024-12-06 06:08:49 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 06:48:50 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5165 [23.5 s]    dev=(HR@5:0.2530,NDCG@5:0.1683) [1.0 s] *
INFO:root:Epoch 2     loss=0.4302 [21.8 s]    dev=(HR@5:0.3259,NDCG@5:0.2218) [1.0 s] *
INFO:root:Epoch 3     loss=0.3927 [21.6 s]    dev=(HR@5:0.3559,NDCG@5:0.2424) [0.9 s] *
INFO:root:Epoch 4     loss=0.3698 [21.6 s]    dev=(HR@5:0.3727,NDCG@5:0.2568) [1.0 s] *
INFO:root:Epoch 5     loss=0.3451 [21.6 s]    dev=(HR@5:0.3919,NDCG@5:0.2733) [0.9 s] *
INFO:root:Epoch 6     loss=0.3200 [21.7 s]    dev=(HR@5:0.4059,NDCG@5:0.2890) [1.0 s] *
INFO:root:Epoch 7     loss=0.3007 [21.5 s]    dev=(HR@5:0.4135,NDCG@5:0.2949) [0.9 s] *
INFO:root:Epoch 8     loss=0.2855 [21.6 s]    dev=(HR@5:0.4203,NDCG@5:0.3015) [0.9 s] *
INFO:root:Epoch 9     loss=0.2715 [21.7 s]    dev=(HR@5:0.4222,NDCG@5:0.3040) [1.0 s] *
INFO:root:Epoch 10    loss=0.2625 [21.7 s]    dev=(HR@5:0.4275,NDCG@5:0.3082) [0.9 s] *
INFO:root:Epoch 11    loss=0.2529 [21.7 s]    dev=(HR@5:0.4307,NDCG@5:0.3116) [1.0 s] *
INFO:root:Epoch 12    loss=0.2456 [21.7 s]    dev=(HR@5:0.4319,NDCG@5:0.3130) [0.9 s] *
INFO:root:Epoch 13    loss=0.2421 [21.6 s]    dev=(HR@5:0.4357,NDCG@5:0.3182) [0.9 s] *
INFO:root:Epoch 14    loss=0.2368 [21.7 s]    dev=(HR@5:0.4366,NDCG@5:0.3171) [0.9 s]
INFO:root:Epoch 15    loss=0.2339 [21.7 s]    dev=(HR@5:0.4355,NDCG@5:0.3157) [0.9 s]
INFO:root:Epoch 16    loss=0.2317 [21.5 s]    dev=(HR@5:0.4372,NDCG@5:0.3189) [0.9 s] *
INFO:root:Epoch 17    loss=0.2281 [21.7 s]    dev=(HR@5:0.4351,NDCG@5:0.3173) [0.9 s]
INFO:root:Epoch 18    loss=0.2241 [21.6 s]    dev=(HR@5:0.4382,NDCG@5:0.3198) [0.9 s] *
INFO:root:Epoch 19    loss=0.2227 [21.6 s]    dev=(HR@5:0.4371,NDCG@5:0.3210) [0.9 s] *
INFO:root:Epoch 20    loss=0.2199 [21.6 s]    dev=(HR@5:0.4417,NDCG@5:0.3234) [0.9 s] *
INFO:root:Epoch 21    loss=0.2168 [21.6 s]    dev=(HR@5:0.4395,NDCG@5:0.3213) [0.9 s]
INFO:root:Epoch 22    loss=0.2161 [21.7 s]    dev=(HR@5:0.4393,NDCG@5:0.3220) [0.9 s]
INFO:root:Epoch 23    loss=0.2166 [21.6 s]    dev=(HR@5:0.4395,NDCG@5:0.3237) [0.9 s] *
INFO:root:Epoch 24    loss=0.2153 [21.5 s]    dev=(HR@5:0.4432,NDCG@5:0.3248) [1.0 s] *
INFO:root:Epoch 25    loss=0.2123 [21.6 s]    dev=(HR@5:0.4400,NDCG@5:0.3224) [0.9 s]
INFO:root:Epoch 26    loss=0.2125 [21.7 s]    dev=(HR@5:0.4409,NDCG@5:0.3236) [0.9 s]
INFO:root:Epoch 27    loss=0.2128 [21.6 s]    dev=(HR@5:0.4452,NDCG@5:0.3273) [1.0 s] *
INFO:root:Epoch 28    loss=0.2128 [21.7 s]    dev=(HR@5:0.4457,NDCG@5:0.3279) [0.9 s] *
INFO:root:Epoch 29    loss=0.2101 [21.6 s]    dev=(HR@5:0.4422,NDCG@5:0.3253) [1.0 s]
INFO:root:Epoch 30    loss=0.2100 [21.7 s]    dev=(HR@5:0.4410,NDCG@5:0.3257) [0.9 s]
INFO:root:Epoch 31    loss=0.2086 [21.6 s]    dev=(HR@5:0.4450,NDCG@5:0.3279) [1.0 s] *
INFO:root:Epoch 32    loss=0.2098 [21.7 s]    dev=(HR@5:0.4456,NDCG@5:0.3270) [0.9 s]
INFO:root:Epoch 33    loss=0.2090 [21.6 s]    dev=(HR@5:0.4440,NDCG@5:0.3263) [1.0 s]
INFO:root:Epoch 34    loss=0.2081 [21.6 s]    dev=(HR@5:0.4408,NDCG@5:0.3237) [0.9 s]
INFO:root:Epoch 35    loss=0.2083 [21.7 s]    dev=(HR@5:0.4398,NDCG@5:0.3227) [0.9 s]
INFO:root:Epoch 36    loss=0.2060 [21.6 s]    dev=(HR@5:0.4374,NDCG@5:0.3220) [0.9 s]
INFO:root:Epoch 37    loss=0.2069 [21.6 s]    dev=(HR@5:0.4419,NDCG@5:0.3229) [1.0 s]
INFO:root:Epoch 38    loss=0.2073 [21.6 s]    dev=(HR@5:0.4398,NDCG@5:0.3222) [0.9 s]
INFO:root:Epoch 39    loss=0.2063 [21.7 s]    dev=(HR@5:0.4390,NDCG@5:0.3210) [1.0 s]
INFO:root:Epoch 40    loss=0.2060 [21.6 s]    dev=(HR@5:0.4401,NDCG@5:0.3224) [0.9 s]
INFO:root:Epoch 41    loss=0.2066 [21.7 s]    dev=(HR@5:0.4390,NDCG@5:0.3220) [1.0 s]
INFO:root:Epoch 42    loss=0.2060 [21.7 s]    dev=(HR@5:0.4439,NDCG@5:0.3233) [0.9 s]
INFO:root:Epoch 43    loss=0.2047 [21.6 s]    dev=(HR@5:0.4438,NDCG@5:0.3257) [1.0 s]
INFO:root:Epoch 44    loss=0.2046 [21.6 s]    dev=(HR@5:0.4423,NDCG@5:0.3227) [0.9 s]
INFO:root:Epoch 45    loss=0.2020 [21.7 s]    dev=(HR@5:0.4437,NDCG@5:0.3258) [0.9 s]
INFO:root:Epoch 46    loss=0.2027 [21.8 s]    dev=(HR@5:0.4423,NDCG@5:0.3234) [0.9 s]
INFO:root:Epoch 47    loss=0.2028 [21.6 s]    dev=(HR@5:0.4450,NDCG@5:0.3243) [0.9 s]
INFO:root:Epoch 48    loss=0.2023 [21.7 s]    dev=(HR@5:0.4400,NDCG@5:0.3230) [0.9 s]
INFO:root:Epoch 49    loss=0.2005 [21.6 s]    dev=(HR@5:0.4424,NDCG@5:0.3255) [0.9 s]
INFO:root:Epoch 50    loss=0.2023 [21.6 s]    dev=(HR@5:0.4418,NDCG@5:0.3246) [0.9 s]
INFO:root:Epoch 51    loss=0.2008 [21.6 s]    dev=(HR@5:0.4437,NDCG@5:0.3263) [0.9 s]
INFO:root:Early stop at 51 based on dev result.
INFO:root:
Best Iter(dev)=   31	 dev=(HR@5:0.4450,NDCG@5:0.3279) [1154.1 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.3977,NDCG@5:0.2841,HR@10:0.5085,NDCG@10:0.3200,HR@20:0.6299,NDCG@20:0.3505,HR@50:0.8390,NDCG@50:0.3919)
INFO:root:
--------------------------------------------- END: 2024-12-06 07:08:06 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 07:54:00 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5165 [23.3 s]    dev=(HR@5:0.2537,NDCG@5:0.1690) [0.9 s] *
INFO:root:Epoch 2     loss=0.4296 [21.4 s]    dev=(HR@5:0.3271,NDCG@5:0.2228) [0.9 s] *
INFO:root:Epoch 3     loss=0.3928 [21.3 s]    dev=(HR@5:0.3543,NDCG@5:0.2412) [0.9 s] *
INFO:root:Epoch 4     loss=0.3710 [21.3 s]    dev=(HR@5:0.3735,NDCG@5:0.2576) [0.9 s] *
INFO:root:Epoch 5     loss=0.3457 [21.4 s]    dev=(HR@5:0.3952,NDCG@5:0.2761) [0.9 s] *
INFO:root:Epoch 6     loss=0.3189 [21.2 s]    dev=(HR@5:0.4133,NDCG@5:0.2965) [0.9 s] *
INFO:root:Epoch 7     loss=0.2983 [21.2 s]    dev=(HR@5:0.4201,NDCG@5:0.3022) [1.0 s] *
INFO:root:Epoch 8     loss=0.2825 [21.2 s]    dev=(HR@5:0.4257,NDCG@5:0.3080) [0.9 s] *
INFO:root:Epoch 9     loss=0.2690 [21.3 s]    dev=(HR@5:0.4277,NDCG@5:0.3110) [0.9 s] *
INFO:root:Epoch 10    loss=0.2603 [21.2 s]    dev=(HR@5:0.4332,NDCG@5:0.3150) [0.9 s] *
INFO:root:Epoch 11    loss=0.2514 [21.2 s]    dev=(HR@5:0.4344,NDCG@5:0.3153) [0.9 s] *
INFO:root:Epoch 12    loss=0.2443 [21.3 s]    dev=(HR@5:0.4360,NDCG@5:0.3172) [0.9 s] *
INFO:root:Epoch 13    loss=0.2408 [21.2 s]    dev=(HR@5:0.4411,NDCG@5:0.3224) [0.9 s] *
INFO:root:Epoch 14    loss=0.2360 [21.3 s]    dev=(HR@5:0.4402,NDCG@5:0.3190) [0.9 s]
INFO:root:Epoch 15    loss=0.2332 [21.4 s]    dev=(HR@5:0.4372,NDCG@5:0.3182) [0.9 s]
INFO:root:Epoch 16    loss=0.2309 [21.2 s]    dev=(HR@5:0.4391,NDCG@5:0.3210) [1.0 s]
INFO:root:Epoch 17    loss=0.2281 [21.3 s]    dev=(HR@5:0.4338,NDCG@5:0.3180) [0.9 s]
INFO:root:Epoch 18    loss=0.2238 [21.3 s]    dev=(HR@5:0.4383,NDCG@5:0.3213) [1.0 s]
INFO:root:Epoch 19    loss=0.2221 [21.4 s]    dev=(HR@5:0.4415,NDCG@5:0.3230) [0.9 s] *
INFO:root:Epoch 20    loss=0.2197 [21.3 s]    dev=(HR@5:0.4414,NDCG@5:0.3238) [0.9 s] *
INFO:root:Epoch 21    loss=0.2161 [21.2 s]    dev=(HR@5:0.4410,NDCG@5:0.3237) [0.9 s]
INFO:root:Epoch 22    loss=0.2166 [21.3 s]    dev=(HR@5:0.4419,NDCG@5:0.3255) [0.9 s] *
INFO:root:Epoch 23    loss=0.2165 [21.2 s]    dev=(HR@5:0.4413,NDCG@5:0.3250) [0.9 s]
INFO:root:Epoch 24    loss=0.2160 [21.1 s]    dev=(HR@5:0.4405,NDCG@5:0.3227) [1.0 s]
INFO:root:Epoch 25    loss=0.2131 [21.3 s]    dev=(HR@5:0.4440,NDCG@5:0.3248) [1.0 s]
INFO:root:Epoch 26    loss=0.2128 [21.2 s]    dev=(HR@5:0.4427,NDCG@5:0.3251) [0.9 s]
INFO:root:Epoch 27    loss=0.2137 [21.3 s]    dev=(HR@5:0.4450,NDCG@5:0.3271) [1.0 s] *
INFO:root:Epoch 28    loss=0.2129 [21.3 s]    dev=(HR@5:0.4455,NDCG@5:0.3294) [0.9 s] *
INFO:root:Epoch 29    loss=0.2108 [21.4 s]    dev=(HR@5:0.4443,NDCG@5:0.3273) [1.0 s]
INFO:root:Epoch 30    loss=0.2108 [21.3 s]    dev=(HR@5:0.4430,NDCG@5:0.3270) [0.9 s]
INFO:root:Epoch 31    loss=0.2098 [21.3 s]    dev=(HR@5:0.4460,NDCG@5:0.3281) [1.0 s]
INFO:root:Epoch 32    loss=0.2099 [21.2 s]    dev=(HR@5:0.4447,NDCG@5:0.3263) [0.9 s]
INFO:root:Epoch 33    loss=0.2096 [21.2 s]    dev=(HR@5:0.4423,NDCG@5:0.3261) [0.9 s]
INFO:root:Epoch 34    loss=0.2088 [21.2 s]    dev=(HR@5:0.4423,NDCG@5:0.3257) [0.9 s]
INFO:root:Epoch 35    loss=0.2088 [21.3 s]    dev=(HR@5:0.4423,NDCG@5:0.3244) [0.9 s]
INFO:root:Epoch 36    loss=0.2062 [21.2 s]    dev=(HR@5:0.4420,NDCG@5:0.3258) [1.0 s]
INFO:root:Epoch 37    loss=0.2074 [21.2 s]    dev=(HR@5:0.4423,NDCG@5:0.3245) [0.9 s]
INFO:root:Epoch 38    loss=0.2078 [21.4 s]    dev=(HR@5:0.4421,NDCG@5:0.3254) [0.9 s]
INFO:root:Epoch 39    loss=0.2069 [21.3 s]    dev=(HR@5:0.4419,NDCG@5:0.3239) [0.9 s]
INFO:root:Epoch 40    loss=0.2063 [21.2 s]    dev=(HR@5:0.4398,NDCG@5:0.3226) [1.0 s]
INFO:root:Epoch 41    loss=0.2072 [21.3 s]    dev=(HR@5:0.4416,NDCG@5:0.3247) [0.9 s]
INFO:root:Epoch 42    loss=0.2059 [21.4 s]    dev=(HR@5:0.4446,NDCG@5:0.3254) [0.9 s]
INFO:root:Epoch 43    loss=0.2046 [21.3 s]    dev=(HR@5:0.4457,NDCG@5:0.3282) [1.0 s]
INFO:root:Epoch 44    loss=0.2048 [21.2 s]    dev=(HR@5:0.4413,NDCG@5:0.3241) [0.9 s]
INFO:root:Epoch 45    loss=0.2020 [21.3 s]    dev=(HR@5:0.4448,NDCG@5:0.3273) [1.0 s]
INFO:root:Epoch 46    loss=0.2025 [21.2 s]    dev=(HR@5:0.4433,NDCG@5:0.3250) [0.9 s]
INFO:root:Epoch 47    loss=0.2028 [21.4 s]    dev=(HR@5:0.4449,NDCG@5:0.3249) [0.9 s]
INFO:root:Epoch 48    loss=0.2021 [21.4 s]    dev=(HR@5:0.4408,NDCG@5:0.3229) [0.9 s]
INFO:root:Early stop at 48 based on dev result.
INFO:root:
Best Iter(dev)=   28	 dev=(HR@5:0.4455,NDCG@5:0.3294) [1068.7 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.4005,NDCG@5:0.2866,HR@10:0.5113,NDCG@10:0.3224,HR@20:0.6327,NDCG@20:0.3530,HR@50:0.8396,NDCG@50:0.3939)
INFO:root:
--------------------------------------------- END: 2024-12-06 08:11:51 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 09:00:08 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5166 [23.2 s]    dev=(HR@5:0.2535,NDCG@5:0.1687) [1.0 s] *
INFO:root:Epoch 2     loss=0.4301 [21.2 s]    dev=(HR@5:0.3259,NDCG@5:0.2217) [0.9 s] *
INFO:root:Epoch 3     loss=0.3944 [21.1 s]    dev=(HR@5:0.3477,NDCG@5:0.2366) [0.9 s] *
INFO:root:Epoch 4     loss=0.3732 [21.2 s]    dev=(HR@5:0.3697,NDCG@5:0.2561) [0.9 s] *
INFO:root:Epoch 5     loss=0.3461 [21.3 s]    dev=(HR@5:0.3946,NDCG@5:0.2769) [0.9 s] *
INFO:root:Epoch 6     loss=0.3184 [21.1 s]    dev=(HR@5:0.4155,NDCG@5:0.2978) [1.0 s] *
INFO:root:Epoch 7     loss=0.2981 [21.3 s]    dev=(HR@5:0.4201,NDCG@5:0.3023) [0.9 s] *
INFO:root:Epoch 8     loss=0.2828 [21.2 s]    dev=(HR@5:0.4259,NDCG@5:0.3083) [1.0 s] *
INFO:root:Epoch 9     loss=0.2698 [21.2 s]    dev=(HR@5:0.4287,NDCG@5:0.3116) [0.9 s] *
INFO:root:Epoch 10    loss=0.2607 [21.2 s]    dev=(HR@5:0.4342,NDCG@5:0.3152) [0.9 s] *
INFO:root:Epoch 11    loss=0.2512 [21.1 s]    dev=(HR@5:0.4340,NDCG@5:0.3154) [0.9 s] *
INFO:root:Epoch 12    loss=0.2438 [21.2 s]    dev=(HR@5:0.4378,NDCG@5:0.3198) [0.9 s] *
INFO:root:Epoch 13    loss=0.2402 [21.2 s]    dev=(HR@5:0.4414,NDCG@5:0.3229) [0.9 s] *
INFO:root:Epoch 14    loss=0.2351 [21.3 s]    dev=(HR@5:0.4406,NDCG@5:0.3217) [0.9 s]
INFO:root:Epoch 15    loss=0.2315 [21.2 s]    dev=(HR@5:0.4383,NDCG@5:0.3183) [1.0 s]
INFO:root:Epoch 16    loss=0.2289 [21.2 s]    dev=(HR@5:0.4381,NDCG@5:0.3213) [0.9 s]
INFO:root:Epoch 17    loss=0.2255 [21.2 s]    dev=(HR@5:0.4357,NDCG@5:0.3196) [0.9 s]
INFO:root:Epoch 18    loss=0.2211 [21.3 s]    dev=(HR@5:0.4428,NDCG@5:0.3244) [0.9 s] *
INFO:root:Epoch 19    loss=0.2189 [21.2 s]    dev=(HR@5:0.4440,NDCG@5:0.3267) [0.9 s] *
INFO:root:Epoch 20    loss=0.2167 [21.3 s]    dev=(HR@5:0.4438,NDCG@5:0.3259) [0.9 s]
INFO:root:Epoch 21    loss=0.2127 [21.3 s]    dev=(HR@5:0.4453,NDCG@5:0.3268) [0.9 s] *
INFO:root:Epoch 22    loss=0.2126 [21.3 s]    dev=(HR@5:0.4417,NDCG@5:0.3256) [0.9 s]
INFO:root:Epoch 23    loss=0.2124 [21.2 s]    dev=(HR@5:0.4430,NDCG@5:0.3260) [0.9 s]
INFO:root:Epoch 24    loss=0.2112 [21.2 s]    dev=(HR@5:0.4448,NDCG@5:0.3249) [1.0 s]
INFO:root:Epoch 25    loss=0.2087 [21.3 s]    dev=(HR@5:0.4428,NDCG@5:0.3251) [0.9 s]
INFO:root:Epoch 26    loss=0.2080 [21.2 s]    dev=(HR@5:0.4471,NDCG@5:0.3290) [0.9 s] *
INFO:root:Epoch 27    loss=0.2085 [21.2 s]    dev=(HR@5:0.4468,NDCG@5:0.3289) [0.9 s]
INFO:root:Epoch 28    loss=0.2076 [21.2 s]    dev=(HR@5:0.4502,NDCG@5:0.3316) [0.9 s] *
INFO:root:Epoch 29    loss=0.2053 [21.2 s]    dev=(HR@5:0.4468,NDCG@5:0.3293) [0.9 s]
INFO:root:Epoch 30    loss=0.2048 [21.3 s]    dev=(HR@5:0.4468,NDCG@5:0.3297) [0.9 s]
INFO:root:Epoch 31    loss=0.2036 [21.2 s]    dev=(HR@5:0.4485,NDCG@5:0.3304) [0.9 s]
INFO:root:Epoch 32    loss=0.2039 [21.3 s]    dev=(HR@5:0.4471,NDCG@5:0.3292) [0.9 s]
INFO:root:Epoch 33    loss=0.2032 [21.2 s]    dev=(HR@5:0.4461,NDCG@5:0.3305) [1.0 s]
INFO:root:Epoch 34    loss=0.2026 [21.2 s]    dev=(HR@5:0.4441,NDCG@5:0.3283) [0.9 s]
INFO:root:Epoch 35    loss=0.2025 [21.2 s]    dev=(HR@5:0.4451,NDCG@5:0.3281) [0.9 s]
INFO:root:Epoch 36    loss=0.1999 [21.3 s]    dev=(HR@5:0.4449,NDCG@5:0.3280) [0.9 s]
INFO:root:Epoch 37    loss=0.2007 [21.2 s]    dev=(HR@5:0.4468,NDCG@5:0.3277) [0.9 s]
INFO:root:Epoch 38    loss=0.2007 [21.2 s]    dev=(HR@5:0.4473,NDCG@5:0.3293) [1.0 s]
INFO:root:Epoch 39    loss=0.1995 [21.2 s]    dev=(HR@5:0.4432,NDCG@5:0.3242) [0.9 s]
INFO:root:Epoch 40    loss=0.1989 [21.2 s]    dev=(HR@5:0.4425,NDCG@5:0.3244) [1.0 s]
INFO:root:Epoch 41    loss=0.1991 [21.3 s]    dev=(HR@5:0.4417,NDCG@5:0.3247) [0.9 s]
INFO:root:Epoch 42    loss=0.1984 [21.2 s]    dev=(HR@5:0.4468,NDCG@5:0.3272) [0.9 s]
INFO:root:Epoch 43    loss=0.1972 [21.3 s]    dev=(HR@5:0.4479,NDCG@5:0.3295) [0.9 s]
INFO:root:Epoch 44    loss=0.1979 [21.2 s]    dev=(HR@5:0.4406,NDCG@5:0.3234) [0.9 s]
INFO:root:Epoch 45    loss=0.1948 [21.3 s]    dev=(HR@5:0.4477,NDCG@5:0.3302) [0.9 s]
INFO:root:Epoch 46    loss=0.1962 [21.3 s]    dev=(HR@5:0.4455,NDCG@5:0.3278) [0.9 s]
INFO:root:Epoch 47    loss=0.1960 [21.3 s]    dev=(HR@5:0.4473,NDCG@5:0.3285) [1.0 s]
INFO:root:Epoch 48    loss=0.1948 [21.2 s]    dev=(HR@5:0.4441,NDCG@5:0.3261) [0.9 s]
INFO:root:Early stop at 48 based on dev result.
INFO:root:
Best Iter(dev)=   28	 dev=(HR@5:0.4502,NDCG@5:0.3316) [1066.8 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.3998,NDCG@5:0.2863,HR@10:0.5132,NDCG@10:0.3230,HR@20:0.6362,NDCG@20:0.3540,HR@50:0.8368,NDCG@50:0.3936)
INFO:root:
--------------------------------------------- END: 2024-12-06 09:17:57 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 10:41:48 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5159 [23.1 s]    dev=(HR@5:0.2502,NDCG@5:0.1666) [1.0 s] *
INFO:root:Epoch 2     loss=0.4332 [21.2 s]    dev=(HR@5:0.3179,NDCG@5:0.2143) [0.9 s] *
INFO:root:Epoch 3     loss=0.3984 [21.3 s]    dev=(HR@5:0.3413,NDCG@5:0.2287) [1.0 s] *
INFO:root:Epoch 4     loss=0.3768 [21.3 s]    dev=(HR@5:0.3639,NDCG@5:0.2493) [0.9 s] *
INFO:root:Epoch 5     loss=0.3523 [21.4 s]    dev=(HR@5:0.3794,NDCG@5:0.2643) [0.9 s] *
INFO:root:Epoch 6     loss=0.3273 [21.3 s]    dev=(HR@5:0.3929,NDCG@5:0.2785) [0.9 s] *
INFO:root:Epoch 7     loss=0.3067 [21.3 s]    dev=(HR@5:0.3981,NDCG@5:0.2848) [0.9 s] *
INFO:root:Epoch 8     loss=0.2894 [21.4 s]    dev=(HR@5:0.4038,NDCG@5:0.2908) [0.9 s] *
INFO:root:Epoch 9     loss=0.2739 [21.1 s]    dev=(HR@5:0.4032,NDCG@5:0.2936) [0.9 s] *
INFO:root:Epoch 10    loss=0.2628 [21.3 s]    dev=(HR@5:0.4078,NDCG@5:0.2967) [1.0 s] *
INFO:root:Epoch 11    loss=0.2536 [21.2 s]    dev=(HR@5:0.4167,NDCG@5:0.3022) [0.9 s] *
INFO:root:Epoch 12    loss=0.2445 [21.3 s]    dev=(HR@5:0.4188,NDCG@5:0.3049) [1.0 s] *
INFO:root:Epoch 13    loss=0.2413 [21.3 s]    dev=(HR@5:0.4228,NDCG@5:0.3088) [0.9 s] *
INFO:root:Epoch 14    loss=0.2349 [21.2 s]    dev=(HR@5:0.4219,NDCG@5:0.3069) [0.9 s]
INFO:root:Epoch 15    loss=0.2324 [21.3 s]    dev=(HR@5:0.4228,NDCG@5:0.3062) [0.9 s]
INFO:root:Epoch 16    loss=0.2285 [21.2 s]    dev=(HR@5:0.4233,NDCG@5:0.3085) [0.9 s]
INFO:root:Epoch 17    loss=0.2253 [21.4 s]    dev=(HR@5:0.4242,NDCG@5:0.3075) [0.9 s]
INFO:root:Epoch 18    loss=0.2211 [21.3 s]    dev=(HR@5:0.4276,NDCG@5:0.3108) [0.9 s] *
INFO:root:Epoch 19    loss=0.2185 [21.2 s]    dev=(HR@5:0.4293,NDCG@5:0.3150) [1.0 s] *
INFO:root:Epoch 20    loss=0.2167 [21.3 s]    dev=(HR@5:0.4302,NDCG@5:0.3158) [0.9 s] *
INFO:root:Epoch 21    loss=0.2128 [21.2 s]    dev=(HR@5:0.4352,NDCG@5:0.3172) [0.9 s] *
INFO:root:Epoch 22    loss=0.2114 [21.3 s]    dev=(HR@5:0.4368,NDCG@5:0.3194) [0.9 s] *
INFO:root:Epoch 23    loss=0.2120 [21.2 s]    dev=(HR@5:0.4261,NDCG@5:0.3130) [0.9 s]
INFO:root:Epoch 24    loss=0.2102 [21.3 s]    dev=(HR@5:0.4334,NDCG@5:0.3162) [0.9 s]
INFO:root:Epoch 25    loss=0.2086 [21.2 s]    dev=(HR@5:0.4327,NDCG@5:0.3164) [0.9 s]
INFO:root:Epoch 26    loss=0.2081 [21.2 s]    dev=(HR@5:0.4355,NDCG@5:0.3175) [0.9 s]
INFO:root:Epoch 27    loss=0.2073 [21.2 s]    dev=(HR@5:0.4353,NDCG@5:0.3202) [0.9 s] *
INFO:root:Epoch 28    loss=0.2071 [21.3 s]    dev=(HR@5:0.4408,NDCG@5:0.3235) [1.0 s] *
INFO:root:Epoch 29    loss=0.2045 [21.3 s]    dev=(HR@5:0.4396,NDCG@5:0.3212) [0.9 s]
INFO:root:Epoch 30    loss=0.2041 [21.2 s]    dev=(HR@5:0.4372,NDCG@5:0.3214) [1.0 s]
INFO:root:Epoch 31    loss=0.2024 [21.2 s]    dev=(HR@5:0.4413,NDCG@5:0.3241) [1.0 s] *
INFO:root:Epoch 32    loss=0.2035 [21.1 s]    dev=(HR@5:0.4437,NDCG@5:0.3253) [0.9 s] *
INFO:root:Epoch 33    loss=0.2026 [21.2 s]    dev=(HR@5:0.4413,NDCG@5:0.3232) [1.0 s]
INFO:root:Epoch 34    loss=0.2018 [21.2 s]    dev=(HR@5:0.4419,NDCG@5:0.3235) [0.9 s]
INFO:root:Epoch 35    loss=0.2010 [21.2 s]    dev=(HR@5:0.4409,NDCG@5:0.3218) [1.0 s]
INFO:root:Epoch 36    loss=0.2001 [21.3 s]    dev=(HR@5:0.4410,NDCG@5:0.3215) [0.9 s]
INFO:root:Epoch 37    loss=0.2004 [21.2 s]    dev=(HR@5:0.4475,NDCG@5:0.3261) [0.9 s] *
INFO:root:Epoch 38    loss=0.2002 [21.3 s]    dev=(HR@5:0.4425,NDCG@5:0.3224) [0.9 s]
INFO:root:Epoch 39    loss=0.1995 [21.1 s]    dev=(HR@5:0.4355,NDCG@5:0.3178) [0.9 s]
INFO:root:Epoch 40    loss=0.1988 [21.2 s]    dev=(HR@5:0.4445,NDCG@5:0.3257) [0.9 s]
INFO:root:Epoch 41    loss=0.1999 [21.2 s]    dev=(HR@5:0.4389,NDCG@5:0.3213) [0.9 s]
INFO:root:Epoch 42    loss=0.1997 [21.2 s]    dev=(HR@5:0.4463,NDCG@5:0.3264) [1.0 s] *
INFO:root:Epoch 43    loss=0.1979 [21.2 s]    dev=(HR@5:0.4464,NDCG@5:0.3276) [0.9 s] *
INFO:root:Epoch 44    loss=0.1995 [21.3 s]    dev=(HR@5:0.4421,NDCG@5:0.3234) [1.0 s]
INFO:root:Epoch 45    loss=0.1955 [21.2 s]    dev=(HR@5:0.4485,NDCG@5:0.3294) [0.9 s] *
INFO:root:Epoch 46    loss=0.1961 [21.3 s]    dev=(HR@5:0.4452,NDCG@5:0.3261) [0.9 s]
INFO:root:Epoch 47    loss=0.1969 [21.3 s]    dev=(HR@5:0.4469,NDCG@5:0.3282) [0.9 s]
INFO:root:Epoch 48    loss=0.1963 [21.3 s]    dev=(HR@5:0.4461,NDCG@5:0.3257) [0.9 s]
INFO:root:Epoch 49    loss=0.1947 [21.2 s]    dev=(HR@5:0.4483,NDCG@5:0.3289) [0.9 s]
INFO:root:Epoch 50    loss=0.1957 [21.3 s]    dev=(HR@5:0.4437,NDCG@5:0.3253) [0.9 s]
INFO:root:Epoch 51    loss=0.1947 [21.2 s]    dev=(HR@5:0.4451,NDCG@5:0.3263) [0.9 s]
INFO:root:Epoch 52    loss=0.1946 [21.3 s]    dev=(HR@5:0.4453,NDCG@5:0.3260) [0.9 s]
INFO:root:Epoch 53    loss=0.1940 [21.3 s]    dev=(HR@5:0.4474,NDCG@5:0.3280) [1.0 s]
INFO:root:Epoch 54    loss=0.1928 [21.4 s]    dev=(HR@5:0.4469,NDCG@5:0.3275) [0.9 s]
INFO:root:Epoch 55    loss=0.1924 [21.3 s]    dev=(HR@5:0.4457,NDCG@5:0.3266) [0.9 s]
INFO:root:Epoch 56    loss=0.1926 [21.3 s]    dev=(HR@5:0.4498,NDCG@5:0.3308) [0.9 s] *
INFO:root:Epoch 57    loss=0.1926 [21.1 s]    dev=(HR@5:0.4483,NDCG@5:0.3302) [0.9 s]
INFO:root:Epoch 58    loss=0.1935 [21.2 s]    dev=(HR@5:0.4469,NDCG@5:0.3302) [1.0 s]
INFO:root:Epoch 59    loss=0.1922 [21.2 s]    dev=(HR@5:0.4461,NDCG@5:0.3276) [0.9 s]
INFO:root:Epoch 60    loss=0.1933 [21.2 s]    dev=(HR@5:0.4441,NDCG@5:0.3276) [0.9 s]
INFO:root:Epoch 61    loss=0.1920 [21.2 s]    dev=(HR@5:0.4485,NDCG@5:0.3301) [0.9 s]
INFO:root:Epoch 62    loss=0.1920 [21.3 s]    dev=(HR@5:0.4464,NDCG@5:0.3281) [0.9 s]
INFO:root:Epoch 63    loss=0.1927 [21.3 s]    dev=(HR@5:0.4483,NDCG@5:0.3297) [0.9 s]
INFO:root:Epoch 64    loss=0.1912 [21.3 s]    dev=(HR@5:0.4451,NDCG@5:0.3260) [0.9 s]
INFO:root:Epoch 65    loss=0.1921 [21.3 s]    dev=(HR@5:0.4440,NDCG@5:0.3256) [0.9 s]
INFO:root:Epoch 66    loss=0.1906 [21.2 s]    dev=(HR@5:0.4430,NDCG@5:0.3244) [0.9 s]
INFO:root:Epoch 67    loss=0.1918 [21.3 s]    dev=(HR@5:0.4440,NDCG@5:0.3259) [0.9 s]
INFO:root:Epoch 68    loss=0.1894 [21.2 s]    dev=(HR@5:0.4456,NDCG@5:0.3269) [0.9 s]
INFO:root:Epoch 69    loss=0.1918 [21.2 s]    dev=(HR@5:0.4447,NDCG@5:0.3268) [0.9 s]
INFO:root:Epoch 70    loss=0.1903 [21.2 s]    dev=(HR@5:0.4458,NDCG@5:0.3277) [0.9 s]
INFO:root:Epoch 71    loss=0.1897 [21.2 s]    dev=(HR@5:0.4460,NDCG@5:0.3290) [0.9 s]
INFO:root:Epoch 72    loss=0.1899 [21.4 s]    dev=(HR@5:0.4400,NDCG@5:0.3247) [0.9 s]
INFO:root:Epoch 73    loss=0.1900 [21.2 s]    dev=(HR@5:0.4472,NDCG@5:0.3285) [0.9 s]
INFO:root:Epoch 74    loss=0.1903 [21.4 s]    dev=(HR@5:0.4466,NDCG@5:0.3272) [0.9 s]
INFO:root:Epoch 75    loss=0.1916 [21.3 s]    dev=(HR@5:0.4477,NDCG@5:0.3288) [0.9 s]
INFO:root:Epoch 76    loss=0.1917 [21.4 s]    dev=(HR@5:0.4483,NDCG@5:0.3294) [1.0 s]
INFO:root:Early stop at 76 based on dev result.
INFO:root:
Best Iter(dev)=   56	 dev=(HR@5:0.4498,NDCG@5:0.3308) [1689.4 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.3998,NDCG@5:0.2867,HR@10:0.5096,NDCG@10:0.3222,HR@20:0.6323,NDCG@20:0.3531,HR@50:0.8345,NDCG@50:0.3932)
INFO:root:
--------------------------------------------- END: 2024-12-06 11:10:00 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 11:45:55 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5161 [23.4 s]    dev=(HR@5:0.2511,NDCG@5:0.1675) [1.0 s] *
INFO:root:Epoch 2     loss=0.4302 [22.0 s]    dev=(HR@5:0.3229,NDCG@5:0.2191) [1.0 s] *
INFO:root:Epoch 3     loss=0.3932 [21.5 s]    dev=(HR@5:0.3495,NDCG@5:0.2370) [1.1 s] *
INFO:root:Epoch 4     loss=0.3691 [21.4 s]    dev=(HR@5:0.3727,NDCG@5:0.2578) [1.0 s] *
INFO:root:Epoch 5     loss=0.3424 [22.0 s]    dev=(HR@5:0.3933,NDCG@5:0.2758) [1.0 s] *
INFO:root:Epoch 6     loss=0.3170 [22.0 s]    dev=(HR@5:0.4109,NDCG@5:0.2914) [1.0 s] *
INFO:root:Epoch 7     loss=0.2982 [23.3 s]    dev=(HR@5:0.4154,NDCG@5:0.2952) [1.8 s] *
INFO:root:Epoch 8     loss=0.2836 [21.6 s]    dev=(HR@5:0.4184,NDCG@5:0.3013) [0.9 s] *
INFO:root:Epoch 9     loss=0.2702 [21.2 s]    dev=(HR@5:0.4216,NDCG@5:0.3052) [0.9 s] *
INFO:root:Epoch 10    loss=0.2622 [21.9 s]    dev=(HR@5:0.4212,NDCG@5:0.3052) [0.9 s] *
INFO:root:Epoch 11    loss=0.2529 [21.5 s]    dev=(HR@5:0.4280,NDCG@5:0.3102) [0.9 s] *
INFO:root:Epoch 12    loss=0.2455 [21.6 s]    dev=(HR@5:0.4300,NDCG@5:0.3118) [1.0 s] *
INFO:root:Epoch 13    loss=0.2415 [21.4 s]    dev=(HR@5:0.4317,NDCG@5:0.3139) [1.0 s] *
INFO:root:Epoch 14    loss=0.2378 [21.4 s]    dev=(HR@5:0.4315,NDCG@5:0.3138) [0.9 s]
INFO:root:Epoch 15    loss=0.2348 [21.5 s]    dev=(HR@5:0.4302,NDCG@5:0.3120) [1.0 s]
INFO:root:Epoch 16    loss=0.2326 [21.1 s]    dev=(HR@5:0.4331,NDCG@5:0.3140) [0.9 s] *
INFO:root:Epoch 17    loss=0.2288 [21.1 s]    dev=(HR@5:0.4330,NDCG@5:0.3124) [1.0 s]
INFO:root:Epoch 18    loss=0.2247 [22.0 s]    dev=(HR@5:0.4367,NDCG@5:0.3167) [0.9 s] *
INFO:root:Epoch 19    loss=0.2233 [21.4 s]    dev=(HR@5:0.4344,NDCG@5:0.3166) [0.9 s]
INFO:root:Epoch 20    loss=0.2202 [21.5 s]    dev=(HR@5:0.4359,NDCG@5:0.3196) [1.0 s] *
INFO:root:Epoch 21    loss=0.2168 [21.3 s]    dev=(HR@5:0.4344,NDCG@5:0.3168) [0.9 s]
INFO:root:Epoch 22    loss=0.2159 [21.6 s]    dev=(HR@5:0.4362,NDCG@5:0.3183) [0.9 s]
INFO:root:Epoch 23    loss=0.2170 [21.4 s]    dev=(HR@5:0.4332,NDCG@5:0.3172) [1.0 s]
INFO:root:Epoch 24    loss=0.2155 [21.6 s]    dev=(HR@5:0.4353,NDCG@5:0.3177) [1.0 s]
INFO:root:Epoch 25    loss=0.2128 [21.3 s]    dev=(HR@5:0.4351,NDCG@5:0.3167) [1.0 s]
INFO:root:Epoch 26    loss=0.2128 [21.3 s]    dev=(HR@5:0.4374,NDCG@5:0.3189) [0.9 s]
INFO:root:Epoch 27    loss=0.2127 [21.2 s]    dev=(HR@5:0.4399,NDCG@5:0.3199) [0.9 s] *
INFO:root:Epoch 28    loss=0.2129 [21.5 s]    dev=(HR@5:0.4384,NDCG@5:0.3215) [0.9 s] *
INFO:root:Epoch 29    loss=0.2103 [21.6 s]    dev=(HR@5:0.4355,NDCG@5:0.3184) [1.0 s]
INFO:root:Epoch 30    loss=0.2093 [21.6 s]    dev=(HR@5:0.4316,NDCG@5:0.3168) [1.0 s]
INFO:root:Epoch 31    loss=0.2092 [21.7 s]    dev=(HR@5:0.4363,NDCG@5:0.3207) [0.9 s]
INFO:root:Epoch 32    loss=0.2093 [21.3 s]    dev=(HR@5:0.4347,NDCG@5:0.3178) [0.9 s]
INFO:root:Epoch 33    loss=0.2088 [21.0 s]    dev=(HR@5:0.4347,NDCG@5:0.3199) [0.9 s]
INFO:root:Epoch 34    loss=0.2077 [21.4 s]    dev=(HR@5:0.4385,NDCG@5:0.3214) [0.9 s]
INFO:root:Epoch 35    loss=0.2085 [21.6 s]    dev=(HR@5:0.4338,NDCG@5:0.3155) [0.9 s]
INFO:root:Epoch 36    loss=0.2065 [21.4 s]    dev=(HR@5:0.4371,NDCG@5:0.3182) [0.9 s]
INFO:root:Epoch 37    loss=0.2070 [21.8 s]    dev=(HR@5:0.4385,NDCG@5:0.3201) [0.9 s]
INFO:root:Epoch 38    loss=0.2063 [21.5 s]    dev=(HR@5:0.4377,NDCG@5:0.3186) [1.0 s]
INFO:root:Epoch 39    loss=0.2061 [21.4 s]    dev=(HR@5:0.4301,NDCG@5:0.3137) [0.9 s]
INFO:root:Epoch 40    loss=0.2053 [21.0 s]    dev=(HR@5:0.4337,NDCG@5:0.3171) [1.0 s]
INFO:root:Epoch 41    loss=0.2062 [21.4 s]    dev=(HR@5:0.4325,NDCG@5:0.3156) [1.0 s]
INFO:root:Epoch 42    loss=0.2052 [21.4 s]    dev=(HR@5:0.4356,NDCG@5:0.3178) [1.0 s]
INFO:root:Epoch 43    loss=0.2034 [21.6 s]    dev=(HR@5:0.4398,NDCG@5:0.3218) [1.0 s] *
INFO:root:Epoch 44    loss=0.2048 [21.5 s]    dev=(HR@5:0.4344,NDCG@5:0.3175) [1.0 s]
INFO:root:Epoch 45    loss=0.2012 [21.7 s]    dev=(HR@5:0.4373,NDCG@5:0.3201) [0.9 s]
INFO:root:Epoch 46    loss=0.2028 [21.6 s]    dev=(HR@5:0.4321,NDCG@5:0.3157) [1.0 s]
INFO:root:Epoch 47    loss=0.2029 [21.3 s]    dev=(HR@5:0.4363,NDCG@5:0.3170) [1.0 s]
INFO:root:Epoch 48    loss=0.2026 [21.6 s]    dev=(HR@5:0.4324,NDCG@5:0.3143) [1.0 s]
INFO:root:Epoch 49    loss=0.2011 [21.4 s]    dev=(HR@5:0.4396,NDCG@5:0.3203) [1.0 s]
INFO:root:Epoch 50    loss=0.2024 [21.3 s]    dev=(HR@5:0.4340,NDCG@5:0.3171) [0.9 s]
INFO:root:Epoch 51    loss=0.2013 [21.3 s]    dev=(HR@5:0.4400,NDCG@5:0.3204) [1.0 s]
INFO:root:Epoch 52    loss=0.2020 [22.6 s]    dev=(HR@5:0.4361,NDCG@5:0.3187) [1.0 s]
INFO:root:Epoch 53    loss=0.2017 [21.4 s]    dev=(HR@5:0.4356,NDCG@5:0.3178) [0.9 s]
INFO:root:Epoch 54    loss=0.2004 [21.3 s]    dev=(HR@5:0.4342,NDCG@5:0.3151) [1.0 s]
INFO:root:Epoch 55    loss=0.1990 [21.0 s]    dev=(HR@5:0.4338,NDCG@5:0.3163) [0.9 s]
INFO:root:Epoch 56    loss=0.1997 [21.2 s]    dev=(HR@5:0.4372,NDCG@5:0.3209) [0.9 s]
INFO:root:Epoch 57    loss=0.2012 [21.2 s]    dev=(HR@5:0.4357,NDCG@5:0.3188) [1.0 s]
INFO:root:Epoch 58    loss=0.2008 [21.5 s]    dev=(HR@5:0.4351,NDCG@5:0.3196) [1.0 s]
INFO:root:Epoch 59    loss=0.2002 [21.6 s]    dev=(HR@5:0.4356,NDCG@5:0.3187) [1.0 s]
INFO:root:Epoch 60    loss=0.2000 [21.2 s]    dev=(HR@5:0.4364,NDCG@5:0.3186) [1.0 s]
INFO:root:Epoch 61    loss=0.2003 [20.9 s]    dev=(HR@5:0.4374,NDCG@5:0.3211) [0.9 s]
INFO:root:Epoch 62    loss=0.2000 [21.2 s]    dev=(HR@5:0.4404,NDCG@5:0.3224) [0.9 s] *
INFO:root:Epoch 63    loss=0.2008 [21.3 s]    dev=(HR@5:0.4395,NDCG@5:0.3218) [0.9 s]
INFO:root:Epoch 64    loss=0.1992 [21.2 s]    dev=(HR@5:0.4368,NDCG@5:0.3171) [0.9 s]
INFO:root:Epoch 65    loss=0.2000 [21.1 s]    dev=(HR@5:0.4371,NDCG@5:0.3192) [1.0 s]
INFO:root:Epoch 66    loss=0.1981 [21.4 s]    dev=(HR@5:0.4392,NDCG@5:0.3188) [0.9 s]
INFO:root:Epoch 67    loss=0.1991 [21.4 s]    dev=(HR@5:0.4363,NDCG@5:0.3178) [1.0 s]
INFO:root:Epoch 68    loss=0.1976 [21.8 s]    dev=(HR@5:0.4376,NDCG@5:0.3202) [1.0 s]
INFO:root:Epoch 69    loss=0.1996 [21.8 s]    dev=(HR@5:0.4416,NDCG@5:0.3218) [1.0 s]
INFO:root:Epoch 70    loss=0.1985 [23.3 s]    dev=(HR@5:0.4382,NDCG@5:0.3201) [1.0 s]
INFO:root:Epoch 71    loss=0.1983 [22.6 s]    dev=(HR@5:0.4393,NDCG@5:0.3211) [1.0 s]
INFO:root:Epoch 72    loss=0.1976 [21.7 s]    dev=(HR@5:0.4368,NDCG@5:0.3195) [1.0 s]
INFO:root:Epoch 73    loss=0.1984 [22.0 s]    dev=(HR@5:0.4375,NDCG@5:0.3197) [1.0 s]
INFO:root:Epoch 74    loss=0.1991 [75.9 s]    dev=(HR@5:0.4414,NDCG@5:0.3214) [1.0 s]
INFO:root:Epoch 75    loss=0.1995 [21.8 s]    dev=(HR@5:0.4392,NDCG@5:0.3199) [1.0 s]
INFO:root:Epoch 76    loss=0.1992 [22.3 s]    dev=(HR@5:0.4353,NDCG@5:0.3173) [1.0 s]
INFO:root:Epoch 77    loss=0.1971 [21.9 s]    dev=(HR@5:0.4408,NDCG@5:0.3203) [1.0 s]
INFO:root:Epoch 78    loss=0.1980 [21.7 s]    dev=(HR@5:0.4421,NDCG@5:0.3200) [1.0 s]
INFO:root:Epoch 79    loss=0.1984 [21.9 s]    dev=(HR@5:0.4391,NDCG@5:0.3200) [1.0 s]
INFO:root:Epoch 80    loss=0.1966 [21.8 s]    dev=(HR@5:0.4395,NDCG@5:0.3191) [1.0 s]
INFO:root:Epoch 81    loss=0.1974 [21.4 s]    dev=(HR@5:0.4373,NDCG@5:0.3164) [0.9 s]
INFO:root:Epoch 82    loss=0.1989 [21.6 s]    dev=(HR@5:0.4400,NDCG@5:0.3196) [1.0 s]
INFO:root:Early stop at 82 based on dev result.
INFO:root:
Best Iter(dev)=   62	 dev=(HR@5:0.4404,NDCG@5:0.3224) [1904.1 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.3915,NDCG@5:0.2758,HR@10:0.5028,NDCG@10:0.3119,HR@20:0.6259,NDCG@20:0.3429,HR@50:0.8332,NDCG@50:0.3840)
INFO:root:
--------------------------------------------- END: 2024-12-06 12:17:41 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 12:58:50 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5163 [27.1 s]    dev=(HR@5:0.2515,NDCG@5:0.1680) [1.0 s] *
INFO:root:Epoch 2     loss=0.4294 [21.4 s]    dev=(HR@5:0.3255,NDCG@5:0.2210) [1.0 s] *
INFO:root:Epoch 3     loss=0.3920 [21.4 s]    dev=(HR@5:0.3520,NDCG@5:0.2391) [1.0 s] *
INFO:root:Epoch 4     loss=0.3671 [21.4 s]    dev=(HR@5:0.3775,NDCG@5:0.2624) [0.9 s] *
INFO:root:Epoch 5     loss=0.3398 [21.3 s]    dev=(HR@5:0.3966,NDCG@5:0.2799) [1.0 s] *
INFO:root:Epoch 6     loss=0.3134 [21.5 s]    dev=(HR@5:0.4167,NDCG@5:0.2981) [0.9 s] *
INFO:root:Epoch 7     loss=0.2943 [21.4 s]    dev=(HR@5:0.4218,NDCG@5:0.3004) [1.0 s] *
INFO:root:Epoch 8     loss=0.2792 [21.4 s]    dev=(HR@5:0.4257,NDCG@5:0.3069) [1.0 s] *
INFO:root:Epoch 9     loss=0.2660 [21.4 s]    dev=(HR@5:0.4274,NDCG@5:0.3100) [1.0 s] *
INFO:root:Epoch 10    loss=0.2576 [21.5 s]    dev=(HR@5:0.4268,NDCG@5:0.3103) [0.9 s] *
INFO:root:Epoch 11    loss=0.2493 [21.3 s]    dev=(HR@5:0.4338,NDCG@5:0.3141) [0.9 s] *
INFO:root:Epoch 12    loss=0.2418 [21.4 s]    dev=(HR@5:0.4326,NDCG@5:0.3143) [0.9 s] *
INFO:root:Epoch 13    loss=0.2386 [21.3 s]    dev=(HR@5:0.4377,NDCG@5:0.3187) [0.9 s] *
INFO:root:Epoch 14    loss=0.2347 [21.4 s]    dev=(HR@5:0.4383,NDCG@5:0.3172) [1.0 s]
INFO:root:Epoch 15    loss=0.2313 [21.3 s]    dev=(HR@5:0.4360,NDCG@5:0.3149) [0.9 s]
INFO:root:Epoch 16    loss=0.2298 [21.2 s]    dev=(HR@5:0.4376,NDCG@5:0.3173) [1.0 s]
INFO:root:Epoch 17    loss=0.2262 [21.3 s]    dev=(HR@5:0.4353,NDCG@5:0.3146) [0.9 s]
INFO:root:Epoch 18    loss=0.2226 [21.4 s]    dev=(HR@5:0.4408,NDCG@5:0.3203) [1.0 s] *
INFO:root:Epoch 19    loss=0.2211 [21.4 s]    dev=(HR@5:0.4431,NDCG@5:0.3226) [1.0 s] *
INFO:root:Epoch 20    loss=0.2181 [21.4 s]    dev=(HR@5:0.4424,NDCG@5:0.3231) [1.0 s] *
INFO:root:Epoch 21    loss=0.2149 [21.4 s]    dev=(HR@5:0.4398,NDCG@5:0.3211) [1.0 s]
INFO:root:Epoch 22    loss=0.2146 [21.3 s]    dev=(HR@5:0.4395,NDCG@5:0.3210) [1.0 s]
INFO:root:Epoch 23    loss=0.2154 [21.4 s]    dev=(HR@5:0.4414,NDCG@5:0.3220) [0.9 s]
INFO:root:Epoch 24    loss=0.2148 [21.3 s]    dev=(HR@5:0.4445,NDCG@5:0.3224) [0.9 s]
INFO:root:Epoch 25    loss=0.2110 [21.4 s]    dev=(HR@5:0.4399,NDCG@5:0.3207) [0.9 s]
INFO:root:Epoch 26    loss=0.2113 [21.4 s]    dev=(HR@5:0.4423,NDCG@5:0.3219) [1.0 s]
INFO:root:Epoch 27    loss=0.2113 [21.3 s]    dev=(HR@5:0.4419,NDCG@5:0.3242) [1.0 s] *
INFO:root:Epoch 28    loss=0.2112 [21.5 s]    dev=(HR@5:0.4479,NDCG@5:0.3278) [1.0 s] *
INFO:root:Epoch 29    loss=0.2092 [21.4 s]    dev=(HR@5:0.4430,NDCG@5:0.3233) [0.9 s]
INFO:root:Epoch 30    loss=0.2074 [21.3 s]    dev=(HR@5:0.4410,NDCG@5:0.3220) [0.9 s]
INFO:root:Epoch 31    loss=0.2074 [21.5 s]    dev=(HR@5:0.4455,NDCG@5:0.3268) [1.0 s]
INFO:root:Epoch 32    loss=0.2075 [21.7 s]    dev=(HR@5:0.4463,NDCG@5:0.3251) [1.0 s]
INFO:root:Epoch 33    loss=0.2076 [21.8 s]    dev=(HR@5:0.4479,NDCG@5:0.3276) [1.0 s]
INFO:root:Epoch 34    loss=0.2063 [21.4 s]    dev=(HR@5:0.4474,NDCG@5:0.3256) [0.9 s]
INFO:root:Epoch 35    loss=0.2075 [21.4 s]    dev=(HR@5:0.4413,NDCG@5:0.3231) [1.0 s]
INFO:root:Epoch 36    loss=0.2049 [21.4 s]    dev=(HR@5:0.4430,NDCG@5:0.3224) [0.9 s]
INFO:root:Epoch 37    loss=0.2057 [21.4 s]    dev=(HR@5:0.4455,NDCG@5:0.3232) [1.0 s]
INFO:root:Epoch 38    loss=0.2047 [21.3 s]    dev=(HR@5:0.4453,NDCG@5:0.3246) [0.9 s]
INFO:root:Epoch 39    loss=0.2057 [21.4 s]    dev=(HR@5:0.4381,NDCG@5:0.3180) [1.0 s]
INFO:root:Epoch 40    loss=0.2048 [21.5 s]    dev=(HR@5:0.4404,NDCG@5:0.3209) [0.9 s]
INFO:root:Epoch 41    loss=0.2049 [21.5 s]    dev=(HR@5:0.4407,NDCG@5:0.3213) [1.0 s]
INFO:root:Epoch 42    loss=0.2045 [21.6 s]    dev=(HR@5:0.4436,NDCG@5:0.3237) [0.9 s]
INFO:root:Epoch 43    loss=0.2025 [21.6 s]    dev=(HR@5:0.4474,NDCG@5:0.3270) [0.9 s]
INFO:root:Epoch 44    loss=0.2040 [21.1 s]    dev=(HR@5:0.4429,NDCG@5:0.3225) [1.0 s]
INFO:root:Epoch 45    loss=0.2010 [21.1 s]    dev=(HR@5:0.4450,NDCG@5:0.3272) [1.0 s]
INFO:root:Epoch 46    loss=0.2023 [21.1 s]    dev=(HR@5:0.4427,NDCG@5:0.3228) [0.9 s]
INFO:root:Epoch 47    loss=0.2021 [21.2 s]    dev=(HR@5:0.4419,NDCG@5:0.3222) [0.9 s]
INFO:root:Epoch 48    loss=0.2020 [21.2 s]    dev=(HR@5:0.4359,NDCG@5:0.3177) [1.0 s]
INFO:root:Early stop at 48 based on dev result.
INFO:root:
Best Iter(dev)=   28	 dev=(HR@5:0.4479,NDCG@5:0.3278) [1077.9 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.3978,NDCG@5:0.2837,HR@10:0.5067,NDCG@10:0.3190,HR@20:0.6302,NDCG@20:0.3501,HR@50:0.8373,NDCG@50:0.3910)
INFO:root:
--------------------------------------------- END: 2024-12-06 13:16:50 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 13:50:37 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5166 [22.8 s]    dev=(HR@5:0.2516,NDCG@5:0.1680) [0.9 s] *
INFO:root:Epoch 2     loss=0.4292 [21.0 s]    dev=(HR@5:0.3267,NDCG@5:0.2220) [0.9 s] *
INFO:root:Epoch 3     loss=0.3905 [21.0 s]    dev=(HR@5:0.3573,NDCG@5:0.2436) [0.9 s] *
INFO:root:Epoch 4     loss=0.3639 [20.9 s]    dev=(HR@5:0.3848,NDCG@5:0.2680) [0.9 s] *
INFO:root:Epoch 5     loss=0.3363 [20.9 s]    dev=(HR@5:0.4032,NDCG@5:0.2847) [0.9 s] *
INFO:root:Epoch 6     loss=0.3109 [20.9 s]    dev=(HR@5:0.4184,NDCG@5:0.3012) [1.0 s] *
INFO:root:Epoch 7     loss=0.2924 [21.0 s]    dev=(HR@5:0.4242,NDCG@5:0.3040) [0.9 s] *
INFO:root:Epoch 8     loss=0.2778 [20.9 s]    dev=(HR@5:0.4309,NDCG@5:0.3123) [0.9 s] *
INFO:root:Epoch 9     loss=0.2644 [20.9 s]    dev=(HR@5:0.4321,NDCG@5:0.3146) [0.9 s] *
INFO:root:Epoch 10    loss=0.2558 [21.0 s]    dev=(HR@5:0.4345,NDCG@5:0.3154) [0.9 s] *
INFO:root:Epoch 11    loss=0.2470 [20.9 s]    dev=(HR@5:0.4359,NDCG@5:0.3167) [0.9 s] *
INFO:root:Epoch 12    loss=0.2396 [20.8 s]    dev=(HR@5:0.4374,NDCG@5:0.3193) [0.9 s] *
INFO:root:Epoch 13    loss=0.2359 [20.9 s]    dev=(HR@5:0.4430,NDCG@5:0.3234) [1.0 s] *
INFO:root:Epoch 14    loss=0.2319 [21.8 s]    dev=(HR@5:0.4428,NDCG@5:0.3223) [1.0 s]
INFO:root:Epoch 15    loss=0.2295 [21.6 s]    dev=(HR@5:0.4385,NDCG@5:0.3196) [0.9 s]
INFO:root:Epoch 16    loss=0.2276 [21.4 s]    dev=(HR@5:0.4404,NDCG@5:0.3204) [1.0 s]
INFO:root:Epoch 17    loss=0.2246 [21.4 s]    dev=(HR@5:0.4388,NDCG@5:0.3191) [1.0 s]
INFO:root:Epoch 18    loss=0.2207 [21.3 s]    dev=(HR@5:0.4424,NDCG@5:0.3235) [1.0 s] *
INFO:root:Epoch 19    loss=0.2196 [21.3 s]    dev=(HR@5:0.4395,NDCG@5:0.3222) [1.0 s]
INFO:root:Epoch 20    loss=0.2164 [21.3 s]    dev=(HR@5:0.4425,NDCG@5:0.3252) [1.0 s] *
INFO:root:Epoch 21    loss=0.2126 [21.2 s]    dev=(HR@5:0.4435,NDCG@5:0.3242) [1.0 s]
INFO:root:Epoch 22    loss=0.2124 [21.3 s]    dev=(HR@5:0.4426,NDCG@5:0.3242) [0.9 s]
INFO:root:Epoch 23    loss=0.2132 [21.3 s]    dev=(HR@5:0.4439,NDCG@5:0.3259) [0.9 s] *
INFO:root:Epoch 24    loss=0.2130 [21.3 s]    dev=(HR@5:0.4432,NDCG@5:0.3225) [0.9 s]
INFO:root:Epoch 25    loss=0.2097 [21.4 s]    dev=(HR@5:0.4423,NDCG@5:0.3233) [0.9 s]
INFO:root:Epoch 26    loss=0.2097 [21.3 s]    dev=(HR@5:0.4444,NDCG@5:0.3246) [0.9 s]
INFO:root:Epoch 27    loss=0.2101 [21.3 s]    dev=(HR@5:0.4415,NDCG@5:0.3235) [1.0 s]
INFO:root:Epoch 28    loss=0.2096 [21.3 s]    dev=(HR@5:0.4439,NDCG@5:0.3270) [1.0 s] *
INFO:root:Epoch 29    loss=0.2084 [21.4 s]    dev=(HR@5:0.4413,NDCG@5:0.3251) [1.0 s]
INFO:root:Epoch 30    loss=0.2073 [21.3 s]    dev=(HR@5:0.4402,NDCG@5:0.3233) [1.0 s]
INFO:root:Epoch 31    loss=0.2064 [21.4 s]    dev=(HR@5:0.4414,NDCG@5:0.3257) [0.9 s]
INFO:root:Epoch 32    loss=0.2066 [21.2 s]    dev=(HR@5:0.4397,NDCG@5:0.3219) [1.0 s]
INFO:root:Epoch 33    loss=0.2069 [21.4 s]    dev=(HR@5:0.4432,NDCG@5:0.3262) [0.9 s]
INFO:root:Epoch 34    loss=0.2059 [21.3 s]    dev=(HR@5:0.4440,NDCG@5:0.3263) [1.0 s]
INFO:root:Epoch 35    loss=0.2066 [21.4 s]    dev=(HR@5:0.4415,NDCG@5:0.3246) [1.0 s]
INFO:root:Epoch 36    loss=0.2039 [21.3 s]    dev=(HR@5:0.4407,NDCG@5:0.3238) [0.9 s]
INFO:root:Epoch 37    loss=0.2046 [21.3 s]    dev=(HR@5:0.4412,NDCG@5:0.3235) [0.9 s]
INFO:root:Epoch 38    loss=0.2051 [21.2 s]    dev=(HR@5:0.4441,NDCG@5:0.3263) [1.0 s]
INFO:root:Epoch 39    loss=0.2054 [21.2 s]    dev=(HR@5:0.4376,NDCG@5:0.3197) [1.0 s]
INFO:root:Epoch 40    loss=0.2047 [21.3 s]    dev=(HR@5:0.4389,NDCG@5:0.3221) [0.9 s]
INFO:root:Epoch 41    loss=0.2057 [21.3 s]    dev=(HR@5:0.4399,NDCG@5:0.3216) [1.0 s]
INFO:root:Epoch 42    loss=0.2038 [21.4 s]    dev=(HR@5:0.4416,NDCG@5:0.3229) [0.9 s]
INFO:root:Epoch 43    loss=0.2033 [21.3 s]    dev=(HR@5:0.4446,NDCG@5:0.3268) [1.0 s]
INFO:root:Epoch 44    loss=0.2043 [21.3 s]    dev=(HR@5:0.4432,NDCG@5:0.3248) [0.9 s]
INFO:root:Epoch 45    loss=0.2017 [21.3 s]    dev=(HR@5:0.4404,NDCG@5:0.3266) [0.9 s]
INFO:root:Epoch 46    loss=0.2032 [21.3 s]    dev=(HR@5:0.4392,NDCG@5:0.3223) [0.9 s]
INFO:root:Epoch 47    loss=0.2027 [21.3 s]    dev=(HR@5:0.4391,NDCG@5:0.3229) [0.9 s]
INFO:root:Epoch 48    loss=0.2026 [21.4 s]    dev=(HR@5:0.4386,NDCG@5:0.3212) [1.0 s]
INFO:root:Early stop at 48 based on dev result.
INFO:root:
Best Iter(dev)=   28	 dev=(HR@5:0.4439,NDCG@5:0.3270) [1066.5 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.3971,NDCG@5:0.2852,HR@10:0.5081,NDCG@10:0.3212,HR@20:0.6316,NDCG@20:0.3523,HR@50:0.8392,NDCG@50:0.3934)
INFO:root:
--------------------------------------------- END: 2024-12-06 14:08:25 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 14:51:02 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5165 [23.4 s]    dev=(HR@5:0.2566,NDCG@5:0.1715) [1.0 s] *
INFO:root:Epoch 2     loss=0.4265 [21.5 s]    dev=(HR@5:0.3327,NDCG@5:0.2265) [0.9 s] *
INFO:root:Epoch 3     loss=0.3887 [21.5 s]    dev=(HR@5:0.3619,NDCG@5:0.2473) [0.9 s] *
INFO:root:Epoch 4     loss=0.3644 [21.5 s]    dev=(HR@5:0.3848,NDCG@5:0.2671) [0.9 s] *
INFO:root:Epoch 5     loss=0.3393 [21.5 s]    dev=(HR@5:0.4028,NDCG@5:0.2835) [1.0 s] *
INFO:root:Epoch 6     loss=0.3142 [21.5 s]    dev=(HR@5:0.4171,NDCG@5:0.2996) [1.0 s] *
INFO:root:Epoch 7     loss=0.2953 [21.4 s]    dev=(HR@5:0.4225,NDCG@5:0.3026) [0.9 s] *
INFO:root:Epoch 8     loss=0.2811 [21.5 s]    dev=(HR@5:0.4264,NDCG@5:0.3084) [1.0 s] *
INFO:root:Epoch 9     loss=0.2678 [21.5 s]    dev=(HR@5:0.4286,NDCG@5:0.3120) [1.0 s] *
INFO:root:Epoch 10    loss=0.2600 [21.5 s]    dev=(HR@5:0.4329,NDCG@5:0.3126) [0.9 s] *
INFO:root:Epoch 11    loss=0.2516 [21.4 s]    dev=(HR@5:0.4338,NDCG@5:0.3141) [1.0 s] *
INFO:root:Epoch 12    loss=0.2438 [21.5 s]    dev=(HR@5:0.4363,NDCG@5:0.3162) [1.0 s] *
INFO:root:Epoch 13    loss=0.2410 [21.5 s]    dev=(HR@5:0.4404,NDCG@5:0.3206) [0.9 s] *
INFO:root:Epoch 14    loss=0.2356 [21.4 s]    dev=(HR@5:0.4410,NDCG@5:0.3207) [0.9 s] *
INFO:root:Epoch 15    loss=0.2327 [21.4 s]    dev=(HR@5:0.4355,NDCG@5:0.3181) [0.9 s]
INFO:root:Epoch 16    loss=0.2316 [21.3 s]    dev=(HR@5:0.4378,NDCG@5:0.3199) [1.0 s]
INFO:root:Epoch 17    loss=0.2270 [21.5 s]    dev=(HR@5:0.4341,NDCG@5:0.3169) [0.9 s]
INFO:root:Epoch 18    loss=0.2233 [21.4 s]    dev=(HR@5:0.4390,NDCG@5:0.3221) [1.0 s] *
INFO:root:Epoch 19    loss=0.2217 [21.5 s]    dev=(HR@5:0.4388,NDCG@5:0.3205) [1.0 s]
INFO:root:Epoch 20    loss=0.2186 [21.5 s]    dev=(HR@5:0.4397,NDCG@5:0.3227) [1.0 s] *
INFO:root:Epoch 21    loss=0.2148 [21.4 s]    dev=(HR@5:0.4415,NDCG@5:0.3232) [1.0 s] *
INFO:root:Epoch 22    loss=0.2152 [21.3 s]    dev=(HR@5:0.4400,NDCG@5:0.3244) [1.0 s] *
INFO:root:Epoch 23    loss=0.2151 [21.4 s]    dev=(HR@5:0.4374,NDCG@5:0.3217) [0.9 s]
INFO:root:Epoch 24    loss=0.2139 [21.4 s]    dev=(HR@5:0.4408,NDCG@5:0.3223) [1.0 s]
INFO:root:Epoch 25    loss=0.2108 [21.5 s]    dev=(HR@5:0.4374,NDCG@5:0.3209) [0.9 s]
INFO:root:Epoch 26    loss=0.2111 [21.4 s]    dev=(HR@5:0.4405,NDCG@5:0.3238) [0.9 s]
INFO:root:Epoch 27    loss=0.2113 [21.5 s]    dev=(HR@5:0.4418,NDCG@5:0.3238) [1.0 s]
INFO:root:Epoch 28    loss=0.2108 [21.4 s]    dev=(HR@5:0.4427,NDCG@5:0.3263) [1.0 s] *
INFO:root:Epoch 29    loss=0.2088 [21.5 s]    dev=(HR@5:0.4410,NDCG@5:0.3254) [1.0 s]
INFO:root:Epoch 30    loss=0.2075 [21.5 s]    dev=(HR@5:0.4427,NDCG@5:0.3242) [0.9 s]
INFO:root:Epoch 31    loss=0.2068 [21.6 s]    dev=(HR@5:0.4449,NDCG@5:0.3278) [0.9 s] *
INFO:root:Epoch 32    loss=0.2071 [21.8 s]    dev=(HR@5:0.4427,NDCG@5:0.3252) [0.9 s]
INFO:root:Epoch 33    loss=0.2067 [21.6 s]    dev=(HR@5:0.4420,NDCG@5:0.3249) [1.0 s]
INFO:root:Epoch 34    loss=0.2058 [21.6 s]    dev=(HR@5:0.4442,NDCG@5:0.3282) [1.0 s] *
INFO:root:Epoch 35    loss=0.2066 [21.5 s]    dev=(HR@5:0.4373,NDCG@5:0.3207) [0.9 s]
INFO:root:Epoch 36    loss=0.2041 [21.5 s]    dev=(HR@5:0.4402,NDCG@5:0.3236) [0.9 s]
INFO:root:Epoch 37    loss=0.2048 [21.5 s]    dev=(HR@5:0.4388,NDCG@5:0.3221) [1.0 s]
INFO:root:Epoch 38    loss=0.2055 [21.5 s]    dev=(HR@5:0.4418,NDCG@5:0.3255) [0.9 s]
INFO:root:Epoch 39    loss=0.2051 [21.5 s]    dev=(HR@5:0.4374,NDCG@5:0.3205) [0.9 s]
INFO:root:Epoch 40    loss=0.2041 [21.5 s]    dev=(HR@5:0.4387,NDCG@5:0.3228) [1.0 s]
INFO:root:Epoch 41    loss=0.2042 [21.6 s]    dev=(HR@5:0.4400,NDCG@5:0.3228) [1.0 s]
INFO:root:Epoch 42    loss=0.2033 [21.6 s]    dev=(HR@5:0.4442,NDCG@5:0.3242) [1.0 s]
INFO:root:Epoch 43    loss=0.2023 [21.5 s]    dev=(HR@5:0.4466,NDCG@5:0.3275) [0.9 s]
INFO:root:Epoch 44    loss=0.2032 [21.4 s]    dev=(HR@5:0.4390,NDCG@5:0.3205) [1.0 s]
INFO:root:Epoch 45    loss=0.2005 [21.5 s]    dev=(HR@5:0.4432,NDCG@5:0.3259) [0.9 s]
INFO:root:Epoch 46    loss=0.2024 [21.5 s]    dev=(HR@5:0.4419,NDCG@5:0.3244) [1.0 s]
INFO:root:Epoch 47    loss=0.2020 [21.5 s]    dev=(HR@5:0.4435,NDCG@5:0.3259) [1.0 s]
INFO:root:Epoch 48    loss=0.2017 [21.5 s]    dev=(HR@5:0.4391,NDCG@5:0.3212) [0.9 s]
INFO:root:Epoch 49    loss=0.2009 [21.5 s]    dev=(HR@5:0.4462,NDCG@5:0.3283) [1.0 s] *
INFO:root:Epoch 50    loss=0.2018 [21.6 s]    dev=(HR@5:0.4434,NDCG@5:0.3244) [1.0 s]
INFO:root:Epoch 51    loss=0.2006 [21.6 s]    dev=(HR@5:0.4469,NDCG@5:0.3280) [0.9 s]
INFO:root:Epoch 52    loss=0.2004 [21.6 s]    dev=(HR@5:0.4428,NDCG@5:0.3251) [1.0 s]
INFO:root:Epoch 53    loss=0.2005 [21.6 s]    dev=(HR@5:0.4424,NDCG@5:0.3246) [1.0 s]
INFO:root:Epoch 54    loss=0.1982 [21.7 s]    dev=(HR@5:0.4447,NDCG@5:0.3248) [1.0 s]
INFO:root:Epoch 55    loss=0.1978 [21.6 s]    dev=(HR@5:0.4430,NDCG@5:0.3239) [0.9 s]
INFO:root:Epoch 56    loss=0.1986 [21.5 s]    dev=(HR@5:0.4472,NDCG@5:0.3271) [1.0 s]
INFO:root:Epoch 57    loss=0.1978 [21.5 s]    dev=(HR@5:0.4436,NDCG@5:0.3269) [1.0 s]
INFO:root:Epoch 58    loss=0.1995 [21.6 s]    dev=(HR@5:0.4455,NDCG@5:0.3290) [1.0 s] *
INFO:root:Epoch 59    loss=0.1982 [21.6 s]    dev=(HR@5:0.4410,NDCG@5:0.3257) [1.0 s]
INFO:root:Epoch 60    loss=0.1984 [21.5 s]    dev=(HR@5:0.4430,NDCG@5:0.3271) [1.0 s]
INFO:root:Epoch 61    loss=0.1981 [21.6 s]    dev=(HR@5:0.4440,NDCG@5:0.3251) [1.0 s]
INFO:root:Epoch 62    loss=0.1977 [21.5 s]    dev=(HR@5:0.4463,NDCG@5:0.3254) [1.0 s]
INFO:root:Epoch 63    loss=0.1985 [21.4 s]    dev=(HR@5:0.4467,NDCG@5:0.3266) [1.0 s]
INFO:root:Epoch 64    loss=0.1967 [21.5 s]    dev=(HR@5:0.4423,NDCG@5:0.3241) [0.9 s]
INFO:root:Epoch 65    loss=0.1976 [21.5 s]    dev=(HR@5:0.4428,NDCG@5:0.3241) [0.9 s]
INFO:root:Epoch 66    loss=0.1961 [21.5 s]    dev=(HR@5:0.4449,NDCG@5:0.3250) [0.9 s]
INFO:root:Epoch 67    loss=0.1969 [21.5 s]    dev=(HR@5:0.4440,NDCG@5:0.3246) [1.0 s]
INFO:root:Epoch 68    loss=0.1955 [21.5 s]    dev=(HR@5:0.4483,NDCG@5:0.3276) [0.9 s]
INFO:root:Epoch 69    loss=0.1971 [21.5 s]    dev=(HR@5:0.4474,NDCG@5:0.3267) [0.9 s]
INFO:root:Epoch 70    loss=0.1957 [21.5 s]    dev=(HR@5:0.4460,NDCG@5:0.3276) [1.0 s]
INFO:root:Epoch 71    loss=0.1955 [21.4 s]    dev=(HR@5:0.4453,NDCG@5:0.3269) [0.9 s]
INFO:root:Epoch 72    loss=0.1957 [21.5 s]    dev=(HR@5:0.4459,NDCG@5:0.3265) [0.9 s]
INFO:root:Epoch 73    loss=0.1956 [21.5 s]    dev=(HR@5:0.4473,NDCG@5:0.3269) [0.9 s]
INFO:root:Epoch 74    loss=0.1956 [21.4 s]    dev=(HR@5:0.4453,NDCG@5:0.3252) [1.0 s]
INFO:root:Epoch 75    loss=0.1974 [21.8 s]    dev=(HR@5:0.4430,NDCG@5:0.3243) [1.0 s]
INFO:root:Epoch 76    loss=0.1966 [21.5 s]    dev=(HR@5:0.4458,NDCG@5:0.3273) [0.9 s]
INFO:root:Epoch 77    loss=0.1950 [21.4 s]    dev=(HR@5:0.4445,NDCG@5:0.3241) [0.9 s]
INFO:root:Epoch 78    loss=0.1950 [21.5 s]    dev=(HR@5:0.4478,NDCG@5:0.3257) [0.9 s]
INFO:root:Early stop at 78 based on dev result.
INFO:root:
Best Iter(dev)=   58	 dev=(HR@5:0.4455,NDCG@5:0.3290) [1754.0 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.4025,NDCG@5:0.2865,HR@10:0.5127,NDCG@10:0.3222,HR@20:0.6311,NDCG@20:0.3519,HR@50:0.8364,NDCG@50:0.3926)
INFO:root:
--------------------------------------------- END: 2024-12-06 15:20:18 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 16:05:20 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5152 [23.3 s]    dev=(HR@5:0.2521,NDCG@5:0.1681) [1.0 s] *
INFO:root:Epoch 2     loss=0.4313 [21.5 s]    dev=(HR@5:0.3191,NDCG@5:0.2154) [0.9 s] *
INFO:root:Epoch 3     loss=0.3973 [21.4 s]    dev=(HR@5:0.3422,NDCG@5:0.2291) [0.9 s] *
INFO:root:Epoch 4     loss=0.3769 [21.4 s]    dev=(HR@5:0.3584,NDCG@5:0.2445) [0.9 s] *
INFO:root:Epoch 5     loss=0.3545 [21.3 s]    dev=(HR@5:0.3755,NDCG@5:0.2621) [1.0 s] *
INFO:root:Epoch 6     loss=0.3313 [21.4 s]    dev=(HR@5:0.3924,NDCG@5:0.2789) [0.9 s] *
INFO:root:Epoch 7     loss=0.3108 [21.4 s]    dev=(HR@5:0.4013,NDCG@5:0.2859) [0.9 s] *
INFO:root:Epoch 8     loss=0.2943 [21.4 s]    dev=(HR@5:0.4071,NDCG@5:0.2916) [1.0 s] *
INFO:root:Epoch 9     loss=0.2779 [21.4 s]    dev=(HR@5:0.4068,NDCG@5:0.2929) [1.0 s] *
INFO:root:Epoch 10    loss=0.2670 [21.5 s]    dev=(HR@5:0.4113,NDCG@5:0.2974) [1.0 s] *
INFO:root:Epoch 11    loss=0.2575 [21.9 s]    dev=(HR@5:0.4178,NDCG@5:0.3012) [1.0 s] *
INFO:root:Epoch 12    loss=0.2478 [22.1 s]    dev=(HR@5:0.4231,NDCG@5:0.3062) [1.0 s] *
INFO:root:Epoch 13    loss=0.2447 [22.0 s]    dev=(HR@5:0.4261,NDCG@5:0.3089) [1.0 s] *
INFO:root:Epoch 14    loss=0.2395 [21.5 s]    dev=(HR@5:0.4229,NDCG@5:0.3051) [1.0 s]
INFO:root:Epoch 15    loss=0.2363 [21.4 s]    dev=(HR@5:0.4204,NDCG@5:0.3046) [1.0 s]
INFO:root:Epoch 16    loss=0.2326 [21.3 s]    dev=(HR@5:0.4245,NDCG@5:0.3092) [0.9 s] *
INFO:root:Epoch 17    loss=0.2294 [21.4 s]    dev=(HR@5:0.4250,NDCG@5:0.3080) [1.0 s]
INFO:root:Epoch 18    loss=0.2244 [21.4 s]    dev=(HR@5:0.4224,NDCG@5:0.3068) [0.9 s]
INFO:root:Epoch 19    loss=0.2222 [21.4 s]    dev=(HR@5:0.4290,NDCG@5:0.3136) [1.0 s] *
INFO:root:Epoch 20    loss=0.2201 [21.4 s]    dev=(HR@5:0.4293,NDCG@5:0.3134) [0.9 s]
INFO:root:Epoch 21    loss=0.2162 [21.4 s]    dev=(HR@5:0.4356,NDCG@5:0.3175) [0.9 s] *
INFO:root:Epoch 22    loss=0.2151 [21.3 s]    dev=(HR@5:0.4336,NDCG@5:0.3172) [0.9 s]
INFO:root:Epoch 23    loss=0.2156 [21.3 s]    dev=(HR@5:0.4255,NDCG@5:0.3118) [1.0 s]
INFO:root:Epoch 24    loss=0.2143 [21.4 s]    dev=(HR@5:0.4382,NDCG@5:0.3191) [1.0 s] *
INFO:root:Epoch 25    loss=0.2110 [21.4 s]    dev=(HR@5:0.4300,NDCG@5:0.3168) [1.0 s]
INFO:root:Epoch 26    loss=0.2115 [21.4 s]    dev=(HR@5:0.4349,NDCG@5:0.3192) [0.9 s] *
INFO:root:Epoch 27    loss=0.2097 [21.4 s]    dev=(HR@5:0.4353,NDCG@5:0.3196) [1.0 s] *
INFO:root:Epoch 28    loss=0.2100 [21.3 s]    dev=(HR@5:0.4364,NDCG@5:0.3210) [0.9 s] *
INFO:root:Epoch 29    loss=0.2077 [21.4 s]    dev=(HR@5:0.4344,NDCG@5:0.3179) [0.9 s]
INFO:root:Epoch 30    loss=0.2076 [21.5 s]    dev=(HR@5:0.4340,NDCG@5:0.3200) [0.9 s]
INFO:root:Epoch 31    loss=0.2062 [21.4 s]    dev=(HR@5:0.4384,NDCG@5:0.3235) [0.9 s] *
INFO:root:Epoch 32    loss=0.2068 [21.4 s]    dev=(HR@5:0.4348,NDCG@5:0.3201) [1.0 s]
INFO:root:Epoch 33    loss=0.2061 [21.5 s]    dev=(HR@5:0.4395,NDCG@5:0.3230) [0.9 s]
INFO:root:Epoch 34    loss=0.2053 [21.3 s]    dev=(HR@5:0.4359,NDCG@5:0.3213) [1.0 s]
INFO:root:Epoch 35    loss=0.2056 [21.3 s]    dev=(HR@5:0.4333,NDCG@5:0.3173) [0.9 s]
INFO:root:Epoch 36    loss=0.2027 [21.4 s]    dev=(HR@5:0.4349,NDCG@5:0.3179) [1.0 s]
INFO:root:Epoch 37    loss=0.2035 [19.7 s]    dev=(HR@5:0.4382,NDCG@5:0.3212) [0.9 s]
INFO:root:Epoch 38    loss=0.2028 [21.5 s]    dev=(HR@5:0.4396,NDCG@5:0.3205) [1.0 s]
INFO:root:Epoch 39    loss=0.2045 [21.4 s]    dev=(HR@5:0.4319,NDCG@5:0.3149) [0.9 s]
INFO:root:Epoch 40    loss=0.2027 [21.6 s]    dev=(HR@5:0.4343,NDCG@5:0.3191) [1.0 s]
INFO:root:Epoch 41    loss=0.2039 [21.4 s]    dev=(HR@5:0.4342,NDCG@5:0.3172) [0.9 s]
INFO:root:Epoch 42    loss=0.2040 [21.5 s]    dev=(HR@5:0.4402,NDCG@5:0.3206) [1.0 s]
INFO:root:Epoch 43    loss=0.2019 [21.4 s]    dev=(HR@5:0.4396,NDCG@5:0.3230) [0.9 s]
INFO:root:Epoch 44    loss=0.2034 [21.3 s]    dev=(HR@5:0.4361,NDCG@5:0.3198) [0.9 s]
INFO:root:Epoch 45    loss=0.2004 [21.4 s]    dev=(HR@5:0.4385,NDCG@5:0.3228) [1.0 s]
INFO:root:Epoch 46    loss=0.2011 [21.4 s]    dev=(HR@5:0.4319,NDCG@5:0.3175) [0.9 s]
INFO:root:Epoch 47    loss=0.2018 [21.3 s]    dev=(HR@5:0.4385,NDCG@5:0.3217) [0.9 s]
INFO:root:Epoch 48    loss=0.2015 [21.3 s]    dev=(HR@5:0.4363,NDCG@5:0.3208) [1.0 s]
INFO:root:Epoch 49    loss=0.1995 [21.3 s]    dev=(HR@5:0.4408,NDCG@5:0.3246) [0.9 s] *
INFO:root:Epoch 50    loss=0.2009 [21.4 s]    dev=(HR@5:0.4369,NDCG@5:0.3212) [1.0 s]
INFO:root:Epoch 51    loss=0.1997 [21.5 s]    dev=(HR@5:0.4387,NDCG@5:0.3205) [0.9 s]
INFO:root:Epoch 52    loss=0.2001 [21.4 s]    dev=(HR@5:0.4395,NDCG@5:0.3208) [1.0 s]
INFO:root:Epoch 53    loss=0.1999 [21.3 s]    dev=(HR@5:0.4365,NDCG@5:0.3201) [0.9 s]
INFO:root:Epoch 54    loss=0.1980 [21.3 s]    dev=(HR@5:0.4357,NDCG@5:0.3197) [1.0 s]
INFO:root:Epoch 55    loss=0.1984 [21.4 s]    dev=(HR@5:0.4402,NDCG@5:0.3226) [0.9 s]
INFO:root:Epoch 56    loss=0.1981 [21.3 s]    dev=(HR@5:0.4399,NDCG@5:0.3235) [0.9 s]
INFO:root:Epoch 57    loss=0.1989 [21.4 s]    dev=(HR@5:0.4386,NDCG@5:0.3211) [1.0 s]
INFO:root:Epoch 58    loss=0.1996 [21.4 s]    dev=(HR@5:0.4450,NDCG@5:0.3273) [0.9 s] *
INFO:root:Epoch 59    loss=0.1989 [21.5 s]    dev=(HR@5:0.4389,NDCG@5:0.3211) [0.9 s]
INFO:root:Epoch 60    loss=0.1991 [21.4 s]    dev=(HR@5:0.4385,NDCG@5:0.3229) [0.9 s]
INFO:root:Epoch 61    loss=0.1983 [21.4 s]    dev=(HR@5:0.4428,NDCG@5:0.3265) [1.0 s]
INFO:root:Epoch 62    loss=0.1977 [21.3 s]    dev=(HR@5:0.4456,NDCG@5:0.3271) [0.9 s]
INFO:root:Epoch 63    loss=0.2002 [21.4 s]    dev=(HR@5:0.4436,NDCG@5:0.3243) [1.0 s]
INFO:root:Epoch 64    loss=0.1972 [21.3 s]    dev=(HR@5:0.4404,NDCG@5:0.3235) [0.9 s]
INFO:root:Epoch 65    loss=0.1983 [21.3 s]    dev=(HR@5:0.4398,NDCG@5:0.3233) [1.0 s]
INFO:root:Epoch 66    loss=0.1966 [21.3 s]    dev=(HR@5:0.4406,NDCG@5:0.3216) [0.9 s]
INFO:root:Epoch 67    loss=0.1973 [21.4 s]    dev=(HR@5:0.4417,NDCG@5:0.3227) [0.9 s]
INFO:root:Epoch 68    loss=0.1955 [21.3 s]    dev=(HR@5:0.4431,NDCG@5:0.3247) [0.9 s]
INFO:root:Epoch 69    loss=0.1976 [21.4 s]    dev=(HR@5:0.4419,NDCG@5:0.3239) [0.9 s]
INFO:root:Epoch 70    loss=0.1966 [21.3 s]    dev=(HR@5:0.4371,NDCG@5:0.3210) [1.0 s]
INFO:root:Epoch 71    loss=0.1958 [21.4 s]    dev=(HR@5:0.4396,NDCG@5:0.3251) [0.9 s]
INFO:root:Epoch 72    loss=0.1952 [21.3 s]    dev=(HR@5:0.4440,NDCG@5:0.3267) [0.9 s]
INFO:root:Epoch 73    loss=0.1966 [21.3 s]    dev=(HR@5:0.4418,NDCG@5:0.3224) [0.9 s]
INFO:root:Epoch 74    loss=0.1965 [21.4 s]    dev=(HR@5:0.4370,NDCG@5:0.3183) [1.0 s]
INFO:root:Epoch 75    loss=0.1980 [21.3 s]    dev=(HR@5:0.4398,NDCG@5:0.3225) [0.9 s]
INFO:root:Epoch 76    loss=0.1971 [21.3 s]    dev=(HR@5:0.4410,NDCG@5:0.3229) [1.0 s]
INFO:root:Epoch 77    loss=0.1958 [21.4 s]    dev=(HR@5:0.4410,NDCG@5:0.3239) [0.9 s]
INFO:root:Epoch 78    loss=0.1956 [21.5 s]    dev=(HR@5:0.4443,NDCG@5:0.3250) [0.9 s]
INFO:root:Early stop at 78 based on dev result.
INFO:root:
Best Iter(dev)=   58	 dev=(HR@5:0.4450,NDCG@5:0.3273) [1744.6 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.3933,NDCG@5:0.2822,HR@10:0.5007,NDCG@10:0.3171,HR@20:0.6250,NDCG@20:0.3485,HR@50:0.8331,NDCG@50:0.3896)
INFO:root:
--------------------------------------------- END: 2024-12-06 16:34:26 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 17:09:34 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5150 [23.6 s]    dev=(HR@5:0.2558,NDCG@5:0.1711) [0.9 s] *
INFO:root:Epoch 2     loss=0.4259 [21.5 s]    dev=(HR@5:0.3299,NDCG@5:0.2239) [1.0 s] *
INFO:root:Epoch 3     loss=0.3887 [21.4 s]    dev=(HR@5:0.3578,NDCG@5:0.2430) [0.9 s] *
INFO:root:Epoch 4     loss=0.3653 [21.5 s]    dev=(HR@5:0.3784,NDCG@5:0.2620) [1.0 s] *
INFO:root:Epoch 5     loss=0.3407 [22.6 s]    dev=(HR@5:0.3973,NDCG@5:0.2809) [1.0 s] *
INFO:root:Epoch 6     loss=0.3160 [21.4 s]    dev=(HR@5:0.4132,NDCG@5:0.2953) [1.0 s] *
INFO:root:Epoch 7     loss=0.2987 [21.4 s]    dev=(HR@5:0.4172,NDCG@5:0.2986) [1.0 s] *
INFO:root:Epoch 8     loss=0.2842 [21.3 s]    dev=(HR@5:0.4265,NDCG@5:0.3084) [1.0 s] *
INFO:root:Epoch 9     loss=0.2708 [21.4 s]    dev=(HR@5:0.4281,NDCG@5:0.3092) [0.9 s] *
INFO:root:Epoch 10    loss=0.2613 [21.4 s]    dev=(HR@5:0.4327,NDCG@5:0.3124) [1.0 s] *
INFO:root:Epoch 11    loss=0.2510 [21.4 s]    dev=(HR@5:0.4382,NDCG@5:0.3164) [1.0 s] *
INFO:root:Epoch 12    loss=0.2436 [21.4 s]    dev=(HR@5:0.4379,NDCG@5:0.3184) [1.0 s] *
INFO:root:Epoch 13    loss=0.2391 [21.4 s]    dev=(HR@5:0.4433,NDCG@5:0.3231) [1.0 s] *
INFO:root:Epoch 14    loss=0.2348 [21.4 s]    dev=(HR@5:0.4419,NDCG@5:0.3224) [0.9 s]
INFO:root:Epoch 15    loss=0.2311 [21.4 s]    dev=(HR@5:0.4418,NDCG@5:0.3221) [0.9 s]
INFO:root:Epoch 16    loss=0.2283 [21.4 s]    dev=(HR@5:0.4427,NDCG@5:0.3225) [0.9 s]
INFO:root:Epoch 17    loss=0.2250 [21.4 s]    dev=(HR@5:0.4406,NDCG@5:0.3205) [0.9 s]
INFO:root:Epoch 18    loss=0.2205 [21.4 s]    dev=(HR@5:0.4421,NDCG@5:0.3230) [1.0 s]
INFO:root:Epoch 19    loss=0.2181 [21.3 s]    dev=(HR@5:0.4409,NDCG@5:0.3221) [1.0 s]
INFO:root:Epoch 20    loss=0.2159 [22.0 s]    dev=(HR@5:0.4455,NDCG@5:0.3257) [1.0 s] *
INFO:root:Epoch 21    loss=0.2123 [21.5 s]    dev=(HR@5:0.4471,NDCG@5:0.3250) [0.9 s]
INFO:root:Epoch 22    loss=0.2116 [21.3 s]    dev=(HR@5:0.4462,NDCG@5:0.3262) [1.0 s] *
INFO:root:Epoch 23    loss=0.2117 [21.4 s]    dev=(HR@5:0.4420,NDCG@5:0.3247) [0.9 s]
INFO:root:Epoch 24    loss=0.2122 [21.4 s]    dev=(HR@5:0.4427,NDCG@5:0.3224) [1.0 s]
INFO:root:Epoch 25    loss=0.2073 [21.4 s]    dev=(HR@5:0.4415,NDCG@5:0.3213) [0.9 s]
INFO:root:Epoch 26    loss=0.2081 [21.5 s]    dev=(HR@5:0.4428,NDCG@5:0.3236) [1.0 s]
INFO:root:Epoch 27    loss=0.2073 [21.5 s]    dev=(HR@5:0.4453,NDCG@5:0.3260) [1.0 s]
INFO:root:Epoch 28    loss=0.2071 [21.4 s]    dev=(HR@5:0.4479,NDCG@5:0.3290) [1.0 s] *
INFO:root:Epoch 29    loss=0.2054 [21.5 s]    dev=(HR@5:0.4413,NDCG@5:0.3248) [1.0 s]
INFO:root:Epoch 30    loss=0.2042 [21.4 s]    dev=(HR@5:0.4427,NDCG@5:0.3255) [0.9 s]
INFO:root:Epoch 31    loss=0.2036 [21.4 s]    dev=(HR@5:0.4474,NDCG@5:0.3283) [1.0 s]
INFO:root:Epoch 32    loss=0.2031 [21.4 s]    dev=(HR@5:0.4485,NDCG@5:0.3270) [1.0 s]
INFO:root:Epoch 33    loss=0.2036 [21.3 s]    dev=(HR@5:0.4460,NDCG@5:0.3268) [1.0 s]
INFO:root:Epoch 34    loss=0.2018 [21.5 s]    dev=(HR@5:0.4438,NDCG@5:0.3264) [1.0 s]
INFO:root:Epoch 35    loss=0.2023 [21.6 s]    dev=(HR@5:0.4392,NDCG@5:0.3214) [0.9 s]
INFO:root:Epoch 36    loss=0.2000 [21.4 s]    dev=(HR@5:0.4432,NDCG@5:0.3236) [1.0 s]
INFO:root:Epoch 37    loss=0.2010 [21.5 s]    dev=(HR@5:0.4444,NDCG@5:0.3236) [1.0 s]
INFO:root:Epoch 38    loss=0.2004 [21.5 s]    dev=(HR@5:0.4455,NDCG@5:0.3245) [0.9 s]
INFO:root:Epoch 39    loss=0.2007 [21.5 s]    dev=(HR@5:0.4413,NDCG@5:0.3217) [1.0 s]
INFO:root:Epoch 40    loss=0.1997 [21.5 s]    dev=(HR@5:0.4439,NDCG@5:0.3243) [0.9 s]
INFO:root:Epoch 41    loss=0.2000 [21.6 s]    dev=(HR@5:0.4446,NDCG@5:0.3238) [1.0 s]
INFO:root:Epoch 42    loss=0.1997 [21.4 s]    dev=(HR@5:0.4445,NDCG@5:0.3252) [0.9 s]
INFO:root:Epoch 43    loss=0.1980 [21.4 s]    dev=(HR@5:0.4477,NDCG@5:0.3277) [0.9 s]
INFO:root:Epoch 44    loss=0.1998 [21.5 s]    dev=(HR@5:0.4440,NDCG@5:0.3241) [0.9 s]
INFO:root:Epoch 45    loss=0.1959 [21.4 s]    dev=(HR@5:0.4440,NDCG@5:0.3280) [0.9 s]
INFO:root:Epoch 46    loss=0.1976 [21.5 s]    dev=(HR@5:0.4434,NDCG@5:0.3248) [1.0 s]
INFO:root:Epoch 47    loss=0.1975 [21.5 s]    dev=(HR@5:0.4438,NDCG@5:0.3233) [1.0 s]
INFO:root:Epoch 48    loss=0.1965 [21.4 s]    dev=(HR@5:0.4438,NDCG@5:0.3238) [1.0 s]
INFO:root:Early stop at 48 based on dev result.
INFO:root:
Best Iter(dev)=   28	 dev=(HR@5:0.4479,NDCG@5:0.3290) [1079.0 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.3979,NDCG@5:0.2845,HR@10:0.5085,NDCG@10:0.3204,HR@20:0.6299,NDCG@20:0.3510,HR@50:0.8377,NDCG@50:0.3920)
INFO:root:
--------------------------------------------- END: 2024-12-06 17:27:35 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 18:04:46 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5152 [23.3 s]    dev=(HR@5:0.2568,NDCG@5:0.1719) [1.0 s] *
INFO:root:Epoch 2     loss=0.4250 [21.4 s]    dev=(HR@5:0.3337,NDCG@5:0.2262) [0.9 s] *
INFO:root:Epoch 3     loss=0.3871 [21.4 s]    dev=(HR@5:0.3620,NDCG@5:0.2469) [1.0 s] *
INFO:root:Epoch 4     loss=0.3619 [21.5 s]    dev=(HR@5:0.3848,NDCG@5:0.2681) [0.9 s] *
INFO:root:Epoch 5     loss=0.3365 [21.3 s]    dev=(HR@5:0.4015,NDCG@5:0.2857) [0.9 s] *
INFO:root:Epoch 6     loss=0.3121 [21.3 s]    dev=(HR@5:0.4181,NDCG@5:0.2989) [1.0 s] *
INFO:root:Epoch 7     loss=0.2946 [21.3 s]    dev=(HR@5:0.4217,NDCG@5:0.3012) [1.0 s] *
INFO:root:Epoch 8     loss=0.2800 [21.3 s]    dev=(HR@5:0.4272,NDCG@5:0.3079) [0.9 s] *
INFO:root:Epoch 9     loss=0.2668 [21.3 s]    dev=(HR@5:0.4315,NDCG@5:0.3129) [0.9 s] *
INFO:root:Epoch 10    loss=0.2565 [21.3 s]    dev=(HR@5:0.4359,NDCG@5:0.3163) [0.9 s] *
INFO:root:Epoch 11    loss=0.2470 [21.3 s]    dev=(HR@5:0.4373,NDCG@5:0.3177) [0.9 s] *
INFO:root:Epoch 12    loss=0.2388 [21.3 s]    dev=(HR@5:0.4377,NDCG@5:0.3192) [1.0 s] *
INFO:root:Epoch 13    loss=0.2345 [21.3 s]    dev=(HR@5:0.4449,NDCG@5:0.3248) [0.9 s] *
INFO:root:Epoch 14    loss=0.2303 [21.3 s]    dev=(HR@5:0.4454,NDCG@5:0.3241) [1.0 s]
INFO:root:Epoch 15    loss=0.2268 [21.4 s]    dev=(HR@5:0.4436,NDCG@5:0.3238) [0.9 s]
INFO:root:Epoch 16    loss=0.2231 [21.3 s]    dev=(HR@5:0.4445,NDCG@5:0.3256) [1.0 s] *
INFO:root:Epoch 17    loss=0.2193 [21.4 s]    dev=(HR@5:0.4432,NDCG@5:0.3238) [1.0 s]
INFO:root:Epoch 18    loss=0.2150 [21.4 s]    dev=(HR@5:0.4465,NDCG@5:0.3280) [1.0 s] *
INFO:root:Epoch 19    loss=0.2128 [21.3 s]    dev=(HR@5:0.4469,NDCG@5:0.3283) [0.9 s] *
INFO:root:Epoch 20    loss=0.2099 [21.3 s]    dev=(HR@5:0.4507,NDCG@5:0.3309) [0.9 s] *
INFO:root:Epoch 21    loss=0.2065 [21.3 s]    dev=(HR@5:0.4484,NDCG@5:0.3295) [0.9 s]
INFO:root:Epoch 22    loss=0.2062 [21.4 s]    dev=(HR@5:0.4491,NDCG@5:0.3304) [0.9 s]
INFO:root:Epoch 23    loss=0.2068 [21.4 s]    dev=(HR@5:0.4450,NDCG@5:0.3278) [1.0 s]
INFO:root:Epoch 24    loss=0.2058 [21.4 s]    dev=(HR@5:0.4492,NDCG@5:0.3289) [0.9 s]
INFO:root:Epoch 25    loss=0.2017 [21.5 s]    dev=(HR@5:0.4473,NDCG@5:0.3268) [1.0 s]
INFO:root:Epoch 26    loss=0.2025 [21.3 s]    dev=(HR@5:0.4500,NDCG@5:0.3299) [1.0 s]
INFO:root:Epoch 27    loss=0.2019 [21.4 s]    dev=(HR@5:0.4507,NDCG@5:0.3309) [0.9 s]
INFO:root:Epoch 28    loss=0.2018 [21.3 s]    dev=(HR@5:0.4543,NDCG@5:0.3334) [1.0 s] *
INFO:root:Epoch 29    loss=0.1999 [21.4 s]    dev=(HR@5:0.4513,NDCG@5:0.3314) [1.0 s]
INFO:root:Epoch 30    loss=0.1991 [21.3 s]    dev=(HR@5:0.4489,NDCG@5:0.3305) [0.9 s]
INFO:root:Epoch 31    loss=0.1981 [21.4 s]    dev=(HR@5:0.4548,NDCG@5:0.3344) [1.0 s] *
INFO:root:Epoch 32    loss=0.1983 [21.3 s]    dev=(HR@5:0.4517,NDCG@5:0.3316) [0.9 s]
INFO:root:Epoch 33    loss=0.1986 [21.4 s]    dev=(HR@5:0.4516,NDCG@5:0.3331) [1.0 s]
INFO:root:Epoch 34    loss=0.1979 [21.4 s]    dev=(HR@5:0.4495,NDCG@5:0.3290) [0.9 s]
INFO:root:Epoch 35    loss=0.1984 [21.4 s]    dev=(HR@5:0.4474,NDCG@5:0.3277) [1.0 s]
INFO:root:Epoch 36    loss=0.1957 [21.4 s]    dev=(HR@5:0.4491,NDCG@5:0.3287) [1.0 s]
INFO:root:Epoch 37    loss=0.1968 [21.3 s]    dev=(HR@5:0.4507,NDCG@5:0.3302) [1.0 s]
INFO:root:Epoch 38    loss=0.1967 [21.6 s]    dev=(HR@5:0.4525,NDCG@5:0.3297) [1.0 s]
INFO:root:Epoch 39    loss=0.1970 [21.5 s]    dev=(HR@5:0.4472,NDCG@5:0.3268) [0.9 s]
INFO:root:Epoch 40    loss=0.1962 [21.4 s]    dev=(HR@5:0.4494,NDCG@5:0.3294) [0.9 s]
INFO:root:Epoch 41    loss=0.1965 [21.4 s]    dev=(HR@5:0.4492,NDCG@5:0.3281) [0.9 s]
INFO:root:Epoch 42    loss=0.1962 [21.3 s]    dev=(HR@5:0.4512,NDCG@5:0.3306) [0.9 s]
INFO:root:Epoch 43    loss=0.1946 [21.4 s]    dev=(HR@5:0.4547,NDCG@5:0.3332) [1.0 s]
INFO:root:Epoch 44    loss=0.1958 [21.4 s]    dev=(HR@5:0.4479,NDCG@5:0.3288) [1.0 s]
INFO:root:Epoch 45    loss=0.1937 [21.6 s]    dev=(HR@5:0.4520,NDCG@5:0.3335) [1.0 s]
INFO:root:Epoch 46    loss=0.1946 [21.3 s]    dev=(HR@5:0.4445,NDCG@5:0.3273) [1.0 s]
INFO:root:Epoch 47    loss=0.1946 [21.4 s]    dev=(HR@5:0.4469,NDCG@5:0.3283) [0.9 s]
INFO:root:Epoch 48    loss=0.1944 [21.4 s]    dev=(HR@5:0.4494,NDCG@5:0.3290) [1.0 s]
INFO:root:Epoch 49    loss=0.1927 [21.3 s]    dev=(HR@5:0.4535,NDCG@5:0.3329) [1.0 s]
INFO:root:Epoch 50    loss=0.1953 [21.5 s]    dev=(HR@5:0.4484,NDCG@5:0.3301) [1.0 s]
INFO:root:Epoch 51    loss=0.1938 [21.3 s]    dev=(HR@5:0.4514,NDCG@5:0.3307) [0.9 s]
INFO:root:Early stop at 51 based on dev result.
INFO:root:
Best Iter(dev)=   31	 dev=(HR@5:0.4548,NDCG@5:0.3344) [1141.1 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.4041,NDCG@5:0.2905,HR@10:0.5102,NDCG@10:0.3247,HR@20:0.6312,NDCG@20:0.3552,HR@50:0.8345,NDCG@50:0.3955)
INFO:root:
--------------------------------------------- END: 2024-12-06 18:23:49 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 19:01:07 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5153 [26.1 s]    dev=(HR@5:0.2594,NDCG@5:0.1739) [1.0 s] *
INFO:root:Epoch 2     loss=0.4238 [21.6 s]    dev=(HR@5:0.3366,NDCG@5:0.2286) [1.0 s] *
INFO:root:Epoch 3     loss=0.3861 [21.3 s]    dev=(HR@5:0.3631,NDCG@5:0.2488) [1.0 s] *
INFO:root:Epoch 4     loss=0.3607 [21.8 s]    dev=(HR@5:0.3873,NDCG@5:0.2711) [1.0 s] *
INFO:root:Epoch 5     loss=0.3354 [21.4 s]    dev=(HR@5:0.4046,NDCG@5:0.2878) [0.9 s] *
INFO:root:Epoch 6     loss=0.3112 [21.6 s]    dev=(HR@5:0.4207,NDCG@5:0.3017) [1.0 s] *
INFO:root:Epoch 7     loss=0.2927 [22.0 s]    dev=(HR@5:0.4261,NDCG@5:0.3061) [1.0 s] *
INFO:root:Epoch 8     loss=0.2765 [21.7 s]    dev=(HR@5:0.4346,NDCG@5:0.3147) [1.0 s] *
INFO:root:Epoch 9     loss=0.2616 [21.6 s]    dev=(HR@5:0.4386,NDCG@5:0.3200) [1.0 s] *
INFO:root:Epoch 10    loss=0.2518 [21.9 s]    dev=(HR@5:0.4419,NDCG@5:0.3230) [1.0 s] *
INFO:root:Epoch 11    loss=0.2411 [21.9 s]    dev=(HR@5:0.4467,NDCG@5:0.3262) [1.2 s] *
INFO:root:Epoch 12    loss=0.2327 [25.1 s]    dev=(HR@5:0.4493,NDCG@5:0.3279) [1.0 s] *
INFO:root:Epoch 13    loss=0.2283 [21.5 s]    dev=(HR@5:0.4541,NDCG@5:0.3321) [1.0 s] *
INFO:root:Epoch 14    loss=0.2236 [21.5 s]    dev=(HR@5:0.4517,NDCG@5:0.3312) [1.0 s]
INFO:root:Epoch 15    loss=0.2205 [21.5 s]    dev=(HR@5:0.4494,NDCG@5:0.3292) [1.0 s]
INFO:root:Epoch 16    loss=0.2178 [21.4 s]    dev=(HR@5:0.4538,NDCG@5:0.3326) [0.9 s] *
INFO:root:Epoch 17    loss=0.2145 [21.4 s]    dev=(HR@5:0.4526,NDCG@5:0.3308) [0.9 s]
INFO:root:Epoch 18    loss=0.2104 [21.5 s]    dev=(HR@5:0.4530,NDCG@5:0.3331) [0.9 s] *
INFO:root:Epoch 19    loss=0.2089 [21.3 s]    dev=(HR@5:0.4534,NDCG@5:0.3325) [0.9 s]
INFO:root:Epoch 20    loss=0.2063 [21.4 s]    dev=(HR@5:0.4547,NDCG@5:0.3345) [0.9 s] *
INFO:root:Epoch 21    loss=0.2029 [21.4 s]    dev=(HR@5:0.4580,NDCG@5:0.3354) [1.0 s] *
INFO:root:Epoch 22    loss=0.2029 [21.4 s]    dev=(HR@5:0.4509,NDCG@5:0.3317) [0.9 s]
INFO:root:Epoch 23    loss=0.2036 [21.5 s]    dev=(HR@5:0.4499,NDCG@5:0.3310) [1.0 s]
INFO:root:Epoch 24    loss=0.2026 [21.4 s]    dev=(HR@5:0.4525,NDCG@5:0.3313) [0.9 s]
INFO:root:Epoch 25    loss=0.1988 [21.3 s]    dev=(HR@5:0.4500,NDCG@5:0.3308) [1.0 s]
INFO:root:Epoch 26    loss=0.1999 [30.1 s]    dev=(HR@5:0.4541,NDCG@5:0.3332) [0.9 s]
INFO:root:Epoch 27    loss=0.1996 [31.8 s]    dev=(HR@5:0.4534,NDCG@5:0.3334) [0.9 s]
INFO:root:Epoch 28    loss=0.1992 [21.4 s]    dev=(HR@5:0.4568,NDCG@5:0.3367) [0.9 s] *
INFO:root:Epoch 29    loss=0.1977 [21.6 s]    dev=(HR@5:0.4513,NDCG@5:0.3339) [1.0 s]
INFO:root:Epoch 30    loss=0.1977 [21.4 s]    dev=(HR@5:0.4549,NDCG@5:0.3352) [0.9 s]
INFO:root:Epoch 31    loss=0.1954 [21.5 s]    dev=(HR@5:0.4549,NDCG@5:0.3365) [0.9 s]
INFO:root:Epoch 32    loss=0.1963 [21.3 s]    dev=(HR@5:0.4541,NDCG@5:0.3337) [1.0 s]
INFO:root:Epoch 33    loss=0.1967 [21.3 s]    dev=(HR@5:0.4584,NDCG@5:0.3402) [0.9 s] *
INFO:root:Epoch 34    loss=0.1962 [21.3 s]    dev=(HR@5:0.4579,NDCG@5:0.3383) [1.0 s]
INFO:root:Epoch 35    loss=0.1958 [21.4 s]    dev=(HR@5:0.4529,NDCG@5:0.3345) [0.9 s]
INFO:root:Epoch 36    loss=0.1936 [21.4 s]    dev=(HR@5:0.4549,NDCG@5:0.3332) [0.9 s]
INFO:root:Epoch 37    loss=0.1939 [21.6 s]    dev=(HR@5:0.4560,NDCG@5:0.3347) [0.9 s]
INFO:root:Epoch 38    loss=0.1949 [21.3 s]    dev=(HR@5:0.4558,NDCG@5:0.3349) [1.0 s]
INFO:root:Epoch 39    loss=0.1950 [21.4 s]    dev=(HR@5:0.4496,NDCG@5:0.3297) [0.9 s]
INFO:root:Epoch 40    loss=0.1943 [21.4 s]    dev=(HR@5:0.4523,NDCG@5:0.3331) [0.9 s]
INFO:root:Epoch 41    loss=0.1951 [21.3 s]    dev=(HR@5:0.4548,NDCG@5:0.3340) [1.0 s]
INFO:root:Epoch 42    loss=0.1941 [21.3 s]    dev=(HR@5:0.4551,NDCG@5:0.3339) [0.9 s]
INFO:root:Epoch 43    loss=0.1925 [21.3 s]    dev=(HR@5:0.4572,NDCG@5:0.3361) [0.9 s]
INFO:root:Epoch 44    loss=0.1941 [21.4 s]    dev=(HR@5:0.4531,NDCG@5:0.3337) [1.0 s]
INFO:root:Epoch 45    loss=0.1913 [21.4 s]    dev=(HR@5:0.4563,NDCG@5:0.3393) [0.9 s]
INFO:root:Epoch 46    loss=0.1923 [21.2 s]    dev=(HR@5:0.4530,NDCG@5:0.3351) [1.0 s]
INFO:root:Epoch 47    loss=0.1928 [22.1 s]    dev=(HR@5:0.4551,NDCG@5:0.3352) [1.0 s]
INFO:root:Epoch 48    loss=0.1927 [21.5 s]    dev=(HR@5:0.4522,NDCG@5:0.3339) [1.0 s]
INFO:root:Epoch 49    loss=0.1907 [21.4 s]    dev=(HR@5:0.4551,NDCG@5:0.3355) [0.9 s]
INFO:root:Epoch 50    loss=0.1935 [21.3 s]    dev=(HR@5:0.4520,NDCG@5:0.3346) [0.9 s]
INFO:root:Epoch 51    loss=0.1912 [21.4 s]    dev=(HR@5:0.4521,NDCG@5:0.3340) [0.9 s]
INFO:root:Epoch 52    loss=0.1923 [21.3 s]    dev=(HR@5:0.4554,NDCG@5:0.3350) [1.0 s]
INFO:root:Epoch 53    loss=0.1914 [21.5 s]    dev=(HR@5:0.4530,NDCG@5:0.3345) [1.0 s]
INFO:root:Early stop at 53 based on dev result.
INFO:root:
Best Iter(dev)=   33	 dev=(HR@5:0.4584,NDCG@5:0.3402) [1216.1 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.4052,NDCG@5:0.2923,HR@10:0.5162,NDCG@10:0.3282,HR@20:0.6377,NDCG@20:0.3588,HR@50:0.8395,NDCG@50:0.3987)
INFO:root:
--------------------------------------------- END: 2024-12-06 19:21:25 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 19:58:59 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5157 [23.3 s]    dev=(HR@5:0.2599,NDCG@5:0.1740) [1.0 s] *
INFO:root:Epoch 2     loss=0.4239 [21.3 s]    dev=(HR@5:0.3376,NDCG@5:0.2300) [0.9 s] *
INFO:root:Epoch 3     loss=0.3853 [21.3 s]    dev=(HR@5:0.3676,NDCG@5:0.2532) [1.0 s] *
INFO:root:Epoch 4     loss=0.3597 [21.2 s]    dev=(HR@5:0.3907,NDCG@5:0.2731) [1.0 s] *
INFO:root:Epoch 5     loss=0.3360 [21.4 s]    dev=(HR@5:0.4031,NDCG@5:0.2863) [0.9 s] *
INFO:root:Epoch 6     loss=0.3135 [21.4 s]    dev=(HR@5:0.4164,NDCG@5:0.2995) [0.9 s] *
INFO:root:Epoch 7     loss=0.2974 [21.3 s]    dev=(HR@5:0.4222,NDCG@5:0.3041) [0.9 s] *
INFO:root:Epoch 8     loss=0.2818 [21.2 s]    dev=(HR@5:0.4290,NDCG@5:0.3124) [1.0 s] *
INFO:root:Epoch 9     loss=0.2682 [21.5 s]    dev=(HR@5:0.4342,NDCG@5:0.3175) [1.0 s] *
INFO:root:Epoch 10    loss=0.2580 [21.3 s]    dev=(HR@5:0.4341,NDCG@5:0.3190) [0.9 s] *
INFO:root:Epoch 11    loss=0.2470 [21.3 s]    dev=(HR@5:0.4437,NDCG@5:0.3237) [0.9 s] *
INFO:root:Epoch 12    loss=0.2381 [21.3 s]    dev=(HR@5:0.4457,NDCG@5:0.3272) [0.9 s] *
INFO:root:Epoch 13    loss=0.2335 [21.2 s]    dev=(HR@5:0.4501,NDCG@5:0.3323) [1.0 s] *
INFO:root:Epoch 14    loss=0.2282 [21.3 s]    dev=(HR@5:0.4482,NDCG@5:0.3303) [0.9 s]
INFO:root:Epoch 15    loss=0.2243 [21.2 s]    dev=(HR@5:0.4492,NDCG@5:0.3299) [0.9 s]
INFO:root:Epoch 16    loss=0.2212 [21.3 s]    dev=(HR@5:0.4491,NDCG@5:0.3309) [1.0 s]
INFO:root:Epoch 17    loss=0.2171 [21.3 s]    dev=(HR@5:0.4469,NDCG@5:0.3306) [1.0 s]
INFO:root:Epoch 18    loss=0.2132 [21.3 s]    dev=(HR@5:0.4513,NDCG@5:0.3334) [1.0 s] *
INFO:root:Epoch 19    loss=0.2117 [21.3 s]    dev=(HR@5:0.4470,NDCG@5:0.3303) [1.0 s]
INFO:root:Epoch 20    loss=0.2088 [21.4 s]    dev=(HR@5:0.4500,NDCG@5:0.3339) [0.9 s] *
INFO:root:Epoch 21    loss=0.2060 [21.3 s]    dev=(HR@5:0.4526,NDCG@5:0.3350) [0.9 s] *
INFO:root:Epoch 22    loss=0.2057 [21.3 s]    dev=(HR@5:0.4487,NDCG@5:0.3328) [0.9 s]
INFO:root:Epoch 23    loss=0.2058 [21.2 s]    dev=(HR@5:0.4512,NDCG@5:0.3345) [0.9 s]
INFO:root:Epoch 24    loss=0.2047 [21.2 s]    dev=(HR@5:0.4509,NDCG@5:0.3327) [0.9 s]
INFO:root:Epoch 25    loss=0.2021 [21.3 s]    dev=(HR@5:0.4474,NDCG@5:0.3310) [0.9 s]
INFO:root:Epoch 26    loss=0.2028 [21.3 s]    dev=(HR@5:0.4466,NDCG@5:0.3325) [1.0 s]
INFO:root:Epoch 27    loss=0.2022 [21.3 s]    dev=(HR@5:0.4495,NDCG@5:0.3335) [1.0 s]
INFO:root:Epoch 28    loss=0.2021 [21.3 s]    dev=(HR@5:0.4490,NDCG@5:0.3349) [1.0 s]
INFO:root:Epoch 29    loss=0.2004 [21.3 s]    dev=(HR@5:0.4483,NDCG@5:0.3334) [0.9 s]
INFO:root:Epoch 30    loss=0.2007 [21.2 s]    dev=(HR@5:0.4520,NDCG@5:0.3356) [1.0 s] *
INFO:root:Epoch 31    loss=0.1981 [21.3 s]    dev=(HR@5:0.4494,NDCG@5:0.3358) [1.0 s] *
INFO:root:Epoch 32    loss=0.1993 [21.3 s]    dev=(HR@5:0.4488,NDCG@5:0.3320) [0.9 s]
INFO:root:Epoch 33    loss=0.1995 [21.3 s]    dev=(HR@5:0.4532,NDCG@5:0.3376) [0.9 s] *
INFO:root:Epoch 34    loss=0.1991 [21.2 s]    dev=(HR@5:0.4513,NDCG@5:0.3361) [1.0 s]
INFO:root:Epoch 35    loss=0.1989 [21.4 s]    dev=(HR@5:0.4521,NDCG@5:0.3354) [1.0 s]
INFO:root:Epoch 36    loss=0.1974 [21.4 s]    dev=(HR@5:0.4529,NDCG@5:0.3335) [1.0 s]
INFO:root:Epoch 37    loss=0.1977 [21.3 s]    dev=(HR@5:0.4528,NDCG@5:0.3345) [0.9 s]
INFO:root:Epoch 38    loss=0.1988 [21.4 s]    dev=(HR@5:0.4509,NDCG@5:0.3347) [1.0 s]
INFO:root:Epoch 39    loss=0.1975 [21.3 s]    dev=(HR@5:0.4475,NDCG@5:0.3308) [0.9 s]
INFO:root:Epoch 40    loss=0.1976 [21.3 s]    dev=(HR@5:0.4496,NDCG@5:0.3349) [1.0 s]
INFO:root:Epoch 41    loss=0.1982 [21.3 s]    dev=(HR@5:0.4516,NDCG@5:0.3350) [1.0 s]
INFO:root:Epoch 42    loss=0.1973 [21.3 s]    dev=(HR@5:0.4532,NDCG@5:0.3340) [0.9 s]
INFO:root:Epoch 43    loss=0.1961 [21.3 s]    dev=(HR@5:0.4544,NDCG@5:0.3371) [1.0 s]
INFO:root:Epoch 44    loss=0.1979 [21.5 s]    dev=(HR@5:0.4501,NDCG@5:0.3331) [1.0 s]
INFO:root:Epoch 45    loss=0.1947 [22.3 s]    dev=(HR@5:0.4522,NDCG@5:0.3376) [1.0 s]
INFO:root:Epoch 46    loss=0.1959 [22.3 s]    dev=(HR@5:0.4513,NDCG@5:0.3358) [1.0 s]
INFO:root:Epoch 47    loss=0.1962 [22.3 s]    dev=(HR@5:0.4498,NDCG@5:0.3329) [1.0 s]
INFO:root:Epoch 48    loss=0.1954 [22.1 s]    dev=(HR@5:0.4498,NDCG@5:0.3332) [1.0 s]
INFO:root:Epoch 49    loss=0.1947 [21.6 s]    dev=(HR@5:0.4524,NDCG@5:0.3350) [1.0 s]
INFO:root:Epoch 50    loss=0.1968 [21.3 s]    dev=(HR@5:0.4484,NDCG@5:0.3322) [1.0 s]
INFO:root:Epoch 51    loss=0.1948 [21.3 s]    dev=(HR@5:0.4488,NDCG@5:0.3331) [1.0 s]
INFO:root:Epoch 52    loss=0.1957 [21.3 s]    dev=(HR@5:0.4492,NDCG@5:0.3319) [0.9 s]
INFO:root:Epoch 53    loss=0.1949 [21.3 s]    dev=(HR@5:0.4479,NDCG@5:0.3320) [1.0 s]
INFO:root:Early stop at 53 based on dev result.
INFO:root:
Best Iter(dev)=   33	 dev=(HR@5:0.4532,NDCG@5:0.3376) [1185.5 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.4043,NDCG@5:0.2933,HR@10:0.5114,NDCG@10:0.3280,HR@20:0.6318,NDCG@20:0.3583,HR@50:0.8358,NDCG@50:0.3987)
INFO:root:
--------------------------------------------- END: 2024-12-06 20:18:46 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 21:15:24 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5143 [24.1 s]    dev=(HR@5:0.2519,NDCG@5:0.1676) [1.0 s] *
INFO:root:Epoch 2     loss=0.4313 [21.7 s]    dev=(HR@5:0.3161,NDCG@5:0.2136) [1.0 s] *
INFO:root:Epoch 3     loss=0.3978 [22.1 s]    dev=(HR@5:0.3394,NDCG@5:0.2281) [1.0 s] *
INFO:root:Epoch 4     loss=0.3764 [21.8 s]    dev=(HR@5:0.3575,NDCG@5:0.2441) [0.9 s] *
INFO:root:Epoch 5     loss=0.3527 [21.7 s]    dev=(HR@5:0.3720,NDCG@5:0.2577) [0.9 s] *
INFO:root:Epoch 6     loss=0.3285 [21.2 s]    dev=(HR@5:0.3925,NDCG@5:0.2784) [0.9 s] *
INFO:root:Epoch 7     loss=0.3092 [22.1 s]    dev=(HR@5:0.4001,NDCG@5:0.2836) [1.0 s] *
INFO:root:Epoch 8     loss=0.2948 [22.1 s]    dev=(HR@5:0.4061,NDCG@5:0.2906) [1.0 s] *
INFO:root:Epoch 9     loss=0.2806 [22.0 s]    dev=(HR@5:0.4051,NDCG@5:0.2917) [1.0 s] *
INFO:root:Epoch 10    loss=0.2718 [22.6 s]    dev=(HR@5:0.4124,NDCG@5:0.2964) [0.9 s] *
INFO:root:Epoch 11    loss=0.2633 [21.6 s]    dev=(HR@5:0.4147,NDCG@5:0.2970) [1.0 s] *
INFO:root:Epoch 12    loss=0.2552 [21.9 s]    dev=(HR@5:0.4169,NDCG@5:0.3008) [1.0 s] *
INFO:root:Epoch 13    loss=0.2513 [22.0 s]    dev=(HR@5:0.4186,NDCG@5:0.3030) [1.0 s] *
INFO:root:Epoch 14    loss=0.2469 [21.8 s]    dev=(HR@5:0.4184,NDCG@5:0.3027) [1.0 s]
INFO:root:Epoch 15    loss=0.2434 [22.3 s]    dev=(HR@5:0.4173,NDCG@5:0.3013) [1.0 s]
INFO:root:Epoch 16    loss=0.2411 [21.9 s]    dev=(HR@5:0.4205,NDCG@5:0.3039) [1.0 s] *
INFO:root:Epoch 17    loss=0.2380 [22.0 s]    dev=(HR@5:0.4154,NDCG@5:0.2998) [1.0 s]
INFO:root:Epoch 18    loss=0.2348 [21.9 s]    dev=(HR@5:0.4183,NDCG@5:0.3035) [1.0 s]
INFO:root:Epoch 19    loss=0.2319 [21.2 s]    dev=(HR@5:0.4196,NDCG@5:0.3049) [0.9 s] *
INFO:root:Epoch 20    loss=0.2294 [21.2 s]    dev=(HR@5:0.4239,NDCG@5:0.3064) [0.9 s] *
INFO:root:Epoch 21    loss=0.2247 [21.2 s]    dev=(HR@5:0.4250,NDCG@5:0.3078) [0.9 s] *
INFO:root:Epoch 22    loss=0.2238 [21.2 s]    dev=(HR@5:0.4239,NDCG@5:0.3068) [0.9 s]
INFO:root:Epoch 23    loss=0.2249 [21.4 s]    dev=(HR@5:0.4177,NDCG@5:0.3048) [1.0 s]
INFO:root:Epoch 24    loss=0.2232 [21.6 s]    dev=(HR@5:0.4268,NDCG@5:0.3091) [0.9 s] *
INFO:root:Epoch 25    loss=0.2198 [21.6 s]    dev=(HR@5:0.4226,NDCG@5:0.3075) [1.0 s]
INFO:root:Epoch 26    loss=0.2205 [21.9 s]    dev=(HR@5:0.4272,NDCG@5:0.3105) [1.0 s] *
INFO:root:Epoch 27    loss=0.2185 [21.8 s]    dev=(HR@5:0.4237,NDCG@5:0.3087) [0.9 s]
INFO:root:Epoch 28    loss=0.2194 [21.8 s]    dev=(HR@5:0.4270,NDCG@5:0.3113) [1.0 s] *
INFO:root:Epoch 29    loss=0.2172 [21.9 s]    dev=(HR@5:0.4291,NDCG@5:0.3115) [1.0 s] *
INFO:root:Epoch 30    loss=0.2161 [21.8 s]    dev=(HR@5:0.4267,NDCG@5:0.3120) [1.0 s] *
INFO:root:Epoch 31    loss=0.2150 [22.2 s]    dev=(HR@5:0.4262,NDCG@5:0.3124) [1.0 s] *
INFO:root:Epoch 32    loss=0.2158 [22.3 s]    dev=(HR@5:0.4269,NDCG@5:0.3100) [1.0 s]
INFO:root:Epoch 33    loss=0.2151 [21.8 s]    dev=(HR@5:0.4291,NDCG@5:0.3123) [1.0 s]
INFO:root:Epoch 34    loss=0.2137 [21.8 s]    dev=(HR@5:0.4321,NDCG@5:0.3152) [1.0 s] *
INFO:root:Epoch 35    loss=0.2138 [22.1 s]    dev=(HR@5:0.4257,NDCG@5:0.3090) [1.0 s]
INFO:root:Epoch 36    loss=0.2119 [21.8 s]    dev=(HR@5:0.4269,NDCG@5:0.3094) [1.0 s]
INFO:root:Epoch 37    loss=0.2120 [21.6 s]    dev=(HR@5:0.4301,NDCG@5:0.3133) [1.0 s]
INFO:root:Epoch 38    loss=0.2117 [21.8 s]    dev=(HR@5:0.4285,NDCG@5:0.3119) [1.0 s]
INFO:root:Epoch 39    loss=0.2124 [21.8 s]    dev=(HR@5:0.4264,NDCG@5:0.3090) [1.0 s]
INFO:root:Epoch 40    loss=0.2116 [21.1 s]    dev=(HR@5:0.4288,NDCG@5:0.3124) [0.9 s]
INFO:root:Epoch 41    loss=0.2125 [22.1 s]    dev=(HR@5:0.4275,NDCG@5:0.3091) [1.0 s]
INFO:root:Epoch 42    loss=0.2117 [22.2 s]    dev=(HR@5:0.4323,NDCG@5:0.3134) [1.0 s]
INFO:root:Epoch 43    loss=0.2109 [22.2 s]    dev=(HR@5:0.4335,NDCG@5:0.3151) [1.0 s]
INFO:root:Epoch 44    loss=0.2116 [21.6 s]    dev=(HR@5:0.4293,NDCG@5:0.3116) [1.0 s]
INFO:root:Epoch 45    loss=0.2081 [21.9 s]    dev=(HR@5:0.4323,NDCG@5:0.3146) [1.0 s]
INFO:root:Epoch 46    loss=0.2098 [22.1 s]    dev=(HR@5:0.4227,NDCG@5:0.3082) [1.1 s]
INFO:root:Epoch 47    loss=0.2096 [22.4 s]    dev=(HR@5:0.4286,NDCG@5:0.3115) [1.0 s]
INFO:root:Epoch 48    loss=0.2090 [21.8 s]    dev=(HR@5:0.4265,NDCG@5:0.3088) [1.0 s]
INFO:root:Epoch 49    loss=0.2076 [22.0 s]    dev=(HR@5:0.4394,NDCG@5:0.3198) [1.0 s] *
INFO:root:Epoch 50    loss=0.2081 [22.3 s]    dev=(HR@5:0.4316,NDCG@5:0.3141) [1.0 s]
INFO:root:Epoch 51    loss=0.2080 [22.0 s]    dev=(HR@5:0.4323,NDCG@5:0.3145) [1.0 s]
INFO:root:Epoch 52    loss=0.2072 [22.1 s]    dev=(HR@5:0.4309,NDCG@5:0.3135) [1.0 s]
INFO:root:Epoch 53    loss=0.2084 [22.5 s]    dev=(HR@5:0.4333,NDCG@5:0.3152) [1.0 s]
INFO:root:Epoch 54    loss=0.2068 [22.2 s]    dev=(HR@5:0.4363,NDCG@5:0.3163) [1.0 s]
INFO:root:Epoch 55    loss=0.2055 [22.3 s]    dev=(HR@5:0.4364,NDCG@5:0.3160) [1.0 s]
INFO:root:Epoch 56    loss=0.2051 [21.5 s]    dev=(HR@5:0.4404,NDCG@5:0.3202) [1.0 s] *
INFO:root:Epoch 57    loss=0.2060 [21.4 s]    dev=(HR@5:0.4391,NDCG@5:0.3194) [1.0 s]
INFO:root:Epoch 58    loss=0.2070 [21.3 s]    dev=(HR@5:0.4408,NDCG@5:0.3215) [0.9 s] *
INFO:root:Epoch 59    loss=0.2060 [21.1 s]    dev=(HR@5:0.4378,NDCG@5:0.3183) [0.9 s]
INFO:root:Epoch 60    loss=0.2058 [21.2 s]    dev=(HR@5:0.4363,NDCG@5:0.3172) [1.0 s]
INFO:root:Epoch 61    loss=0.2061 [21.1 s]    dev=(HR@5:0.4381,NDCG@5:0.3189) [0.9 s]
INFO:root:Epoch 62    loss=0.2048 [21.2 s]    dev=(HR@5:0.4409,NDCG@5:0.3207) [0.9 s]
INFO:root:Epoch 63    loss=0.2058 [21.1 s]    dev=(HR@5:0.4403,NDCG@5:0.3198) [1.0 s]
INFO:root:Epoch 64    loss=0.2042 [21.0 s]    dev=(HR@5:0.4368,NDCG@5:0.3168) [0.9 s]
INFO:root:Epoch 65    loss=0.2050 [21.2 s]    dev=(HR@5:0.4372,NDCG@5:0.3172) [0.9 s]
INFO:root:Epoch 66    loss=0.2030 [21.1 s]    dev=(HR@5:0.4372,NDCG@5:0.3170) [1.0 s]
INFO:root:Epoch 67    loss=0.2037 [21.4 s]    dev=(HR@5:0.4363,NDCG@5:0.3174) [0.9 s]
INFO:root:Epoch 68    loss=0.2031 [21.5 s]    dev=(HR@5:0.4405,NDCG@5:0.3208) [1.0 s]
INFO:root:Epoch 69    loss=0.2042 [21.5 s]    dev=(HR@5:0.4393,NDCG@5:0.3187) [1.0 s]
INFO:root:Epoch 70    loss=0.2037 [21.7 s]    dev=(HR@5:0.4373,NDCG@5:0.3182) [0.9 s]
INFO:root:Epoch 71    loss=0.2027 [21.3 s]    dev=(HR@5:0.4386,NDCG@5:0.3194) [1.0 s]
INFO:root:Epoch 72    loss=0.2021 [21.0 s]    dev=(HR@5:0.4389,NDCG@5:0.3193) [0.9 s]
INFO:root:Epoch 73    loss=0.2039 [21.2 s]    dev=(HR@5:0.4370,NDCG@5:0.3181) [0.9 s]
INFO:root:Epoch 74    loss=0.2036 [21.7 s]    dev=(HR@5:0.4380,NDCG@5:0.3167) [0.9 s]
INFO:root:Epoch 75    loss=0.2042 [21.7 s]    dev=(HR@5:0.4371,NDCG@5:0.3168) [1.0 s]
INFO:root:Epoch 76    loss=0.2035 [22.3 s]    dev=(HR@5:0.4378,NDCG@5:0.3187) [1.0 s]
INFO:root:Epoch 77    loss=0.2027 [22.1 s]    dev=(HR@5:0.4378,NDCG@5:0.3188) [1.0 s]
INFO:root:Epoch 78    loss=0.2018 [22.3 s]    dev=(HR@5:0.4378,NDCG@5:0.3171) [1.0 s]
INFO:root:Early stop at 78 based on dev result.
INFO:root:
Best Iter(dev)=   58	 dev=(HR@5:0.4408,NDCG@5:0.3215) [1774.4 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.3899,NDCG@5:0.2766,HR@10:0.4995,NDCG@10:0.3121,HR@20:0.6273,NDCG@20:0.3444,HR@50:0.8318,NDCG@50:0.3848)
INFO:root:
--------------------------------------------- END: 2024-12-06 21:45:01 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 22:26:18 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5142 [27.3 s]    dev=(HR@5:0.2589,NDCG@5:0.1734) [1.0 s] *
INFO:root:Epoch 2     loss=0.4235 [22.2 s]    dev=(HR@5:0.3338,NDCG@5:0.2278) [1.0 s] *
INFO:root:Epoch 3     loss=0.3864 [21.8 s]    dev=(HR@5:0.3645,NDCG@5:0.2498) [0.9 s] *
INFO:root:Epoch 4     loss=0.3629 [22.0 s]    dev=(HR@5:0.3819,NDCG@5:0.2653) [1.0 s] *
INFO:root:Epoch 5     loss=0.3382 [22.1 s]    dev=(HR@5:0.3998,NDCG@5:0.2796) [1.0 s] *
INFO:root:Epoch 6     loss=0.3133 [21.7 s]    dev=(HR@5:0.4120,NDCG@5:0.2920) [1.0 s] *
INFO:root:Epoch 7     loss=0.2951 [21.5 s]    dev=(HR@5:0.4176,NDCG@5:0.2978) [0.9 s] *
INFO:root:Epoch 8     loss=0.2802 [22.1 s]    dev=(HR@5:0.4264,NDCG@5:0.3071) [1.0 s] *
INFO:root:Epoch 9     loss=0.2660 [21.9 s]    dev=(HR@5:0.4281,NDCG@5:0.3086) [1.1 s] *
INFO:root:Epoch 10    loss=0.2566 [22.4 s]    dev=(HR@5:0.4335,NDCG@5:0.3128) [1.0 s] *
INFO:root:Epoch 11    loss=0.2475 [21.7 s]    dev=(HR@5:0.4343,NDCG@5:0.3143) [1.0 s] *
INFO:root:Epoch 12    loss=0.2405 [21.9 s]    dev=(HR@5:0.4361,NDCG@5:0.3161) [1.0 s] *
INFO:root:Epoch 13    loss=0.2364 [22.0 s]    dev=(HR@5:0.4415,NDCG@5:0.3201) [1.0 s] *
INFO:root:Epoch 14    loss=0.2324 [21.9 s]    dev=(HR@5:0.4405,NDCG@5:0.3190) [1.0 s]
INFO:root:Epoch 15    loss=0.2295 [22.2 s]    dev=(HR@5:0.4396,NDCG@5:0.3186) [1.0 s]
INFO:root:Epoch 16    loss=0.2271 [22.2 s]    dev=(HR@5:0.4388,NDCG@5:0.3187) [1.0 s]
INFO:root:Epoch 17    loss=0.2240 [22.3 s]    dev=(HR@5:0.4394,NDCG@5:0.3192) [1.0 s]
INFO:root:Epoch 18    loss=0.2195 [21.9 s]    dev=(HR@5:0.4385,NDCG@5:0.3197) [1.0 s]
INFO:root:Epoch 19    loss=0.2182 [21.7 s]    dev=(HR@5:0.4387,NDCG@5:0.3193) [1.0 s]
INFO:root:Epoch 20    loss=0.2165 [21.8 s]    dev=(HR@5:0.4427,NDCG@5:0.3229) [1.0 s] *
INFO:root:Epoch 21    loss=0.2125 [22.1 s]    dev=(HR@5:0.4430,NDCG@5:0.3219) [1.0 s]
INFO:root:Epoch 22    loss=0.2121 [22.3 s]    dev=(HR@5:0.4435,NDCG@5:0.3225) [1.0 s]
INFO:root:Epoch 23    loss=0.2129 [22.1 s]    dev=(HR@5:0.4388,NDCG@5:0.3202) [1.0 s]
INFO:root:Epoch 24    loss=0.2127 [21.8 s]    dev=(HR@5:0.4443,NDCG@5:0.3217) [1.0 s]
INFO:root:Epoch 25    loss=0.2093 [22.0 s]    dev=(HR@5:0.4395,NDCG@5:0.3197) [1.0 s]
INFO:root:Epoch 26    loss=0.2098 [22.1 s]    dev=(HR@5:0.4391,NDCG@5:0.3190) [1.0 s]
INFO:root:Epoch 27    loss=0.2090 [22.3 s]    dev=(HR@5:0.4380,NDCG@5:0.3182) [1.0 s]
INFO:root:Epoch 28    loss=0.2094 [22.0 s]    dev=(HR@5:0.4430,NDCG@5:0.3250) [1.0 s] *
INFO:root:Epoch 29    loss=0.2078 [21.9 s]    dev=(HR@5:0.4418,NDCG@5:0.3216) [1.0 s]
INFO:root:Epoch 30    loss=0.2067 [21.9 s]    dev=(HR@5:0.4405,NDCG@5:0.3228) [1.0 s]
INFO:root:Epoch 31    loss=0.2068 [21.6 s]    dev=(HR@5:0.4408,NDCG@5:0.3226) [1.0 s]
INFO:root:Epoch 32    loss=0.2065 [21.6 s]    dev=(HR@5:0.4393,NDCG@5:0.3204) [0.9 s]
INFO:root:Epoch 33    loss=0.2070 [22.0 s]    dev=(HR@5:0.4410,NDCG@5:0.3231) [1.0 s]
INFO:root:Epoch 34    loss=0.2057 [21.6 s]    dev=(HR@5:0.4432,NDCG@5:0.3232) [0.9 s]
INFO:root:Epoch 35    loss=0.2065 [21.3 s]    dev=(HR@5:0.4353,NDCG@5:0.3179) [1.0 s]
INFO:root:Epoch 36    loss=0.2051 [21.5 s]    dev=(HR@5:0.4384,NDCG@5:0.3188) [0.9 s]
INFO:root:Epoch 37    loss=0.2058 [21.9 s]    dev=(HR@5:0.4393,NDCG@5:0.3205) [1.0 s]
INFO:root:Epoch 38    loss=0.2056 [21.4 s]    dev=(HR@5:0.4412,NDCG@5:0.3222) [1.0 s]
INFO:root:Epoch 39    loss=0.2064 [21.5 s]    dev=(HR@5:0.4338,NDCG@5:0.3141) [1.0 s]
INFO:root:Epoch 40    loss=0.2055 [22.1 s]    dev=(HR@5:0.4395,NDCG@5:0.3186) [1.0 s]
INFO:root:Epoch 41    loss=0.2059 [21.9 s]    dev=(HR@5:0.4398,NDCG@5:0.3205) [1.0 s]
INFO:root:Epoch 42    loss=0.2056 [22.2 s]    dev=(HR@5:0.4442,NDCG@5:0.3226) [1.0 s]
INFO:root:Epoch 43    loss=0.2046 [21.9 s]    dev=(HR@5:0.4447,NDCG@5:0.3248) [1.0 s]
INFO:root:Epoch 44    loss=0.2056 [21.5 s]    dev=(HR@5:0.4408,NDCG@5:0.3217) [1.0 s]
INFO:root:Epoch 45    loss=0.2030 [21.4 s]    dev=(HR@5:0.4436,NDCG@5:0.3244) [0.9 s]
INFO:root:Epoch 46    loss=0.2042 [21.5 s]    dev=(HR@5:0.4370,NDCG@5:0.3180) [1.0 s]
INFO:root:Epoch 47    loss=0.2042 [22.2 s]    dev=(HR@5:0.4387,NDCG@5:0.3191) [1.0 s]
INFO:root:Epoch 48    loss=0.2038 [22.0 s]    dev=(HR@5:0.4370,NDCG@5:0.3192) [1.0 s]
INFO:root:Early stop at 48 based on dev result.
INFO:root:
Best Iter(dev)=   28	 dev=(HR@5:0.4430,NDCG@5:0.3250) [1103.1 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.3966,NDCG@5:0.2813,HR@10:0.5070,NDCG@10:0.3170,HR@20:0.6284,NDCG@20:0.3475,HR@50:0.8341,NDCG@50:0.3882)
INFO:root:
--------------------------------------------- END: 2024-12-06 22:44:43 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 23:20:30 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5141 [23.7 s]    dev=(HR@5:0.2665,NDCG@5:0.1781) [1.0 s] *
INFO:root:Epoch 2     loss=0.4209 [21.2 s]    dev=(HR@5:0.3393,NDCG@5:0.2320) [0.9 s] *
INFO:root:Epoch 3     loss=0.3838 [21.2 s]    dev=(HR@5:0.3695,NDCG@5:0.2541) [0.9 s] *
INFO:root:Epoch 4     loss=0.3603 [21.2 s]    dev=(HR@5:0.3890,NDCG@5:0.2701) [0.9 s] *
INFO:root:Epoch 5     loss=0.3373 [21.1 s]    dev=(HR@5:0.4007,NDCG@5:0.2837) [1.0 s] *
INFO:root:Epoch 6     loss=0.3124 [21.2 s]    dev=(HR@5:0.4188,NDCG@5:0.2994) [0.9 s] *
INFO:root:Epoch 7     loss=0.2944 [21.2 s]    dev=(HR@5:0.4257,NDCG@5:0.3051) [0.9 s] *
INFO:root:Epoch 8     loss=0.2794 [21.2 s]    dev=(HR@5:0.4285,NDCG@5:0.3097) [0.9 s] *
INFO:root:Epoch 9     loss=0.2659 [21.3 s]    dev=(HR@5:0.4325,NDCG@5:0.3126) [0.9 s] *
INFO:root:Epoch 10    loss=0.2571 [21.2 s]    dev=(HR@5:0.4361,NDCG@5:0.3190) [0.9 s] *
INFO:root:Epoch 11    loss=0.2473 [21.1 s]    dev=(HR@5:0.4404,NDCG@5:0.3220) [0.9 s] *
INFO:root:Epoch 12    loss=0.2390 [21.2 s]    dev=(HR@5:0.4450,NDCG@5:0.3247) [0.9 s] *
INFO:root:Epoch 13    loss=0.2346 [21.2 s]    dev=(HR@5:0.4478,NDCG@5:0.3278) [1.0 s] *
INFO:root:Epoch 14    loss=0.2299 [21.1 s]    dev=(HR@5:0.4476,NDCG@5:0.3282) [0.9 s] *
INFO:root:Epoch 15    loss=0.2264 [21.4 s]    dev=(HR@5:0.4440,NDCG@5:0.3273) [0.9 s]
INFO:root:Epoch 16    loss=0.2236 [21.3 s]    dev=(HR@5:0.4453,NDCG@5:0.3277) [1.0 s]
INFO:root:Epoch 17    loss=0.2203 [21.3 s]    dev=(HR@5:0.4461,NDCG@5:0.3278) [0.9 s]
INFO:root:Epoch 18    loss=0.2155 [21.3 s]    dev=(HR@5:0.4470,NDCG@5:0.3286) [0.9 s] *
INFO:root:Epoch 19    loss=0.2142 [21.2 s]    dev=(HR@5:0.4504,NDCG@5:0.3316) [1.0 s] *
INFO:root:Epoch 20    loss=0.2114 [21.2 s]    dev=(HR@5:0.4493,NDCG@5:0.3317) [0.9 s] *
INFO:root:Epoch 21    loss=0.2072 [21.3 s]    dev=(HR@5:0.4468,NDCG@5:0.3299) [0.9 s]
INFO:root:Epoch 22    loss=0.2072 [21.2 s]    dev=(HR@5:0.4461,NDCG@5:0.3317) [0.9 s]
INFO:root:Epoch 23    loss=0.2077 [21.3 s]    dev=(HR@5:0.4436,NDCG@5:0.3298) [1.0 s]
INFO:root:Epoch 24    loss=0.2059 [21.3 s]    dev=(HR@5:0.4493,NDCG@5:0.3306) [0.9 s]
INFO:root:Epoch 25    loss=0.2032 [21.4 s]    dev=(HR@5:0.4452,NDCG@5:0.3297) [0.9 s]
INFO:root:Epoch 26    loss=0.2036 [21.4 s]    dev=(HR@5:0.4455,NDCG@5:0.3292) [1.0 s]
INFO:root:Epoch 27    loss=0.2033 [21.2 s]    dev=(HR@5:0.4474,NDCG@5:0.3313) [0.9 s]
INFO:root:Epoch 28    loss=0.2024 [21.2 s]    dev=(HR@5:0.4504,NDCG@5:0.3349) [0.9 s] *
INFO:root:Epoch 29    loss=0.2010 [21.2 s]    dev=(HR@5:0.4466,NDCG@5:0.3310) [0.9 s]
INFO:root:Epoch 30    loss=0.2010 [21.3 s]    dev=(HR@5:0.4459,NDCG@5:0.3305) [1.0 s]
INFO:root:Epoch 31    loss=0.2003 [21.3 s]    dev=(HR@5:0.4511,NDCG@5:0.3354) [0.9 s] *
INFO:root:Epoch 32    loss=0.2007 [21.1 s]    dev=(HR@5:0.4508,NDCG@5:0.3321) [0.9 s]
INFO:root:Epoch 33    loss=0.2008 [21.2 s]    dev=(HR@5:0.4513,NDCG@5:0.3348) [0.9 s]
INFO:root:Epoch 34    loss=0.2001 [21.3 s]    dev=(HR@5:0.4497,NDCG@5:0.3329) [1.0 s]
INFO:root:Epoch 35    loss=0.2004 [21.2 s]    dev=(HR@5:0.4481,NDCG@5:0.3304) [1.0 s]
INFO:root:Epoch 36    loss=0.1980 [21.2 s]    dev=(HR@5:0.4479,NDCG@5:0.3293) [0.9 s]
INFO:root:Epoch 37    loss=0.1984 [21.2 s]    dev=(HR@5:0.4485,NDCG@5:0.3320) [0.9 s]
INFO:root:Epoch 38    loss=0.1989 [21.2 s]    dev=(HR@5:0.4511,NDCG@5:0.3325) [1.0 s]
INFO:root:Epoch 39    loss=0.1995 [21.2 s]    dev=(HR@5:0.4436,NDCG@5:0.3268) [0.9 s]
INFO:root:Epoch 40    loss=0.1978 [21.3 s]    dev=(HR@5:0.4494,NDCG@5:0.3304) [0.9 s]
INFO:root:Epoch 41    loss=0.1991 [21.2 s]    dev=(HR@5:0.4484,NDCG@5:0.3305) [1.0 s]
INFO:root:Epoch 42    loss=0.1987 [21.2 s]    dev=(HR@5:0.4513,NDCG@5:0.3309) [0.9 s]
INFO:root:Epoch 43    loss=0.1967 [21.2 s]    dev=(HR@5:0.4513,NDCG@5:0.3332) [0.9 s]
INFO:root:Epoch 44    loss=0.1990 [21.2 s]    dev=(HR@5:0.4490,NDCG@5:0.3299) [1.0 s]
INFO:root:Epoch 45    loss=0.1951 [21.2 s]    dev=(HR@5:0.4492,NDCG@5:0.3326) [0.9 s]
INFO:root:Epoch 46    loss=0.1969 [21.2 s]    dev=(HR@5:0.4490,NDCG@5:0.3310) [0.9 s]
INFO:root:Epoch 47    loss=0.1969 [21.2 s]    dev=(HR@5:0.4492,NDCG@5:0.3302) [1.0 s]
INFO:root:Epoch 48    loss=0.1970 [21.2 s]    dev=(HR@5:0.4472,NDCG@5:0.3291) [0.9 s]
INFO:root:Epoch 49    loss=0.1962 [21.1 s]    dev=(HR@5:0.4519,NDCG@5:0.3322) [0.9 s]
INFO:root:Epoch 50    loss=0.1973 [21.3 s]    dev=(HR@5:0.4470,NDCG@5:0.3298) [1.0 s]
INFO:root:Epoch 51    loss=0.1958 [21.3 s]    dev=(HR@5:0.4483,NDCG@5:0.3329) [0.9 s]
INFO:root:Early stop at 51 based on dev result.
INFO:root:
Best Iter(dev)=   31	 dev=(HR@5:0.4511,NDCG@5:0.3354) [1133.4 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.4026,NDCG@5:0.2894,HR@10:0.5095,NDCG@10:0.3240,HR@20:0.6320,NDCG@20:0.3549,HR@50:0.8343,NDCG@50:0.3949)
INFO:root:
--------------------------------------------- END: 2024-12-06 23:39:25 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-07 00:30:49 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5143 [27.6 s]    dev=(HR@5:0.2613,NDCG@5:0.1751) [1.0 s] *
INFO:root:Epoch 2     loss=0.4226 [21.8 s]    dev=(HR@5:0.3375,NDCG@5:0.2297) [1.0 s] *
INFO:root:Epoch 3     loss=0.3855 [21.7 s]    dev=(HR@5:0.3635,NDCG@5:0.2491) [0.9 s] *
INFO:root:Epoch 4     loss=0.3599 [22.8 s]    dev=(HR@5:0.3889,NDCG@5:0.2706) [1.0 s] *
INFO:root:Epoch 5     loss=0.3348 [22.0 s]    dev=(HR@5:0.4017,NDCG@5:0.2858) [1.0 s] *
INFO:root:Epoch 6     loss=0.3101 [21.9 s]    dev=(HR@5:0.4193,NDCG@5:0.2991) [1.0 s] *
INFO:root:Epoch 7     loss=0.2934 [22.0 s]    dev=(HR@5:0.4241,NDCG@5:0.3036) [1.0 s] *
INFO:root:Epoch 8     loss=0.2794 [22.5 s]    dev=(HR@5:0.4282,NDCG@5:0.3099) [1.0 s] *
INFO:root:Epoch 9     loss=0.2667 [21.9 s]    dev=(HR@5:0.4301,NDCG@5:0.3111) [1.0 s] *
INFO:root:Epoch 10    loss=0.2586 [21.8 s]    dev=(HR@5:0.4327,NDCG@5:0.3154) [1.0 s] *
INFO:root:Epoch 11    loss=0.2493 [22.0 s]    dev=(HR@5:0.4368,NDCG@5:0.3174) [1.0 s] *
INFO:root:Epoch 12    loss=0.2413 [22.2 s]    dev=(HR@5:0.4405,NDCG@5:0.3212) [1.0 s] *
INFO:root:Epoch 13    loss=0.2377 [22.0 s]    dev=(HR@5:0.4443,NDCG@5:0.3261) [0.9 s] *
INFO:root:Epoch 14    loss=0.2339 [21.7 s]    dev=(HR@5:0.4448,NDCG@5:0.3248) [0.9 s]
INFO:root:Epoch 15    loss=0.2300 [22.0 s]    dev=(HR@5:0.4417,NDCG@5:0.3230) [0.9 s]
INFO:root:Epoch 16    loss=0.2278 [21.7 s]    dev=(HR@5:0.4442,NDCG@5:0.3245) [1.0 s]
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-07 00:44:23 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:30:49 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:30:59 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:31:09 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:31:20 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:31:29 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:31:38 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:31:47 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:31:56 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:32:06 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:32:15 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:32:26 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:32:37 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:32:46 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:32:55 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:33:04 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:33:13 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:33:23 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:33:33 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:33:42 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:33:51 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:34:00 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:34:10 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:34:20 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:34:29 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:34:40 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:38:26 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:38:37 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:38:46 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:38:55 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:39:04 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:39:14 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:39:23 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:39:32 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:39:41 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:39:50 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:40:00 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:40:10 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:40:21 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:40:30 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:40:39 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:40:48 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:40:58 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:41:07 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:41:16 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-22 12:49:18 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [12.6 s]    dev=(HR@5:0.2505,NDCG@5:0.1665) [0.4 s] *
INFO:root:Epoch 2     loss=0.4331 [10.7 s]    dev=(HR@5:0.3203,NDCG@5:0.2166) [0.3 s] *
INFO:root:Epoch 3     loss=0.4000 [10.5 s]    dev=(HR@5:0.3404,NDCG@5:0.2289) [0.4 s] *
INFO:root:Epoch 4     loss=0.3827 [11.1 s]    dev=(HR@5:0.3599,NDCG@5:0.2482) [0.4 s] *
INFO:root:Epoch 5     loss=0.3608 [10.3 s]    dev=(HR@5:0.3731,NDCG@5:0.2591) [0.4 s] *
INFO:root:Epoch 6     loss=0.3380 [10.6 s]    dev=(HR@5:0.3863,NDCG@5:0.2737) [0.4 s] *
INFO:root:Epoch 7     loss=0.3214 [10.8 s]    dev=(HR@5:0.3915,NDCG@5:0.2776) [0.4 s] *
INFO:root:Epoch 8     loss=0.3055 [10.1 s]    dev=(HR@5:0.3977,NDCG@5:0.2847) [0.4 s] *
INFO:root:Epoch 9     loss=0.2904 [11.0 s]    dev=(HR@5:0.4012,NDCG@5:0.2880) [0.4 s] *
INFO:root:Epoch 10    loss=0.2795 [10.5 s]    dev=(HR@5:0.4056,NDCG@5:0.2920) [0.3 s] *
INFO:root:Epoch 11    loss=0.2678 [11.0 s]    dev=(HR@5:0.4132,NDCG@5:0.2980) [0.4 s] *
INFO:root:Epoch 12    loss=0.2585 [9.9 s]    dev=(HR@5:0.4158,NDCG@5:0.3004) [0.4 s] *
INFO:root:Epoch 13    loss=0.2531 [9.8 s]    dev=(HR@5:0.4226,NDCG@5:0.3069) [0.4 s] *
INFO:root:Epoch 14    loss=0.2459 [10.9 s]    dev=(HR@5:0.4192,NDCG@5:0.3050) [0.4 s]
INFO:root:Epoch 15    loss=0.2426 [11.4 s]    dev=(HR@5:0.4208,NDCG@5:0.3057) [0.4 s]
INFO:root:Epoch 16    loss=0.2376 [10.6 s]    dev=(HR@5:0.4231,NDCG@5:0.3077) [0.4 s] *
INFO:root:Epoch 17    loss=0.2345 [10.2 s]    dev=(HR@5:0.4210,NDCG@5:0.3076) [0.4 s]
INFO:root:Epoch 18    loss=0.2285 [10.2 s]    dev=(HR@5:0.4248,NDCG@5:0.3103) [0.4 s] *
INFO:root:Epoch 19    loss=0.2248 [11.4 s]    dev=(HR@5:0.4321,NDCG@5:0.3160) [0.4 s] *
INFO:root:Epoch 20    loss=0.2222 [11.3 s]    dev=(HR@5:0.4308,NDCG@5:0.3165) [0.4 s] *
INFO:root:Epoch 21    loss=0.2172 [9.6 s]    dev=(HR@5:0.4307,NDCG@5:0.3164) [0.3 s]
INFO:root:Epoch 22    loss=0.2153 [11.0 s]    dev=(HR@5:0.4289,NDCG@5:0.3139) [0.4 s]
INFO:root:Epoch 23    loss=0.2157 [10.2 s]    dev=(HR@5:0.4272,NDCG@5:0.3132) [0.3 s]
INFO:root:Epoch 24    loss=0.2144 [9.5 s]    dev=(HR@5:0.4331,NDCG@5:0.3173) [0.4 s] *
INFO:root:Epoch 25    loss=0.2101 [10.8 s]    dev=(HR@5:0.4316,NDCG@5:0.3166) [0.4 s]
INFO:root:Epoch 26    loss=0.2106 [11.2 s]    dev=(HR@5:0.4314,NDCG@5:0.3177) [0.4 s] *
INFO:root:Epoch 27    loss=0.2086 [10.5 s]    dev=(HR@5:0.4331,NDCG@5:0.3185) [0.4 s] *
INFO:root:Epoch 28    loss=0.2080 [10.0 s]    dev=(HR@5:0.4366,NDCG@5:0.3211) [0.4 s] *
INFO:root:Epoch 29    loss=0.2061 [9.8 s]    dev=(HR@5:0.4331,NDCG@5:0.3177) [0.4 s]
INFO:root:Epoch 30    loss=0.2056 [10.8 s]    dev=(HR@5:0.4340,NDCG@5:0.3187) [0.4 s]
INFO:root:Epoch 31    loss=0.2042 [11.0 s]    dev=(HR@5:0.4354,NDCG@5:0.3200) [0.3 s]
INFO:root:Epoch 32    loss=0.2051 [10.1 s]    dev=(HR@5:0.4345,NDCG@5:0.3191) [0.3 s]
INFO:root:Epoch 33    loss=0.2030 [11.1 s]    dev=(HR@5:0.4378,NDCG@5:0.3209) [0.4 s]
INFO:root:Epoch 34    loss=0.2025 [10.2 s]    dev=(HR@5:0.4351,NDCG@5:0.3201) [0.4 s]
INFO:root:Epoch 35    loss=0.2038 [10.8 s]    dev=(HR@5:0.4350,NDCG@5:0.3180) [0.4 s]
INFO:root:Epoch 36    loss=0.2002 [11.3 s]    dev=(HR@5:0.4339,NDCG@5:0.3181) [0.4 s]
INFO:root:Epoch 37    loss=0.2008 [10.4 s]    dev=(HR@5:0.4361,NDCG@5:0.3195) [0.4 s]
INFO:root:Epoch 38    loss=0.2012 [11.3 s]    dev=(HR@5:0.4383,NDCG@5:0.3197) [0.4 s]
INFO:root:Epoch 39    loss=0.2005 [10.0 s]    dev=(HR@5:0.4306,NDCG@5:0.3146) [0.4 s]
INFO:root:Epoch 40    loss=0.1999 [11.2 s]    dev=(HR@5:0.4318,NDCG@5:0.3185) [0.4 s]
INFO:root:Epoch 41    loss=0.2001 [11.3 s]    dev=(HR@5:0.4318,NDCG@5:0.3163) [0.4 s]
INFO:root:Epoch 42    loss=0.1998 [10.3 s]    dev=(HR@5:0.4333,NDCG@5:0.3167) [0.4 s]
INFO:root:Epoch 43    loss=0.1983 [10.1 s]    dev=(HR@5:0.4341,NDCG@5:0.3195) [0.4 s]
INFO:root:Epoch 44    loss=0.1996 [10.4 s]    dev=(HR@5:0.4341,NDCG@5:0.3172) [0.4 s]
INFO:root:Epoch 45    loss=0.1963 [11.2 s]    dev=(HR@5:0.4359,NDCG@5:0.3202) [0.4 s]
INFO:root:Epoch 46    loss=0.1978 [10.5 s]    dev=(HR@5:0.4334,NDCG@5:0.3179) [0.4 s]
INFO:root:Epoch 47    loss=0.1988 [9.3 s]    dev=(HR@5:0.4324,NDCG@5:0.3167) [0.3 s]
INFO:root:Epoch 48    loss=0.1965 [10.2 s]    dev=(HR@5:0.4306,NDCG@5:0.3141) [0.4 s]
INFO:root:Early stop at 48 based on dev result.
INFO:root:
Best Iter(dev)=   28	 dev=(HR@5:0.4366,NDCG@5:0.3211) [527.1 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.3867,NDCG@5:0.2760,HR@10:0.4925,NDCG@10:0.3103,HR@20:0.6116,NDCG@20:0.3402,HR@50:0.8232,NDCG@50:0.3820)
INFO:root:
--------------------------------------------- END: 2024-12-22 12:58:07 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-22 13:21:30 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [12.3 s]    dev=(HR@5:0.2509,NDCG@5:0.1668) [0.3 s] *
INFO:root:Epoch 2     loss=0.4327 [9.9 s]    dev=(HR@5:0.3210,NDCG@5:0.2176) [0.4 s] *
INFO:root:Epoch 3     loss=0.3998 [10.3 s]    dev=(HR@5:0.3395,NDCG@5:0.2283) [0.4 s] *
INFO:root:Epoch 4     loss=0.3839 [10.4 s]    dev=(HR@5:0.3579,NDCG@5:0.2466) [0.4 s] *
INFO:root:Epoch 5     loss=0.3606 [10.6 s]    dev=(HR@5:0.3743,NDCG@5:0.2597) [0.4 s] *
INFO:root:Epoch 6     loss=0.3363 [9.7 s]    dev=(HR@5:0.3909,NDCG@5:0.2759) [0.4 s] *
INFO:root:Epoch 7     loss=0.3179 [10.3 s]    dev=(HR@5:0.3962,NDCG@5:0.2803) [0.4 s] *
INFO:root:Epoch 8     loss=0.3004 [10.5 s]    dev=(HR@5:0.4005,NDCG@5:0.2866) [0.4 s] *
INFO:root:Epoch 9     loss=0.2842 [10.4 s]    dev=(HR@5:0.4037,NDCG@5:0.2913) [0.4 s] *
INFO:root:Epoch 10    loss=0.2736 [10.4 s]    dev=(HR@5:0.4109,NDCG@5:0.2956) [0.4 s] *
INFO:root:Epoch 11    loss=0.2625 [10.3 s]    dev=(HR@5:0.4154,NDCG@5:0.2982) [0.4 s] *
INFO:root:Epoch 12    loss=0.2540 [10.6 s]    dev=(HR@5:0.4180,NDCG@5:0.3017) [0.4 s] *
INFO:root:Epoch 13    loss=0.2491 [10.7 s]    dev=(HR@5:0.4220,NDCG@5:0.3065) [0.4 s] *
INFO:root:Epoch 14    loss=0.2427 [9.7 s]    dev=(HR@5:0.4187,NDCG@5:0.3034) [0.4 s]
INFO:root:Epoch 15    loss=0.2396 [10.9 s]    dev=(HR@5:0.4201,NDCG@5:0.3046) [0.4 s]
INFO:root:Epoch 16    loss=0.2347 [10.7 s]    dev=(HR@5:0.4225,NDCG@5:0.3076) [0.4 s] *
INFO:root:Epoch 17    loss=0.2314 [10.5 s]    dev=(HR@5:0.4205,NDCG@5:0.3073) [0.4 s]
INFO:root:Epoch 18    loss=0.2266 [10.7 s]    dev=(HR@5:0.4281,NDCG@5:0.3113) [0.4 s] *
INFO:root:Epoch 19    loss=0.2229 [10.9 s]    dev=(HR@5:0.4253,NDCG@5:0.3113) [0.4 s]
INFO:root:Epoch 20    loss=0.2210 [10.5 s]    dev=(HR@5:0.4278,NDCG@5:0.3138) [0.4 s] *
INFO:root:Epoch 21    loss=0.2161 [10.3 s]    dev=(HR@5:0.4295,NDCG@5:0.3146) [0.4 s] *
INFO:root:Epoch 22    loss=0.2146 [10.4 s]    dev=(HR@5:0.4267,NDCG@5:0.3136) [0.4 s]
INFO:root:Epoch 23    loss=0.2145 [10.8 s]    dev=(HR@5:0.4236,NDCG@5:0.3112) [0.4 s]
INFO:root:Epoch 24    loss=0.2136 [10.9 s]    dev=(HR@5:0.4311,NDCG@5:0.3156) [0.4 s] *
INFO:root:Epoch 25    loss=0.2099 [10.1 s]    dev=(HR@5:0.4288,NDCG@5:0.3146) [0.4 s]
INFO:root:Epoch 26    loss=0.2098 [10.1 s]    dev=(HR@5:0.4314,NDCG@5:0.3178) [0.4 s] *
INFO:root:Epoch 27    loss=0.2091 [10.5 s]    dev=(HR@5:0.4312,NDCG@5:0.3181) [0.4 s] *
INFO:root:Epoch 28    loss=0.2079 [10.0 s]    dev=(HR@5:0.4321,NDCG@5:0.3186) [0.4 s] *
INFO:root:Epoch 29    loss=0.2064 [10.4 s]    dev=(HR@5:0.4292,NDCG@5:0.3147) [0.3 s]
INFO:root:Epoch 30    loss=0.2054 [10.2 s]    dev=(HR@5:0.4330,NDCG@5:0.3198) [0.4 s] *
INFO:root:Epoch 31    loss=0.2041 [10.9 s]    dev=(HR@5:0.4348,NDCG@5:0.3199) [0.4 s] *
INFO:root:Epoch 32    loss=0.2045 [10.9 s]    dev=(HR@5:0.4361,NDCG@5:0.3209) [0.4 s] *
INFO:root:Epoch 33    loss=0.2026 [11.5 s]    dev=(HR@5:0.4340,NDCG@5:0.3193) [0.4 s]
INFO:root:Epoch 34    loss=0.2016 [11.0 s]    dev=(HR@5:0.4313,NDCG@5:0.3170) [0.4 s]
INFO:root:Epoch 35    loss=0.2025 [10.7 s]    dev=(HR@5:0.4304,NDCG@5:0.3153) [0.4 s]
INFO:root:Epoch 36    loss=0.2002 [10.2 s]    dev=(HR@5:0.4353,NDCG@5:0.3188) [0.4 s]
INFO:root:Epoch 37    loss=0.1997 [11.4 s]    dev=(HR@5:0.4323,NDCG@5:0.3169) [0.4 s]
INFO:root:Epoch 38    loss=0.2008 [10.7 s]    dev=(HR@5:0.4352,NDCG@5:0.3181) [0.4 s]
INFO:root:Epoch 39    loss=0.1996 [10.5 s]    dev=(HR@5:0.4306,NDCG@5:0.3152) [0.4 s]
INFO:root:Epoch 40    loss=0.1984 [11.2 s]    dev=(HR@5:0.4337,NDCG@5:0.3191) [0.4 s]
INFO:root:Epoch 41    loss=0.1986 [10.9 s]    dev=(HR@5:0.4336,NDCG@5:0.3174) [0.4 s]
INFO:root:Epoch 42    loss=0.1990 [10.7 s]    dev=(HR@5:0.4357,NDCG@5:0.3194) [0.4 s]
INFO:root:Epoch 43    loss=0.1974 [10.9 s]    dev=(HR@5:0.4352,NDCG@5:0.3202) [0.4 s]
INFO:root:Epoch 44    loss=0.1986 [11.2 s]    dev=(HR@5:0.4354,NDCG@5:0.3195) [0.4 s]
INFO:root:Epoch 45    loss=0.1947 [10.9 s]    dev=(HR@5:0.4369,NDCG@5:0.3217) [0.4 s] *
INFO:root:Epoch 46    loss=0.1955 [11.0 s]    dev=(HR@5:0.4346,NDCG@5:0.3202) [0.4 s]
INFO:root:Epoch 47    loss=0.1971 [10.4 s]    dev=(HR@5:0.4387,NDCG@5:0.3204) [0.4 s]
INFO:root:Epoch 48    loss=0.1943 [10.9 s]    dev=(HR@5:0.4338,NDCG@5:0.3168) [0.4 s]
INFO:root:Epoch 49    loss=0.1943 [11.1 s]    dev=(HR@5:0.4404,NDCG@5:0.3240) [0.4 s] *
INFO:root:Epoch 50    loss=0.1956 [11.2 s]    dev=(HR@5:0.4358,NDCG@5:0.3208) [0.4 s]
INFO:root:Epoch 51    loss=0.1940 [9.8 s]    dev=(HR@5:0.4368,NDCG@5:0.3214) [0.4 s]
INFO:root:Epoch 52    loss=0.1942 [10.9 s]    dev=(HR@5:0.4333,NDCG@5:0.3183) [0.4 s]
INFO:root:Epoch 53    loss=0.1934 [10.9 s]    dev=(HR@5:0.4338,NDCG@5:0.3178) [0.3 s]
INFO:root:Epoch 54    loss=0.1915 [11.5 s]    dev=(HR@5:0.4345,NDCG@5:0.3206) [0.4 s]
INFO:root:Epoch 55    loss=0.1919 [11.0 s]    dev=(HR@5:0.4394,NDCG@5:0.3218) [0.4 s]
INFO:root:Epoch 56    loss=0.1920 [10.3 s]    dev=(HR@5:0.4361,NDCG@5:0.3218) [0.4 s]
INFO:root:Epoch 57    loss=0.1924 [11.4 s]    dev=(HR@5:0.4392,NDCG@5:0.3254) [0.4 s] *
INFO:root:Epoch 58    loss=0.1931 [11.1 s]    dev=(HR@5:0.4400,NDCG@5:0.3234) [0.4 s]
INFO:root:Epoch 59    loss=0.1910 [10.8 s]    dev=(HR@5:0.4349,NDCG@5:0.3204) [0.3 s]
INFO:root:Epoch 60    loss=0.1919 [11.3 s]    dev=(HR@5:0.4323,NDCG@5:0.3186) [0.4 s]
INFO:root:Epoch 61    loss=0.1917 [10.6 s]    dev=(HR@5:0.4402,NDCG@5:0.3236) [0.4 s]
INFO:root:Epoch 62    loss=0.1913 [10.8 s]    dev=(HR@5:0.4395,NDCG@5:0.3228) [0.4 s]
INFO:root:Epoch 63    loss=0.1921 [11.3 s]    dev=(HR@5:0.4410,NDCG@5:0.3227) [0.4 s]
INFO:root:Epoch 64    loss=0.1905 [10.6 s]    dev=(HR@5:0.4372,NDCG@5:0.3191) [0.4 s]
INFO:root:Epoch 65    loss=0.1920 [10.9 s]    dev=(HR@5:0.4380,NDCG@5:0.3209) [0.4 s]
INFO:root:Epoch 66    loss=0.1895 [10.6 s]    dev=(HR@5:0.4395,NDCG@5:0.3195) [0.4 s]
INFO:root:Epoch 67    loss=0.1903 [10.4 s]    dev=(HR@5:0.4399,NDCG@5:0.3221) [0.4 s]
INFO:root:Epoch 68    loss=0.1879 [10.5 s]    dev=(HR@5:0.4373,NDCG@5:0.3216) [0.4 s]
INFO:root:Epoch 69    loss=0.1902 [10.8 s]    dev=(HR@5:0.4402,NDCG@5:0.3244) [0.3 s]
INFO:root:Epoch 70    loss=0.1894 [10.6 s]    dev=(HR@5:0.4401,NDCG@5:0.3238) [0.3 s]
INFO:root:Epoch 71    loss=0.1890 [8.8 s]    dev=(HR@5:0.4405,NDCG@5:0.3255) [0.4 s] *
INFO:root:Epoch 72    loss=0.1878 [10.5 s]    dev=(HR@5:0.4394,NDCG@5:0.3238) [0.4 s]
INFO:root:Epoch 73    loss=0.1886 [10.9 s]    dev=(HR@5:0.4385,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 74    loss=0.1893 [10.9 s]    dev=(HR@5:0.4378,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 75    loss=0.1910 [11.0 s]    dev=(HR@5:0.4375,NDCG@5:0.3234) [0.4 s]
INFO:root:Epoch 76    loss=0.1895 [11.4 s]    dev=(HR@5:0.4417,NDCG@5:0.3249) [0.4 s]
INFO:root:Epoch 77    loss=0.1876 [9.7 s]    dev=(HR@5:0.4389,NDCG@5:0.3239) [0.4 s]
INFO:root:Epoch 78    loss=0.1882 [10.7 s]    dev=(HR@5:0.4376,NDCG@5:0.3226) [0.4 s]
INFO:root:Epoch 79    loss=0.1886 [11.5 s]    dev=(HR@5:0.4460,NDCG@5:0.3287) [0.4 s] *
INFO:root:Epoch 80    loss=0.1872 [11.1 s]    dev=(HR@5:0.4434,NDCG@5:0.3240) [0.3 s]
INFO:root:Epoch 81    loss=0.1869 [11.6 s]    dev=(HR@5:0.4367,NDCG@5:0.3183) [0.4 s]
INFO:root:Epoch 82    loss=0.1881 [11.2 s]    dev=(HR@5:0.4396,NDCG@5:0.3229) [0.4 s]
INFO:root:Epoch 83    loss=0.1865 [11.1 s]    dev=(HR@5:0.4431,NDCG@5:0.3262) [0.4 s]
INFO:root:Epoch 84    loss=0.1868 [10.7 s]    dev=(HR@5:0.4409,NDCG@5:0.3260) [0.4 s]
INFO:root:Epoch 85    loss=0.1879 [11.1 s]    dev=(HR@5:0.4428,NDCG@5:0.3265) [0.4 s]
INFO:root:Epoch 86    loss=0.1884 [10.7 s]    dev=(HR@5:0.4329,NDCG@5:0.3202) [0.4 s]
INFO:root:Epoch 87    loss=0.1867 [10.1 s]    dev=(HR@5:0.4381,NDCG@5:0.3237) [0.4 s]
INFO:root:Epoch 88    loss=0.1866 [10.9 s]    dev=(HR@5:0.4387,NDCG@5:0.3228) [0.4 s]
INFO:root:Epoch 89    loss=0.1850 [11.2 s]    dev=(HR@5:0.4361,NDCG@5:0.3221) [0.4 s]
INFO:root:Epoch 90    loss=0.1852 [10.9 s]    dev=(HR@5:0.4409,NDCG@5:0.3241) [0.4 s]
INFO:root:Epoch 91    loss=0.1866 [10.8 s]    dev=(HR@5:0.4421,NDCG@5:0.3259) [0.4 s]
INFO:root:Epoch 92    loss=0.1838 [10.4 s]    dev=(HR@5:0.4356,NDCG@5:0.3198) [0.4 s]
INFO:root:Epoch 93    loss=0.1865 [11.0 s]    dev=(HR@5:0.4390,NDCG@5:0.3207) [0.3 s]
INFO:root:Epoch 94    loss=0.1864 [11.1 s]    dev=(HR@5:0.4373,NDCG@5:0.3240) [0.4 s]
INFO:root:Epoch 95    loss=0.1861 [10.4 s]    dev=(HR@5:0.4411,NDCG@5:0.3253) [0.4 s]
INFO:root:Epoch 96    loss=0.1849 [10.9 s]    dev=(HR@5:0.4366,NDCG@5:0.3221) [0.4 s]
INFO:root:Epoch 97    loss=0.1854 [11.3 s]    dev=(HR@5:0.4370,NDCG@5:0.3205) [0.4 s]
INFO:root:Epoch 98    loss=0.1847 [11.3 s]    dev=(HR@5:0.4376,NDCG@5:0.3214) [0.4 s]
INFO:root:Epoch 99    loss=0.1855 [11.6 s]    dev=(HR@5:0.4391,NDCG@5:0.3226) [0.4 s]
INFO:root:Early stop at 99 based on dev result.
INFO:root:
Best Iter(dev)=   79	 dev=(HR@5:0.4460,NDCG@5:0.3287) [1101.5 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.3983,NDCG@5:0.2858,HR@10:0.5078,NDCG@10:0.3214,HR@20:0.6281,NDCG@20:0.3517,HR@50:0.8367,NDCG@50:0.3931)
INFO:root:
--------------------------------------------- END: 2024-12-22 13:39:55 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-22 14:24:30 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [12.5 s]    dev=(HR@5:0.2505,NDCG@5:0.1665) [0.4 s] *
INFO:root:Epoch 2     loss=0.4331 [11.1 s]    dev=(HR@5:0.3203,NDCG@5:0.2166) [0.3 s] *
INFO:root:Epoch 3     loss=0.4000 [10.7 s]    dev=(HR@5:0.3404,NDCG@5:0.2289) [0.3 s] *
INFO:root:Epoch 4     loss=0.3827 [10.8 s]    dev=(HR@5:0.3599,NDCG@5:0.2482) [0.4 s] *
INFO:root:Epoch 5     loss=0.3608 [10.3 s]    dev=(HR@5:0.3731,NDCG@5:0.2591) [0.4 s] *
INFO:root:Epoch 6     loss=0.3380 [11.0 s]    dev=(HR@5:0.3863,NDCG@5:0.2737) [0.4 s] *
INFO:root:Epoch 7     loss=0.3214 [11.0 s]    dev=(HR@5:0.3915,NDCG@5:0.2776) [0.4 s] *
INFO:root:Epoch 8     loss=0.3055 [10.4 s]    dev=(HR@5:0.3977,NDCG@5:0.2847) [0.4 s] *
INFO:root:Epoch 9     loss=0.2904 [10.5 s]    dev=(HR@5:0.4012,NDCG@5:0.2880) [0.4 s] *
INFO:root:Epoch 10    loss=0.2795 [11.1 s]    dev=(HR@5:0.4056,NDCG@5:0.2920) [0.4 s] *
INFO:root:Epoch 11    loss=0.2678 [11.1 s]    dev=(HR@5:0.4132,NDCG@5:0.2980) [0.4 s] *
INFO:root:Epoch 12    loss=0.2585 [10.9 s]    dev=(HR@5:0.4158,NDCG@5:0.3004) [0.4 s] *
INFO:root:Epoch 13    loss=0.2531 [11.6 s]    dev=(HR@5:0.4226,NDCG@5:0.3069) [0.4 s] *
INFO:root:Epoch 14    loss=0.2459 [10.2 s]    dev=(HR@5:0.4192,NDCG@5:0.3050) [0.4 s]
INFO:root:Epoch 15    loss=0.2426 [11.1 s]    dev=(HR@5:0.4208,NDCG@5:0.3057) [0.4 s]
INFO:root:Epoch 16    loss=0.2376 [10.4 s]    dev=(HR@5:0.4231,NDCG@5:0.3077) [0.4 s] *
INFO:root:Epoch 17    loss=0.2345 [10.9 s]    dev=(HR@5:0.4210,NDCG@5:0.3076) [0.4 s]
INFO:root:Epoch 18    loss=0.2285 [11.4 s]    dev=(HR@5:0.4248,NDCG@5:0.3103) [0.4 s] *
INFO:root:Epoch 19    loss=0.2248 [10.0 s]    dev=(HR@5:0.4321,NDCG@5:0.3160) [0.4 s] *
INFO:root:Epoch 20    loss=0.2222 [11.4 s]    dev=(HR@5:0.4308,NDCG@5:0.3165) [0.4 s] *
INFO:root:Epoch 21    loss=0.2172 [11.4 s]    dev=(HR@5:0.4307,NDCG@5:0.3164) [0.4 s]
INFO:root:Epoch 22    loss=0.2153 [10.1 s]    dev=(HR@5:0.4289,NDCG@5:0.3139) [0.4 s]
INFO:root:Epoch 23    loss=0.2157 [11.1 s]    dev=(HR@5:0.4272,NDCG@5:0.3132) [0.4 s]
INFO:root:Epoch 24    loss=0.2144 [10.6 s]    dev=(HR@5:0.4331,NDCG@5:0.3173) [0.4 s] *
INFO:root:Epoch 25    loss=0.2101 [10.7 s]    dev=(HR@5:0.4316,NDCG@5:0.3166) [0.4 s]
INFO:root:Epoch 26    loss=0.2106 [9.8 s]    dev=(HR@5:0.4314,NDCG@5:0.3177) [0.4 s] *
INFO:root:Epoch 27    loss=0.2086 [11.1 s]    dev=(HR@5:0.4331,NDCG@5:0.3185) [0.4 s] *
INFO:root:Epoch 28    loss=0.2080 [11.0 s]    dev=(HR@5:0.4366,NDCG@5:0.3211) [0.4 s] *
INFO:root:Epoch 29    loss=0.2061 [10.5 s]    dev=(HR@5:0.4331,NDCG@5:0.3177) [0.4 s]
INFO:root:Epoch 30    loss=0.2056 [10.4 s]    dev=(HR@5:0.4340,NDCG@5:0.3187) [0.4 s]
INFO:root:Epoch 31    loss=0.2042 [11.3 s]    dev=(HR@5:0.4354,NDCG@5:0.3200) [0.4 s]
INFO:root:Epoch 32    loss=0.2051 [9.8 s]    dev=(HR@5:0.4345,NDCG@5:0.3191) [0.4 s]
INFO:root:Epoch 33    loss=0.2030 [11.2 s]    dev=(HR@5:0.4378,NDCG@5:0.3209) [0.4 s]
INFO:root:Epoch 34    loss=0.2025 [10.0 s]    dev=(HR@5:0.4351,NDCG@5:0.3201) [0.3 s]
INFO:root:Epoch 35    loss=0.2038 [10.4 s]    dev=(HR@5:0.4350,NDCG@5:0.3180) [0.4 s]
INFO:root:Epoch 36    loss=0.2002 [10.8 s]    dev=(HR@5:0.4339,NDCG@5:0.3181) [0.4 s]
INFO:root:Epoch 37    loss=0.2008 [10.4 s]    dev=(HR@5:0.4361,NDCG@5:0.3195) [0.4 s]
INFO:root:Epoch 38    loss=0.2012 [11.4 s]    dev=(HR@5:0.4383,NDCG@5:0.3197) [0.4 s]
INFO:root:Epoch 39    loss=0.2005 [11.5 s]    dev=(HR@5:0.4306,NDCG@5:0.3146) [0.4 s]
INFO:root:Epoch 40    loss=0.1999 [10.4 s]    dev=(HR@5:0.4318,NDCG@5:0.3185) [0.4 s]
INFO:root:Epoch 41    loss=0.2001 [10.1 s]    dev=(HR@5:0.4318,NDCG@5:0.3163) [0.4 s]
INFO:root:Epoch 42    loss=0.1998 [11.0 s]    dev=(HR@5:0.4333,NDCG@5:0.3167) [0.4 s]
INFO:root:Epoch 43    loss=0.1983 [11.3 s]    dev=(HR@5:0.4341,NDCG@5:0.3195) [0.4 s]
INFO:root:Epoch 44    loss=0.1996 [10.2 s]    dev=(HR@5:0.4341,NDCG@5:0.3172) [0.4 s]
INFO:root:Epoch 45    loss=0.1963 [11.1 s]    dev=(HR@5:0.4359,NDCG@5:0.3202) [0.4 s]
INFO:root:Epoch 46    loss=0.1978 [10.8 s]    dev=(HR@5:0.4334,NDCG@5:0.3179) [0.4 s]
INFO:root:Epoch 47    loss=0.1988 [11.0 s]    dev=(HR@5:0.4324,NDCG@5:0.3167) [0.4 s]
INFO:root:Epoch 48    loss=0.1965 [10.0 s]    dev=(HR@5:0.4306,NDCG@5:0.3141) [0.4 s]
INFO:root:Early stop at 48 based on dev result.
INFO:root:
Best Iter(dev)=   28	 dev=(HR@5:0.4366,NDCG@5:0.3211) [536.4 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.3867,NDCG@5:0.2760,HR@10:0.4925,NDCG@10:0.3103,HR@20:0.6116,NDCG@20:0.3402,HR@50:0.8232,NDCG@50:0.3820)
INFO:root:
--------------------------------------------- END: 2024-12-22 14:33:29 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-22 14:58:16 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [12.4 s]    dev=(HR@5:0.2509,NDCG@5:0.1668) [0.4 s] *
INFO:root:Epoch 2     loss=0.4327 [11.2 s]    dev=(HR@5:0.3210,NDCG@5:0.2176) [0.4 s] *
INFO:root:Epoch 3     loss=0.3998 [10.2 s]    dev=(HR@5:0.3395,NDCG@5:0.2283) [0.4 s] *
INFO:root:Epoch 4     loss=0.3839 [10.3 s]    dev=(HR@5:0.3579,NDCG@5:0.2466) [0.4 s] *
INFO:root:Epoch 5     loss=0.3606 [11.3 s]    dev=(HR@5:0.3743,NDCG@5:0.2597) [0.4 s] *
INFO:root:Epoch 6     loss=0.3363 [10.3 s]    dev=(HR@5:0.3909,NDCG@5:0.2759) [0.4 s] *
INFO:root:Epoch 7     loss=0.3179 [10.3 s]    dev=(HR@5:0.3962,NDCG@5:0.2803) [0.4 s] *
INFO:root:Epoch 8     loss=0.3004 [11.2 s]    dev=(HR@5:0.4005,NDCG@5:0.2866) [0.4 s] *
INFO:root:Epoch 9     loss=0.2842 [11.1 s]    dev=(HR@5:0.4037,NDCG@5:0.2913) [0.4 s] *
INFO:root:Epoch 10    loss=0.2736 [10.0 s]    dev=(HR@5:0.4109,NDCG@5:0.2956) [0.4 s] *
INFO:root:Epoch 11    loss=0.2625 [11.2 s]    dev=(HR@5:0.4154,NDCG@5:0.2982) [0.4 s] *
INFO:root:Epoch 12    loss=0.2540 [10.0 s]    dev=(HR@5:0.4180,NDCG@5:0.3017) [0.4 s] *
INFO:root:Epoch 13    loss=0.2491 [11.0 s]    dev=(HR@5:0.4220,NDCG@5:0.3065) [0.4 s] *
INFO:root:Epoch 14    loss=0.2427 [10.3 s]    dev=(HR@5:0.4187,NDCG@5:0.3034) [0.4 s]
INFO:root:Epoch 15    loss=0.2396 [10.1 s]    dev=(HR@5:0.4201,NDCG@5:0.3046) [0.4 s]
INFO:root:Epoch 16    loss=0.2347 [10.6 s]    dev=(HR@5:0.4225,NDCG@5:0.3076) [0.4 s] *
INFO:root:Epoch 17    loss=0.2314 [11.1 s]    dev=(HR@5:0.4205,NDCG@5:0.3073) [0.4 s]
INFO:root:Epoch 18    loss=0.2266 [10.7 s]    dev=(HR@5:0.4281,NDCG@5:0.3113) [0.3 s] *
INFO:root:Epoch 19    loss=0.2229 [11.2 s]    dev=(HR@5:0.4253,NDCG@5:0.3113) [0.3 s]
INFO:root:Epoch 20    loss=0.2210 [10.4 s]    dev=(HR@5:0.4278,NDCG@5:0.3138) [0.4 s] *
INFO:root:Epoch 21    loss=0.2161 [11.3 s]    dev=(HR@5:0.4295,NDCG@5:0.3146) [0.4 s] *
INFO:root:Epoch 22    loss=0.2146 [9.9 s]    dev=(HR@5:0.4267,NDCG@5:0.3136) [0.4 s]
INFO:root:Epoch 23    loss=0.2145 [10.7 s]    dev=(HR@5:0.4236,NDCG@5:0.3112) [0.3 s]
INFO:root:Epoch 24    loss=0.2136 [10.7 s]    dev=(HR@5:0.4311,NDCG@5:0.3156) [0.4 s] *
INFO:root:Epoch 25    loss=0.2099 [9.7 s]    dev=(HR@5:0.4288,NDCG@5:0.3146) [0.4 s]
INFO:root:Epoch 26    loss=0.2098 [11.2 s]    dev=(HR@5:0.4314,NDCG@5:0.3178) [0.4 s] *
INFO:root:Epoch 27    loss=0.2091 [11.2 s]    dev=(HR@5:0.4312,NDCG@5:0.3181) [0.4 s] *
INFO:root:Epoch 28    loss=0.2079 [10.3 s]    dev=(HR@5:0.4321,NDCG@5:0.3186) [0.4 s] *
INFO:root:Epoch 29    loss=0.2064 [11.5 s]    dev=(HR@5:0.4292,NDCG@5:0.3147) [0.4 s]
INFO:root:Epoch 30    loss=0.2054 [10.1 s]    dev=(HR@5:0.4330,NDCG@5:0.3198) [0.4 s] *
INFO:root:Epoch 31    loss=0.2041 [10.6 s]    dev=(HR@5:0.4348,NDCG@5:0.3199) [0.4 s] *
INFO:root:Epoch 32    loss=0.2045 [10.4 s]    dev=(HR@5:0.4361,NDCG@5:0.3209) [0.4 s] *
INFO:root:Epoch 33    loss=0.2026 [10.0 s]    dev=(HR@5:0.4340,NDCG@5:0.3193) [0.4 s]
INFO:root:Epoch 34    loss=0.2016 [10.1 s]    dev=(HR@5:0.4313,NDCG@5:0.3170) [0.4 s]
INFO:root:Epoch 35    loss=0.2025 [10.2 s]    dev=(HR@5:0.4304,NDCG@5:0.3153) [0.4 s]
INFO:root:Epoch 36    loss=0.2002 [11.3 s]    dev=(HR@5:0.4353,NDCG@5:0.3188) [0.4 s]
INFO:root:Epoch 37    loss=0.1997 [11.4 s]    dev=(HR@5:0.4323,NDCG@5:0.3169) [0.4 s]
INFO:root:Epoch 38    loss=0.2008 [10.3 s]    dev=(HR@5:0.4352,NDCG@5:0.3181) [0.4 s]
INFO:root:Epoch 39    loss=0.1996 [10.4 s]    dev=(HR@5:0.4306,NDCG@5:0.3152) [0.4 s]
INFO:root:Epoch 40    loss=0.1984 [10.9 s]    dev=(HR@5:0.4337,NDCG@5:0.3191) [0.4 s]
INFO:root:Epoch 41    loss=0.1986 [11.1 s]    dev=(HR@5:0.4336,NDCG@5:0.3174) [0.4 s]
INFO:root:Epoch 42    loss=0.1990 [9.8 s]    dev=(HR@5:0.4357,NDCG@5:0.3194) [0.4 s]
INFO:root:Epoch 43    loss=0.1974 [9.4 s]    dev=(HR@5:0.4352,NDCG@5:0.3202) [0.4 s]
INFO:root:Epoch 44    loss=0.1986 [10.7 s]    dev=(HR@5:0.4354,NDCG@5:0.3195) [0.4 s]
INFO:root:Epoch 45    loss=0.1947 [10.7 s]    dev=(HR@5:0.4369,NDCG@5:0.3217) [0.4 s] *
INFO:root:Epoch 46    loss=0.1955 [11.5 s]    dev=(HR@5:0.4346,NDCG@5:0.3202) [0.4 s]
INFO:root:Epoch 47    loss=0.1971 [10.4 s]    dev=(HR@5:0.4387,NDCG@5:0.3204) [0.4 s]
INFO:root:Epoch 48    loss=0.1943 [11.2 s]    dev=(HR@5:0.4338,NDCG@5:0.3168) [0.4 s]
INFO:root:Epoch 49    loss=0.1943 [10.6 s]    dev=(HR@5:0.4404,NDCG@5:0.3240) [0.3 s] *
INFO:root:Epoch 50    loss=0.1956 [11.2 s]    dev=(HR@5:0.4358,NDCG@5:0.3208) [0.4 s]
INFO:root:Epoch 51    loss=0.1940 [11.1 s]    dev=(HR@5:0.4368,NDCG@5:0.3214) [0.4 s]
INFO:root:Epoch 52    loss=0.1942 [10.2 s]    dev=(HR@5:0.4333,NDCG@5:0.3183) [0.4 s]
INFO:root:Epoch 53    loss=0.1934 [10.2 s]    dev=(HR@5:0.4338,NDCG@5:0.3178) [0.4 s]
INFO:root:Epoch 54    loss=0.1915 [11.2 s]    dev=(HR@5:0.4345,NDCG@5:0.3206) [0.4 s]
INFO:root:Epoch 55    loss=0.1919 [10.8 s]    dev=(HR@5:0.4394,NDCG@5:0.3218) [0.4 s]
INFO:root:Epoch 56    loss=0.1920 [10.7 s]    dev=(HR@5:0.4361,NDCG@5:0.3218) [0.4 s]
INFO:root:Epoch 57    loss=0.1924 [10.8 s]    dev=(HR@5:0.4392,NDCG@5:0.3254) [0.4 s] *
INFO:root:Epoch 58    loss=0.1931 [10.3 s]    dev=(HR@5:0.4400,NDCG@5:0.3234) [0.4 s]
INFO:root:Epoch 59    loss=0.1910 [11.0 s]    dev=(HR@5:0.4349,NDCG@5:0.3204) [0.4 s]
INFO:root:Epoch 60    loss=0.1919 [11.0 s]    dev=(HR@5:0.4323,NDCG@5:0.3186) [0.4 s]
INFO:root:Epoch 61    loss=0.1917 [10.6 s]    dev=(HR@5:0.4402,NDCG@5:0.3236) [0.4 s]
INFO:root:Epoch 62    loss=0.1913 [10.2 s]    dev=(HR@5:0.4395,NDCG@5:0.3228) [0.4 s]
INFO:root:Epoch 63    loss=0.1921 [10.5 s]    dev=(HR@5:0.4410,NDCG@5:0.3227) [0.4 s]
INFO:root:Epoch 64    loss=0.1905 [10.8 s]    dev=(HR@5:0.4372,NDCG@5:0.3191) [0.4 s]
INFO:root:Epoch 65    loss=0.1920 [10.7 s]    dev=(HR@5:0.4380,NDCG@5:0.3209) [0.4 s]
INFO:root:Epoch 66    loss=0.1895 [10.2 s]    dev=(HR@5:0.4395,NDCG@5:0.3195) [0.4 s]
INFO:root:Epoch 67    loss=0.1903 [10.3 s]    dev=(HR@5:0.4399,NDCG@5:0.3221) [0.4 s]
INFO:root:Epoch 68    loss=0.1879 [11.4 s]    dev=(HR@5:0.4373,NDCG@5:0.3216) [0.4 s]
INFO:root:Epoch 69    loss=0.1902 [11.2 s]    dev=(HR@5:0.4402,NDCG@5:0.3244) [0.4 s]
INFO:root:Epoch 70    loss=0.1894 [10.2 s]    dev=(HR@5:0.4401,NDCG@5:0.3238) [0.4 s]
INFO:root:Epoch 71    loss=0.1890 [9.2 s]    dev=(HR@5:0.4405,NDCG@5:0.3255) [0.4 s] *
INFO:root:Epoch 72    loss=0.1878 [10.7 s]    dev=(HR@5:0.4394,NDCG@5:0.3238) [0.3 s]
INFO:root:Epoch 73    loss=0.1886 [10.8 s]    dev=(HR@5:0.4385,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 74    loss=0.1893 [10.3 s]    dev=(HR@5:0.4378,NDCG@5:0.3213) [0.3 s]
INFO:root:Epoch 75    loss=0.1910 [11.2 s]    dev=(HR@5:0.4375,NDCG@5:0.3234) [0.4 s]
INFO:root:Epoch 76    loss=0.1895 [10.4 s]    dev=(HR@5:0.4417,NDCG@5:0.3249) [0.4 s]
INFO:root:Epoch 77    loss=0.1876 [10.2 s]    dev=(HR@5:0.4389,NDCG@5:0.3239) [0.4 s]
INFO:root:Epoch 78    loss=0.1882 [10.3 s]    dev=(HR@5:0.4376,NDCG@5:0.3226) [0.3 s]
INFO:root:Epoch 79    loss=0.1886 [11.1 s]    dev=(HR@5:0.4460,NDCG@5:0.3287) [0.4 s] *
INFO:root:Epoch 80    loss=0.1872 [10.3 s]    dev=(HR@5:0.4434,NDCG@5:0.3240) [0.4 s]
INFO:root:Epoch 81    loss=0.1869 [11.3 s]    dev=(HR@5:0.4367,NDCG@5:0.3183) [0.4 s]
INFO:root:Epoch 82    loss=0.1881 [11.5 s]    dev=(HR@5:0.4396,NDCG@5:0.3229) [0.4 s]
INFO:root:Epoch 83    loss=0.1865 [10.5 s]    dev=(HR@5:0.4431,NDCG@5:0.3262) [0.4 s]
INFO:root:Epoch 84    loss=0.1868 [10.6 s]    dev=(HR@5:0.4409,NDCG@5:0.3260) [0.4 s]
INFO:root:Epoch 85    loss=0.1879 [11.2 s]    dev=(HR@5:0.4428,NDCG@5:0.3265) [0.4 s]
INFO:root:Epoch 86    loss=0.1884 [10.9 s]    dev=(HR@5:0.4329,NDCG@5:0.3202) [0.4 s]
INFO:root:Epoch 87    loss=0.1867 [10.6 s]    dev=(HR@5:0.4381,NDCG@5:0.3237) [0.4 s]
INFO:root:Epoch 88    loss=0.1866 [10.3 s]    dev=(HR@5:0.4387,NDCG@5:0.3228) [0.3 s]
INFO:root:Epoch 89    loss=0.1850 [11.2 s]    dev=(HR@5:0.4361,NDCG@5:0.3221) [0.4 s]
INFO:root:Epoch 90    loss=0.1852 [11.2 s]    dev=(HR@5:0.4409,NDCG@5:0.3241) [0.4 s]
INFO:root:Epoch 91    loss=0.1866 [10.7 s]    dev=(HR@5:0.4421,NDCG@5:0.3259) [0.4 s]
INFO:root:Epoch 92    loss=0.1838 [10.2 s]    dev=(HR@5:0.4356,NDCG@5:0.3198) [0.4 s]
INFO:root:Epoch 93    loss=0.1865 [10.2 s]    dev=(HR@5:0.4390,NDCG@5:0.3207) [0.3 s]
INFO:root:Epoch 94    loss=0.1864 [10.8 s]    dev=(HR@5:0.4373,NDCG@5:0.3240) [0.4 s]
INFO:root:Epoch 95    loss=0.1861 [10.7 s]    dev=(HR@5:0.4411,NDCG@5:0.3253) [0.4 s]
INFO:root:Epoch 96    loss=0.1849 [11.4 s]    dev=(HR@5:0.4366,NDCG@5:0.3221) [0.4 s]
INFO:root:Epoch 97    loss=0.1854 [10.6 s]    dev=(HR@5:0.4370,NDCG@5:0.3205) [0.4 s]
INFO:root:Epoch 98    loss=0.1847 [8.8 s]    dev=(HR@5:0.4376,NDCG@5:0.3214) [0.4 s]
INFO:root:Epoch 99    loss=0.1855 [11.3 s]    dev=(HR@5:0.4391,NDCG@5:0.3226) [0.4 s]
INFO:root:Early stop at 99 based on dev result.
INFO:root:
Best Iter(dev)=   79	 dev=(HR@5:0.4460,NDCG@5:0.3287) [1093.7 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.3983,NDCG@5:0.2858,HR@10:0.5078,NDCG@10:0.3214,HR@20:0.6281,NDCG@20:0.3517,HR@50:0.8367,NDCG@50:0.3931)
INFO:root:
--------------------------------------------- END: 2024-12-22 15:16:32 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-22 15:49:38 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [12.2 s]    dev=(HR@5:0.2509,NDCG@5:0.1668) [0.4 s] *
INFO:root:Epoch 2     loss=0.4327 [11.0 s]    dev=(HR@5:0.3215,NDCG@5:0.2180) [0.4 s] *
INFO:root:Epoch 3     loss=0.3999 [10.4 s]    dev=(HR@5:0.3391,NDCG@5:0.2282) [0.4 s] *
INFO:root:Epoch 4     loss=0.3851 [11.3 s]    dev=(HR@5:0.3532,NDCG@5:0.2423) [0.4 s] *
INFO:root:Epoch 5     loss=0.3642 [11.4 s]    dev=(HR@5:0.3687,NDCG@5:0.2551) [0.4 s] *
INFO:root:Epoch 6     loss=0.3397 [10.6 s]    dev=(HR@5:0.3875,NDCG@5:0.2731) [0.4 s] *
INFO:root:Epoch 7     loss=0.3204 [11.7 s]    dev=(HR@5:0.3932,NDCG@5:0.2773) [0.4 s] *
INFO:root:Epoch 8     loss=0.3028 [10.2 s]    dev=(HR@5:0.4019,NDCG@5:0.2860) [0.4 s] *
INFO:root:Epoch 9     loss=0.2864 [11.2 s]    dev=(HR@5:0.4060,NDCG@5:0.2908) [0.4 s] *
INFO:root:Epoch 10    loss=0.2757 [11.6 s]    dev=(HR@5:0.4099,NDCG@5:0.2938) [0.4 s] *
INFO:root:Epoch 11    loss=0.2641 [10.9 s]    dev=(HR@5:0.4132,NDCG@5:0.2963) [0.4 s] *
INFO:root:Epoch 12    loss=0.2551 [11.4 s]    dev=(HR@5:0.4160,NDCG@5:0.2997) [0.4 s] *
INFO:root:Epoch 13    loss=0.2496 [11.0 s]    dev=(HR@5:0.4227,NDCG@5:0.3066) [0.4 s] *
INFO:root:Epoch 14    loss=0.2426 [11.4 s]    dev=(HR@5:0.4199,NDCG@5:0.3035) [0.4 s]
INFO:root:Epoch 15    loss=0.2391 [10.8 s]    dev=(HR@5:0.4222,NDCG@5:0.3059) [0.4 s]
INFO:root:Epoch 16    loss=0.2346 [11.2 s]    dev=(HR@5:0.4234,NDCG@5:0.3084) [0.4 s] *
INFO:root:Epoch 17    loss=0.2312 [10.3 s]    dev=(HR@5:0.4210,NDCG@5:0.3074) [0.4 s]
INFO:root:Epoch 18    loss=0.2261 [11.2 s]    dev=(HR@5:0.4250,NDCG@5:0.3101) [0.4 s] *
INFO:root:Epoch 19    loss=0.2225 [10.6 s]    dev=(HR@5:0.4249,NDCG@5:0.3111) [0.4 s] *
INFO:root:Epoch 20    loss=0.2208 [11.1 s]    dev=(HR@5:0.4277,NDCG@5:0.3136) [0.4 s] *
INFO:root:Epoch 21    loss=0.2159 [9.9 s]    dev=(HR@5:0.4321,NDCG@5:0.3158) [0.4 s] *
INFO:root:Epoch 22    loss=0.2146 [11.3 s]    dev=(HR@5:0.4323,NDCG@5:0.3154) [0.4 s]
INFO:root:Epoch 23    loss=0.2145 [10.6 s]    dev=(HR@5:0.4254,NDCG@5:0.3119) [0.4 s]
INFO:root:Epoch 24    loss=0.2139 [10.3 s]    dev=(HR@5:0.4312,NDCG@5:0.3145) [0.4 s]
INFO:root:Epoch 25    loss=0.2104 [11.2 s]    dev=(HR@5:0.4269,NDCG@5:0.3132) [0.4 s]
INFO:root:Epoch 26    loss=0.2103 [10.9 s]    dev=(HR@5:0.4326,NDCG@5:0.3169) [0.4 s] *
INFO:root:Epoch 27    loss=0.2094 [11.2 s]    dev=(HR@5:0.4316,NDCG@5:0.3178) [0.4 s] *
INFO:root:Epoch 28    loss=0.2087 [10.7 s]    dev=(HR@5:0.4356,NDCG@5:0.3208) [0.3 s] *
INFO:root:Epoch 29    loss=0.2073 [11.1 s]    dev=(HR@5:0.4304,NDCG@5:0.3154) [0.4 s]
INFO:root:Epoch 30    loss=0.2069 [10.4 s]    dev=(HR@5:0.4332,NDCG@5:0.3196) [0.4 s]
INFO:root:Epoch 31    loss=0.2055 [11.4 s]    dev=(HR@5:0.4340,NDCG@5:0.3193) [0.4 s]
INFO:root:Epoch 32    loss=0.2060 [10.5 s]    dev=(HR@5:0.4363,NDCG@5:0.3198) [0.4 s]
INFO:root:Epoch 33    loss=0.2045 [11.2 s]    dev=(HR@5:0.4363,NDCG@5:0.3199) [0.4 s]
INFO:root:Epoch 34    loss=0.2033 [11.2 s]    dev=(HR@5:0.4319,NDCG@5:0.3179) [0.4 s]
INFO:root:Epoch 35    loss=0.2044 [10.2 s]    dev=(HR@5:0.4323,NDCG@5:0.3163) [0.4 s]
INFO:root:Epoch 36    loss=0.2021 [11.1 s]    dev=(HR@5:0.4351,NDCG@5:0.3184) [0.4 s]
INFO:root:Epoch 37    loss=0.2020 [10.6 s]    dev=(HR@5:0.4342,NDCG@5:0.3176) [0.4 s]
INFO:root:Epoch 38    loss=0.2028 [11.3 s]    dev=(HR@5:0.4357,NDCG@5:0.3190) [0.4 s]
INFO:root:Epoch 39    loss=0.2010 [10.3 s]    dev=(HR@5:0.4314,NDCG@5:0.3146) [0.4 s]
INFO:root:Epoch 40    loss=0.1996 [11.2 s]    dev=(HR@5:0.4361,NDCG@5:0.3195) [0.5 s]
INFO:root:Epoch 41    loss=0.2007 [10.6 s]    dev=(HR@5:0.4350,NDCG@5:0.3181) [0.4 s]
INFO:root:Epoch 42    loss=0.2011 [11.4 s]    dev=(HR@5:0.4400,NDCG@5:0.3225) [0.4 s] *
INFO:root:Epoch 43    loss=0.1990 [10.2 s]    dev=(HR@5:0.4371,NDCG@5:0.3234) [0.4 s] *
INFO:root:Epoch 44    loss=0.2004 [11.5 s]    dev=(HR@5:0.4400,NDCG@5:0.3232) [0.4 s]
INFO:root:Epoch 45    loss=0.1967 [11.5 s]    dev=(HR@5:0.4409,NDCG@5:0.3242) [0.4 s] *
INFO:root:Epoch 46    loss=0.1970 [10.6 s]    dev=(HR@5:0.4356,NDCG@5:0.3202) [0.4 s]
INFO:root:Epoch 47    loss=0.1984 [11.0 s]    dev=(HR@5:0.4348,NDCG@5:0.3196) [0.4 s]
INFO:root:Epoch 48    loss=0.1961 [10.1 s]    dev=(HR@5:0.4330,NDCG@5:0.3161) [0.3 s]
INFO:root:Epoch 49    loss=0.1952 [10.3 s]    dev=(HR@5:0.4399,NDCG@5:0.3252) [0.5 s] *
INFO:root:Epoch 50    loss=0.1968 [11.3 s]    dev=(HR@5:0.4346,NDCG@5:0.3198) [0.4 s]
INFO:root:Epoch 51    loss=0.1951 [10.8 s]    dev=(HR@5:0.4397,NDCG@5:0.3218) [0.4 s]
INFO:root:Epoch 52    loss=0.1955 [10.5 s]    dev=(HR@5:0.4357,NDCG@5:0.3200) [0.4 s]
INFO:root:Epoch 53    loss=0.1945 [11.2 s]    dev=(HR@5:0.4380,NDCG@5:0.3207) [0.4 s]
INFO:root:Epoch 54    loss=0.1930 [10.2 s]    dev=(HR@5:0.4421,NDCG@5:0.3243) [0.4 s]
INFO:root:Epoch 55    loss=0.1931 [10.9 s]    dev=(HR@5:0.4384,NDCG@5:0.3209) [0.4 s]
INFO:root:Epoch 56    loss=0.1924 [10.8 s]    dev=(HR@5:0.4398,NDCG@5:0.3243) [0.4 s]
INFO:root:Epoch 57    loss=0.1937 [10.8 s]    dev=(HR@5:0.4423,NDCG@5:0.3277) [0.4 s] *
INFO:root:Epoch 58    loss=0.1941 [10.5 s]    dev=(HR@5:0.4419,NDCG@5:0.3249) [0.3 s]
INFO:root:Epoch 59    loss=0.1922 [10.2 s]    dev=(HR@5:0.4370,NDCG@5:0.3229) [0.4 s]
INFO:root:Epoch 60    loss=0.1930 [10.5 s]    dev=(HR@5:0.4392,NDCG@5:0.3221) [0.3 s]
INFO:root:Epoch 61    loss=0.1927 [11.0 s]    dev=(HR@5:0.4434,NDCG@5:0.3247) [0.4 s]
INFO:root:Epoch 62    loss=0.1921 [11.3 s]    dev=(HR@5:0.4429,NDCG@5:0.3246) [0.4 s]
INFO:root:Epoch 63    loss=0.1928 [10.2 s]    dev=(HR@5:0.4417,NDCG@5:0.3241) [0.4 s]
INFO:root:Epoch 64    loss=0.1908 [10.4 s]    dev=(HR@5:0.4413,NDCG@5:0.3221) [0.4 s]
INFO:root:Epoch 65    loss=0.1923 [11.3 s]    dev=(HR@5:0.4411,NDCG@5:0.3232) [0.4 s]
INFO:root:Epoch 66    loss=0.1907 [11.3 s]    dev=(HR@5:0.4456,NDCG@5:0.3247) [0.3 s]
INFO:root:Epoch 67    loss=0.1907 [10.5 s]    dev=(HR@5:0.4389,NDCG@5:0.3216) [0.4 s]
INFO:root:Epoch 68    loss=0.1894 [11.3 s]    dev=(HR@5:0.4412,NDCG@5:0.3239) [0.4 s]
INFO:root:Epoch 69    loss=0.1912 [10.7 s]    dev=(HR@5:0.4417,NDCG@5:0.3246) [0.5 s]
INFO:root:Epoch 70    loss=0.1903 [11.2 s]    dev=(HR@5:0.4450,NDCG@5:0.3272) [0.4 s]
INFO:root:Epoch 71    loss=0.1895 [11.4 s]    dev=(HR@5:0.4447,NDCG@5:0.3267) [0.3 s]
INFO:root:Epoch 72    loss=0.1886 [10.6 s]    dev=(HR@5:0.4402,NDCG@5:0.3235) [0.4 s]
INFO:root:Epoch 73    loss=0.1897 [11.3 s]    dev=(HR@5:0.4427,NDCG@5:0.3257) [0.4 s]
INFO:root:Epoch 74    loss=0.1900 [10.8 s]    dev=(HR@5:0.4377,NDCG@5:0.3220) [0.4 s]
INFO:root:Epoch 75    loss=0.1911 [11.2 s]    dev=(HR@5:0.4392,NDCG@5:0.3239) [0.4 s]
INFO:root:Epoch 76    loss=0.1907 [10.5 s]    dev=(HR@5:0.4412,NDCG@5:0.3251) [0.4 s]
INFO:root:Epoch 77    loss=0.1888 [11.3 s]    dev=(HR@5:0.4419,NDCG@5:0.3248) [0.4 s]
INFO:root:Early stop at 77 based on dev result.
INFO:root:
Best Iter(dev)=   57	 dev=(HR@5:0.4423,NDCG@5:0.3277) [869.4 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.3906,NDCG@5:0.2816,HR@10:0.4979,NDCG@10:0.3163,HR@20:0.6217,NDCG@20:0.3476,HR@50:0.8301,NDCG@50:0.3889)
INFO:root:
--------------------------------------------- END: 2024-12-22 16:04:10 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-22 20:48:29 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [12.3 s]    dev=(HR@5:0.2505,NDCG@5:0.1665) [0.4 s] *
INFO:root:Epoch 2     loss=0.4331 [11.3 s]    dev=(HR@5:0.3203,NDCG@5:0.2166) [0.4 s] *
INFO:root:Epoch 3     loss=0.4000 [11.5 s]    dev=(HR@5:0.3404,NDCG@5:0.2289) [0.4 s] *
INFO:root:Epoch 4     loss=0.3827 [11.5 s]    dev=(HR@5:0.3599,NDCG@5:0.2482) [0.4 s] *
INFO:root:Epoch 5     loss=0.3608 [10.4 s]    dev=(HR@5:0.3731,NDCG@5:0.2591) [0.4 s] *
INFO:root:Epoch 6     loss=0.3380 [11.0 s]    dev=(HR@5:0.3863,NDCG@5:0.2737) [0.4 s] *
INFO:root:Epoch 7     loss=0.3214 [10.2 s]    dev=(HR@5:0.3915,NDCG@5:0.2776) [0.4 s] *
INFO:root:Epoch 8     loss=0.3055 [11.3 s]    dev=(HR@5:0.3977,NDCG@5:0.2847) [0.4 s] *
INFO:root:Epoch 9     loss=0.2904 [10.9 s]    dev=(HR@5:0.4012,NDCG@5:0.2880) [0.4 s] *
INFO:root:Epoch 10    loss=0.2795 [10.6 s]    dev=(HR@5:0.4056,NDCG@5:0.2920) [0.4 s] *
INFO:root:Epoch 11    loss=0.2678 [10.8 s]    dev=(HR@5:0.4132,NDCG@5:0.2980) [0.4 s] *
INFO:root:Epoch 12    loss=0.2585 [11.2 s]    dev=(HR@5:0.4158,NDCG@5:0.3004) [0.4 s] *
INFO:root:Epoch 13    loss=0.2531 [11.3 s]    dev=(HR@5:0.4226,NDCG@5:0.3069) [0.4 s] *
INFO:root:Epoch 14    loss=0.2459 [11.1 s]    dev=(HR@5:0.4192,NDCG@5:0.3050) [0.4 s]
INFO:root:Epoch 15    loss=0.2426 [11.0 s]    dev=(HR@5:0.4208,NDCG@5:0.3057) [0.4 s]
INFO:root:Epoch 16    loss=0.2376 [10.8 s]    dev=(HR@5:0.4231,NDCG@5:0.3077) [0.4 s] *
INFO:root:Epoch 17    loss=0.2345 [11.0 s]    dev=(HR@5:0.4210,NDCG@5:0.3076) [0.3 s]
INFO:root:Epoch 18    loss=0.2285 [11.2 s]    dev=(HR@5:0.4248,NDCG@5:0.3103) [0.4 s] *
INFO:root:Epoch 19    loss=0.2248 [11.4 s]    dev=(HR@5:0.4321,NDCG@5:0.3160) [0.4 s] *
INFO:root:Epoch 20    loss=0.2222 [11.4 s]    dev=(HR@5:0.4308,NDCG@5:0.3165) [0.4 s] *
INFO:root:Epoch 21    loss=0.2172 [11.4 s]    dev=(HR@5:0.4307,NDCG@5:0.3164) [0.3 s]
INFO:root:Epoch 22    loss=0.2153 [11.3 s]    dev=(HR@5:0.4289,NDCG@5:0.3139) [0.4 s]
INFO:root:Epoch 23    loss=0.2157 [11.4 s]    dev=(HR@5:0.4272,NDCG@5:0.3132) [0.4 s]
INFO:root:Epoch 24    loss=0.2144 [11.1 s]    dev=(HR@5:0.4331,NDCG@5:0.3173) [0.4 s] *
INFO:root:Epoch 25    loss=0.2101 [11.2 s]    dev=(HR@5:0.4316,NDCG@5:0.3166) [0.4 s]
INFO:root:Epoch 26    loss=0.2106 [11.0 s]    dev=(HR@5:0.4314,NDCG@5:0.3177) [0.4 s] *
INFO:root:Epoch 27    loss=0.2086 [11.1 s]    dev=(HR@5:0.4331,NDCG@5:0.3185) [0.4 s] *
INFO:root:Epoch 28    loss=0.2080 [11.0 s]    dev=(HR@5:0.4366,NDCG@5:0.3211) [0.4 s] *
INFO:root:Epoch 29    loss=0.2061 [10.8 s]    dev=(HR@5:0.4331,NDCG@5:0.3177) [0.3 s]
INFO:root:Epoch 30    loss=0.2056 [10.8 s]    dev=(HR@5:0.4340,NDCG@5:0.3187) [0.4 s]
INFO:root:Epoch 31    loss=0.2042 [10.7 s]    dev=(HR@5:0.4354,NDCG@5:0.3200) [0.4 s]
INFO:root:Epoch 32    loss=0.2051 [10.3 s]    dev=(HR@5:0.4345,NDCG@5:0.3191) [0.4 s]
INFO:root:Epoch 33    loss=0.2030 [10.8 s]    dev=(HR@5:0.4378,NDCG@5:0.3209) [0.4 s]
INFO:root:Epoch 34    loss=0.2025 [10.9 s]    dev=(HR@5:0.4351,NDCG@5:0.3201) [0.4 s]
INFO:root:Epoch 35    loss=0.2038 [11.5 s]    dev=(HR@5:0.4350,NDCG@5:0.3180) [0.4 s]
INFO:root:Epoch 36    loss=0.2002 [11.3 s]    dev=(HR@5:0.4339,NDCG@5:0.3181) [0.4 s]
INFO:root:Epoch 37    loss=0.2008 [11.3 s]    dev=(HR@5:0.4361,NDCG@5:0.3195) [0.4 s]
INFO:root:Epoch 38    loss=0.2012 [11.2 s]    dev=(HR@5:0.4383,NDCG@5:0.3197) [0.4 s]
INFO:root:Epoch 39    loss=0.2005 [11.2 s]    dev=(HR@5:0.4306,NDCG@5:0.3146) [0.4 s]
INFO:root:Epoch 40    loss=0.1999 [11.2 s]    dev=(HR@5:0.4318,NDCG@5:0.3185) [0.4 s]
INFO:root:Epoch 41    loss=0.2001 [11.3 s]    dev=(HR@5:0.4318,NDCG@5:0.3163) [0.4 s]
INFO:root:Epoch 42    loss=0.1998 [10.3 s]    dev=(HR@5:0.4333,NDCG@5:0.3167) [0.4 s]
INFO:root:Epoch 43    loss=0.1983 [10.9 s]    dev=(HR@5:0.4341,NDCG@5:0.3195) [0.4 s]
INFO:root:Epoch 44    loss=0.1996 [10.5 s]    dev=(HR@5:0.4341,NDCG@5:0.3172) [0.4 s]
INFO:root:Epoch 45    loss=0.1963 [11.3 s]    dev=(HR@5:0.4359,NDCG@5:0.3202) [0.4 s]
INFO:root:Epoch 46    loss=0.1978 [11.4 s]    dev=(HR@5:0.4334,NDCG@5:0.3179) [0.3 s]
INFO:root:Epoch 47    loss=0.1988 [11.2 s]    dev=(HR@5:0.4324,NDCG@5:0.3167) [0.4 s]
INFO:root:Epoch 48    loss=0.1965 [11.2 s]    dev=(HR@5:0.4306,NDCG@5:0.3141) [0.4 s]
INFO:root:Early stop at 48 based on dev result.
INFO:root:
Best Iter(dev)=   28	 dev=(HR@5:0.4366,NDCG@5:0.3211) [549.8 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.3867,NDCG@5:0.2760,HR@10:0.4925,NDCG@10:0.3103,HR@20:0.6116,NDCG@20:0.3402,HR@50:0.8232,NDCG@50:0.3820)
INFO:root:
--------------------------------------------- END: 2024-12-22 20:57:42 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-22 21:22:44 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [13.0 s]    dev=(HR@5:0.2509,NDCG@5:0.1668) [0.4 s] *
INFO:root:Epoch 2     loss=0.4327 [11.6 s]    dev=(HR@5:0.3210,NDCG@5:0.2176) [0.4 s] *
INFO:root:Epoch 3     loss=0.3998 [11.0 s]    dev=(HR@5:0.3395,NDCG@5:0.2283) [0.4 s] *
INFO:root:Epoch 4     loss=0.3839 [10.8 s]    dev=(HR@5:0.3579,NDCG@5:0.2466) [0.4 s] *
INFO:root:Epoch 5     loss=0.3606 [10.9 s]    dev=(HR@5:0.3743,NDCG@5:0.2597) [0.4 s] *
INFO:root:Epoch 6     loss=0.3363 [10.8 s]    dev=(HR@5:0.3909,NDCG@5:0.2759) [0.4 s] *
INFO:root:Epoch 7     loss=0.3179 [10.8 s]    dev=(HR@5:0.3962,NDCG@5:0.2803) [0.4 s] *
INFO:root:Epoch 8     loss=0.3004 [10.8 s]    dev=(HR@5:0.4005,NDCG@5:0.2866) [0.4 s] *
INFO:root:Epoch 9     loss=0.2842 [10.8 s]    dev=(HR@5:0.4037,NDCG@5:0.2913) [0.4 s] *
INFO:root:Epoch 10    loss=0.2736 [11.4 s]    dev=(HR@5:0.4109,NDCG@5:0.2956) [0.4 s] *
INFO:root:Epoch 11    loss=0.2625 [11.7 s]    dev=(HR@5:0.4154,NDCG@5:0.2982) [0.4 s] *
INFO:root:Epoch 12    loss=0.2540 [11.3 s]    dev=(HR@5:0.4180,NDCG@5:0.3017) [0.4 s] *
INFO:root:Epoch 13    loss=0.2491 [10.8 s]    dev=(HR@5:0.4220,NDCG@5:0.3065) [0.4 s] *
INFO:root:Epoch 14    loss=0.2427 [10.6 s]    dev=(HR@5:0.4187,NDCG@5:0.3034) [0.4 s]
INFO:root:Epoch 15    loss=0.2396 [10.1 s]    dev=(HR@5:0.4201,NDCG@5:0.3046) [0.4 s]
INFO:root:Epoch 16    loss=0.2347 [9.6 s]    dev=(HR@5:0.4225,NDCG@5:0.3076) [0.4 s] *
INFO:root:Epoch 17    loss=0.2314 [10.0 s]    dev=(HR@5:0.4205,NDCG@5:0.3073) [0.4 s]
INFO:root:Epoch 18    loss=0.2266 [11.6 s]    dev=(HR@5:0.4281,NDCG@5:0.3113) [0.4 s] *
INFO:root:Epoch 19    loss=0.2229 [11.6 s]    dev=(HR@5:0.4253,NDCG@5:0.3113) [0.4 s]
INFO:root:Epoch 20    loss=0.2210 [11.5 s]    dev=(HR@5:0.4278,NDCG@5:0.3138) [0.4 s] *
INFO:root:Epoch 21    loss=0.2161 [11.2 s]    dev=(HR@5:0.4295,NDCG@5:0.3146) [0.4 s] *
INFO:root:Epoch 22    loss=0.2146 [10.9 s]    dev=(HR@5:0.4267,NDCG@5:0.3136) [0.4 s]
INFO:root:Epoch 23    loss=0.2145 [11.4 s]    dev=(HR@5:0.4236,NDCG@5:0.3112) [0.4 s]
INFO:root:Epoch 24    loss=0.2136 [11.4 s]    dev=(HR@5:0.4311,NDCG@5:0.3156) [0.4 s] *
INFO:root:Epoch 25    loss=0.2099 [11.4 s]    dev=(HR@5:0.4288,NDCG@5:0.3146) [0.4 s]
INFO:root:Epoch 26    loss=0.2098 [11.5 s]    dev=(HR@5:0.4314,NDCG@5:0.3178) [0.4 s] *
INFO:root:Epoch 27    loss=0.2091 [11.2 s]    dev=(HR@5:0.4312,NDCG@5:0.3181) [0.4 s] *
INFO:root:Epoch 28    loss=0.2079 [11.4 s]    dev=(HR@5:0.4321,NDCG@5:0.3186) [0.4 s] *
INFO:root:Epoch 29    loss=0.2064 [11.4 s]    dev=(HR@5:0.4292,NDCG@5:0.3147) [0.3 s]
INFO:root:Epoch 30    loss=0.2054 [11.3 s]    dev=(HR@5:0.4330,NDCG@5:0.3198) [0.4 s] *
INFO:root:Epoch 31    loss=0.2041 [11.4 s]    dev=(HR@5:0.4348,NDCG@5:0.3199) [0.4 s] *
INFO:root:Epoch 32    loss=0.2045 [11.2 s]    dev=(HR@5:0.4361,NDCG@5:0.3209) [0.4 s] *
INFO:root:Epoch 33    loss=0.2026 [11.3 s]    dev=(HR@5:0.4340,NDCG@5:0.3193) [0.4 s]
INFO:root:Epoch 34    loss=0.2016 [11.4 s]    dev=(HR@5:0.4313,NDCG@5:0.3170) [0.4 s]
INFO:root:Epoch 35    loss=0.2025 [11.3 s]    dev=(HR@5:0.4304,NDCG@5:0.3153) [0.4 s]
INFO:root:Epoch 36    loss=0.2002 [11.5 s]    dev=(HR@5:0.4353,NDCG@5:0.3188) [0.4 s]
INFO:root:Epoch 37    loss=0.1997 [11.5 s]    dev=(HR@5:0.4323,NDCG@5:0.3169) [0.4 s]
INFO:root:Epoch 38    loss=0.2008 [11.4 s]    dev=(HR@5:0.4352,NDCG@5:0.3181) [0.4 s]
INFO:root:Epoch 39    loss=0.1996 [11.2 s]    dev=(HR@5:0.4306,NDCG@5:0.3152) [0.4 s]
INFO:root:Epoch 40    loss=0.1984 [11.3 s]    dev=(HR@5:0.4337,NDCG@5:0.3191) [0.4 s]
INFO:root:Epoch 41    loss=0.1986 [11.3 s]    dev=(HR@5:0.4336,NDCG@5:0.3174) [0.4 s]
INFO:root:Epoch 42    loss=0.1990 [10.9 s]    dev=(HR@5:0.4357,NDCG@5:0.3194) [0.4 s]
INFO:root:Epoch 43    loss=0.1974 [11.4 s]    dev=(HR@5:0.4352,NDCG@5:0.3202) [0.4 s]
INFO:root:Epoch 44    loss=0.1986 [11.4 s]    dev=(HR@5:0.4354,NDCG@5:0.3195) [0.4 s]
INFO:root:Epoch 45    loss=0.1947 [11.2 s]    dev=(HR@5:0.4369,NDCG@5:0.3217) [0.4 s] *
INFO:root:Epoch 46    loss=0.1955 [11.4 s]    dev=(HR@5:0.4346,NDCG@5:0.3202) [0.4 s]
INFO:root:Epoch 47    loss=0.1971 [11.5 s]    dev=(HR@5:0.4387,NDCG@5:0.3204) [0.4 s]
INFO:root:Epoch 48    loss=0.1943 [11.3 s]    dev=(HR@5:0.4338,NDCG@5:0.3168) [0.4 s]
INFO:root:Epoch 49    loss=0.1943 [11.3 s]    dev=(HR@5:0.4404,NDCG@5:0.3240) [0.4 s] *
INFO:root:Epoch 50    loss=0.1956 [11.8 s]    dev=(HR@5:0.4358,NDCG@5:0.3208) [0.4 s]
INFO:root:Epoch 51    loss=0.1940 [11.4 s]    dev=(HR@5:0.4368,NDCG@5:0.3214) [0.4 s]
INFO:root:Epoch 52    loss=0.1942 [11.5 s]    dev=(HR@5:0.4333,NDCG@5:0.3183) [0.4 s]
INFO:root:Epoch 53    loss=0.1934 [11.1 s]    dev=(HR@5:0.4338,NDCG@5:0.3178) [0.4 s]
INFO:root:Epoch 54    loss=0.1915 [11.2 s]    dev=(HR@5:0.4345,NDCG@5:0.3206) [0.4 s]
INFO:root:Epoch 55    loss=0.1919 [11.3 s]    dev=(HR@5:0.4394,NDCG@5:0.3218) [0.4 s]
INFO:root:Epoch 56    loss=0.1920 [10.9 s]    dev=(HR@5:0.4361,NDCG@5:0.3218) [0.4 s]
INFO:root:Epoch 57    loss=0.1924 [11.5 s]    dev=(HR@5:0.4392,NDCG@5:0.3254) [0.4 s] *
INFO:root:Epoch 58    loss=0.1931 [11.3 s]    dev=(HR@5:0.4400,NDCG@5:0.3234) [0.4 s]
INFO:root:Epoch 59    loss=0.1910 [11.3 s]    dev=(HR@5:0.4349,NDCG@5:0.3204) [0.4 s]
INFO:root:Epoch 60    loss=0.1919 [11.4 s]    dev=(HR@5:0.4323,NDCG@5:0.3186) [0.4 s]
INFO:root:Epoch 61    loss=0.1917 [11.5 s]    dev=(HR@5:0.4402,NDCG@5:0.3236) [0.4 s]
INFO:root:Epoch 62    loss=0.1913 [11.4 s]    dev=(HR@5:0.4395,NDCG@5:0.3228) [0.4 s]
INFO:root:Epoch 63    loss=0.1921 [11.6 s]    dev=(HR@5:0.4410,NDCG@5:0.3227) [0.4 s]
INFO:root:Epoch 64    loss=0.1905 [11.1 s]    dev=(HR@5:0.4372,NDCG@5:0.3191) [0.4 s]
INFO:root:Epoch 65    loss=0.1920 [11.0 s]    dev=(HR@5:0.4380,NDCG@5:0.3209) [0.4 s]
INFO:root:Epoch 66    loss=0.1895 [10.7 s]    dev=(HR@5:0.4395,NDCG@5:0.3195) [0.4 s]
INFO:root:Epoch 67    loss=0.1903 [10.3 s]    dev=(HR@5:0.4399,NDCG@5:0.3221) [0.4 s]
INFO:root:Epoch 68    loss=0.1879 [10.7 s]    dev=(HR@5:0.4373,NDCG@5:0.3216) [0.4 s]
INFO:root:Epoch 69    loss=0.1902 [11.4 s]    dev=(HR@5:0.4402,NDCG@5:0.3244) [0.4 s]
INFO:root:Epoch 70    loss=0.1894 [11.4 s]    dev=(HR@5:0.4401,NDCG@5:0.3238) [0.4 s]
INFO:root:Epoch 71    loss=0.1890 [11.4 s]    dev=(HR@5:0.4405,NDCG@5:0.3255) [0.4 s] *
INFO:root:Epoch 72    loss=0.1878 [11.5 s]    dev=(HR@5:0.4394,NDCG@5:0.3238) [0.4 s]
INFO:root:Epoch 73    loss=0.1886 [11.4 s]    dev=(HR@5:0.4385,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 74    loss=0.1893 [9.2 s]    dev=(HR@5:0.4378,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 75    loss=0.1910 [11.2 s]    dev=(HR@5:0.4375,NDCG@5:0.3234) [0.4 s]
INFO:root:Epoch 76    loss=0.1895 [11.4 s]    dev=(HR@5:0.4417,NDCG@5:0.3249) [0.4 s]
INFO:root:Epoch 77    loss=0.1876 [11.3 s]    dev=(HR@5:0.4389,NDCG@5:0.3239) [0.4 s]
INFO:root:Epoch 78    loss=0.1882 [11.3 s]    dev=(HR@5:0.4376,NDCG@5:0.3226) [0.4 s]
INFO:root:Epoch 79    loss=0.1886 [11.3 s]    dev=(HR@5:0.4460,NDCG@5:0.3287) [0.4 s] *
INFO:root:Epoch 80    loss=0.1872 [11.3 s]    dev=(HR@5:0.4434,NDCG@5:0.3240) [0.4 s]
INFO:root:Epoch 81    loss=0.1869 [11.2 s]    dev=(HR@5:0.4367,NDCG@5:0.3183) [0.4 s]
INFO:root:Epoch 82    loss=0.1881 [11.4 s]    dev=(HR@5:0.4396,NDCG@5:0.3229) [0.4 s]
INFO:root:Epoch 83    loss=0.1865 [11.4 s]    dev=(HR@5:0.4431,NDCG@5:0.3262) [0.4 s]
INFO:root:Epoch 84    loss=0.1868 [11.5 s]    dev=(HR@5:0.4409,NDCG@5:0.3260) [0.4 s]
INFO:root:Epoch 85    loss=0.1879 [11.3 s]    dev=(HR@5:0.4428,NDCG@5:0.3265) [0.4 s]
INFO:root:Epoch 86    loss=0.1884 [11.4 s]    dev=(HR@5:0.4329,NDCG@5:0.3202) [0.4 s]
INFO:root:Epoch 87    loss=0.1867 [11.3 s]    dev=(HR@5:0.4381,NDCG@5:0.3237) [0.4 s]
INFO:root:Epoch 88    loss=0.1866 [11.0 s]    dev=(HR@5:0.4387,NDCG@5:0.3228) [0.4 s]
INFO:root:Epoch 89    loss=0.1850 [11.3 s]    dev=(HR@5:0.4361,NDCG@5:0.3221) [0.4 s]
INFO:root:Epoch 90    loss=0.1852 [11.3 s]    dev=(HR@5:0.4409,NDCG@5:0.3241) [0.4 s]
INFO:root:Epoch 91    loss=0.1866 [11.6 s]    dev=(HR@5:0.4421,NDCG@5:0.3259) [0.4 s]
INFO:root:Epoch 92    loss=0.1838 [11.5 s]    dev=(HR@5:0.4356,NDCG@5:0.3198) [0.4 s]
INFO:root:Epoch 93    loss=0.1865 [10.7 s]    dev=(HR@5:0.4390,NDCG@5:0.3207) [0.4 s]
INFO:root:Epoch 94    loss=0.1864 [11.4 s]    dev=(HR@5:0.4373,NDCG@5:0.3240) [0.4 s]
INFO:root:Epoch 95    loss=0.1861 [11.3 s]    dev=(HR@5:0.4411,NDCG@5:0.3253) [0.4 s]
INFO:root:Epoch 96    loss=0.1849 [11.5 s]    dev=(HR@5:0.4366,NDCG@5:0.3221) [0.4 s]
INFO:root:Epoch 97    loss=0.1854 [11.4 s]    dev=(HR@5:0.4370,NDCG@5:0.3205) [0.4 s]
INFO:root:Epoch 98    loss=0.1847 [11.4 s]    dev=(HR@5:0.4376,NDCG@5:0.3214) [0.4 s]
INFO:root:Epoch 99    loss=0.1855 [9.9 s]    dev=(HR@5:0.4391,NDCG@5:0.3226) [0.4 s]
INFO:root:Early stop at 99 based on dev result.
INFO:root:
Best Iter(dev)=   79	 dev=(HR@5:0.4460,NDCG@5:0.3287) [1148.8 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.3983,NDCG@5:0.2858,HR@10:0.5078,NDCG@10:0.3214,HR@20:0.6281,NDCG@20:0.3517,HR@50:0.8367,NDCG@50:0.3931)
INFO:root:
--------------------------------------------- END: 2024-12-22 21:41:56 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-22 22:16:40 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [12.6 s]    dev=(HR@5:0.2509,NDCG@5:0.1668) [0.4 s] *
INFO:root:Epoch 2     loss=0.4327 [11.0 s]    dev=(HR@5:0.3215,NDCG@5:0.2180) [0.4 s] *
INFO:root:Epoch 3     loss=0.3999 [11.7 s]    dev=(HR@5:0.3391,NDCG@5:0.2282) [0.4 s] *
INFO:root:Epoch 4     loss=0.3851 [11.2 s]    dev=(HR@5:0.3532,NDCG@5:0.2423) [0.4 s] *
INFO:root:Epoch 5     loss=0.3642 [10.7 s]    dev=(HR@5:0.3687,NDCG@5:0.2551) [0.4 s] *
INFO:root:Epoch 6     loss=0.3397 [11.2 s]    dev=(HR@5:0.3875,NDCG@5:0.2731) [0.4 s] *
INFO:root:Epoch 7     loss=0.3204 [10.6 s]    dev=(HR@5:0.3932,NDCG@5:0.2773) [0.4 s] *
INFO:root:Epoch 8     loss=0.3028 [10.7 s]    dev=(HR@5:0.4019,NDCG@5:0.2860) [0.4 s] *
INFO:root:Epoch 9     loss=0.2864 [10.7 s]    dev=(HR@5:0.4060,NDCG@5:0.2908) [0.4 s] *
INFO:root:Epoch 10    loss=0.2757 [11.3 s]    dev=(HR@5:0.4099,NDCG@5:0.2938) [0.4 s] *
INFO:root:Epoch 11    loss=0.2641 [11.2 s]    dev=(HR@5:0.4132,NDCG@5:0.2963) [0.4 s] *
INFO:root:Epoch 12    loss=0.2551 [10.7 s]    dev=(HR@5:0.4160,NDCG@5:0.2997) [0.4 s] *
INFO:root:Epoch 13    loss=0.2496 [10.9 s]    dev=(HR@5:0.4227,NDCG@5:0.3066) [0.4 s] *
INFO:root:Epoch 14    loss=0.2426 [11.6 s]    dev=(HR@5:0.4199,NDCG@5:0.3035) [0.4 s]
INFO:root:Epoch 15    loss=0.2391 [11.3 s]    dev=(HR@5:0.4222,NDCG@5:0.3059) [0.4 s]
INFO:root:Epoch 16    loss=0.2346 [10.5 s]    dev=(HR@5:0.4234,NDCG@5:0.3084) [0.4 s] *
INFO:root:Epoch 17    loss=0.2312 [11.2 s]    dev=(HR@5:0.4210,NDCG@5:0.3074) [0.4 s]
INFO:root:Epoch 18    loss=0.2261 [11.8 s]    dev=(HR@5:0.4250,NDCG@5:0.3101) [0.4 s] *
INFO:root:Epoch 19    loss=0.2225 [11.4 s]    dev=(HR@5:0.4249,NDCG@5:0.3111) [0.4 s] *
INFO:root:Epoch 20    loss=0.2208 [11.6 s]    dev=(HR@5:0.4277,NDCG@5:0.3136) [0.4 s] *
INFO:root:Epoch 21    loss=0.2159 [11.6 s]    dev=(HR@5:0.4321,NDCG@5:0.3158) [0.4 s] *
INFO:root:Epoch 22    loss=0.2146 [11.1 s]    dev=(HR@5:0.4323,NDCG@5:0.3154) [0.4 s]
INFO:root:Epoch 23    loss=0.2145 [11.4 s]    dev=(HR@5:0.4254,NDCG@5:0.3119) [0.4 s]
INFO:root:Epoch 24    loss=0.2139 [11.2 s]    dev=(HR@5:0.4312,NDCG@5:0.3145) [0.4 s]
INFO:root:Epoch 25    loss=0.2104 [11.0 s]    dev=(HR@5:0.4269,NDCG@5:0.3132) [0.4 s]
INFO:root:Epoch 26    loss=0.2103 [11.3 s]    dev=(HR@5:0.4326,NDCG@5:0.3169) [0.4 s] *
INFO:root:Epoch 27    loss=0.2094 [11.3 s]    dev=(HR@5:0.4316,NDCG@5:0.3178) [0.4 s] *
INFO:root:Epoch 28    loss=0.2087 [11.3 s]    dev=(HR@5:0.4356,NDCG@5:0.3208) [0.4 s] *
INFO:root:Epoch 29    loss=0.2073 [11.4 s]    dev=(HR@5:0.4304,NDCG@5:0.3154) [0.4 s]
INFO:root:Epoch 30    loss=0.2069 [11.3 s]    dev=(HR@5:0.4332,NDCG@5:0.3196) [0.4 s]
INFO:root:Epoch 31    loss=0.2055 [10.6 s]    dev=(HR@5:0.4340,NDCG@5:0.3193) [0.4 s]
INFO:root:Epoch 32    loss=0.2060 [11.3 s]    dev=(HR@5:0.4363,NDCG@5:0.3198) [0.4 s]
INFO:root:Epoch 33    loss=0.2045 [11.3 s]    dev=(HR@5:0.4363,NDCG@5:0.3199) [0.4 s]
INFO:root:Epoch 34    loss=0.2033 [11.4 s]    dev=(HR@5:0.4319,NDCG@5:0.3179) [0.4 s]
INFO:root:Epoch 35    loss=0.2044 [11.5 s]    dev=(HR@5:0.4323,NDCG@5:0.3163) [0.4 s]
INFO:root:Epoch 36    loss=0.2021 [11.4 s]    dev=(HR@5:0.4351,NDCG@5:0.3184) [0.4 s]
INFO:root:Epoch 37    loss=0.2020 [11.2 s]    dev=(HR@5:0.4342,NDCG@5:0.3176) [0.4 s]
INFO:root:Epoch 38    loss=0.2028 [10.0 s]    dev=(HR@5:0.4357,NDCG@5:0.3190) [0.4 s]
INFO:root:Epoch 39    loss=0.2010 [11.1 s]    dev=(HR@5:0.4314,NDCG@5:0.3146) [0.4 s]
INFO:root:Epoch 40    loss=0.1996 [11.1 s]    dev=(HR@5:0.4361,NDCG@5:0.3195) [0.4 s]
INFO:root:Epoch 41    loss=0.2007 [11.0 s]    dev=(HR@5:0.4350,NDCG@5:0.3181) [0.3 s]
INFO:root:Epoch 42    loss=0.2011 [10.5 s]    dev=(HR@5:0.4400,NDCG@5:0.3225) [0.3 s] *
INFO:root:Epoch 43    loss=0.1990 [11.0 s]    dev=(HR@5:0.4371,NDCG@5:0.3234) [0.4 s] *
INFO:root:Epoch 44    loss=0.2004 [11.2 s]    dev=(HR@5:0.4400,NDCG@5:0.3232) [0.4 s]
INFO:root:Epoch 45    loss=0.1967 [11.2 s]    dev=(HR@5:0.4409,NDCG@5:0.3242) [0.4 s] *
INFO:root:Epoch 46    loss=0.1970 [11.4 s]    dev=(HR@5:0.4356,NDCG@5:0.3202) [0.4 s]
INFO:root:Epoch 47    loss=0.1984 [11.3 s]    dev=(HR@5:0.4348,NDCG@5:0.3196) [0.4 s]
INFO:root:Epoch 48    loss=0.1961 [10.5 s]    dev=(HR@5:0.4330,NDCG@5:0.3161) [0.4 s]
INFO:root:Epoch 49    loss=0.1952 [10.2 s]    dev=(HR@5:0.4399,NDCG@5:0.3252) [0.4 s] *
INFO:root:Epoch 50    loss=0.1968 [10.2 s]    dev=(HR@5:0.4346,NDCG@5:0.3198) [0.4 s]
INFO:root:Epoch 51    loss=0.1951 [10.9 s]    dev=(HR@5:0.4397,NDCG@5:0.3218) [0.4 s]
INFO:root:Epoch 52    loss=0.1955 [11.2 s]    dev=(HR@5:0.4357,NDCG@5:0.3200) [0.4 s]
INFO:root:Epoch 53    loss=0.1945 [11.4 s]    dev=(HR@5:0.4380,NDCG@5:0.3207) [0.4 s]
INFO:root:Epoch 54    loss=0.1930 [10.3 s]    dev=(HR@5:0.4421,NDCG@5:0.3243) [0.4 s]
INFO:root:Epoch 55    loss=0.1931 [11.0 s]    dev=(HR@5:0.4384,NDCG@5:0.3209) [0.4 s]
INFO:root:Epoch 56    loss=0.1924 [10.8 s]    dev=(HR@5:0.4398,NDCG@5:0.3243) [0.4 s]
INFO:root:Epoch 57    loss=0.1937 [11.3 s]    dev=(HR@5:0.4423,NDCG@5:0.3277) [0.5 s] *
INFO:root:Epoch 58    loss=0.1941 [10.8 s]    dev=(HR@5:0.4419,NDCG@5:0.3249) [0.4 s]
INFO:root:Epoch 59    loss=0.1922 [11.3 s]    dev=(HR@5:0.4370,NDCG@5:0.3229) [0.4 s]
INFO:root:Epoch 60    loss=0.1930 [10.7 s]    dev=(HR@5:0.4392,NDCG@5:0.3221) [0.4 s]
INFO:root:Epoch 61    loss=0.1927 [10.5 s]    dev=(HR@5:0.4434,NDCG@5:0.3247) [0.4 s]
INFO:root:Epoch 62    loss=0.1921 [10.5 s]    dev=(HR@5:0.4429,NDCG@5:0.3246) [0.4 s]
INFO:root:Epoch 63    loss=0.1928 [11.1 s]    dev=(HR@5:0.4417,NDCG@5:0.3241) [0.4 s]
INFO:root:Epoch 64    loss=0.1908 [10.9 s]    dev=(HR@5:0.4413,NDCG@5:0.3221) [0.4 s]
INFO:root:Epoch 65    loss=0.1923 [11.2 s]    dev=(HR@5:0.4411,NDCG@5:0.3232) [0.4 s]
INFO:root:Epoch 66    loss=0.1907 [11.5 s]    dev=(HR@5:0.4456,NDCG@5:0.3247) [0.4 s]
INFO:root:Epoch 67    loss=0.1907 [11.3 s]    dev=(HR@5:0.4389,NDCG@5:0.3216) [0.4 s]
INFO:root:Epoch 68    loss=0.1894 [11.1 s]    dev=(HR@5:0.4412,NDCG@5:0.3239) [0.4 s]
INFO:root:Epoch 69    loss=0.1912 [11.2 s]    dev=(HR@5:0.4417,NDCG@5:0.3246) [0.4 s]
INFO:root:Epoch 70    loss=0.1903 [11.3 s]    dev=(HR@5:0.4450,NDCG@5:0.3272) [0.4 s]
INFO:root:Epoch 71    loss=0.1895 [11.4 s]    dev=(HR@5:0.4447,NDCG@5:0.3267) [0.4 s]
INFO:root:Epoch 72    loss=0.1886 [11.2 s]    dev=(HR@5:0.4402,NDCG@5:0.3235) [0.4 s]
INFO:root:Epoch 73    loss=0.1897 [11.2 s]    dev=(HR@5:0.4427,NDCG@5:0.3257) [0.4 s]
INFO:root:Epoch 74    loss=0.1900 [11.4 s]    dev=(HR@5:0.4377,NDCG@5:0.3220) [0.4 s]
INFO:root:Epoch 75    loss=0.1911 [11.0 s]    dev=(HR@5:0.4392,NDCG@5:0.3239) [0.4 s]
INFO:root:Epoch 76    loss=0.1907 [11.1 s]    dev=(HR@5:0.4412,NDCG@5:0.3251) [0.4 s]
INFO:root:Epoch 77    loss=0.1888 [11.1 s]    dev=(HR@5:0.4419,NDCG@5:0.3248) [0.4 s]
INFO:root:Early stop at 77 based on dev result.
INFO:root:
Best Iter(dev)=   57	 dev=(HR@5:0.4423,NDCG@5:0.3277) [885.1 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.3906,NDCG@5:0.2816,HR@10:0.4979,NDCG@10:0.3163,HR@20:0.6217,NDCG@20:0.3476,HR@50:0.8301,NDCG@50:0.3889)
INFO:root:
--------------------------------------------- END: 2024-12-22 22:31:28 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-22 23:03:32 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5165 [12.6 s]    dev=(HR@5:0.2511,NDCG@5:0.1669) [0.5 s] *
INFO:root:Epoch 2     loss=0.4327 [11.5 s]    dev=(HR@5:0.3217,NDCG@5:0.2183) [0.4 s] *
INFO:root:Epoch 3     loss=0.3999 [11.1 s]    dev=(HR@5:0.3392,NDCG@5:0.2283) [0.4 s] *
INFO:root:Epoch 4     loss=0.3851 [11.3 s]    dev=(HR@5:0.3528,NDCG@5:0.2418) [0.4 s] *
INFO:root:Epoch 5     loss=0.3646 [11.1 s]    dev=(HR@5:0.3665,NDCG@5:0.2534) [0.4 s] *
INFO:root:Epoch 6     loss=0.3398 [10.6 s]    dev=(HR@5:0.3864,NDCG@5:0.2728) [0.4 s] *
INFO:root:Epoch 7     loss=0.3192 [10.8 s]    dev=(HR@5:0.3947,NDCG@5:0.2789) [0.4 s] *
INFO:root:Epoch 8     loss=0.3009 [11.0 s]    dev=(HR@5:0.4011,NDCG@5:0.2871) [0.4 s] *
INFO:root:Epoch 9     loss=0.2842 [11.3 s]    dev=(HR@5:0.4049,NDCG@5:0.2912) [0.4 s] *
INFO:root:Epoch 10    loss=0.2734 [11.3 s]    dev=(HR@5:0.4099,NDCG@5:0.2949) [0.4 s] *
INFO:root:Epoch 11    loss=0.2618 [11.1 s]    dev=(HR@5:0.4160,NDCG@5:0.2991) [0.4 s] *
INFO:root:Epoch 12    loss=0.2531 [11.2 s]    dev=(HR@5:0.4169,NDCG@5:0.3014) [0.4 s] *
INFO:root:Epoch 13    loss=0.2479 [11.1 s]    dev=(HR@5:0.4259,NDCG@5:0.3088) [0.4 s] *
INFO:root:Epoch 14    loss=0.2412 [10.1 s]    dev=(HR@5:0.4225,NDCG@5:0.3056) [0.4 s]
INFO:root:Epoch 15    loss=0.2381 [11.2 s]    dev=(HR@5:0.4227,NDCG@5:0.3064) [0.4 s]
INFO:root:Epoch 16    loss=0.2332 [11.5 s]    dev=(HR@5:0.4231,NDCG@5:0.3083) [0.4 s]
INFO:root:Epoch 17    loss=0.2300 [11.4 s]    dev=(HR@5:0.4242,NDCG@5:0.3095) [0.4 s] *
INFO:root:Epoch 18    loss=0.2253 [11.5 s]    dev=(HR@5:0.4248,NDCG@5:0.3101) [0.4 s] *
INFO:root:Epoch 19    loss=0.2218 [11.3 s]    dev=(HR@5:0.4276,NDCG@5:0.3122) [0.5 s] *
INFO:root:Epoch 20    loss=0.2201 [11.2 s]    dev=(HR@5:0.4304,NDCG@5:0.3158) [0.4 s] *
INFO:root:Epoch 21    loss=0.2153 [11.3 s]    dev=(HR@5:0.4321,NDCG@5:0.3170) [0.4 s] *
INFO:root:Epoch 22    loss=0.2138 [10.9 s]    dev=(HR@5:0.4325,NDCG@5:0.3157) [0.4 s]
INFO:root:Epoch 23    loss=0.2138 [11.2 s]    dev=(HR@5:0.4260,NDCG@5:0.3124) [0.4 s]
INFO:root:Epoch 24    loss=0.2131 [11.2 s]    dev=(HR@5:0.4334,NDCG@5:0.3168) [0.4 s]
INFO:root:Epoch 25    loss=0.2096 [11.1 s]    dev=(HR@5:0.4278,NDCG@5:0.3143) [0.4 s]
INFO:root:Epoch 26    loss=0.2097 [11.2 s]    dev=(HR@5:0.4313,NDCG@5:0.3176) [0.4 s] *
INFO:root:Epoch 27    loss=0.2086 [10.9 s]    dev=(HR@5:0.4311,NDCG@5:0.3186) [0.4 s] *
INFO:root:Epoch 28    loss=0.2076 [11.1 s]    dev=(HR@5:0.4351,NDCG@5:0.3207) [0.4 s] *
INFO:root:Epoch 29    loss=0.2060 [11.3 s]    dev=(HR@5:0.4310,NDCG@5:0.3159) [0.4 s]
INFO:root:Epoch 30    loss=0.2050 [11.5 s]    dev=(HR@5:0.4346,NDCG@5:0.3210) [0.4 s] *
INFO:root:Epoch 31    loss=0.2043 [11.4 s]    dev=(HR@5:0.4345,NDCG@5:0.3201) [0.4 s]
INFO:root:Epoch 32    loss=0.2044 [11.5 s]    dev=(HR@5:0.4370,NDCG@5:0.3220) [0.4 s] *
INFO:root:Epoch 33    loss=0.2028 [11.0 s]    dev=(HR@5:0.4360,NDCG@5:0.3207) [0.4 s]
INFO:root:Epoch 34    loss=0.2012 [10.8 s]    dev=(HR@5:0.4333,NDCG@5:0.3188) [0.4 s]
INFO:root:Epoch 35    loss=0.2019 [10.7 s]    dev=(HR@5:0.4318,NDCG@5:0.3163) [0.4 s]
INFO:root:Epoch 36    loss=0.2002 [11.2 s]    dev=(HR@5:0.4353,NDCG@5:0.3194) [0.4 s]
INFO:root:Epoch 37    loss=0.1999 [10.7 s]    dev=(HR@5:0.4366,NDCG@5:0.3202) [0.4 s]
INFO:root:Epoch 38    loss=0.2004 [10.9 s]    dev=(HR@5:0.4379,NDCG@5:0.3206) [0.4 s]
INFO:root:Epoch 39    loss=0.1992 [10.9 s]    dev=(HR@5:0.4326,NDCG@5:0.3167) [0.4 s]
INFO:root:Epoch 40    loss=0.1980 [10.2 s]    dev=(HR@5:0.4357,NDCG@5:0.3189) [0.3 s]
INFO:root:Epoch 41    loss=0.1989 [9.9 s]    dev=(HR@5:0.4369,NDCG@5:0.3192) [0.3 s]
INFO:root:Epoch 42    loss=0.1995 [11.2 s]    dev=(HR@5:0.4385,NDCG@5:0.3217) [0.4 s]
INFO:root:Epoch 43    loss=0.1973 [11.0 s]    dev=(HR@5:0.4400,NDCG@5:0.3227) [0.4 s] *
INFO:root:Epoch 44    loss=0.1987 [10.3 s]    dev=(HR@5:0.4390,NDCG@5:0.3220) [0.4 s]
INFO:root:Epoch 45    loss=0.1953 [11.0 s]    dev=(HR@5:0.4421,NDCG@5:0.3256) [0.4 s] *
INFO:root:Epoch 46    loss=0.1958 [11.1 s]    dev=(HR@5:0.4376,NDCG@5:0.3223) [0.4 s]
INFO:root:Epoch 47    loss=0.1971 [9.7 s]    dev=(HR@5:0.4370,NDCG@5:0.3216) [0.4 s]
INFO:root:Epoch 48    loss=0.1948 [11.3 s]    dev=(HR@5:0.4352,NDCG@5:0.3187) [0.4 s]
INFO:root:Epoch 49    loss=0.1941 [11.1 s]    dev=(HR@5:0.4407,NDCG@5:0.3242) [0.4 s]
INFO:root:Epoch 50    loss=0.1957 [11.5 s]    dev=(HR@5:0.4349,NDCG@5:0.3205) [0.4 s]
INFO:root:Epoch 51    loss=0.1940 [11.3 s]    dev=(HR@5:0.4358,NDCG@5:0.3219) [0.4 s]
INFO:root:Epoch 52    loss=0.1944 [11.2 s]    dev=(HR@5:0.4367,NDCG@5:0.3211) [0.4 s]
INFO:root:Epoch 53    loss=0.1936 [11.3 s]    dev=(HR@5:0.4383,NDCG@5:0.3209) [0.4 s]
INFO:root:Epoch 54    loss=0.1917 [11.2 s]    dev=(HR@5:0.4423,NDCG@5:0.3240) [0.4 s]
INFO:root:Epoch 55    loss=0.1926 [11.1 s]    dev=(HR@5:0.4406,NDCG@5:0.3224) [0.4 s]
INFO:root:Epoch 56    loss=0.1917 [11.2 s]    dev=(HR@5:0.4390,NDCG@5:0.3246) [0.4 s]
INFO:root:Epoch 57    loss=0.1934 [11.1 s]    dev=(HR@5:0.4419,NDCG@5:0.3268) [0.4 s] *
INFO:root:Epoch 58    loss=0.1934 [11.3 s]    dev=(HR@5:0.4451,NDCG@5:0.3261) [0.4 s]
INFO:root:Epoch 59    loss=0.1912 [11.1 s]    dev=(HR@5:0.4393,NDCG@5:0.3232) [0.4 s]
INFO:root:Epoch 60    loss=0.1921 [11.2 s]    dev=(HR@5:0.4398,NDCG@5:0.3231) [0.4 s]
INFO:root:Epoch 61    loss=0.1920 [11.0 s]    dev=(HR@5:0.4401,NDCG@5:0.3234) [0.4 s]
INFO:root:Epoch 62    loss=0.1918 [11.4 s]    dev=(HR@5:0.4442,NDCG@5:0.3251) [0.4 s]
INFO:root:Epoch 63    loss=0.1920 [11.1 s]    dev=(HR@5:0.4446,NDCG@5:0.3261) [0.4 s]
INFO:root:Epoch 64    loss=0.1905 [11.2 s]    dev=(HR@5:0.4408,NDCG@5:0.3234) [0.4 s]
INFO:root:Epoch 65    loss=0.1914 [11.3 s]    dev=(HR@5:0.4453,NDCG@5:0.3255) [0.4 s]
INFO:root:Epoch 66    loss=0.1895 [11.3 s]    dev=(HR@5:0.4411,NDCG@5:0.3229) [0.4 s]
INFO:root:Epoch 67    loss=0.1902 [11.2 s]    dev=(HR@5:0.4438,NDCG@5:0.3249) [0.4 s]
INFO:root:Epoch 68    loss=0.1878 [10.9 s]    dev=(HR@5:0.4393,NDCG@5:0.3233) [0.4 s]
INFO:root:Epoch 69    loss=0.1902 [11.1 s]    dev=(HR@5:0.4424,NDCG@5:0.3269) [0.4 s] *
INFO:root:Epoch 70    loss=0.1895 [10.7 s]    dev=(HR@5:0.4425,NDCG@5:0.3255) [0.4 s]
INFO:root:Epoch 71    loss=0.1886 [11.4 s]    dev=(HR@5:0.4476,NDCG@5:0.3282) [0.3 s] *
INFO:root:Epoch 72    loss=0.1877 [10.9 s]    dev=(HR@5:0.4368,NDCG@5:0.3223) [0.4 s]
INFO:root:Epoch 73    loss=0.1887 [9.4 s]    dev=(HR@5:0.4453,NDCG@5:0.3278) [0.4 s]
INFO:root:Epoch 74    loss=0.1889 [11.3 s]    dev=(HR@5:0.4395,NDCG@5:0.3231) [0.4 s]
INFO:root:Epoch 75    loss=0.1896 [11.4 s]    dev=(HR@5:0.4393,NDCG@5:0.3237) [0.4 s]
INFO:root:Epoch 76    loss=0.1896 [11.1 s]    dev=(HR@5:0.4408,NDCG@5:0.3248) [0.4 s]
INFO:root:Epoch 77    loss=0.1875 [10.8 s]    dev=(HR@5:0.4391,NDCG@5:0.3243) [0.4 s]
INFO:root:Epoch 78    loss=0.1877 [11.4 s]    dev=(HR@5:0.4394,NDCG@5:0.3226) [0.4 s]
INFO:root:Epoch 79    loss=0.1882 [11.3 s]    dev=(HR@5:0.4487,NDCG@5:0.3286) [0.4 s] *
INFO:root:Epoch 80    loss=0.1869 [11.2 s]    dev=(HR@5:0.4434,NDCG@5:0.3242) [0.4 s]
INFO:root:Epoch 81    loss=0.1873 [11.5 s]    dev=(HR@5:0.4363,NDCG@5:0.3180) [0.4 s]
INFO:root:Epoch 82    loss=0.1881 [11.0 s]    dev=(HR@5:0.4406,NDCG@5:0.3238) [0.4 s]
INFO:root:Epoch 83    loss=0.1864 [10.9 s]    dev=(HR@5:0.4432,NDCG@5:0.3259) [0.4 s]
INFO:root:Epoch 84    loss=0.1869 [11.0 s]    dev=(HR@5:0.4426,NDCG@5:0.3262) [0.4 s]
INFO:root:Epoch 85    loss=0.1879 [11.0 s]    dev=(HR@5:0.4419,NDCG@5:0.3259) [0.4 s]
INFO:root:Epoch 86    loss=0.1878 [11.1 s]    dev=(HR@5:0.4429,NDCG@5:0.3261) [0.4 s]
INFO:root:Epoch 87    loss=0.1862 [11.3 s]    dev=(HR@5:0.4385,NDCG@5:0.3242) [0.4 s]
INFO:root:Epoch 88    loss=0.1862 [10.6 s]    dev=(HR@5:0.4408,NDCG@5:0.3233) [0.4 s]
INFO:root:Epoch 89    loss=0.1851 [10.6 s]    dev=(HR@5:0.4428,NDCG@5:0.3262) [0.4 s]
INFO:root:Epoch 90    loss=0.1851 [10.6 s]    dev=(HR@5:0.4460,NDCG@5:0.3281) [0.4 s]
INFO:root:Epoch 91    loss=0.1858 [11.2 s]    dev=(HR@5:0.4408,NDCG@5:0.3256) [0.4 s]
INFO:root:Epoch 92    loss=0.1842 [10.5 s]    dev=(HR@5:0.4403,NDCG@5:0.3222) [0.4 s]
INFO:root:Epoch 93    loss=0.1856 [11.0 s]    dev=(HR@5:0.4394,NDCG@5:0.3227) [0.4 s]
INFO:root:Epoch 94    loss=0.1853 [11.4 s]    dev=(HR@5:0.4413,NDCG@5:0.3243) [0.4 s]
INFO:root:Epoch 95    loss=0.1863 [10.6 s]    dev=(HR@5:0.4429,NDCG@5:0.3268) [0.4 s]
INFO:root:Epoch 96    loss=0.1840 [11.0 s]    dev=(HR@5:0.4417,NDCG@5:0.3259) [0.4 s]
INFO:root:Epoch 97    loss=0.1852 [11.3 s]    dev=(HR@5:0.4434,NDCG@5:0.3246) [0.4 s]
INFO:root:Epoch 98    loss=0.1845 [11.5 s]    dev=(HR@5:0.4427,NDCG@5:0.3234) [0.4 s]
INFO:root:Epoch 99    loss=0.1852 [10.8 s]    dev=(HR@5:0.4458,NDCG@5:0.3270) [0.4 s]
INFO:root:Early stop at 99 based on dev result.
INFO:root:
Best Iter(dev)=   79	 dev=(HR@5:0.4487,NDCG@5:0.3286) [1133.2 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.3989,NDCG@5:0.2863,HR@10:0.5053,NDCG@10:0.3209,HR@20:0.6305,NDCG@20:0.3525,HR@50:0.8371,NDCG@50:0.3934)
INFO:root:
--------------------------------------------- END: 2024-12-22 23:22:28 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-22 23:51:11 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5165 [13.2 s]    dev=(HR@5:0.2509,NDCG@5:0.1668) [0.4 s] *
INFO:root:Epoch 2     loss=0.4327 [12.1 s]    dev=(HR@5:0.3215,NDCG@5:0.2182) [0.4 s] *
INFO:root:Epoch 3     loss=0.3999 [12.0 s]    dev=(HR@5:0.3390,NDCG@5:0.2282) [0.4 s] *
INFO:root:Epoch 4     loss=0.3852 [12.1 s]    dev=(HR@5:0.3530,NDCG@5:0.2417) [0.4 s] *
INFO:root:Epoch 5     loss=0.3651 [12.0 s]    dev=(HR@5:0.3660,NDCG@5:0.2531) [0.4 s] *
INFO:root:Epoch 6     loss=0.3415 [11.8 s]    dev=(HR@5:0.3844,NDCG@5:0.2706) [0.4 s] *
INFO:root:Epoch 7     loss=0.3212 [12.1 s]    dev=(HR@5:0.3921,NDCG@5:0.2763) [0.4 s] *
INFO:root:Epoch 8     loss=0.3030 [12.1 s]    dev=(HR@5:0.3999,NDCG@5:0.2859) [0.4 s] *
INFO:root:Epoch 9     loss=0.2863 [12.0 s]    dev=(HR@5:0.4040,NDCG@5:0.2901) [0.4 s] *
INFO:root:Epoch 10    loss=0.2757 [11.9 s]    dev=(HR@5:0.4103,NDCG@5:0.2941) [0.4 s] *
INFO:root:Epoch 11    loss=0.2638 [12.0 s]    dev=(HR@5:0.4141,NDCG@5:0.2974) [0.4 s] *
INFO:root:Epoch 12    loss=0.2551 [11.6 s]    dev=(HR@5:0.4182,NDCG@5:0.3009) [0.4 s] *
INFO:root:Epoch 13    loss=0.2498 [11.9 s]    dev=(HR@5:0.4241,NDCG@5:0.3075) [0.4 s] *
INFO:root:Epoch 14    loss=0.2429 [12.0 s]    dev=(HR@5:0.4218,NDCG@5:0.3050) [0.4 s]
INFO:root:Epoch 15    loss=0.2392 [11.7 s]    dev=(HR@5:0.4237,NDCG@5:0.3066) [0.4 s]
INFO:root:Epoch 16    loss=0.2352 [12.1 s]    dev=(HR@5:0.4240,NDCG@5:0.3083) [0.4 s] *
INFO:root:Epoch 17    loss=0.2316 [12.0 s]    dev=(HR@5:0.4238,NDCG@5:0.3092) [0.3 s] *
INFO:root:Epoch 18    loss=0.2266 [11.6 s]    dev=(HR@5:0.4276,NDCG@5:0.3110) [0.4 s] *
INFO:root:Epoch 19    loss=0.2231 [11.8 s]    dev=(HR@5:0.4291,NDCG@5:0.3133) [0.4 s] *
INFO:root:Epoch 20    loss=0.2219 [12.0 s]    dev=(HR@5:0.4308,NDCG@5:0.3159) [0.4 s] *
INFO:root:Epoch 21    loss=0.2170 [12.0 s]    dev=(HR@5:0.4335,NDCG@5:0.3177) [0.4 s] *
INFO:root:Epoch 22    loss=0.2160 [11.7 s]    dev=(HR@5:0.4337,NDCG@5:0.3159) [0.4 s]
INFO:root:Epoch 23    loss=0.2163 [11.8 s]    dev=(HR@5:0.4291,NDCG@5:0.3143) [0.4 s]
INFO:root:Epoch 24    loss=0.2153 [11.7 s]    dev=(HR@5:0.4329,NDCG@5:0.3166) [0.4 s]
INFO:root:Epoch 25    loss=0.2120 [11.7 s]    dev=(HR@5:0.4299,NDCG@5:0.3134) [0.4 s]
INFO:root:Epoch 26    loss=0.2120 [12.0 s]    dev=(HR@5:0.4340,NDCG@5:0.3176) [0.4 s]
INFO:root:Epoch 27    loss=0.2108 [12.0 s]    dev=(HR@5:0.4357,NDCG@5:0.3208) [0.4 s] *
INFO:root:Epoch 28    loss=0.2102 [12.0 s]    dev=(HR@5:0.4379,NDCG@5:0.3225) [0.4 s] *
INFO:root:Epoch 29    loss=0.2084 [12.0 s]    dev=(HR@5:0.4360,NDCG@5:0.3183) [0.4 s]
INFO:root:Epoch 30    loss=0.2072 [12.0 s]    dev=(HR@5:0.4366,NDCG@5:0.3205) [0.4 s]
INFO:root:Epoch 31    loss=0.2065 [11.6 s]    dev=(HR@5:0.4362,NDCG@5:0.3203) [0.4 s]
INFO:root:Epoch 32    loss=0.2068 [12.0 s]    dev=(HR@5:0.4380,NDCG@5:0.3221) [0.4 s]
INFO:root:Epoch 33    loss=0.2052 [12.0 s]    dev=(HR@5:0.4392,NDCG@5:0.3218) [0.4 s]
INFO:root:Epoch 34    loss=0.2039 [11.8 s]    dev=(HR@5:0.4388,NDCG@5:0.3205) [0.4 s]
INFO:root:Epoch 35    loss=0.2049 [12.1 s]    dev=(HR@5:0.4348,NDCG@5:0.3182) [0.4 s]
INFO:root:Epoch 36    loss=0.2031 [11.8 s]    dev=(HR@5:0.4410,NDCG@5:0.3219) [0.4 s]
INFO:root:Epoch 37    loss=0.2027 [11.4 s]    dev=(HR@5:0.4415,NDCG@5:0.3220) [0.4 s]
INFO:root:Epoch 38    loss=0.2035 [11.3 s]    dev=(HR@5:0.4405,NDCG@5:0.3212) [0.4 s]
INFO:root:Epoch 39    loss=0.2021 [11.7 s]    dev=(HR@5:0.4377,NDCG@5:0.3195) [0.4 s]
INFO:root:Epoch 40    loss=0.2006 [11.9 s]    dev=(HR@5:0.4374,NDCG@5:0.3194) [0.4 s]
INFO:root:Epoch 41    loss=0.2020 [12.0 s]    dev=(HR@5:0.4391,NDCG@5:0.3198) [0.4 s]
INFO:root:Epoch 42    loss=0.2023 [11.9 s]    dev=(HR@5:0.4419,NDCG@5:0.3225) [0.4 s]
INFO:root:Epoch 43    loss=0.2002 [11.8 s]    dev=(HR@5:0.4446,NDCG@5:0.3263) [0.4 s] *
INFO:root:Epoch 44    loss=0.2020 [11.8 s]    dev=(HR@5:0.4413,NDCG@5:0.3231) [0.4 s]
INFO:root:Epoch 45    loss=0.1980 [12.1 s]    dev=(HR@5:0.4452,NDCG@5:0.3264) [0.4 s] *
INFO:root:Epoch 46    loss=0.1988 [12.0 s]    dev=(HR@5:0.4405,NDCG@5:0.3244) [0.4 s]
INFO:root:Epoch 47    loss=0.2003 [12.0 s]    dev=(HR@5:0.4400,NDCG@5:0.3231) [0.4 s]
INFO:root:Epoch 48    loss=0.1982 [11.9 s]    dev=(HR@5:0.4376,NDCG@5:0.3199) [0.4 s]
INFO:root:Epoch 49    loss=0.1974 [12.1 s]    dev=(HR@5:0.4391,NDCG@5:0.3235) [0.4 s]
INFO:root:Epoch 50    loss=0.1988 [11.9 s]    dev=(HR@5:0.4368,NDCG@5:0.3212) [0.4 s]
INFO:root:Epoch 51    loss=0.1968 [11.8 s]    dev=(HR@5:0.4418,NDCG@5:0.3233) [0.4 s]
INFO:root:Epoch 52    loss=0.1976 [11.7 s]    dev=(HR@5:0.4402,NDCG@5:0.3223) [0.4 s]
INFO:root:Epoch 53    loss=0.1965 [11.9 s]    dev=(HR@5:0.4371,NDCG@5:0.3206) [0.4 s]
INFO:root:Epoch 54    loss=0.1944 [11.5 s]    dev=(HR@5:0.4428,NDCG@5:0.3240) [0.4 s]
INFO:root:Epoch 55    loss=0.1951 [12.0 s]    dev=(HR@5:0.4410,NDCG@5:0.3228) [0.4 s]
INFO:root:Epoch 56    loss=0.1948 [12.1 s]    dev=(HR@5:0.4451,NDCG@5:0.3277) [0.4 s] *
INFO:root:Epoch 57    loss=0.1958 [11.5 s]    dev=(HR@5:0.4462,NDCG@5:0.3283) [0.4 s] *
INFO:root:Epoch 58    loss=0.1960 [11.0 s]    dev=(HR@5:0.4441,NDCG@5:0.3267) [0.4 s]
INFO:root:Epoch 59    loss=0.1941 [11.4 s]    dev=(HR@5:0.4403,NDCG@5:0.3238) [0.4 s]
INFO:root:Epoch 60    loss=0.1950 [10.6 s]    dev=(HR@5:0.4420,NDCG@5:0.3253) [0.4 s]
INFO:root:Epoch 61    loss=0.1949 [11.4 s]    dev=(HR@5:0.4449,NDCG@5:0.3266) [0.4 s]
INFO:root:Epoch 62    loss=0.1939 [11.6 s]    dev=(HR@5:0.4449,NDCG@5:0.3250) [0.4 s]
INFO:root:Epoch 63    loss=0.1945 [11.6 s]    dev=(HR@5:0.4466,NDCG@5:0.3269) [0.4 s]
INFO:root:Epoch 64    loss=0.1930 [11.1 s]    dev=(HR@5:0.4439,NDCG@5:0.3248) [0.4 s]
INFO:root:Epoch 65    loss=0.1945 [11.3 s]    dev=(HR@5:0.4434,NDCG@5:0.3248) [0.4 s]
INFO:root:Epoch 66    loss=0.1926 [11.5 s]    dev=(HR@5:0.4455,NDCG@5:0.3253) [0.4 s]
INFO:root:Epoch 67    loss=0.1927 [11.5 s]    dev=(HR@5:0.4476,NDCG@5:0.3258) [0.4 s]
INFO:root:Epoch 68    loss=0.1908 [11.5 s]    dev=(HR@5:0.4432,NDCG@5:0.3244) [0.4 s]
INFO:root:Epoch 69    loss=0.1930 [11.4 s]    dev=(HR@5:0.4475,NDCG@5:0.3291) [0.4 s] *
INFO:root:Epoch 70    loss=0.1925 [11.4 s]    dev=(HR@5:0.4442,NDCG@5:0.3268) [0.4 s]
INFO:root:Epoch 71    loss=0.1916 [11.5 s]    dev=(HR@5:0.4440,NDCG@5:0.3269) [0.4 s]
INFO:root:Epoch 72    loss=0.1911 [11.4 s]    dev=(HR@5:0.4400,NDCG@5:0.3234) [0.4 s]
INFO:root:Epoch 73    loss=0.1910 [11.0 s]    dev=(HR@5:0.4457,NDCG@5:0.3270) [0.4 s]
INFO:root:Epoch 74    loss=0.1919 [10.9 s]    dev=(HR@5:0.4425,NDCG@5:0.3231) [0.4 s]
INFO:root:Epoch 75    loss=0.1923 [11.1 s]    dev=(HR@5:0.4423,NDCG@5:0.3256) [0.4 s]
INFO:root:Epoch 76    loss=0.1924 [11.1 s]    dev=(HR@5:0.4416,NDCG@5:0.3251) [0.4 s]
INFO:root:Epoch 77    loss=0.1907 [9.6 s]    dev=(HR@5:0.4427,NDCG@5:0.3260) [0.4 s]
INFO:root:Epoch 78    loss=0.1909 [11.4 s]    dev=(HR@5:0.4436,NDCG@5:0.3233) [0.4 s]
INFO:root:Epoch 79    loss=0.1919 [11.3 s]    dev=(HR@5:0.4453,NDCG@5:0.3268) [0.3 s]
INFO:root:Epoch 80    loss=0.1897 [9.7 s]    dev=(HR@5:0.4462,NDCG@5:0.3256) [0.4 s]
INFO:root:Epoch 81    loss=0.1900 [11.1 s]    dev=(HR@5:0.4372,NDCG@5:0.3188) [0.4 s]
INFO:root:Epoch 82    loss=0.1918 [11.4 s]    dev=(HR@5:0.4438,NDCG@5:0.3249) [0.4 s]
INFO:root:Epoch 83    loss=0.1894 [11.0 s]    dev=(HR@5:0.4462,NDCG@5:0.3263) [0.4 s]
INFO:root:Epoch 84    loss=0.1895 [11.2 s]    dev=(HR@5:0.4471,NDCG@5:0.3264) [0.4 s]
INFO:root:Epoch 85    loss=0.1911 [11.2 s]    dev=(HR@5:0.4449,NDCG@5:0.3262) [0.4 s]
INFO:root:Epoch 86    loss=0.1911 [11.6 s]    dev=(HR@5:0.4444,NDCG@5:0.3264) [0.4 s]
INFO:root:Epoch 87    loss=0.1894 [11.2 s]    dev=(HR@5:0.4445,NDCG@5:0.3277) [0.4 s]
INFO:root:Epoch 88    loss=0.1900 [11.6 s]    dev=(HR@5:0.4427,NDCG@5:0.3242) [0.4 s]
INFO:root:Epoch 89    loss=0.1892 [11.4 s]    dev=(HR@5:0.4436,NDCG@5:0.3261) [0.4 s]
INFO:root:Early stop at 89 based on dev result.
INFO:root:
Best Iter(dev)=   69	 dev=(HR@5:0.4475,NDCG@5:0.3291) [1071.6 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.3946,NDCG@5:0.2845,HR@10:0.5030,NDCG@10:0.3197,HR@20:0.6263,NDCG@20:0.3507,HR@50:0.8346,NDCG@50:0.3920)
INFO:root:
--------------------------------------------- END: 2024-12-23 00:09:06 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 00:39:11 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [12.6 s]    dev=(HR@5:0.2496,NDCG@5:0.1659) [0.4 s] *
INFO:root:Epoch 2     loss=0.4337 [10.9 s]    dev=(HR@5:0.3193,NDCG@5:0.2156) [0.4 s] *
INFO:root:Epoch 3     loss=0.3986 [10.8 s]    dev=(HR@5:0.3443,NDCG@5:0.2318) [0.4 s] *
INFO:root:Epoch 4     loss=0.3777 [10.9 s]    dev=(HR@5:0.3665,NDCG@5:0.2527) [0.4 s] *
INFO:root:Epoch 5     loss=0.3527 [11.0 s]    dev=(HR@5:0.3813,NDCG@5:0.2656) [0.4 s] *
INFO:root:Epoch 6     loss=0.3263 [10.6 s]    dev=(HR@5:0.3977,NDCG@5:0.2816) [0.4 s] *
INFO:root:Epoch 7     loss=0.3062 [11.1 s]    dev=(HR@5:0.4007,NDCG@5:0.2864) [0.4 s] *
INFO:root:Epoch 8     loss=0.2891 [10.9 s]    dev=(HR@5:0.4062,NDCG@5:0.2913) [0.4 s] *
INFO:root:Epoch 9     loss=0.2748 [10.8 s]    dev=(HR@5:0.4055,NDCG@5:0.2933) [0.4 s] *
INFO:root:Epoch 10    loss=0.2649 [11.1 s]    dev=(HR@5:0.4118,NDCG@5:0.2975) [0.4 s] *
INFO:root:Epoch 11    loss=0.2554 [10.9 s]    dev=(HR@5:0.4169,NDCG@5:0.3007) [0.4 s] *
INFO:root:Epoch 12    loss=0.2470 [11.5 s]    dev=(HR@5:0.4160,NDCG@5:0.3018) [0.4 s] *
INFO:root:Epoch 13    loss=0.2431 [11.3 s]    dev=(HR@5:0.4228,NDCG@5:0.3081) [0.4 s] *
INFO:root:Epoch 14    loss=0.2373 [11.1 s]    dev=(HR@5:0.4220,NDCG@5:0.3058) [0.4 s]
INFO:root:Epoch 15    loss=0.2348 [11.1 s]    dev=(HR@5:0.4188,NDCG@5:0.3049) [0.4 s]
INFO:root:Epoch 16    loss=0.2313 [11.1 s]    dev=(HR@5:0.4209,NDCG@5:0.3062) [0.4 s]
INFO:root:Epoch 17    loss=0.2281 [11.2 s]    dev=(HR@5:0.4211,NDCG@5:0.3048) [0.4 s]
INFO:root:Epoch 18    loss=0.2249 [11.5 s]    dev=(HR@5:0.4265,NDCG@5:0.3113) [0.4 s] *
INFO:root:Epoch 19    loss=0.2223 [11.1 s]    dev=(HR@5:0.4242,NDCG@5:0.3101) [0.4 s]
INFO:root:Epoch 20    loss=0.2201 [11.4 s]    dev=(HR@5:0.4254,NDCG@5:0.3122) [0.4 s] *
INFO:root:Epoch 21    loss=0.2170 [11.3 s]    dev=(HR@5:0.4278,NDCG@5:0.3139) [0.4 s] *
INFO:root:Epoch 22    loss=0.2150 [11.1 s]    dev=(HR@5:0.4307,NDCG@5:0.3148) [0.4 s] *
INFO:root:Epoch 23    loss=0.2152 [10.9 s]    dev=(HR@5:0.4242,NDCG@5:0.3117) [0.4 s]
INFO:root:Epoch 24    loss=0.2144 [11.4 s]    dev=(HR@5:0.4320,NDCG@5:0.3159) [0.4 s] *
INFO:root:Epoch 25    loss=0.2109 [11.2 s]    dev=(HR@5:0.4296,NDCG@5:0.3144) [0.4 s]
INFO:root:Epoch 26    loss=0.2107 [11.1 s]    dev=(HR@5:0.4297,NDCG@5:0.3146) [0.4 s]
INFO:root:Epoch 27    loss=0.2102 [11.3 s]    dev=(HR@5:0.4314,NDCG@5:0.3174) [0.4 s] *
INFO:root:Epoch 28    loss=0.2105 [11.6 s]    dev=(HR@5:0.4351,NDCG@5:0.3197) [0.4 s] *
INFO:root:Epoch 29    loss=0.2069 [11.2 s]    dev=(HR@5:0.4327,NDCG@5:0.3186) [0.4 s]
INFO:root:Epoch 30    loss=0.2073 [11.5 s]    dev=(HR@5:0.4337,NDCG@5:0.3182) [0.4 s]
INFO:root:Epoch 31    loss=0.2048 [11.2 s]    dev=(HR@5:0.4371,NDCG@5:0.3215) [0.4 s] *
INFO:root:Epoch 32    loss=0.2061 [11.2 s]    dev=(HR@5:0.4319,NDCG@5:0.3168) [0.4 s]
INFO:root:Epoch 33    loss=0.2051 [10.6 s]    dev=(HR@5:0.4342,NDCG@5:0.3182) [0.4 s]
INFO:root:Epoch 34    loss=0.2038 [10.9 s]    dev=(HR@5:0.4332,NDCG@5:0.3171) [0.4 s]
INFO:root:Epoch 35    loss=0.2050 [11.4 s]    dev=(HR@5:0.4353,NDCG@5:0.3169) [0.4 s]
INFO:root:Epoch 36    loss=0.2025 [11.3 s]    dev=(HR@5:0.4354,NDCG@5:0.3180) [0.4 s]
INFO:root:Epoch 37    loss=0.2026 [11.3 s]    dev=(HR@5:0.4351,NDCG@5:0.3179) [0.4 s]
INFO:root:Epoch 38    loss=0.2021 [11.1 s]    dev=(HR@5:0.4341,NDCG@5:0.3169) [0.4 s]
INFO:root:Epoch 39    loss=0.2029 [11.1 s]    dev=(HR@5:0.4338,NDCG@5:0.3171) [0.4 s]
INFO:root:Epoch 40    loss=0.2007 [11.3 s]    dev=(HR@5:0.4368,NDCG@5:0.3207) [0.4 s]
INFO:root:Epoch 41    loss=0.2020 [11.4 s]    dev=(HR@5:0.4319,NDCG@5:0.3162) [0.4 s]
INFO:root:Epoch 42    loss=0.2017 [10.6 s]    dev=(HR@5:0.4378,NDCG@5:0.3203) [0.4 s]
INFO:root:Epoch 43    loss=0.1996 [9.2 s]    dev=(HR@5:0.4368,NDCG@5:0.3228) [0.4 s] *
INFO:root:Epoch 44    loss=0.2018 [11.1 s]    dev=(HR@5:0.4350,NDCG@5:0.3190) [0.4 s]
INFO:root:Epoch 45    loss=0.1976 [11.4 s]    dev=(HR@5:0.4375,NDCG@5:0.3221) [0.4 s]
INFO:root:Epoch 46    loss=0.1993 [11.7 s]    dev=(HR@5:0.4373,NDCG@5:0.3207) [0.4 s]
INFO:root:Epoch 47    loss=0.2000 [11.6 s]    dev=(HR@5:0.4378,NDCG@5:0.3210) [0.4 s]
INFO:root:Epoch 48    loss=0.1981 [11.3 s]    dev=(HR@5:0.4362,NDCG@5:0.3187) [0.4 s]
INFO:root:Epoch 49    loss=0.1971 [11.2 s]    dev=(HR@5:0.4408,NDCG@5:0.3234) [0.4 s] *
INFO:root:Epoch 50    loss=0.1984 [11.2 s]    dev=(HR@5:0.4363,NDCG@5:0.3196) [0.4 s]
INFO:root:Epoch 51    loss=0.1971 [11.1 s]    dev=(HR@5:0.4386,NDCG@5:0.3217) [0.4 s]
INFO:root:Epoch 52    loss=0.1977 [9.9 s]    dev=(HR@5:0.4379,NDCG@5:0.3205) [0.4 s]
INFO:root:Epoch 53    loss=0.1971 [11.0 s]    dev=(HR@5:0.4389,NDCG@5:0.3225) [0.4 s]
INFO:root:Epoch 54    loss=0.1948 [11.4 s]    dev=(HR@5:0.4407,NDCG@5:0.3218) [0.4 s]
INFO:root:Epoch 55    loss=0.1956 [11.5 s]    dev=(HR@5:0.4383,NDCG@5:0.3202) [0.4 s]
INFO:root:Epoch 56    loss=0.1942 [11.2 s]    dev=(HR@5:0.4429,NDCG@5:0.3257) [0.4 s] *
INFO:root:Epoch 57    loss=0.1954 [11.0 s]    dev=(HR@5:0.4408,NDCG@5:0.3242) [0.4 s]
INFO:root:Epoch 58    loss=0.1957 [11.2 s]    dev=(HR@5:0.4429,NDCG@5:0.3242) [0.4 s]
INFO:root:Epoch 59    loss=0.1947 [11.4 s]    dev=(HR@5:0.4387,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 60    loss=0.1948 [11.3 s]    dev=(HR@5:0.4397,NDCG@5:0.3240) [0.4 s]
INFO:root:Epoch 61    loss=0.1949 [11.1 s]    dev=(HR@5:0.4396,NDCG@5:0.3230) [0.4 s]
INFO:root:Epoch 62    loss=0.1942 [11.4 s]    dev=(HR@5:0.4455,NDCG@5:0.3261) [0.4 s] *
INFO:root:Epoch 63    loss=0.1945 [10.8 s]    dev=(HR@5:0.4464,NDCG@5:0.3263) [0.4 s] *
INFO:root:Epoch 64    loss=0.1928 [11.1 s]    dev=(HR@5:0.4403,NDCG@5:0.3210) [0.4 s]
INFO:root:Epoch 65    loss=0.1947 [11.1 s]    dev=(HR@5:0.4421,NDCG@5:0.3241) [0.4 s]
INFO:root:Epoch 66    loss=0.1921 [10.6 s]    dev=(HR@5:0.4466,NDCG@5:0.3243) [0.4 s]
INFO:root:Epoch 67    loss=0.1932 [11.1 s]    dev=(HR@5:0.4400,NDCG@5:0.3212) [0.4 s]
INFO:root:Epoch 68    loss=0.1909 [11.0 s]    dev=(HR@5:0.4415,NDCG@5:0.3241) [0.4 s]
INFO:root:Epoch 69    loss=0.1930 [11.3 s]    dev=(HR@5:0.4448,NDCG@5:0.3277) [0.4 s] *
INFO:root:Epoch 70    loss=0.1912 [11.2 s]    dev=(HR@5:0.4408,NDCG@5:0.3244) [0.4 s]
INFO:root:Epoch 71    loss=0.1906 [11.1 s]    dev=(HR@5:0.4406,NDCG@5:0.3245) [0.4 s]
INFO:root:Epoch 72    loss=0.1901 [11.5 s]    dev=(HR@5:0.4395,NDCG@5:0.3244) [0.4 s]
INFO:root:Epoch 73    loss=0.1912 [11.6 s]    dev=(HR@5:0.4452,NDCG@5:0.3260) [0.4 s]
INFO:root:Epoch 74    loss=0.1917 [11.2 s]    dev=(HR@5:0.4420,NDCG@5:0.3241) [0.4 s]
INFO:root:Epoch 75    loss=0.1924 [11.4 s]    dev=(HR@5:0.4427,NDCG@5:0.3243) [0.4 s]
INFO:root:Epoch 76    loss=0.1919 [11.4 s]    dev=(HR@5:0.4476,NDCG@5:0.3292) [0.4 s] *
INFO:root:Epoch 77    loss=0.1904 [11.0 s]    dev=(HR@5:0.4464,NDCG@5:0.3263) [0.4 s]
INFO:root:Epoch 78    loss=0.1902 [11.1 s]    dev=(HR@5:0.4421,NDCG@5:0.3239) [0.4 s]
INFO:root:Epoch 79    loss=0.1909 [11.4 s]    dev=(HR@5:0.4424,NDCG@5:0.3234) [0.4 s]
INFO:root:Epoch 80    loss=0.1891 [11.2 s]    dev=(HR@5:0.4415,NDCG@5:0.3222) [0.4 s]
INFO:root:Epoch 81    loss=0.1895 [11.5 s]    dev=(HR@5:0.4363,NDCG@5:0.3191) [0.4 s]
INFO:root:Epoch 82    loss=0.1919 [11.5 s]    dev=(HR@5:0.4422,NDCG@5:0.3241) [0.4 s]
INFO:root:Epoch 83    loss=0.1891 [11.5 s]    dev=(HR@5:0.4453,NDCG@5:0.3267) [0.4 s]
INFO:root:Epoch 84    loss=0.1894 [11.3 s]    dev=(HR@5:0.4437,NDCG@5:0.3248) [0.4 s]
INFO:root:Epoch 85    loss=0.1907 [11.4 s]    dev=(HR@5:0.4419,NDCG@5:0.3233) [0.4 s]
INFO:root:Epoch 86    loss=0.1901 [11.6 s]    dev=(HR@5:0.4430,NDCG@5:0.3240) [0.4 s]
INFO:root:Epoch 87    loss=0.1888 [11.2 s]    dev=(HR@5:0.4428,NDCG@5:0.3250) [0.4 s]
INFO:root:Epoch 88    loss=0.1903 [9.7 s]    dev=(HR@5:0.4452,NDCG@5:0.3254) [0.4 s]
INFO:root:Epoch 89    loss=0.1898 [11.1 s]    dev=(HR@5:0.4395,NDCG@5:0.3211) [0.4 s]
INFO:root:Epoch 90    loss=0.1892 [11.4 s]    dev=(HR@5:0.4447,NDCG@5:0.3252) [0.4 s]
INFO:root:Epoch 91    loss=0.1893 [11.6 s]    dev=(HR@5:0.4466,NDCG@5:0.3271) [0.4 s]
INFO:root:Epoch 92    loss=0.1873 [11.2 s]    dev=(HR@5:0.4423,NDCG@5:0.3237) [0.4 s]
INFO:root:Epoch 93    loss=0.1893 [10.9 s]    dev=(HR@5:0.4373,NDCG@5:0.3196) [0.4 s]
INFO:root:Epoch 94    loss=0.1890 [11.1 s]    dev=(HR@5:0.4443,NDCG@5:0.3253) [0.4 s]
INFO:root:Epoch 95    loss=0.1890 [11.0 s]    dev=(HR@5:0.4447,NDCG@5:0.3252) [0.4 s]
INFO:root:Epoch 96    loss=0.1875 [11.2 s]    dev=(HR@5:0.4416,NDCG@5:0.3231) [0.4 s]
INFO:root:Early stop at 96 based on dev result.
INFO:root:
Best Iter(dev)=   76	 dev=(HR@5:0.4476,NDCG@5:0.3292) [1108.8 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.3978,NDCG@5:0.2833,HR@10:0.5083,NDCG@10:0.3192,HR@20:0.6295,NDCG@20:0.3497,HR@50:0.8376,NDCG@50:0.3909)
INFO:root:
--------------------------------------------- END: 2024-12-23 00:57:42 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 01:16:59 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5165 [12.6 s]    dev=(HR@5:0.2507,NDCG@5:0.1666) [0.4 s] *
INFO:root:Epoch 2     loss=0.4322 [11.1 s]    dev=(HR@5:0.3202,NDCG@5:0.2172) [0.3 s] *
INFO:root:Epoch 3     loss=0.3951 [10.8 s]    dev=(HR@5:0.3485,NDCG@5:0.2364) [0.3 s] *
INFO:root:Epoch 4     loss=0.3717 [10.9 s]    dev=(HR@5:0.3706,NDCG@5:0.2552) [0.4 s] *
INFO:root:Epoch 5     loss=0.3464 [11.1 s]    dev=(HR@5:0.3880,NDCG@5:0.2712) [0.4 s] *
INFO:root:Epoch 6     loss=0.3205 [11.1 s]    dev=(HR@5:0.4039,NDCG@5:0.2868) [0.4 s] *
INFO:root:Epoch 7     loss=0.3009 [11.3 s]    dev=(HR@5:0.4099,NDCG@5:0.2931) [0.4 s] *
INFO:root:Epoch 8     loss=0.2847 [10.8 s]    dev=(HR@5:0.4163,NDCG@5:0.3002) [0.4 s] *
INFO:root:Epoch 9     loss=0.2697 [11.4 s]    dev=(HR@5:0.4232,NDCG@5:0.3047) [0.4 s] *
INFO:root:Epoch 10    loss=0.2604 [10.3 s]    dev=(HR@5:0.4242,NDCG@5:0.3063) [0.4 s] *
INFO:root:Epoch 11    loss=0.2503 [11.1 s]    dev=(HR@5:0.4287,NDCG@5:0.3094) [0.4 s] *
INFO:root:Epoch 12    loss=0.2427 [11.4 s]    dev=(HR@5:0.4321,NDCG@5:0.3135) [0.4 s] *
INFO:root:Epoch 13    loss=0.2389 [11.4 s]    dev=(HR@5:0.4387,NDCG@5:0.3200) [0.4 s] *
INFO:root:Epoch 14    loss=0.2329 [11.0 s]    dev=(HR@5:0.4372,NDCG@5:0.3173) [0.4 s]
INFO:root:Epoch 15    loss=0.2299 [11.2 s]    dev=(HR@5:0.4353,NDCG@5:0.3159) [0.4 s]
INFO:root:Epoch 16    loss=0.2268 [10.6 s]    dev=(HR@5:0.4423,NDCG@5:0.3214) [0.3 s] *
INFO:root:Epoch 17    loss=0.2229 [11.2 s]    dev=(HR@5:0.4376,NDCG@5:0.3186) [0.4 s]
INFO:root:Epoch 18    loss=0.2189 [11.2 s]    dev=(HR@5:0.4406,NDCG@5:0.3209) [0.4 s]
INFO:root:Epoch 19    loss=0.2173 [11.2 s]    dev=(HR@5:0.4422,NDCG@5:0.3237) [0.4 s] *
INFO:root:Epoch 20    loss=0.2150 [11.1 s]    dev=(HR@5:0.4434,NDCG@5:0.3263) [0.4 s] *
INFO:root:Epoch 21    loss=0.2107 [11.0 s]    dev=(HR@5:0.4469,NDCG@5:0.3263) [0.4 s]
INFO:root:Epoch 22    loss=0.2101 [10.8 s]    dev=(HR@5:0.4447,NDCG@5:0.3247) [0.4 s]
INFO:root:Epoch 23    loss=0.2110 [11.1 s]    dev=(HR@5:0.4434,NDCG@5:0.3266) [0.4 s] *
INFO:root:Epoch 24    loss=0.2098 [11.4 s]    dev=(HR@5:0.4452,NDCG@5:0.3248) [0.4 s]
INFO:root:Epoch 25    loss=0.2064 [11.2 s]    dev=(HR@5:0.4443,NDCG@5:0.3253) [0.4 s]
INFO:root:Epoch 26    loss=0.2066 [10.8 s]    dev=(HR@5:0.4468,NDCG@5:0.3269) [0.4 s] *
INFO:root:Epoch 27    loss=0.2066 [11.1 s]    dev=(HR@5:0.4479,NDCG@5:0.3292) [0.4 s] *
INFO:root:Epoch 28    loss=0.2067 [11.3 s]    dev=(HR@5:0.4511,NDCG@5:0.3312) [0.4 s] *
INFO:root:Epoch 29    loss=0.2047 [11.3 s]    dev=(HR@5:0.4472,NDCG@5:0.3279) [0.4 s]
INFO:root:Epoch 30    loss=0.2041 [11.3 s]    dev=(HR@5:0.4464,NDCG@5:0.3290) [0.4 s]
INFO:root:Epoch 31    loss=0.2034 [11.3 s]    dev=(HR@5:0.4501,NDCG@5:0.3303) [0.4 s]
INFO:root:Epoch 32    loss=0.2029 [10.8 s]    dev=(HR@5:0.4477,NDCG@5:0.3294) [0.4 s]
INFO:root:Epoch 33    loss=0.2030 [10.6 s]    dev=(HR@5:0.4455,NDCG@5:0.3272) [0.4 s]
INFO:root:Epoch 34    loss=0.2022 [11.2 s]    dev=(HR@5:0.4485,NDCG@5:0.3279) [0.4 s]
INFO:root:Epoch 35    loss=0.2025 [9.8 s]    dev=(HR@5:0.4423,NDCG@5:0.3245) [0.4 s]
INFO:root:Epoch 36    loss=0.1999 [11.0 s]    dev=(HR@5:0.4442,NDCG@5:0.3267) [0.4 s]
INFO:root:Epoch 37    loss=0.2005 [11.2 s]    dev=(HR@5:0.4480,NDCG@5:0.3277) [0.4 s]
INFO:root:Epoch 38    loss=0.2005 [11.1 s]    dev=(HR@5:0.4436,NDCG@5:0.3258) [0.4 s]
INFO:root:Epoch 39    loss=0.1993 [11.3 s]    dev=(HR@5:0.4423,NDCG@5:0.3231) [0.4 s]
INFO:root:Epoch 40    loss=0.1991 [10.7 s]    dev=(HR@5:0.4451,NDCG@5:0.3264) [0.4 s]
INFO:root:Epoch 41    loss=0.1996 [11.4 s]    dev=(HR@5:0.4438,NDCG@5:0.3236) [0.4 s]
INFO:root:Epoch 42    loss=0.1991 [11.1 s]    dev=(HR@5:0.4469,NDCG@5:0.3265) [0.4 s]
INFO:root:Epoch 43    loss=0.1975 [11.0 s]    dev=(HR@5:0.4491,NDCG@5:0.3293) [0.4 s]
INFO:root:Epoch 44    loss=0.1989 [11.0 s]    dev=(HR@5:0.4466,NDCG@5:0.3267) [0.4 s]
INFO:root:Epoch 45    loss=0.1959 [10.6 s]    dev=(HR@5:0.4477,NDCG@5:0.3289) [0.4 s]
INFO:root:Epoch 46    loss=0.1968 [10.8 s]    dev=(HR@5:0.4457,NDCG@5:0.3285) [0.4 s]
INFO:root:Epoch 47    loss=0.1967 [10.8 s]    dev=(HR@5:0.4479,NDCG@5:0.3280) [0.4 s]
INFO:root:Epoch 48    loss=0.1955 [11.1 s]    dev=(HR@5:0.4450,NDCG@5:0.3273) [0.4 s]
INFO:root:Early stop at 48 based on dev result.
INFO:root:
Best Iter(dev)=   28	 dev=(HR@5:0.4511,NDCG@5:0.3312) [549.2 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.3977,NDCG@5:0.2844,HR@10:0.5122,NDCG@10:0.3214,HR@20:0.6355,NDCG@20:0.3525,HR@50:0.8384,NDCG@50:0.3926)
INFO:root:
--------------------------------------------- END: 2024-12-23 01:26:11 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 01:45:51 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [12.4 s]    dev=(HR@5:0.2526,NDCG@5:0.1679) [0.4 s] *
INFO:root:Epoch 2     loss=0.4300 [11.1 s]    dev=(HR@5:0.3273,NDCG@5:0.2222) [0.4 s] *
INFO:root:Epoch 3     loss=0.3922 [11.1 s]    dev=(HR@5:0.3564,NDCG@5:0.2436) [0.4 s] *
INFO:root:Epoch 4     loss=0.3705 [10.9 s]    dev=(HR@5:0.3715,NDCG@5:0.2574) [0.4 s] *
INFO:root:Epoch 5     loss=0.3481 [11.2 s]    dev=(HR@5:0.3898,NDCG@5:0.2724) [0.4 s] *
INFO:root:Epoch 6     loss=0.3236 [11.2 s]    dev=(HR@5:0.4077,NDCG@5:0.2891) [0.4 s] *
INFO:root:Epoch 7     loss=0.3037 [11.2 s]    dev=(HR@5:0.4151,NDCG@5:0.2957) [0.4 s] *
INFO:root:Epoch 8     loss=0.2869 [10.8 s]    dev=(HR@5:0.4216,NDCG@5:0.3035) [0.4 s] *
INFO:root:Epoch 9     loss=0.2711 [10.4 s]    dev=(HR@5:0.4275,NDCG@5:0.3078) [0.4 s] *
INFO:root:Epoch 10    loss=0.2613 [11.3 s]    dev=(HR@5:0.4294,NDCG@5:0.3107) [0.4 s] *
INFO:root:Epoch 11    loss=0.2509 [10.6 s]    dev=(HR@5:0.4342,NDCG@5:0.3145) [0.4 s] *
INFO:root:Epoch 12    loss=0.2428 [11.4 s]    dev=(HR@5:0.4363,NDCG@5:0.3180) [0.4 s] *
INFO:root:Epoch 13    loss=0.2386 [11.3 s]    dev=(HR@5:0.4419,NDCG@5:0.3223) [0.4 s] *
INFO:root:Epoch 14    loss=0.2329 [11.4 s]    dev=(HR@5:0.4413,NDCG@5:0.3208) [0.4 s]
INFO:root:Epoch 15    loss=0.2299 [11.0 s]    dev=(HR@5:0.4421,NDCG@5:0.3208) [0.4 s]
INFO:root:Epoch 16    loss=0.2268 [11.2 s]    dev=(HR@5:0.4436,NDCG@5:0.3241) [0.4 s] *
INFO:root:Epoch 17    loss=0.2236 [11.2 s]    dev=(HR@5:0.4406,NDCG@5:0.3210) [0.4 s]
INFO:root:Epoch 18    loss=0.2191 [11.0 s]    dev=(HR@5:0.4466,NDCG@5:0.3273) [0.4 s] *
INFO:root:Epoch 19    loss=0.2173 [10.4 s]    dev=(HR@5:0.4436,NDCG@5:0.3269) [0.4 s]
INFO:root:Epoch 20    loss=0.2149 [11.1 s]    dev=(HR@5:0.4445,NDCG@5:0.3279) [0.4 s] *
INFO:root:Epoch 21    loss=0.2112 [11.1 s]    dev=(HR@5:0.4460,NDCG@5:0.3271) [0.4 s]
INFO:root:Epoch 22    loss=0.2105 [11.5 s]    dev=(HR@5:0.4453,NDCG@5:0.3273) [0.4 s]
INFO:root:Epoch 23    loss=0.2112 [11.6 s]    dev=(HR@5:0.4449,NDCG@5:0.3273) [0.4 s]
INFO:root:Epoch 24    loss=0.2103 [10.9 s]    dev=(HR@5:0.4455,NDCG@5:0.3259) [0.4 s]
INFO:root:Epoch 25    loss=0.2070 [11.3 s]    dev=(HR@5:0.4478,NDCG@5:0.3281) [0.4 s] *
INFO:root:Epoch 26    loss=0.2074 [11.1 s]    dev=(HR@5:0.4509,NDCG@5:0.3304) [0.4 s] *
INFO:root:Epoch 27    loss=0.2070 [11.3 s]    dev=(HR@5:0.4496,NDCG@5:0.3315) [0.4 s] *
INFO:root:Epoch 28    loss=0.2075 [11.2 s]    dev=(HR@5:0.4528,NDCG@5:0.3337) [0.4 s] *
INFO:root:Epoch 29    loss=0.2048 [11.3 s]    dev=(HR@5:0.4511,NDCG@5:0.3317) [0.3 s]
INFO:root:Epoch 30    loss=0.2039 [10.9 s]    dev=(HR@5:0.4484,NDCG@5:0.3308) [0.4 s]
INFO:root:Epoch 31    loss=0.2034 [11.2 s]    dev=(HR@5:0.4494,NDCG@5:0.3311) [0.4 s]
INFO:root:Epoch 32    loss=0.2039 [10.9 s]    dev=(HR@5:0.4506,NDCG@5:0.3312) [0.4 s]
INFO:root:Epoch 33    loss=0.2032 [10.7 s]    dev=(HR@5:0.4485,NDCG@5:0.3305) [0.4 s]
INFO:root:Epoch 34    loss=0.2031 [10.9 s]    dev=(HR@5:0.4486,NDCG@5:0.3298) [0.4 s]
INFO:root:Epoch 35    loss=0.2029 [10.5 s]    dev=(HR@5:0.4460,NDCG@5:0.3289) [0.4 s]
INFO:root:Epoch 36    loss=0.2008 [11.2 s]    dev=(HR@5:0.4480,NDCG@5:0.3291) [0.4 s]
INFO:root:Epoch 37    loss=0.2018 [11.2 s]    dev=(HR@5:0.4483,NDCG@5:0.3287) [0.4 s]
INFO:root:Epoch 38    loss=0.2016 [11.4 s]    dev=(HR@5:0.4471,NDCG@5:0.3287) [0.4 s]
INFO:root:Epoch 39    loss=0.2009 [11.5 s]    dev=(HR@5:0.4462,NDCG@5:0.3260) [0.4 s]
INFO:root:Epoch 40    loss=0.2003 [11.3 s]    dev=(HR@5:0.4462,NDCG@5:0.3275) [0.4 s]
INFO:root:Epoch 41    loss=0.2014 [11.6 s]    dev=(HR@5:0.4469,NDCG@5:0.3274) [0.4 s]
INFO:root:Epoch 42    loss=0.2009 [11.4 s]    dev=(HR@5:0.4515,NDCG@5:0.3297) [0.4 s]
INFO:root:Epoch 43    loss=0.1991 [11.2 s]    dev=(HR@5:0.4478,NDCG@5:0.3306) [0.4 s]
INFO:root:Epoch 44    loss=0.2002 [10.8 s]    dev=(HR@5:0.4445,NDCG@5:0.3265) [0.4 s]
INFO:root:Epoch 45    loss=0.1979 [10.1 s]    dev=(HR@5:0.4486,NDCG@5:0.3327) [0.4 s]
INFO:root:Epoch 46    loss=0.1986 [10.8 s]    dev=(HR@5:0.4452,NDCG@5:0.3271) [0.4 s]
INFO:root:Epoch 47    loss=0.1990 [11.2 s]    dev=(HR@5:0.4487,NDCG@5:0.3299) [0.4 s]
INFO:root:Epoch 48    loss=0.1981 [11.3 s]    dev=(HR@5:0.4467,NDCG@5:0.3283) [0.4 s]
INFO:root:Early stop at 48 based on dev result.
INFO:root:
Best Iter(dev)=   28	 dev=(HR@5:0.4528,NDCG@5:0.3337) [552.3 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.4035,NDCG@5:0.2879,HR@10:0.5147,NDCG@10:0.3239,HR@20:0.6381,NDCG@20:0.3550,HR@50:0.8405,NDCG@50:0.3949)
INFO:root:
--------------------------------------------- END: 2024-12-23 01:55:06 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 02:15:34 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5165 [13.2 s]    dev=(HR@5:0.2535,NDCG@5:0.1687) [0.4 s] *
INFO:root:Epoch 2     loss=0.4296 [11.1 s]    dev=(HR@5:0.3265,NDCG@5:0.2226) [0.4 s] *
INFO:root:Epoch 3     loss=0.3929 [11.2 s]    dev=(HR@5:0.3533,NDCG@5:0.2418) [0.4 s] *
INFO:root:Epoch 4     loss=0.3721 [11.2 s]    dev=(HR@5:0.3704,NDCG@5:0.2566) [0.4 s] *
INFO:root:Epoch 5     loss=0.3500 [11.3 s]    dev=(HR@5:0.3893,NDCG@5:0.2717) [0.4 s] *
INFO:root:Epoch 6     loss=0.3268 [11.3 s]    dev=(HR@5:0.4037,NDCG@5:0.2858) [0.4 s] *
INFO:root:Epoch 7     loss=0.3083 [11.5 s]    dev=(HR@5:0.4095,NDCG@5:0.2906) [0.4 s] *
INFO:root:Epoch 8     loss=0.2931 [11.2 s]    dev=(HR@5:0.4169,NDCG@5:0.2984) [0.4 s] *
INFO:root:Epoch 9     loss=0.2783 [11.2 s]    dev=(HR@5:0.4203,NDCG@5:0.3016) [0.4 s] *
INFO:root:Epoch 10    loss=0.2697 [11.4 s]    dev=(HR@5:0.4243,NDCG@5:0.3052) [0.4 s] *
INFO:root:Epoch 11    loss=0.2594 [11.6 s]    dev=(HR@5:0.4251,NDCG@5:0.3058) [0.4 s] *
INFO:root:Epoch 12    loss=0.2516 [11.4 s]    dev=(HR@5:0.4313,NDCG@5:0.3116) [0.4 s] *
INFO:root:Epoch 13    loss=0.2473 [11.1 s]    dev=(HR@5:0.4364,NDCG@5:0.3152) [0.4 s] *
INFO:root:Epoch 14    loss=0.2414 [11.5 s]    dev=(HR@5:0.4328,NDCG@5:0.3124) [0.4 s]
INFO:root:Epoch 15    loss=0.2384 [11.4 s]    dev=(HR@5:0.4346,NDCG@5:0.3134) [0.4 s]
INFO:root:Epoch 16    loss=0.2360 [11.5 s]    dev=(HR@5:0.4387,NDCG@5:0.3175) [0.3 s] *
INFO:root:Epoch 17    loss=0.2323 [11.1 s]    dev=(HR@5:0.4353,NDCG@5:0.3159) [0.4 s]
INFO:root:Epoch 18    loss=0.2268 [11.2 s]    dev=(HR@5:0.4401,NDCG@5:0.3199) [0.4 s] *
INFO:root:Epoch 19    loss=0.2254 [11.0 s]    dev=(HR@5:0.4425,NDCG@5:0.3221) [0.4 s] *
INFO:root:Epoch 20    loss=0.2225 [11.2 s]    dev=(HR@5:0.4427,NDCG@5:0.3236) [0.4 s] *
INFO:root:Epoch 21    loss=0.2184 [11.2 s]    dev=(HR@5:0.4441,NDCG@5:0.3240) [0.4 s] *
INFO:root:Epoch 22    loss=0.2176 [11.0 s]    dev=(HR@5:0.4423,NDCG@5:0.3232) [0.4 s]
INFO:root:Epoch 23    loss=0.2184 [10.9 s]    dev=(HR@5:0.4381,NDCG@5:0.3218) [0.4 s]
INFO:root:Epoch 24    loss=0.2171 [10.9 s]    dev=(HR@5:0.4426,NDCG@5:0.3212) [0.4 s]
INFO:root:Epoch 25    loss=0.2135 [11.2 s]    dev=(HR@5:0.4436,NDCG@5:0.3225) [0.4 s]
INFO:root:Epoch 26    loss=0.2131 [11.0 s]    dev=(HR@5:0.4482,NDCG@5:0.3262) [0.4 s] *
INFO:root:Epoch 27    loss=0.2130 [10.6 s]    dev=(HR@5:0.4460,NDCG@5:0.3257) [0.4 s]
INFO:root:Epoch 28    loss=0.2129 [10.8 s]    dev=(HR@5:0.4466,NDCG@5:0.3290) [0.4 s] *
INFO:root:Epoch 29    loss=0.2105 [11.0 s]    dev=(HR@5:0.4443,NDCG@5:0.3260) [0.4 s]
INFO:root:Epoch 30    loss=0.2097 [11.1 s]    dev=(HR@5:0.4478,NDCG@5:0.3279) [0.4 s]
INFO:root:Epoch 31    loss=0.2091 [10.4 s]    dev=(HR@5:0.4481,NDCG@5:0.3298) [0.4 s] *
INFO:root:Epoch 32    loss=0.2096 [11.0 s]    dev=(HR@5:0.4452,NDCG@5:0.3255) [0.4 s]
INFO:root:Epoch 33    loss=0.2087 [11.1 s]    dev=(HR@5:0.4498,NDCG@5:0.3290) [0.4 s]
INFO:root:Epoch 34    loss=0.2085 [11.2 s]    dev=(HR@5:0.4507,NDCG@5:0.3297) [0.4 s]
INFO:root:Epoch 35    loss=0.2089 [11.3 s]    dev=(HR@5:0.4494,NDCG@5:0.3272) [0.4 s]
INFO:root:Epoch 36    loss=0.2062 [11.1 s]    dev=(HR@5:0.4454,NDCG@5:0.3263) [0.4 s]
INFO:root:Epoch 37    loss=0.2066 [11.1 s]    dev=(HR@5:0.4484,NDCG@5:0.3273) [0.4 s]
INFO:root:Epoch 38    loss=0.2070 [11.2 s]    dev=(HR@5:0.4494,NDCG@5:0.3270) [0.4 s]
INFO:root:Epoch 39    loss=0.2068 [11.2 s]    dev=(HR@5:0.4417,NDCG@5:0.3208) [0.4 s]
INFO:root:Epoch 40    loss=0.2058 [11.5 s]    dev=(HR@5:0.4433,NDCG@5:0.3238) [0.4 s]
INFO:root:Epoch 41    loss=0.2073 [11.3 s]    dev=(HR@5:0.4460,NDCG@5:0.3251) [0.4 s]
INFO:root:Epoch 42    loss=0.2066 [11.0 s]    dev=(HR@5:0.4498,NDCG@5:0.3268) [0.3 s]
INFO:root:Epoch 43    loss=0.2050 [11.0 s]    dev=(HR@5:0.4471,NDCG@5:0.3291) [0.4 s]
INFO:root:Epoch 44    loss=0.2057 [10.2 s]    dev=(HR@5:0.4477,NDCG@5:0.3272) [0.4 s]
INFO:root:Epoch 45    loss=0.2039 [12.1 s]    dev=(HR@5:0.4487,NDCG@5:0.3295) [0.4 s]
INFO:root:Epoch 46    loss=0.2039 [10.8 s]    dev=(HR@5:0.4458,NDCG@5:0.3265) [0.4 s]
INFO:root:Epoch 47    loss=0.2047 [11.4 s]    dev=(HR@5:0.4455,NDCG@5:0.3265) [0.4 s]
INFO:root:Epoch 48    loss=0.2034 [11.4 s]    dev=(HR@5:0.4422,NDCG@5:0.3230) [0.4 s]
INFO:root:Epoch 49    loss=0.2021 [11.4 s]    dev=(HR@5:0.4468,NDCG@5:0.3281) [0.4 s]
INFO:root:Epoch 50    loss=0.2041 [11.1 s]    dev=(HR@5:0.4440,NDCG@5:0.3263) [0.4 s]
INFO:root:Epoch 51    loss=0.2020 [10.7 s]    dev=(HR@5:0.4479,NDCG@5:0.3279) [0.4 s]
INFO:root:Early stop at 51 based on dev result.
INFO:root:
Best Iter(dev)=   31	 dev=(HR@5:0.4481,NDCG@5:0.3298) [591.0 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.3979,NDCG@5:0.2835,HR@10:0.5081,NDCG@10:0.3193,HR@20:0.6317,NDCG@20:0.3503,HR@50:0.8425,NDCG@50:0.3921)
INFO:root:
--------------------------------------------- END: 2024-12-23 02:25:28 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 02:44:38 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5166 [12.0 s]    dev=(HR@5:0.2527,NDCG@5:0.1681) [0.4 s] *
INFO:root:Epoch 2     loss=0.4305 [11.4 s]    dev=(HR@5:0.3261,NDCG@5:0.2216) [0.4 s] *
INFO:root:Epoch 3     loss=0.3942 [11.6 s]    dev=(HR@5:0.3496,NDCG@5:0.2381) [0.4 s] *
INFO:root:Epoch 4     loss=0.3737 [11.4 s]    dev=(HR@5:0.3678,NDCG@5:0.2539) [0.4 s] *
INFO:root:Epoch 5     loss=0.3507 [11.5 s]    dev=(HR@5:0.3865,NDCG@5:0.2687) [0.4 s] *
INFO:root:Epoch 6     loss=0.3260 [11.3 s]    dev=(HR@5:0.4047,NDCG@5:0.2878) [0.4 s] *
INFO:root:Epoch 7     loss=0.3052 [11.4 s]    dev=(HR@5:0.4154,NDCG@5:0.2968) [0.4 s] *
INFO:root:Epoch 8     loss=0.2881 [11.1 s]    dev=(HR@5:0.4204,NDCG@5:0.3034) [0.4 s] *
INFO:root:Epoch 9     loss=0.2722 [10.4 s]    dev=(HR@5:0.4236,NDCG@5:0.3070) [0.4 s] *
INFO:root:Epoch 10    loss=0.2625 [11.4 s]    dev=(HR@5:0.4312,NDCG@5:0.3125) [0.4 s] *
INFO:root:Epoch 11    loss=0.2520 [11.4 s]    dev=(HR@5:0.4331,NDCG@5:0.3139) [0.4 s] *
INFO:root:Epoch 12    loss=0.2445 [10.6 s]    dev=(HR@5:0.4353,NDCG@5:0.3171) [0.4 s] *
INFO:root:Epoch 13    loss=0.2404 [10.8 s]    dev=(HR@5:0.4428,NDCG@5:0.3225) [0.4 s] *
INFO:root:Epoch 14    loss=0.2352 [10.7 s]    dev=(HR@5:0.4405,NDCG@5:0.3196) [0.4 s]
INFO:root:Epoch 15    loss=0.2326 [11.3 s]    dev=(HR@5:0.4381,NDCG@5:0.3173) [0.4 s]
INFO:root:Epoch 16    loss=0.2307 [11.3 s]    dev=(HR@5:0.4404,NDCG@5:0.3216) [0.4 s]
INFO:root:Epoch 17    loss=0.2275 [11.2 s]    dev=(HR@5:0.4366,NDCG@5:0.3192) [0.4 s]
INFO:root:Epoch 18    loss=0.2230 [11.3 s]    dev=(HR@5:0.4402,NDCG@5:0.3217) [0.4 s]
INFO:root:Epoch 19    loss=0.2217 [11.1 s]    dev=(HR@5:0.4400,NDCG@5:0.3222) [0.4 s]
INFO:root:Epoch 20    loss=0.2194 [11.3 s]    dev=(HR@5:0.4428,NDCG@5:0.3245) [0.4 s] *
INFO:root:Epoch 21    loss=0.2156 [11.4 s]    dev=(HR@5:0.4443,NDCG@5:0.3259) [0.4 s] *
INFO:root:Epoch 22    loss=0.2158 [11.2 s]    dev=(HR@5:0.4438,NDCG@5:0.3245) [0.4 s]
INFO:root:Epoch 23    loss=0.2162 [11.3 s]    dev=(HR@5:0.4417,NDCG@5:0.3243) [0.4 s]
INFO:root:Epoch 24    loss=0.2152 [11.3 s]    dev=(HR@5:0.4471,NDCG@5:0.3255) [0.4 s]
INFO:root:Epoch 25    loss=0.2120 [11.3 s]    dev=(HR@5:0.4418,NDCG@5:0.3226) [0.4 s]
INFO:root:Epoch 26    loss=0.2120 [11.2 s]    dev=(HR@5:0.4470,NDCG@5:0.3268) [0.4 s] *
INFO:root:Epoch 27    loss=0.2121 [11.1 s]    dev=(HR@5:0.4464,NDCG@5:0.3281) [0.4 s] *
INFO:root:Epoch 28    loss=0.2114 [11.2 s]    dev=(HR@5:0.4492,NDCG@5:0.3300) [0.4 s] *
INFO:root:Epoch 29    loss=0.2095 [11.2 s]    dev=(HR@5:0.4464,NDCG@5:0.3273) [0.4 s]
INFO:root:Epoch 30    loss=0.2087 [11.2 s]    dev=(HR@5:0.4484,NDCG@5:0.3293) [0.4 s]
INFO:root:Epoch 31    loss=0.2083 [11.4 s]    dev=(HR@5:0.4494,NDCG@5:0.3304) [0.4 s] *
INFO:root:Epoch 32    loss=0.2085 [11.2 s]    dev=(HR@5:0.4451,NDCG@5:0.3264) [0.4 s]
INFO:root:Epoch 33    loss=0.2076 [11.3 s]    dev=(HR@5:0.4485,NDCG@5:0.3287) [0.4 s]
INFO:root:Epoch 34    loss=0.2072 [11.3 s]    dev=(HR@5:0.4498,NDCG@5:0.3295) [0.4 s]
INFO:root:Epoch 35    loss=0.2080 [11.0 s]    dev=(HR@5:0.4474,NDCG@5:0.3271) [0.4 s]
INFO:root:Epoch 36    loss=0.2053 [11.4 s]    dev=(HR@5:0.4464,NDCG@5:0.3265) [0.4 s]
INFO:root:Epoch 37    loss=0.2055 [11.1 s]    dev=(HR@5:0.4483,NDCG@5:0.3282) [0.4 s]
INFO:root:Epoch 38    loss=0.2065 [11.2 s]    dev=(HR@5:0.4466,NDCG@5:0.3270) [0.4 s]
INFO:root:Epoch 39    loss=0.2061 [11.2 s]    dev=(HR@5:0.4440,NDCG@5:0.3229) [0.4 s]
INFO:root:Epoch 40    loss=0.2047 [11.0 s]    dev=(HR@5:0.4450,NDCG@5:0.3249) [0.4 s]
INFO:root:Epoch 41    loss=0.2059 [10.2 s]    dev=(HR@5:0.4443,NDCG@5:0.3244) [0.4 s]
INFO:root:Epoch 42    loss=0.2058 [10.0 s]    dev=(HR@5:0.4452,NDCG@5:0.3258) [0.4 s]
INFO:root:Epoch 43    loss=0.2040 [11.5 s]    dev=(HR@5:0.4475,NDCG@5:0.3291) [0.4 s]
INFO:root:Epoch 44    loss=0.2044 [10.8 s]    dev=(HR@5:0.4453,NDCG@5:0.3260) [0.4 s]
INFO:root:Epoch 45    loss=0.2023 [10.9 s]    dev=(HR@5:0.4477,NDCG@5:0.3290) [0.4 s]
INFO:root:Epoch 46    loss=0.2024 [10.6 s]    dev=(HR@5:0.4418,NDCG@5:0.3249) [0.4 s]
INFO:root:Epoch 47    loss=0.2033 [11.2 s]    dev=(HR@5:0.4450,NDCG@5:0.3263) [0.4 s]
INFO:root:Epoch 48    loss=0.2019 [10.4 s]    dev=(HR@5:0.4417,NDCG@5:0.3240) [0.4 s]
INFO:root:Epoch 49    loss=0.2003 [11.5 s]    dev=(HR@5:0.4419,NDCG@5:0.3260) [0.4 s]
INFO:root:Epoch 50    loss=0.2025 [10.7 s]    dev=(HR@5:0.4440,NDCG@5:0.3265) [0.4 s]
INFO:root:Epoch 51    loss=0.2003 [11.0 s]    dev=(HR@5:0.4451,NDCG@5:0.3265) [0.4 s]
INFO:root:Early stop at 51 based on dev result.
INFO:root:
Best Iter(dev)=   31	 dev=(HR@5:0.4494,NDCG@5:0.3304) [588.0 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.3992,NDCG@5:0.2857,HR@10:0.5109,NDCG@10:0.3218,HR@20:0.6317,NDCG@20:0.3522,HR@50:0.8411,NDCG@50:0.3937)
INFO:root:
--------------------------------------------- END: 2024-12-23 02:54:29 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 03:30:08 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5159 [12.4 s]    dev=(HR@5:0.2499,NDCG@5:0.1663) [0.4 s] *
INFO:root:Epoch 2     loss=0.4331 [11.1 s]    dev=(HR@5:0.3176,NDCG@5:0.2143) [0.4 s] *
INFO:root:Epoch 3     loss=0.3977 [11.3 s]    dev=(HR@5:0.3434,NDCG@5:0.2307) [0.4 s] *
INFO:root:Epoch 4     loss=0.3760 [11.1 s]    dev=(HR@5:0.3641,NDCG@5:0.2501) [0.4 s] *
INFO:root:Epoch 5     loss=0.3519 [11.5 s]    dev=(HR@5:0.3787,NDCG@5:0.2639) [0.4 s] *
INFO:root:Epoch 6     loss=0.3283 [11.2 s]    dev=(HR@5:0.3910,NDCG@5:0.2768) [0.4 s] *
INFO:root:Epoch 7     loss=0.3087 [11.3 s]    dev=(HR@5:0.3951,NDCG@5:0.2823) [0.4 s] *
INFO:root:Epoch 8     loss=0.2921 [11.4 s]    dev=(HR@5:0.4012,NDCG@5:0.2886) [0.4 s] *
INFO:root:Epoch 9     loss=0.2771 [11.3 s]    dev=(HR@5:0.4006,NDCG@5:0.2916) [0.4 s] *
INFO:root:Epoch 10    loss=0.2665 [11.2 s]    dev=(HR@5:0.4062,NDCG@5:0.2945) [0.4 s] *
INFO:root:Epoch 11    loss=0.2573 [11.3 s]    dev=(HR@5:0.4168,NDCG@5:0.3010) [0.4 s] *
INFO:root:Epoch 12    loss=0.2484 [11.2 s]    dev=(HR@5:0.4173,NDCG@5:0.3027) [0.4 s] *
INFO:root:Epoch 13    loss=0.2451 [10.4 s]    dev=(HR@5:0.4216,NDCG@5:0.3071) [0.4 s] *
INFO:root:Epoch 14    loss=0.2387 [11.2 s]    dev=(HR@5:0.4224,NDCG@5:0.3059) [0.4 s]
INFO:root:Epoch 15    loss=0.2367 [11.2 s]    dev=(HR@5:0.4214,NDCG@5:0.3056) [0.4 s]
INFO:root:Epoch 16    loss=0.2329 [11.2 s]    dev=(HR@5:0.4225,NDCG@5:0.3080) [0.4 s] *
INFO:root:Epoch 17    loss=0.2299 [11.1 s]    dev=(HR@5:0.4234,NDCG@5:0.3071) [0.4 s]
INFO:root:Epoch 18    loss=0.2256 [11.1 s]    dev=(HR@5:0.4238,NDCG@5:0.3095) [0.4 s] *
INFO:root:Epoch 19    loss=0.2237 [11.2 s]    dev=(HR@5:0.4256,NDCG@5:0.3117) [0.4 s] *
INFO:root:Epoch 20    loss=0.2221 [11.4 s]    dev=(HR@5:0.4262,NDCG@5:0.3115) [0.4 s]
INFO:root:Epoch 21    loss=0.2177 [11.1 s]    dev=(HR@5:0.4297,NDCG@5:0.3129) [0.4 s] *
INFO:root:Epoch 22    loss=0.2161 [11.1 s]    dev=(HR@5:0.4331,NDCG@5:0.3160) [0.4 s] *
INFO:root:Epoch 23    loss=0.2170 [11.4 s]    dev=(HR@5:0.4201,NDCG@5:0.3093) [0.4 s]
INFO:root:Epoch 24    loss=0.2152 [11.2 s]    dev=(HR@5:0.4304,NDCG@5:0.3137) [0.4 s]
INFO:root:Epoch 25    loss=0.2134 [10.8 s]    dev=(HR@5:0.4312,NDCG@5:0.3145) [0.4 s]
INFO:root:Epoch 26    loss=0.2136 [11.1 s]    dev=(HR@5:0.4300,NDCG@5:0.3142) [0.4 s]
INFO:root:Epoch 27    loss=0.2124 [11.1 s]    dev=(HR@5:0.4343,NDCG@5:0.3175) [0.4 s] *
INFO:root:Epoch 28    loss=0.2126 [10.9 s]    dev=(HR@5:0.4345,NDCG@5:0.3189) [0.4 s] *
INFO:root:Epoch 29    loss=0.2098 [11.0 s]    dev=(HR@5:0.4311,NDCG@5:0.3159) [0.4 s]
INFO:root:Epoch 30    loss=0.2094 [10.8 s]    dev=(HR@5:0.4323,NDCG@5:0.3171) [0.4 s]
INFO:root:Epoch 31    loss=0.2071 [11.0 s]    dev=(HR@5:0.4349,NDCG@5:0.3210) [0.4 s] *
INFO:root:Epoch 32    loss=0.2085 [11.0 s]    dev=(HR@5:0.4366,NDCG@5:0.3208) [0.4 s]
INFO:root:Epoch 33    loss=0.2074 [11.1 s]    dev=(HR@5:0.4368,NDCG@5:0.3193) [0.4 s]
INFO:root:Epoch 34    loss=0.2068 [11.4 s]    dev=(HR@5:0.4396,NDCG@5:0.3197) [0.4 s]
INFO:root:Epoch 35    loss=0.2064 [11.5 s]    dev=(HR@5:0.4358,NDCG@5:0.3164) [0.4 s]
INFO:root:Epoch 36    loss=0.2053 [11.3 s]    dev=(HR@5:0.4373,NDCG@5:0.3177) [0.4 s]
INFO:root:Epoch 37    loss=0.2056 [11.5 s]    dev=(HR@5:0.4385,NDCG@5:0.3204) [0.4 s]
INFO:root:Epoch 38    loss=0.2047 [11.5 s]    dev=(HR@5:0.4366,NDCG@5:0.3185) [0.4 s]
INFO:root:Epoch 39    loss=0.2050 [11.2 s]    dev=(HR@5:0.4340,NDCG@5:0.3155) [0.4 s]
INFO:root:Epoch 40    loss=0.2039 [11.3 s]    dev=(HR@5:0.4392,NDCG@5:0.3207) [0.4 s]
INFO:root:Epoch 41    loss=0.2054 [11.3 s]    dev=(HR@5:0.4344,NDCG@5:0.3166) [0.4 s]
INFO:root:Epoch 42    loss=0.2050 [10.9 s]    dev=(HR@5:0.4441,NDCG@5:0.3224) [0.4 s] *
INFO:root:Epoch 43    loss=0.2027 [10.4 s]    dev=(HR@5:0.4417,NDCG@5:0.3236) [0.4 s] *
INFO:root:Epoch 44    loss=0.2052 [11.3 s]    dev=(HR@5:0.4404,NDCG@5:0.3211) [0.4 s]
INFO:root:Epoch 45    loss=0.2004 [11.0 s]    dev=(HR@5:0.4439,NDCG@5:0.3255) [0.4 s] *
INFO:root:Epoch 46    loss=0.2020 [11.1 s]    dev=(HR@5:0.4410,NDCG@5:0.3221) [0.4 s]
INFO:root:Epoch 47    loss=0.2026 [11.1 s]    dev=(HR@5:0.4420,NDCG@5:0.3238) [0.4 s]
INFO:root:Epoch 48    loss=0.2016 [11.2 s]    dev=(HR@5:0.4423,NDCG@5:0.3228) [0.4 s]
INFO:root:Epoch 49    loss=0.2000 [11.2 s]    dev=(HR@5:0.4457,NDCG@5:0.3270) [0.4 s] *
INFO:root:Epoch 50    loss=0.2012 [11.4 s]    dev=(HR@5:0.4383,NDCG@5:0.3215) [0.4 s]
INFO:root:Epoch 51    loss=0.2000 [11.6 s]    dev=(HR@5:0.4440,NDCG@5:0.3247) [0.4 s]
INFO:root:Epoch 52    loss=0.1995 [10.1 s]    dev=(HR@5:0.4426,NDCG@5:0.3226) [0.4 s]
INFO:root:Epoch 53    loss=0.1993 [10.4 s]    dev=(HR@5:0.4460,NDCG@5:0.3264) [0.4 s]
INFO:root:Epoch 54    loss=0.1978 [10.7 s]    dev=(HR@5:0.4429,NDCG@5:0.3254) [0.4 s]
INFO:root:Epoch 55    loss=0.1976 [11.4 s]    dev=(HR@5:0.4444,NDCG@5:0.3237) [0.4 s]
INFO:root:Epoch 56    loss=0.1967 [11.0 s]    dev=(HR@5:0.4460,NDCG@5:0.3273) [0.4 s] *
INFO:root:Epoch 57    loss=0.1978 [10.9 s]    dev=(HR@5:0.4447,NDCG@5:0.3276) [0.4 s] *
INFO:root:Epoch 58    loss=0.1981 [11.0 s]    dev=(HR@5:0.4466,NDCG@5:0.3277) [0.3 s] *
INFO:root:Epoch 59    loss=0.1973 [11.3 s]    dev=(HR@5:0.4441,NDCG@5:0.3246) [0.4 s]
INFO:root:Epoch 60    loss=0.1978 [11.1 s]    dev=(HR@5:0.4442,NDCG@5:0.3267) [0.4 s]
INFO:root:Epoch 61    loss=0.1968 [11.1 s]    dev=(HR@5:0.4487,NDCG@5:0.3295) [0.4 s] *
INFO:root:Epoch 62    loss=0.1960 [11.1 s]    dev=(HR@5:0.4509,NDCG@5:0.3302) [0.4 s] *
INFO:root:Epoch 63    loss=0.1970 [11.1 s]    dev=(HR@5:0.4496,NDCG@5:0.3290) [0.4 s]
INFO:root:Epoch 64    loss=0.1952 [11.2 s]    dev=(HR@5:0.4449,NDCG@5:0.3260) [0.4 s]
INFO:root:Epoch 65    loss=0.1962 [11.4 s]    dev=(HR@5:0.4447,NDCG@5:0.3253) [0.4 s]
INFO:root:Epoch 66    loss=0.1951 [11.1 s]    dev=(HR@5:0.4459,NDCG@5:0.3257) [0.4 s]
INFO:root:Epoch 67    loss=0.1955 [11.1 s]    dev=(HR@5:0.4448,NDCG@5:0.3263) [0.4 s]
INFO:root:Epoch 68    loss=0.1933 [11.2 s]    dev=(HR@5:0.4444,NDCG@5:0.3254) [0.4 s]
INFO:root:Epoch 69    loss=0.1957 [11.2 s]    dev=(HR@5:0.4415,NDCG@5:0.3240) [0.4 s]
INFO:root:Epoch 70    loss=0.1941 [11.3 s]    dev=(HR@5:0.4468,NDCG@5:0.3287) [0.4 s]
INFO:root:Epoch 71    loss=0.1942 [11.3 s]    dev=(HR@5:0.4424,NDCG@5:0.3283) [0.4 s]
INFO:root:Epoch 72    loss=0.1931 [11.3 s]    dev=(HR@5:0.4456,NDCG@5:0.3282) [0.4 s]
INFO:root:Epoch 73    loss=0.1934 [11.0 s]    dev=(HR@5:0.4472,NDCG@5:0.3281) [0.4 s]
INFO:root:Epoch 74    loss=0.1948 [11.1 s]    dev=(HR@5:0.4449,NDCG@5:0.3259) [0.4 s]
INFO:root:Epoch 75    loss=0.1954 [11.1 s]    dev=(HR@5:0.4451,NDCG@5:0.3267) [0.4 s]
INFO:root:Epoch 76    loss=0.1951 [11.2 s]    dev=(HR@5:0.4488,NDCG@5:0.3296) [0.3 s]
INFO:root:Epoch 77    loss=0.1927 [11.0 s]    dev=(HR@5:0.4466,NDCG@5:0.3278) [0.4 s]
INFO:root:Epoch 78    loss=0.1930 [11.0 s]    dev=(HR@5:0.4477,NDCG@5:0.3272) [0.4 s]
INFO:root:Epoch 79    loss=0.1939 [10.1 s]    dev=(HR@5:0.4485,NDCG@5:0.3279) [0.4 s]
INFO:root:Epoch 80    loss=0.1917 [11.4 s]    dev=(HR@5:0.4502,NDCG@5:0.3292) [0.4 s]
INFO:root:Epoch 81    loss=0.1919 [11.3 s]    dev=(HR@5:0.4400,NDCG@5:0.3214) [0.4 s]
INFO:root:Epoch 82    loss=0.1948 [11.3 s]    dev=(HR@5:0.4474,NDCG@5:0.3276) [0.5 s]
INFO:root:Early stop at 82 based on dev result.
INFO:root:
Best Iter(dev)=   62	 dev=(HR@5:0.4509,NDCG@5:0.3302) [945.3 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.4039,NDCG@5:0.2870,HR@10:0.5142,NDCG@10:0.3227,HR@20:0.6328,NDCG@20:0.3525,HR@50:0.8390,NDCG@50:0.3933)
INFO:root:
--------------------------------------------- END: 2024-12-23 03:45:57 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 04:05:04 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5162 [12.4 s]    dev=(HR@5:0.2516,NDCG@5:0.1675) [0.4 s] *
INFO:root:Epoch 2     loss=0.4302 [11.5 s]    dev=(HR@5:0.3222,NDCG@5:0.2187) [0.4 s] *
INFO:root:Epoch 3     loss=0.3931 [11.1 s]    dev=(HR@5:0.3509,NDCG@5:0.2383) [0.4 s] *
INFO:root:Epoch 4     loss=0.3696 [11.4 s]    dev=(HR@5:0.3710,NDCG@5:0.2572) [0.4 s] *
INFO:root:Epoch 5     loss=0.3439 [11.1 s]    dev=(HR@5:0.3900,NDCG@5:0.2740) [0.4 s] *
INFO:root:Epoch 6     loss=0.3185 [11.5 s]    dev=(HR@5:0.4105,NDCG@5:0.2907) [0.4 s] *
INFO:root:Epoch 7     loss=0.2988 [11.3 s]    dev=(HR@5:0.4179,NDCG@5:0.2963) [0.4 s] *
INFO:root:Epoch 8     loss=0.2822 [11.2 s]    dev=(HR@5:0.4230,NDCG@5:0.3041) [0.4 s] *
INFO:root:Epoch 9     loss=0.2669 [11.1 s]    dev=(HR@5:0.4258,NDCG@5:0.3087) [0.4 s] *
INFO:root:Epoch 10    loss=0.2576 [10.5 s]    dev=(HR@5:0.4288,NDCG@5:0.3108) [0.4 s] *
INFO:root:Epoch 11    loss=0.2477 [11.0 s]    dev=(HR@5:0.4357,NDCG@5:0.3151) [0.4 s] *
INFO:root:Epoch 12    loss=0.2396 [11.4 s]    dev=(HR@5:0.4362,NDCG@5:0.3172) [0.4 s] *
INFO:root:Epoch 13    loss=0.2347 [11.4 s]    dev=(HR@5:0.4421,NDCG@5:0.3212) [0.4 s] *
INFO:root:Epoch 14    loss=0.2305 [11.1 s]    dev=(HR@5:0.4451,NDCG@5:0.3225) [0.4 s] *
INFO:root:Epoch 15    loss=0.2280 [11.2 s]    dev=(HR@5:0.4374,NDCG@5:0.3184) [0.4 s]
INFO:root:Epoch 16    loss=0.2253 [10.0 s]    dev=(HR@5:0.4420,NDCG@5:0.3200) [0.4 s]
INFO:root:Epoch 17    loss=0.2215 [11.1 s]    dev=(HR@5:0.4445,NDCG@5:0.3218) [0.4 s]
INFO:root:Epoch 18    loss=0.2172 [11.3 s]    dev=(HR@5:0.4430,NDCG@5:0.3242) [0.4 s] *
INFO:root:Epoch 19    loss=0.2164 [11.2 s]    dev=(HR@5:0.4430,NDCG@5:0.3231) [0.4 s]
INFO:root:Epoch 20    loss=0.2127 [11.4 s]    dev=(HR@5:0.4446,NDCG@5:0.3257) [0.4 s] *
INFO:root:Epoch 21    loss=0.2096 [11.2 s]    dev=(HR@5:0.4456,NDCG@5:0.3247) [0.4 s]
INFO:root:Epoch 22    loss=0.2087 [11.1 s]    dev=(HR@5:0.4486,NDCG@5:0.3281) [0.4 s] *
INFO:root:Epoch 23    loss=0.2089 [11.3 s]    dev=(HR@5:0.4437,NDCG@5:0.3256) [0.4 s]
INFO:root:Epoch 24    loss=0.2076 [11.3 s]    dev=(HR@5:0.4456,NDCG@5:0.3239) [0.4 s]
INFO:root:Epoch 25    loss=0.2047 [11.3 s]    dev=(HR@5:0.4465,NDCG@5:0.3253) [0.4 s]
INFO:root:Epoch 26    loss=0.2043 [10.9 s]    dev=(HR@5:0.4479,NDCG@5:0.3276) [0.3 s]
INFO:root:Epoch 27    loss=0.2043 [11.0 s]    dev=(HR@5:0.4500,NDCG@5:0.3285) [0.4 s] *
INFO:root:Epoch 28    loss=0.2041 [11.1 s]    dev=(HR@5:0.4507,NDCG@5:0.3306) [0.4 s] *
INFO:root:Epoch 29    loss=0.2018 [10.8 s]    dev=(HR@5:0.4486,NDCG@5:0.3281) [0.4 s]
INFO:root:Epoch 30    loss=0.2005 [11.3 s]    dev=(HR@5:0.4439,NDCG@5:0.3253) [0.4 s]
INFO:root:Epoch 31    loss=0.2002 [11.4 s]    dev=(HR@5:0.4526,NDCG@5:0.3315) [0.4 s] *
INFO:root:Epoch 32    loss=0.1996 [11.3 s]    dev=(HR@5:0.4492,NDCG@5:0.3290) [0.4 s]
INFO:root:Epoch 33    loss=0.1995 [11.2 s]    dev=(HR@5:0.4489,NDCG@5:0.3295) [0.4 s]
INFO:root:Epoch 34    loss=0.1979 [10.7 s]    dev=(HR@5:0.4485,NDCG@5:0.3284) [0.4 s]
INFO:root:Epoch 35    loss=0.1987 [11.0 s]    dev=(HR@5:0.4447,NDCG@5:0.3244) [0.4 s]
INFO:root:Epoch 36    loss=0.1974 [10.7 s]    dev=(HR@5:0.4455,NDCG@5:0.3249) [0.4 s]
INFO:root:Epoch 37    loss=0.1980 [11.0 s]    dev=(HR@5:0.4485,NDCG@5:0.3280) [0.4 s]
INFO:root:Epoch 38    loss=0.1968 [11.4 s]    dev=(HR@5:0.4495,NDCG@5:0.3273) [0.4 s]
INFO:root:Epoch 39    loss=0.1976 [11.3 s]    dev=(HR@5:0.4408,NDCG@5:0.3226) [0.4 s]
INFO:root:Epoch 40    loss=0.1966 [11.3 s]    dev=(HR@5:0.4455,NDCG@5:0.3264) [0.4 s]
INFO:root:Epoch 41    loss=0.1972 [11.5 s]    dev=(HR@5:0.4442,NDCG@5:0.3259) [0.4 s]
INFO:root:Epoch 42    loss=0.1966 [11.4 s]    dev=(HR@5:0.4482,NDCG@5:0.3275) [0.4 s]
INFO:root:Epoch 43    loss=0.1953 [11.3 s]    dev=(HR@5:0.4480,NDCG@5:0.3293) [0.4 s]
INFO:root:Epoch 44    loss=0.1976 [11.1 s]    dev=(HR@5:0.4404,NDCG@5:0.3239) [0.4 s]
INFO:root:Epoch 45    loss=0.1931 [11.2 s]    dev=(HR@5:0.4486,NDCG@5:0.3303) [0.4 s]
INFO:root:Epoch 46    loss=0.1950 [11.3 s]    dev=(HR@5:0.4477,NDCG@5:0.3263) [0.4 s]
INFO:root:Epoch 47    loss=0.1951 [11.3 s]    dev=(HR@5:0.4445,NDCG@5:0.3253) [0.4 s]
INFO:root:Epoch 48    loss=0.1949 [11.3 s]    dev=(HR@5:0.4442,NDCG@5:0.3251) [0.4 s]
INFO:root:Epoch 49    loss=0.1934 [11.3 s]    dev=(HR@5:0.4497,NDCG@5:0.3295) [0.4 s]
INFO:root:Epoch 50    loss=0.1950 [11.3 s]    dev=(HR@5:0.4429,NDCG@5:0.3256) [0.4 s]
INFO:root:Epoch 51    loss=0.1938 [11.5 s]    dev=(HR@5:0.4509,NDCG@5:0.3317) [0.4 s] *
INFO:root:Epoch 52    loss=0.1944 [11.3 s]    dev=(HR@5:0.4481,NDCG@5:0.3290) [0.4 s]
INFO:root:Epoch 53    loss=0.1942 [11.0 s]    dev=(HR@5:0.4427,NDCG@5:0.3251) [0.4 s]
INFO:root:Epoch 54    loss=0.1925 [11.4 s]    dev=(HR@5:0.4436,NDCG@5:0.3259) [0.4 s]
INFO:root:Epoch 55    loss=0.1922 [11.2 s]    dev=(HR@5:0.4461,NDCG@5:0.3259) [0.4 s]
INFO:root:Epoch 56    loss=0.1933 [11.5 s]    dev=(HR@5:0.4481,NDCG@5:0.3303) [0.4 s]
INFO:root:Epoch 57    loss=0.1933 [11.2 s]    dev=(HR@5:0.4472,NDCG@5:0.3299) [0.4 s]
INFO:root:Epoch 58    loss=0.1934 [11.4 s]    dev=(HR@5:0.4491,NDCG@5:0.3309) [0.4 s]
INFO:root:Epoch 59    loss=0.1934 [11.3 s]    dev=(HR@5:0.4460,NDCG@5:0.3305) [0.4 s]
INFO:root:Epoch 60    loss=0.1929 [10.7 s]    dev=(HR@5:0.4459,NDCG@5:0.3280) [0.4 s]
INFO:root:Epoch 61    loss=0.1935 [10.7 s]    dev=(HR@5:0.4507,NDCG@5:0.3331) [0.4 s] *
INFO:root:Epoch 62    loss=0.1932 [10.9 s]    dev=(HR@5:0.4493,NDCG@5:0.3309) [0.4 s]
INFO:root:Epoch 63    loss=0.1935 [11.0 s]    dev=(HR@5:0.4479,NDCG@5:0.3306) [0.4 s]
INFO:root:Epoch 64    loss=0.1912 [11.1 s]    dev=(HR@5:0.4483,NDCG@5:0.3276) [0.4 s]
INFO:root:Epoch 65    loss=0.1933 [11.4 s]    dev=(HR@5:0.4475,NDCG@5:0.3283) [0.4 s]
INFO:root:Epoch 66    loss=0.1913 [10.3 s]    dev=(HR@5:0.4472,NDCG@5:0.3257) [0.4 s]
INFO:root:Epoch 67    loss=0.1924 [11.4 s]    dev=(HR@5:0.4489,NDCG@5:0.3289) [0.4 s]
INFO:root:Epoch 68    loss=0.1908 [11.4 s]    dev=(HR@5:0.4488,NDCG@5:0.3306) [0.4 s]
INFO:root:Epoch 69    loss=0.1926 [11.2 s]    dev=(HR@5:0.4487,NDCG@5:0.3305) [0.4 s]
INFO:root:Epoch 70    loss=0.1919 [11.2 s]    dev=(HR@5:0.4473,NDCG@5:0.3291) [0.4 s]
INFO:root:Epoch 71    loss=0.1913 [10.8 s]    dev=(HR@5:0.4500,NDCG@5:0.3304) [0.4 s]
INFO:root:Epoch 72    loss=0.1909 [11.1 s]    dev=(HR@5:0.4466,NDCG@5:0.3295) [0.4 s]
INFO:root:Epoch 73    loss=0.1914 [11.2 s]    dev=(HR@5:0.4480,NDCG@5:0.3300) [0.4 s]
INFO:root:Epoch 74    loss=0.1927 [11.2 s]    dev=(HR@5:0.4489,NDCG@5:0.3284) [0.4 s]
INFO:root:Epoch 75    loss=0.1928 [11.1 s]    dev=(HR@5:0.4496,NDCG@5:0.3309) [0.4 s]
INFO:root:Epoch 76    loss=0.1922 [10.8 s]    dev=(HR@5:0.4463,NDCG@5:0.3300) [0.4 s]
INFO:root:Epoch 77    loss=0.1907 [11.2 s]    dev=(HR@5:0.4481,NDCG@5:0.3295) [0.4 s]
INFO:root:Epoch 78    loss=0.1913 [11.4 s]    dev=(HR@5:0.4532,NDCG@5:0.3300) [0.4 s]
INFO:root:Epoch 79    loss=0.1921 [11.3 s]    dev=(HR@5:0.4501,NDCG@5:0.3288) [0.4 s]
INFO:root:Epoch 80    loss=0.1898 [11.4 s]    dev=(HR@5:0.4507,NDCG@5:0.3303) [0.4 s]
INFO:root:Epoch 81    loss=0.1909 [11.5 s]    dev=(HR@5:0.4514,NDCG@5:0.3284) [0.4 s]
INFO:root:Early stop at 81 based on dev result.
INFO:root:
Best Iter(dev)=   61	 dev=(HR@5:0.4507,NDCG@5:0.3331) [937.4 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.4004,NDCG@5:0.2847,HR@10:0.5099,NDCG@10:0.3200,HR@20:0.6300,NDCG@20:0.3503,HR@50:0.8370,NDCG@50:0.3912)
INFO:root:
--------------------------------------------- END: 2024-12-23 04:20:44 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 04:44:06 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [12.2 s]    dev=(HR@5:0.2524,NDCG@5:0.1683) [0.4 s] *
INFO:root:Epoch 2     loss=0.4294 [11.0 s]    dev=(HR@5:0.3265,NDCG@5:0.2213) [0.4 s] *
INFO:root:Epoch 3     loss=0.3916 [10.7 s]    dev=(HR@5:0.3549,NDCG@5:0.2414) [0.4 s] *
INFO:root:Epoch 4     loss=0.3670 [10.7 s]    dev=(HR@5:0.3778,NDCG@5:0.2633) [0.4 s] *
INFO:root:Epoch 5     loss=0.3408 [10.7 s]    dev=(HR@5:0.3975,NDCG@5:0.2804) [0.4 s] *
INFO:root:Epoch 6     loss=0.3145 [11.3 s]    dev=(HR@5:0.4187,NDCG@5:0.2996) [0.4 s] *
INFO:root:Epoch 7     loss=0.2942 [10.7 s]    dev=(HR@5:0.4261,NDCG@5:0.3045) [0.4 s] *
INFO:root:Epoch 8     loss=0.2778 [10.7 s]    dev=(HR@5:0.4332,NDCG@5:0.3127) [0.4 s] *
INFO:root:Epoch 9     loss=0.2630 [10.7 s]    dev=(HR@5:0.4354,NDCG@5:0.3160) [0.4 s] *
INFO:root:Epoch 10    loss=0.2532 [10.7 s]    dev=(HR@5:0.4353,NDCG@5:0.3172) [0.4 s] *
INFO:root:Epoch 11    loss=0.2439 [10.8 s]    dev=(HR@5:0.4434,NDCG@5:0.3214) [0.4 s] *
INFO:root:Epoch 12    loss=0.2360 [10.6 s]    dev=(HR@5:0.4442,NDCG@5:0.3240) [0.4 s] *
INFO:root:Epoch 13    loss=0.2322 [10.7 s]    dev=(HR@5:0.4466,NDCG@5:0.3268) [0.4 s] *
INFO:root:Epoch 14    loss=0.2270 [10.6 s]    dev=(HR@5:0.4489,NDCG@5:0.3266) [0.4 s]
INFO:root:Epoch 15    loss=0.2242 [10.6 s]    dev=(HR@5:0.4481,NDCG@5:0.3244) [0.4 s]
INFO:root:Epoch 16    loss=0.2215 [10.6 s]    dev=(HR@5:0.4507,NDCG@5:0.3275) [0.4 s] *
INFO:root:Epoch 17    loss=0.2183 [10.4 s]    dev=(HR@5:0.4460,NDCG@5:0.3242) [0.4 s]
INFO:root:Epoch 18    loss=0.2144 [11.1 s]    dev=(HR@5:0.4525,NDCG@5:0.3309) [0.4 s] *
INFO:root:Epoch 19    loss=0.2129 [11.1 s]    dev=(HR@5:0.4515,NDCG@5:0.3310) [0.4 s] *
INFO:root:Epoch 20    loss=0.2097 [11.3 s]    dev=(HR@5:0.4539,NDCG@5:0.3347) [0.4 s] *
INFO:root:Epoch 21    loss=0.2064 [10.9 s]    dev=(HR@5:0.4529,NDCG@5:0.3314) [0.4 s]
INFO:root:Epoch 22    loss=0.2060 [10.1 s]    dev=(HR@5:0.4524,NDCG@5:0.3313) [0.4 s]
INFO:root:Epoch 23    loss=0.2059 [9.9 s]    dev=(HR@5:0.4486,NDCG@5:0.3301) [0.4 s]
INFO:root:Epoch 24    loss=0.2057 [11.2 s]    dev=(HR@5:0.4526,NDCG@5:0.3306) [0.4 s]
INFO:root:Epoch 25    loss=0.2025 [10.2 s]    dev=(HR@5:0.4504,NDCG@5:0.3308) [0.4 s]
INFO:root:Epoch 26    loss=0.2024 [11.4 s]    dev=(HR@5:0.4517,NDCG@5:0.3318) [0.4 s]
INFO:root:Epoch 27    loss=0.2012 [10.8 s]    dev=(HR@5:0.4562,NDCG@5:0.3348) [0.4 s] *
INFO:root:Epoch 28    loss=0.2018 [11.4 s]    dev=(HR@5:0.4560,NDCG@5:0.3364) [0.4 s] *
INFO:root:Epoch 29    loss=0.1997 [10.5 s]    dev=(HR@5:0.4558,NDCG@5:0.3339) [0.4 s]
INFO:root:Epoch 30    loss=0.1977 [10.7 s]    dev=(HR@5:0.4496,NDCG@5:0.3298) [0.4 s]
INFO:root:Epoch 31    loss=0.1976 [11.3 s]    dev=(HR@5:0.4551,NDCG@5:0.3346) [0.4 s]
INFO:root:Epoch 32    loss=0.1973 [11.1 s]    dev=(HR@5:0.4557,NDCG@5:0.3339) [0.4 s]
INFO:root:Epoch 33    loss=0.1975 [11.1 s]    dev=(HR@5:0.4575,NDCG@5:0.3346) [0.4 s]
INFO:root:Epoch 34    loss=0.1968 [11.2 s]    dev=(HR@5:0.4545,NDCG@5:0.3323) [0.4 s]
INFO:root:Epoch 35    loss=0.1973 [11.4 s]    dev=(HR@5:0.4517,NDCG@5:0.3313) [0.4 s]
INFO:root:Epoch 36    loss=0.1948 [11.1 s]    dev=(HR@5:0.4515,NDCG@5:0.3313) [0.4 s]
INFO:root:Epoch 37    loss=0.1955 [11.2 s]    dev=(HR@5:0.4494,NDCG@5:0.3301) [0.4 s]
INFO:root:Epoch 38    loss=0.1953 [11.2 s]    dev=(HR@5:0.4539,NDCG@5:0.3319) [0.4 s]
INFO:root:Epoch 39    loss=0.1956 [10.9 s]    dev=(HR@5:0.4457,NDCG@5:0.3250) [0.4 s]
INFO:root:Epoch 40    loss=0.1950 [10.7 s]    dev=(HR@5:0.4498,NDCG@5:0.3282) [0.4 s]
INFO:root:Epoch 41    loss=0.1960 [11.5 s]    dev=(HR@5:0.4494,NDCG@5:0.3278) [0.4 s]
INFO:root:Epoch 42    loss=0.1947 [11.4 s]    dev=(HR@5:0.4534,NDCG@5:0.3309) [0.4 s]
INFO:root:Epoch 43    loss=0.1940 [11.6 s]    dev=(HR@5:0.4545,NDCG@5:0.3345) [0.4 s]
INFO:root:Epoch 44    loss=0.1954 [11.3 s]    dev=(HR@5:0.4466,NDCG@5:0.3284) [0.4 s]
INFO:root:Epoch 45    loss=0.1928 [11.3 s]    dev=(HR@5:0.4516,NDCG@5:0.3319) [0.4 s]
INFO:root:Epoch 46    loss=0.1942 [11.2 s]    dev=(HR@5:0.4494,NDCG@5:0.3293) [0.4 s]
INFO:root:Epoch 47    loss=0.1941 [11.1 s]    dev=(HR@5:0.4479,NDCG@5:0.3280) [0.4 s]
INFO:root:Epoch 48    loss=0.1943 [11.5 s]    dev=(HR@5:0.4424,NDCG@5:0.3243) [0.4 s]
INFO:root:Early stop at 48 based on dev result.
INFO:root:
Best Iter(dev)=   28	 dev=(HR@5:0.4560,NDCG@5:0.3364) [545.5 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.4082,NDCG@5:0.2918,HR@10:0.5187,NDCG@10:0.3275,HR@20:0.6427,NDCG@20:0.3588,HR@50:0.8404,NDCG@50:0.3979)
INFO:root:
--------------------------------------------- END: 2024-12-23 04:53:14 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 05:17:08 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5166 [12.5 s]    dev=(HR@5:0.2535,NDCG@5:0.1692) [0.4 s] *
INFO:root:Epoch 2     loss=0.4283 [11.4 s]    dev=(HR@5:0.3304,NDCG@5:0.2243) [0.4 s] *
INFO:root:Epoch 3     loss=0.3894 [11.5 s]    dev=(HR@5:0.3622,NDCG@5:0.2484) [0.4 s] *
INFO:root:Epoch 4     loss=0.3634 [11.3 s]    dev=(HR@5:0.3866,NDCG@5:0.2695) [0.4 s] *
INFO:root:Epoch 5     loss=0.3375 [11.5 s]    dev=(HR@5:0.4022,NDCG@5:0.2838) [0.4 s] *
INFO:root:Epoch 6     loss=0.3127 [11.6 s]    dev=(HR@5:0.4157,NDCG@5:0.2997) [0.4 s] *
INFO:root:Epoch 7     loss=0.2940 [11.5 s]    dev=(HR@5:0.4244,NDCG@5:0.3037) [0.4 s] *
INFO:root:Epoch 8     loss=0.2802 [11.6 s]    dev=(HR@5:0.4255,NDCG@5:0.3090) [0.4 s] *
INFO:root:Epoch 9     loss=0.2668 [10.8 s]    dev=(HR@5:0.4297,NDCG@5:0.3126) [0.4 s] *
INFO:root:Epoch 10    loss=0.2589 [11.1 s]    dev=(HR@5:0.4311,NDCG@5:0.3133) [0.4 s] *
INFO:root:Epoch 11    loss=0.2502 [11.5 s]    dev=(HR@5:0.4354,NDCG@5:0.3162) [0.4 s] *
INFO:root:Epoch 12    loss=0.2432 [11.5 s]    dev=(HR@5:0.4351,NDCG@5:0.3170) [0.4 s] *
INFO:root:Epoch 13    loss=0.2394 [11.3 s]    dev=(HR@5:0.4409,NDCG@5:0.3223) [0.4 s] *
INFO:root:Epoch 14    loss=0.2346 [11.6 s]    dev=(HR@5:0.4399,NDCG@5:0.3203) [0.4 s]
INFO:root:Epoch 15    loss=0.2315 [10.7 s]    dev=(HR@5:0.4392,NDCG@5:0.3199) [0.4 s]
INFO:root:Epoch 16    loss=0.2294 [11.5 s]    dev=(HR@5:0.4410,NDCG@5:0.3224) [0.4 s] *
INFO:root:Epoch 17    loss=0.2254 [11.3 s]    dev=(HR@5:0.4400,NDCG@5:0.3208) [0.4 s]
INFO:root:Epoch 18    loss=0.2208 [11.2 s]    dev=(HR@5:0.4447,NDCG@5:0.3258) [0.4 s] *
INFO:root:Epoch 19    loss=0.2198 [11.2 s]    dev=(HR@5:0.4438,NDCG@5:0.3248) [0.4 s]
INFO:root:Epoch 20    loss=0.2156 [11.2 s]    dev=(HR@5:0.4468,NDCG@5:0.3280) [0.4 s] *
INFO:root:Epoch 21    loss=0.2114 [11.4 s]    dev=(HR@5:0.4455,NDCG@5:0.3259) [0.4 s]
INFO:root:Epoch 22    loss=0.2110 [11.2 s]    dev=(HR@5:0.4432,NDCG@5:0.3254) [0.4 s]
INFO:root:Epoch 23    loss=0.2108 [11.3 s]    dev=(HR@5:0.4449,NDCG@5:0.3271) [0.4 s]
INFO:root:Epoch 24    loss=0.2098 [10.2 s]    dev=(HR@5:0.4438,NDCG@5:0.3260) [0.4 s]
INFO:root:Epoch 25    loss=0.2065 [11.0 s]    dev=(HR@5:0.4457,NDCG@5:0.3260) [0.4 s]
INFO:root:Epoch 26    loss=0.2063 [11.3 s]    dev=(HR@5:0.4479,NDCG@5:0.3279) [0.4 s]
INFO:root:Epoch 27    loss=0.2061 [11.1 s]    dev=(HR@5:0.4468,NDCG@5:0.3279) [0.4 s]
INFO:root:Epoch 28    loss=0.2051 [11.4 s]    dev=(HR@5:0.4522,NDCG@5:0.3321) [0.4 s] *
INFO:root:Epoch 29    loss=0.2030 [11.3 s]    dev=(HR@5:0.4456,NDCG@5:0.3278) [0.4 s]
INFO:root:Epoch 30    loss=0.2012 [11.7 s]    dev=(HR@5:0.4461,NDCG@5:0.3281) [0.4 s]
INFO:root:Epoch 31    loss=0.2013 [11.1 s]    dev=(HR@5:0.4476,NDCG@5:0.3299) [0.4 s]
INFO:root:Epoch 32    loss=0.2008 [11.4 s]    dev=(HR@5:0.4456,NDCG@5:0.3267) [0.4 s]
INFO:root:Epoch 33    loss=0.1998 [11.5 s]    dev=(HR@5:0.4455,NDCG@5:0.3275) [0.4 s]
INFO:root:Epoch 34    loss=0.1994 [9.9 s]    dev=(HR@5:0.4470,NDCG@5:0.3305) [0.4 s]
INFO:root:Epoch 35    loss=0.1998 [11.1 s]    dev=(HR@5:0.4446,NDCG@5:0.3261) [0.4 s]
INFO:root:Epoch 36    loss=0.1973 [11.7 s]    dev=(HR@5:0.4485,NDCG@5:0.3279) [0.4 s]
INFO:root:Epoch 37    loss=0.1976 [11.6 s]    dev=(HR@5:0.4487,NDCG@5:0.3265) [0.4 s]
INFO:root:Epoch 38    loss=0.1976 [11.5 s]    dev=(HR@5:0.4467,NDCG@5:0.3274) [0.4 s]
INFO:root:Epoch 39    loss=0.1982 [11.5 s]    dev=(HR@5:0.4412,NDCG@5:0.3226) [0.4 s]
INFO:root:Epoch 40    loss=0.1968 [11.3 s]    dev=(HR@5:0.4427,NDCG@5:0.3247) [0.4 s]
INFO:root:Epoch 41    loss=0.1976 [11.2 s]    dev=(HR@5:0.4434,NDCG@5:0.3250) [0.4 s]
INFO:root:Epoch 42    loss=0.1966 [11.4 s]    dev=(HR@5:0.4488,NDCG@5:0.3281) [0.4 s]
INFO:root:Epoch 43    loss=0.1948 [11.1 s]    dev=(HR@5:0.4495,NDCG@5:0.3289) [0.4 s]
INFO:root:Epoch 44    loss=0.1960 [11.3 s]    dev=(HR@5:0.4499,NDCG@5:0.3291) [0.4 s]
INFO:root:Epoch 45    loss=0.1931 [11.1 s]    dev=(HR@5:0.4477,NDCG@5:0.3299) [0.4 s]
INFO:root:Epoch 46    loss=0.1948 [10.6 s]    dev=(HR@5:0.4434,NDCG@5:0.3272) [0.4 s]
INFO:root:Epoch 47    loss=0.1946 [11.4 s]    dev=(HR@5:0.4470,NDCG@5:0.3272) [0.4 s]
INFO:root:Epoch 48    loss=0.1941 [11.2 s]    dev=(HR@5:0.4446,NDCG@5:0.3261) [0.4 s]
INFO:root:Early stop at 48 based on dev result.
INFO:root:
Best Iter(dev)=   28	 dev=(HR@5:0.4522,NDCG@5:0.3321) [560.6 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.4016,NDCG@5:0.2876,HR@10:0.5113,NDCG@10:0.3231,HR@20:0.6306,NDCG@20:0.3532,HR@50:0.8401,NDCG@50:0.3946)
INFO:root:
--------------------------------------------- END: 2024-12-23 05:26:31 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 05:46:19 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5165 [12.6 s]    dev=(HR@5:0.2550,NDCG@5:0.1704) [0.4 s] *
INFO:root:Epoch 2     loss=0.4273 [11.3 s]    dev=(HR@5:0.3310,NDCG@5:0.2254) [0.4 s] *
INFO:root:Epoch 3     loss=0.3889 [11.4 s]    dev=(HR@5:0.3616,NDCG@5:0.2472) [0.4 s] *
INFO:root:Epoch 4     loss=0.3643 [11.5 s]    dev=(HR@5:0.3838,NDCG@5:0.2660) [0.4 s] *
INFO:root:Epoch 5     loss=0.3409 [11.3 s]    dev=(HR@5:0.3982,NDCG@5:0.2811) [0.4 s] *
INFO:root:Epoch 6     loss=0.3183 [11.3 s]    dev=(HR@5:0.4124,NDCG@5:0.2960) [0.4 s] *
INFO:root:Epoch 7     loss=0.3011 [11.3 s]    dev=(HR@5:0.4186,NDCG@5:0.3002) [0.4 s] *
INFO:root:Epoch 8     loss=0.2871 [10.9 s]    dev=(HR@5:0.4248,NDCG@5:0.3061) [0.4 s] *
INFO:root:Epoch 9     loss=0.2733 [11.1 s]    dev=(HR@5:0.4279,NDCG@5:0.3111) [0.4 s] *
INFO:root:Epoch 10    loss=0.2644 [11.3 s]    dev=(HR@5:0.4333,NDCG@5:0.3140) [0.4 s] *
INFO:root:Epoch 11    loss=0.2546 [11.4 s]    dev=(HR@5:0.4334,NDCG@5:0.3147) [0.4 s] *
INFO:root:Epoch 12    loss=0.2472 [11.2 s]    dev=(HR@5:0.4365,NDCG@5:0.3176) [0.4 s] *
INFO:root:Epoch 13    loss=0.2434 [11.4 s]    dev=(HR@5:0.4417,NDCG@5:0.3223) [0.4 s] *
INFO:root:Epoch 14    loss=0.2386 [11.3 s]    dev=(HR@5:0.4407,NDCG@5:0.3207) [0.4 s]
INFO:root:Epoch 15    loss=0.2359 [11.1 s]    dev=(HR@5:0.4396,NDCG@5:0.3199) [0.4 s]
INFO:root:Epoch 16    loss=0.2343 [11.1 s]    dev=(HR@5:0.4366,NDCG@5:0.3200) [0.4 s]
INFO:root:Epoch 17    loss=0.2308 [11.2 s]    dev=(HR@5:0.4348,NDCG@5:0.3172) [0.4 s]
INFO:root:Epoch 18    loss=0.2268 [11.1 s]    dev=(HR@5:0.4411,NDCG@5:0.3240) [0.4 s] *
INFO:root:Epoch 19    loss=0.2261 [11.2 s]    dev=(HR@5:0.4377,NDCG@5:0.3201) [0.4 s]
INFO:root:Epoch 20    loss=0.2230 [11.2 s]    dev=(HR@5:0.4415,NDCG@5:0.3242) [0.4 s] *
INFO:root:Epoch 21    loss=0.2196 [10.7 s]    dev=(HR@5:0.4406,NDCG@5:0.3238) [0.4 s]
INFO:root:Epoch 22    loss=0.2198 [10.6 s]    dev=(HR@5:0.4382,NDCG@5:0.3228) [0.4 s]
INFO:root:Epoch 23    loss=0.2201 [11.2 s]    dev=(HR@5:0.4393,NDCG@5:0.3235) [0.4 s]
INFO:root:Epoch 24    loss=0.2195 [10.6 s]    dev=(HR@5:0.4423,NDCG@5:0.3228) [0.4 s]
INFO:root:Epoch 25    loss=0.2162 [10.6 s]    dev=(HR@5:0.4407,NDCG@5:0.3225) [0.4 s]
INFO:root:Epoch 26    loss=0.2163 [10.6 s]    dev=(HR@5:0.4414,NDCG@5:0.3222) [0.4 s]
INFO:root:Epoch 27    loss=0.2170 [11.0 s]    dev=(HR@5:0.4408,NDCG@5:0.3237) [0.4 s]
INFO:root:Epoch 28    loss=0.2162 [10.3 s]    dev=(HR@5:0.4437,NDCG@5:0.3266) [0.4 s] *
INFO:root:Epoch 29    loss=0.2140 [11.0 s]    dev=(HR@5:0.4424,NDCG@5:0.3248) [0.4 s]
INFO:root:Epoch 30    loss=0.2134 [11.3 s]    dev=(HR@5:0.4425,NDCG@5:0.3231) [0.4 s]
INFO:root:Epoch 31    loss=0.2133 [11.2 s]    dev=(HR@5:0.4432,NDCG@5:0.3258) [0.4 s]
INFO:root:Epoch 32    loss=0.2133 [10.6 s]    dev=(HR@5:0.4391,NDCG@5:0.3220) [0.4 s]
INFO:root:Epoch 33    loss=0.2132 [11.0 s]    dev=(HR@5:0.4406,NDCG@5:0.3234) [0.4 s]
INFO:root:Epoch 34    loss=0.2122 [11.2 s]    dev=(HR@5:0.4441,NDCG@5:0.3262) [0.4 s]
INFO:root:Epoch 35    loss=0.2131 [11.2 s]    dev=(HR@5:0.4384,NDCG@5:0.3206) [0.4 s]
INFO:root:Epoch 36    loss=0.2107 [11.0 s]    dev=(HR@5:0.4408,NDCG@5:0.3234) [0.4 s]
INFO:root:Epoch 37    loss=0.2118 [11.0 s]    dev=(HR@5:0.4400,NDCG@5:0.3209) [0.4 s]
INFO:root:Epoch 38    loss=0.2119 [10.9 s]    dev=(HR@5:0.4393,NDCG@5:0.3215) [0.4 s]
INFO:root:Epoch 39    loss=0.2125 [11.1 s]    dev=(HR@5:0.4370,NDCG@5:0.3191) [0.4 s]
INFO:root:Epoch 40    loss=0.2115 [10.5 s]    dev=(HR@5:0.4378,NDCG@5:0.3190) [0.4 s]
INFO:root:Epoch 41    loss=0.2115 [11.3 s]    dev=(HR@5:0.4360,NDCG@5:0.3179) [0.4 s]
INFO:root:Epoch 42    loss=0.2110 [11.3 s]    dev=(HR@5:0.4419,NDCG@5:0.3210) [0.4 s]
INFO:root:Epoch 43    loss=0.2099 [11.3 s]    dev=(HR@5:0.4438,NDCG@5:0.3242) [0.4 s]
INFO:root:Epoch 44    loss=0.2108 [11.2 s]    dev=(HR@5:0.4358,NDCG@5:0.3172) [0.4 s]
INFO:root:Epoch 45    loss=0.2080 [11.5 s]    dev=(HR@5:0.4433,NDCG@5:0.3247) [0.4 s]
INFO:root:Epoch 46    loss=0.2097 [11.4 s]    dev=(HR@5:0.4389,NDCG@5:0.3218) [0.4 s]
INFO:root:Epoch 47    loss=0.2096 [11.2 s]    dev=(HR@5:0.4394,NDCG@5:0.3207) [0.4 s]
INFO:root:Epoch 48    loss=0.2093 [11.3 s]    dev=(HR@5:0.4376,NDCG@5:0.3184) [0.4 s]
INFO:root:Early stop at 48 based on dev result.
INFO:root:
Best Iter(dev)=   28	 dev=(HR@5:0.4437,NDCG@5:0.3266) [553.0 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.3956,NDCG@5:0.2836,HR@10:0.5082,NDCG@10:0.3201,HR@20:0.6310,NDCG@20:0.3510,HR@50:0.8429,NDCG@50:0.3929)
INFO:root:
--------------------------------------------- END: 2024-12-23 05:55:34 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 06:26:20 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5152 [12.9 s]    dev=(HR@5:0.2526,NDCG@5:0.1682) [0.4 s] *
INFO:root:Epoch 2     loss=0.4309 [11.9 s]    dev=(HR@5:0.3222,NDCG@5:0.2175) [0.4 s] *
INFO:root:Epoch 3     loss=0.3958 [12.0 s]    dev=(HR@5:0.3482,NDCG@5:0.2357) [0.4 s] *
INFO:root:Epoch 4     loss=0.3737 [11.9 s]    dev=(HR@5:0.3646,NDCG@5:0.2512) [0.4 s] *
INFO:root:Epoch 5     loss=0.3517 [11.7 s]    dev=(HR@5:0.3790,NDCG@5:0.2658) [0.4 s] *
INFO:root:Epoch 6     loss=0.3307 [11.9 s]    dev=(HR@5:0.3926,NDCG@5:0.2792) [0.4 s] *
INFO:root:Epoch 7     loss=0.3131 [11.8 s]    dev=(HR@5:0.3954,NDCG@5:0.2834) [0.4 s] *
INFO:root:Epoch 8     loss=0.2982 [11.8 s]    dev=(HR@5:0.4017,NDCG@5:0.2893) [0.4 s] *
INFO:root:Epoch 9     loss=0.2828 [11.7 s]    dev=(HR@5:0.4041,NDCG@5:0.2924) [0.4 s] *
INFO:root:Epoch 10    loss=0.2725 [11.8 s]    dev=(HR@5:0.4083,NDCG@5:0.2959) [0.4 s] *
INFO:root:Epoch 11    loss=0.2624 [11.8 s]    dev=(HR@5:0.4140,NDCG@5:0.2985) [0.4 s] *
INFO:root:Epoch 12    loss=0.2534 [11.9 s]    dev=(HR@5:0.4207,NDCG@5:0.3042) [0.4 s] *
INFO:root:Epoch 13    loss=0.2497 [12.0 s]    dev=(HR@5:0.4236,NDCG@5:0.3076) [0.4 s] *
INFO:root:Epoch 14    loss=0.2448 [11.8 s]    dev=(HR@5:0.4188,NDCG@5:0.3026) [0.4 s]
INFO:root:Epoch 15    loss=0.2416 [11.7 s]    dev=(HR@5:0.4248,NDCG@5:0.3062) [0.4 s]
INFO:root:Epoch 16    loss=0.2383 [10.9 s]    dev=(HR@5:0.4237,NDCG@5:0.3063) [0.4 s]
INFO:root:Epoch 17    loss=0.2353 [11.3 s]    dev=(HR@5:0.4195,NDCG@5:0.3048) [0.4 s]
INFO:root:Epoch 18    loss=0.2302 [11.8 s]    dev=(HR@5:0.4239,NDCG@5:0.3063) [0.4 s]
INFO:root:Epoch 19    loss=0.2283 [11.9 s]    dev=(HR@5:0.4262,NDCG@5:0.3096) [0.4 s] *
INFO:root:Epoch 20    loss=0.2260 [11.5 s]    dev=(HR@5:0.4295,NDCG@5:0.3110) [0.4 s] *
INFO:root:Epoch 21    loss=0.2224 [11.7 s]    dev=(HR@5:0.4295,NDCG@5:0.3110) [0.4 s]
INFO:root:Epoch 22    loss=0.2219 [11.2 s]    dev=(HR@5:0.4245,NDCG@5:0.3086) [0.4 s]
INFO:root:Epoch 23    loss=0.2224 [11.4 s]    dev=(HR@5:0.4237,NDCG@5:0.3090) [0.4 s]
INFO:root:Epoch 24    loss=0.2210 [10.9 s]    dev=(HR@5:0.4343,NDCG@5:0.3141) [0.4 s] *
INFO:root:Epoch 25    loss=0.2174 [11.8 s]    dev=(HR@5:0.4282,NDCG@5:0.3112) [0.4 s]
INFO:root:Epoch 26    loss=0.2181 [11.9 s]    dev=(HR@5:0.4359,NDCG@5:0.3158) [0.4 s] *
INFO:root:Epoch 27    loss=0.2174 [12.1 s]    dev=(HR@5:0.4304,NDCG@5:0.3123) [0.4 s]
INFO:root:Epoch 28    loss=0.2173 [12.0 s]    dev=(HR@5:0.4359,NDCG@5:0.3165) [0.4 s] *
INFO:root:Epoch 29    loss=0.2143 [11.3 s]    dev=(HR@5:0.4315,NDCG@5:0.3144) [0.4 s]
INFO:root:Epoch 30    loss=0.2142 [11.4 s]    dev=(HR@5:0.4267,NDCG@5:0.3126) [0.4 s]
INFO:root:Epoch 31    loss=0.2132 [12.0 s]    dev=(HR@5:0.4353,NDCG@5:0.3191) [0.4 s] *
INFO:root:Epoch 32    loss=0.2144 [11.7 s]    dev=(HR@5:0.4350,NDCG@5:0.3153) [0.4 s]
INFO:root:Epoch 33    loss=0.2132 [11.6 s]    dev=(HR@5:0.4327,NDCG@5:0.3156) [0.4 s]
INFO:root:Epoch 34    loss=0.2124 [11.9 s]    dev=(HR@5:0.4336,NDCG@5:0.3151) [0.4 s]
INFO:root:Epoch 35    loss=0.2124 [11.9 s]    dev=(HR@5:0.4307,NDCG@5:0.3118) [0.4 s]
INFO:root:Epoch 36    loss=0.2107 [11.9 s]    dev=(HR@5:0.4335,NDCG@5:0.3145) [0.4 s]
INFO:root:Epoch 37    loss=0.2110 [12.0 s]    dev=(HR@5:0.4333,NDCG@5:0.3142) [0.4 s]
INFO:root:Epoch 38    loss=0.2110 [11.8 s]    dev=(HR@5:0.4346,NDCG@5:0.3151) [0.4 s]
INFO:root:Epoch 39    loss=0.2118 [11.9 s]    dev=(HR@5:0.4265,NDCG@5:0.3091) [0.4 s]
INFO:root:Epoch 40    loss=0.2108 [12.0 s]    dev=(HR@5:0.4310,NDCG@5:0.3130) [0.4 s]
INFO:root:Epoch 41    loss=0.2120 [11.2 s]    dev=(HR@5:0.4328,NDCG@5:0.3127) [0.4 s]
INFO:root:Epoch 42    loss=0.2121 [11.4 s]    dev=(HR@5:0.4343,NDCG@5:0.3153) [0.4 s]
INFO:root:Epoch 43    loss=0.2097 [11.7 s]    dev=(HR@5:0.4336,NDCG@5:0.3172) [0.4 s]
INFO:root:Epoch 44    loss=0.2114 [11.5 s]    dev=(HR@5:0.4319,NDCG@5:0.3143) [0.4 s]
INFO:root:Epoch 45    loss=0.2075 [11.5 s]    dev=(HR@5:0.4348,NDCG@5:0.3182) [0.4 s]
INFO:root:Epoch 46    loss=0.2089 [11.1 s]    dev=(HR@5:0.4306,NDCG@5:0.3140) [0.4 s]
INFO:root:Epoch 47    loss=0.2096 [11.8 s]    dev=(HR@5:0.4328,NDCG@5:0.3143) [0.4 s]
INFO:root:Epoch 48    loss=0.2087 [11.8 s]    dev=(HR@5:0.4311,NDCG@5:0.3120) [0.4 s]
INFO:root:Epoch 49    loss=0.2074 [12.0 s]    dev=(HR@5:0.4350,NDCG@5:0.3169) [0.4 s]
INFO:root:Epoch 50    loss=0.2082 [12.0 s]    dev=(HR@5:0.4304,NDCG@5:0.3146) [0.4 s]
INFO:root:Epoch 51    loss=0.2072 [11.9 s]    dev=(HR@5:0.4361,NDCG@5:0.3176) [0.4 s]
INFO:root:Early stop at 51 based on dev result.
INFO:root:
Best Iter(dev)=   31	 dev=(HR@5:0.4353,NDCG@5:0.3191) [618.5 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.3829,NDCG@5:0.2737,HR@10:0.4913,NDCG@10:0.3088,HR@20:0.6129,NDCG@20:0.3394,HR@50:0.8247,NDCG@50:0.3814)
INFO:root:
--------------------------------------------- END: 2024-12-23 06:36:42 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 07:06:53 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5150 [12.4 s]    dev=(HR@5:0.2548,NDCG@5:0.1702) [0.4 s] *
INFO:root:Epoch 2     loss=0.4263 [11.3 s]    dev=(HR@5:0.3293,NDCG@5:0.2237) [0.4 s] *
INFO:root:Epoch 3     loss=0.3889 [11.1 s]    dev=(HR@5:0.3573,NDCG@5:0.2423) [0.4 s] *
INFO:root:Epoch 4     loss=0.3655 [10.2 s]    dev=(HR@5:0.3772,NDCG@5:0.2610) [0.4 s] *
INFO:root:Epoch 5     loss=0.3416 [11.2 s]    dev=(HR@5:0.3955,NDCG@5:0.2783) [0.4 s] *
INFO:root:Epoch 6     loss=0.3174 [11.1 s]    dev=(HR@5:0.4109,NDCG@5:0.2923) [0.4 s] *
INFO:root:Epoch 7     loss=0.2996 [11.0 s]    dev=(HR@5:0.4151,NDCG@5:0.2959) [0.4 s] *
INFO:root:Epoch 8     loss=0.2853 [11.3 s]    dev=(HR@5:0.4206,NDCG@5:0.3028) [0.4 s] *
INFO:root:Epoch 9     loss=0.2720 [11.0 s]    dev=(HR@5:0.4263,NDCG@5:0.3059) [0.4 s] *
INFO:root:Epoch 10    loss=0.2632 [10.9 s]    dev=(HR@5:0.4272,NDCG@5:0.3079) [0.4 s] *
INFO:root:Epoch 11    loss=0.2525 [11.3 s]    dev=(HR@5:0.4287,NDCG@5:0.3106) [0.4 s] *
INFO:root:Epoch 12    loss=0.2454 [11.1 s]    dev=(HR@5:0.4323,NDCG@5:0.3135) [0.4 s] *
INFO:root:Epoch 13    loss=0.2411 [11.2 s]    dev=(HR@5:0.4374,NDCG@5:0.3175) [0.4 s] *
INFO:root:Epoch 14    loss=0.2365 [11.4 s]    dev=(HR@5:0.4380,NDCG@5:0.3171) [0.4 s]
INFO:root:Epoch 15    loss=0.2329 [11.6 s]    dev=(HR@5:0.4367,NDCG@5:0.3171) [0.4 s]
INFO:root:Epoch 16    loss=0.2297 [11.1 s]    dev=(HR@5:0.4368,NDCG@5:0.3178) [0.4 s] *
INFO:root:Epoch 17    loss=0.2261 [11.2 s]    dev=(HR@5:0.4379,NDCG@5:0.3177) [0.4 s]
INFO:root:Epoch 18    loss=0.2214 [11.2 s]    dev=(HR@5:0.4380,NDCG@5:0.3181) [0.4 s] *
INFO:root:Epoch 19    loss=0.2188 [11.0 s]    dev=(HR@5:0.4391,NDCG@5:0.3199) [0.4 s] *
INFO:root:Epoch 20    loss=0.2163 [10.1 s]    dev=(HR@5:0.4453,NDCG@5:0.3245) [0.4 s] *
INFO:root:Epoch 21    loss=0.2125 [11.1 s]    dev=(HR@5:0.4455,NDCG@5:0.3236) [0.4 s]
INFO:root:Epoch 22    loss=0.2116 [10.9 s]    dev=(HR@5:0.4432,NDCG@5:0.3242) [0.4 s]
INFO:root:Epoch 23    loss=0.2124 [11.0 s]    dev=(HR@5:0.4430,NDCG@5:0.3249) [0.4 s] *
INFO:root:Epoch 24    loss=0.2116 [11.8 s]    dev=(HR@5:0.4452,NDCG@5:0.3248) [0.4 s]
INFO:root:Epoch 25    loss=0.2066 [11.3 s]    dev=(HR@5:0.4415,NDCG@5:0.3206) [0.4 s]
INFO:root:Epoch 26    loss=0.2078 [11.4 s]    dev=(HR@5:0.4442,NDCG@5:0.3243) [0.4 s]
INFO:root:Epoch 27    loss=0.2074 [11.4 s]    dev=(HR@5:0.4432,NDCG@5:0.3242) [0.4 s]
INFO:root:Epoch 28    loss=0.2066 [11.4 s]    dev=(HR@5:0.4470,NDCG@5:0.3263) [0.4 s] *
INFO:root:Epoch 29    loss=0.2049 [10.8 s]    dev=(HR@5:0.4408,NDCG@5:0.3221) [0.3 s]
INFO:root:Epoch 30    loss=0.2044 [11.1 s]    dev=(HR@5:0.4419,NDCG@5:0.3241) [0.4 s]
INFO:root:Epoch 31    loss=0.2025 [11.2 s]    dev=(HR@5:0.4457,NDCG@5:0.3278) [0.4 s] *
INFO:root:Epoch 32    loss=0.2036 [11.2 s]    dev=(HR@5:0.4461,NDCG@5:0.3253) [0.4 s]
INFO:root:Epoch 33    loss=0.2031 [11.0 s]    dev=(HR@5:0.4451,NDCG@5:0.3274) [0.4 s]
INFO:root:Epoch 34    loss=0.2017 [11.3 s]    dev=(HR@5:0.4439,NDCG@5:0.3246) [0.4 s]
INFO:root:Epoch 35    loss=0.2028 [11.2 s]    dev=(HR@5:0.4357,NDCG@5:0.3185) [0.4 s]
INFO:root:Epoch 36    loss=0.2000 [11.1 s]    dev=(HR@5:0.4407,NDCG@5:0.3220) [0.4 s]
INFO:root:Epoch 37    loss=0.2013 [11.5 s]    dev=(HR@5:0.4440,NDCG@5:0.3251) [0.4 s]
INFO:root:Epoch 38    loss=0.2002 [11.4 s]    dev=(HR@5:0.4388,NDCG@5:0.3197) [0.4 s]
INFO:root:Epoch 39    loss=0.2010 [11.4 s]    dev=(HR@5:0.4395,NDCG@5:0.3203) [0.4 s]
INFO:root:Epoch 40    loss=0.1996 [10.5 s]    dev=(HR@5:0.4427,NDCG@5:0.3239) [0.4 s]
INFO:root:Epoch 41    loss=0.2014 [11.3 s]    dev=(HR@5:0.4415,NDCG@5:0.3216) [0.4 s]
INFO:root:Epoch 42    loss=0.2007 [11.4 s]    dev=(HR@5:0.4443,NDCG@5:0.3243) [0.4 s]
INFO:root:Epoch 43    loss=0.1988 [11.4 s]    dev=(HR@5:0.4466,NDCG@5:0.3284) [0.4 s] *
INFO:root:Epoch 44    loss=0.2003 [11.0 s]    dev=(HR@5:0.4420,NDCG@5:0.3236) [0.4 s]
INFO:root:Epoch 45    loss=0.1971 [11.3 s]    dev=(HR@5:0.4440,NDCG@5:0.3253) [0.4 s]
INFO:root:Epoch 46    loss=0.1991 [11.1 s]    dev=(HR@5:0.4432,NDCG@5:0.3233) [0.4 s]
INFO:root:Epoch 47    loss=0.1984 [11.2 s]    dev=(HR@5:0.4436,NDCG@5:0.3236) [0.4 s]
INFO:root:Epoch 48    loss=0.1985 [11.0 s]    dev=(HR@5:0.4457,NDCG@5:0.3253) [0.4 s]
INFO:root:Epoch 49    loss=0.1968 [10.0 s]    dev=(HR@5:0.4516,NDCG@5:0.3304) [0.4 s] *
INFO:root:Epoch 50    loss=0.1991 [9.6 s]    dev=(HR@5:0.4417,NDCG@5:0.3242) [0.4 s]
INFO:root:Epoch 51    loss=0.1970 [9.7 s]    dev=(HR@5:0.4447,NDCG@5:0.3257) [0.4 s]
INFO:root:Epoch 52    loss=0.1976 [9.8 s]    dev=(HR@5:0.4463,NDCG@5:0.3269) [0.4 s]
INFO:root:Epoch 53    loss=0.1977 [9.4 s]    dev=(HR@5:0.4462,NDCG@5:0.3264) [0.4 s]
INFO:root:Epoch 54    loss=0.1963 [10.6 s]    dev=(HR@5:0.4450,NDCG@5:0.3253) [0.4 s]
INFO:root:Epoch 55    loss=0.1963 [10.9 s]    dev=(HR@5:0.4439,NDCG@5:0.3237) [0.4 s]
INFO:root:Epoch 56    loss=0.1959 [11.4 s]    dev=(HR@5:0.4477,NDCG@5:0.3281) [0.4 s]
INFO:root:Epoch 57    loss=0.1968 [11.0 s]    dev=(HR@5:0.4461,NDCG@5:0.3293) [0.4 s]
INFO:root:Epoch 58    loss=0.1977 [11.3 s]    dev=(HR@5:0.4487,NDCG@5:0.3313) [0.4 s] *
INFO:root:Epoch 59    loss=0.1965 [11.1 s]    dev=(HR@5:0.4424,NDCG@5:0.3252) [0.4 s]
INFO:root:Epoch 60    loss=0.1967 [11.1 s]    dev=(HR@5:0.4480,NDCG@5:0.3298) [0.4 s]
INFO:root:Epoch 61    loss=0.1972 [11.0 s]    dev=(HR@5:0.4479,NDCG@5:0.3304) [0.4 s]
INFO:root:Epoch 62    loss=0.1966 [11.3 s]    dev=(HR@5:0.4517,NDCG@5:0.3315) [0.4 s] *
INFO:root:Epoch 63    loss=0.1979 [11.0 s]    dev=(HR@5:0.4512,NDCG@5:0.3302) [0.4 s]
INFO:root:Epoch 64    loss=0.1953 [11.2 s]    dev=(HR@5:0.4466,NDCG@5:0.3283) [0.4 s]
INFO:root:Epoch 65    loss=0.1965 [11.3 s]    dev=(HR@5:0.4462,NDCG@5:0.3257) [0.4 s]
INFO:root:Epoch 66    loss=0.1949 [11.3 s]    dev=(HR@5:0.4463,NDCG@5:0.3272) [0.4 s]
INFO:root:Epoch 67    loss=0.1957 [11.2 s]    dev=(HR@5:0.4477,NDCG@5:0.3269) [0.4 s]
INFO:root:Epoch 68    loss=0.1942 [11.4 s]    dev=(HR@5:0.4467,NDCG@5:0.3280) [0.4 s]
INFO:root:Epoch 69    loss=0.1961 [11.4 s]    dev=(HR@5:0.4479,NDCG@5:0.3280) [0.4 s]
INFO:root:Epoch 70    loss=0.1950 [11.4 s]    dev=(HR@5:0.4455,NDCG@5:0.3276) [0.4 s]
INFO:root:Epoch 71    loss=0.1949 [11.0 s]    dev=(HR@5:0.4489,NDCG@5:0.3304) [0.4 s]
INFO:root:Epoch 72    loss=0.1942 [10.8 s]    dev=(HR@5:0.4495,NDCG@5:0.3289) [0.4 s]
INFO:root:Epoch 73    loss=0.1944 [11.0 s]    dev=(HR@5:0.4423,NDCG@5:0.3230) [0.4 s]
INFO:root:Epoch 74    loss=0.1962 [11.1 s]    dev=(HR@5:0.4471,NDCG@5:0.3258) [0.4 s]
INFO:root:Epoch 75    loss=0.1964 [10.6 s]    dev=(HR@5:0.4547,NDCG@5:0.3317) [0.4 s] *
INFO:root:Epoch 76    loss=0.1951 [11.4 s]    dev=(HR@5:0.4502,NDCG@5:0.3291) [0.4 s]
INFO:root:Epoch 77    loss=0.1946 [10.8 s]    dev=(HR@5:0.4477,NDCG@5:0.3269) [0.4 s]
INFO:root:Epoch 78    loss=0.1949 [11.2 s]    dev=(HR@5:0.4487,NDCG@5:0.3268) [0.4 s]
INFO:root:Epoch 79    loss=0.1960 [11.1 s]    dev=(HR@5:0.4504,NDCG@5:0.3284) [0.4 s]
INFO:root:Epoch 80    loss=0.1939 [11.0 s]    dev=(HR@5:0.4477,NDCG@5:0.3270) [0.4 s]
INFO:root:Epoch 81    loss=0.1934 [10.9 s]    dev=(HR@5:0.4438,NDCG@5:0.3233) [0.4 s]
INFO:root:Epoch 82    loss=0.1952 [10.8 s]    dev=(HR@5:0.4479,NDCG@5:0.3279) [0.4 s]
INFO:root:Epoch 83    loss=0.1935 [11.5 s]    dev=(HR@5:0.4508,NDCG@5:0.3302) [0.4 s]
INFO:root:Epoch 84    loss=0.1927 [11.3 s]    dev=(HR@5:0.4470,NDCG@5:0.3271) [0.4 s]
INFO:root:Epoch 85    loss=0.1949 [11.0 s]    dev=(HR@5:0.4506,NDCG@5:0.3289) [0.4 s]
INFO:root:Epoch 86    loss=0.1941 [11.5 s]    dev=(HR@5:0.4468,NDCG@5:0.3276) [0.4 s]
INFO:root:Epoch 87    loss=0.1942 [10.8 s]    dev=(HR@5:0.4500,NDCG@5:0.3283) [0.4 s]
INFO:root:Epoch 88    loss=0.1934 [11.1 s]    dev=(HR@5:0.4484,NDCG@5:0.3288) [0.4 s]
INFO:root:Epoch 89    loss=0.1924 [11.2 s]    dev=(HR@5:0.4473,NDCG@5:0.3282) [0.4 s]
INFO:root:Epoch 90    loss=0.1918 [11.1 s]    dev=(HR@5:0.4520,NDCG@5:0.3302) [0.4 s]
INFO:root:Epoch 91    loss=0.1927 [11.1 s]    dev=(HR@5:0.4519,NDCG@5:0.3286) [0.4 s]
INFO:root:Epoch 92    loss=0.1911 [11.2 s]    dev=(HR@5:0.4488,NDCG@5:0.3275) [0.4 s]
INFO:root:Epoch 93    loss=0.1929 [11.0 s]    dev=(HR@5:0.4505,NDCG@5:0.3282) [0.4 s]
INFO:root:Epoch 94    loss=0.1930 [11.0 s]    dev=(HR@5:0.4480,NDCG@5:0.3271) [0.4 s]
INFO:root:Epoch 95    loss=0.1924 [10.9 s]    dev=(HR@5:0.4482,NDCG@5:0.3286) [0.4 s]
INFO:root:Early stop at 95 based on dev result.
INFO:root:
Best Iter(dev)=   75	 dev=(HR@5:0.4547,NDCG@5:0.3317) [1087.8 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.4038,NDCG@5:0.2870,HR@10:0.5150,NDCG@10:0.3231,HR@20:0.6389,NDCG@20:0.3543,HR@50:0.8430,NDCG@50:0.3947)
INFO:root:
--------------------------------------------- END: 2024-12-23 07:25:03 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 07:45:09 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5153 [13.1 s]    dev=(HR@5:0.2558,NDCG@5:0.1714) [0.4 s] *
INFO:root:Epoch 2     loss=0.4253 [11.5 s]    dev=(HR@5:0.3318,NDCG@5:0.2256) [0.4 s] *
INFO:root:Epoch 3     loss=0.3868 [11.4 s]    dev=(HR@5:0.3633,NDCG@5:0.2481) [0.4 s] *
INFO:root:Epoch 4     loss=0.3612 [11.1 s]    dev=(HR@5:0.3854,NDCG@5:0.2688) [0.4 s] *
INFO:root:Epoch 5     loss=0.3364 [11.4 s]    dev=(HR@5:0.4017,NDCG@5:0.2851) [0.4 s] *
INFO:root:Epoch 6     loss=0.3125 [11.1 s]    dev=(HR@5:0.4169,NDCG@5:0.2969) [0.4 s] *
INFO:root:Epoch 7     loss=0.2953 [10.1 s]    dev=(HR@5:0.4207,NDCG@5:0.3004) [0.4 s] *
INFO:root:Epoch 8     loss=0.2811 [11.0 s]    dev=(HR@5:0.4254,NDCG@5:0.3074) [0.4 s] *
INFO:root:Epoch 9     loss=0.2676 [10.9 s]    dev=(HR@5:0.4313,NDCG@5:0.3121) [0.4 s] *
INFO:root:Epoch 10    loss=0.2574 [11.2 s]    dev=(HR@5:0.4355,NDCG@5:0.3163) [0.4 s] *
INFO:root:Epoch 11    loss=0.2472 [10.7 s]    dev=(HR@5:0.4361,NDCG@5:0.3170) [0.4 s] *
INFO:root:Epoch 12    loss=0.2391 [11.2 s]    dev=(HR@5:0.4389,NDCG@5:0.3204) [0.4 s] *
INFO:root:Epoch 13    loss=0.2344 [11.3 s]    dev=(HR@5:0.4438,NDCG@5:0.3247) [0.4 s] *
INFO:root:Epoch 14    loss=0.2299 [11.2 s]    dev=(HR@5:0.4433,NDCG@5:0.3238) [0.4 s]
INFO:root:Epoch 15    loss=0.2262 [11.1 s]    dev=(HR@5:0.4448,NDCG@5:0.3239) [0.4 s]
INFO:root:Epoch 16    loss=0.2223 [11.0 s]    dev=(HR@5:0.4459,NDCG@5:0.3267) [0.4 s] *
INFO:root:Epoch 17    loss=0.2183 [11.1 s]    dev=(HR@5:0.4436,NDCG@5:0.3235) [0.4 s]
INFO:root:Epoch 18    loss=0.2142 [11.3 s]    dev=(HR@5:0.4474,NDCG@5:0.3293) [0.3 s] *
INFO:root:Epoch 19    loss=0.2120 [11.5 s]    dev=(HR@5:0.4454,NDCG@5:0.3274) [0.4 s]
INFO:root:Epoch 20    loss=0.2091 [11.1 s]    dev=(HR@5:0.4521,NDCG@5:0.3311) [0.4 s] *
INFO:root:Epoch 21    loss=0.2059 [11.1 s]    dev=(HR@5:0.4494,NDCG@5:0.3298) [0.4 s]
INFO:root:Epoch 22    loss=0.2056 [11.0 s]    dev=(HR@5:0.4500,NDCG@5:0.3314) [0.4 s] *
INFO:root:Epoch 23    loss=0.2062 [10.9 s]    dev=(HR@5:0.4442,NDCG@5:0.3286) [0.4 s]
INFO:root:Epoch 24    loss=0.2052 [11.1 s]    dev=(HR@5:0.4457,NDCG@5:0.3273) [0.4 s]
INFO:root:Epoch 25    loss=0.2012 [11.1 s]    dev=(HR@5:0.4487,NDCG@5:0.3285) [0.4 s]
INFO:root:Epoch 26    loss=0.2021 [11.1 s]    dev=(HR@5:0.4524,NDCG@5:0.3313) [0.4 s]
INFO:root:Epoch 27    loss=0.2012 [11.0 s]    dev=(HR@5:0.4513,NDCG@5:0.3315) [0.4 s] *
INFO:root:Epoch 28    loss=0.2016 [11.0 s]    dev=(HR@5:0.4549,NDCG@5:0.3339) [0.4 s] *
INFO:root:Epoch 29    loss=0.1997 [11.2 s]    dev=(HR@5:0.4510,NDCG@5:0.3300) [0.4 s]
INFO:root:Epoch 30    loss=0.1990 [10.9 s]    dev=(HR@5:0.4504,NDCG@5:0.3311) [0.4 s]
INFO:root:Epoch 31    loss=0.1981 [11.1 s]    dev=(HR@5:0.4533,NDCG@5:0.3331) [0.4 s]
INFO:root:Epoch 32    loss=0.1983 [11.3 s]    dev=(HR@5:0.4514,NDCG@5:0.3314) [0.4 s]
INFO:root:Epoch 33    loss=0.1985 [11.1 s]    dev=(HR@5:0.4506,NDCG@5:0.3326) [0.4 s]
INFO:root:Epoch 34    loss=0.1978 [11.1 s]    dev=(HR@5:0.4485,NDCG@5:0.3287) [0.4 s]
INFO:root:Epoch 35    loss=0.1984 [11.4 s]    dev=(HR@5:0.4489,NDCG@5:0.3278) [0.4 s]
INFO:root:Epoch 36    loss=0.1961 [11.3 s]    dev=(HR@5:0.4515,NDCG@5:0.3302) [0.4 s]
INFO:root:Epoch 37    loss=0.1971 [11.5 s]    dev=(HR@5:0.4489,NDCG@5:0.3292) [0.4 s]
INFO:root:Epoch 38    loss=0.1970 [11.2 s]    dev=(HR@5:0.4513,NDCG@5:0.3291) [0.4 s]
INFO:root:Epoch 39    loss=0.1975 [10.7 s]    dev=(HR@5:0.4465,NDCG@5:0.3261) [0.4 s]
INFO:root:Epoch 40    loss=0.1969 [11.0 s]    dev=(HR@5:0.4483,NDCG@5:0.3287) [0.4 s]
INFO:root:Epoch 41    loss=0.1966 [11.2 s]    dev=(HR@5:0.4464,NDCG@5:0.3258) [0.4 s]
INFO:root:Epoch 42    loss=0.1966 [11.2 s]    dev=(HR@5:0.4503,NDCG@5:0.3293) [0.4 s]
INFO:root:Epoch 43    loss=0.1954 [11.3 s]    dev=(HR@5:0.4536,NDCG@5:0.3324) [0.4 s]
INFO:root:Epoch 44    loss=0.1965 [11.0 s]    dev=(HR@5:0.4462,NDCG@5:0.3270) [0.4 s]
INFO:root:Epoch 45    loss=0.1946 [11.3 s]    dev=(HR@5:0.4506,NDCG@5:0.3322) [0.4 s]
INFO:root:Epoch 46    loss=0.1954 [11.4 s]    dev=(HR@5:0.4447,NDCG@5:0.3265) [0.4 s]
INFO:root:Epoch 47    loss=0.1954 [11.4 s]    dev=(HR@5:0.4455,NDCG@5:0.3273) [0.4 s]
INFO:root:Epoch 48    loss=0.1950 [11.5 s]    dev=(HR@5:0.4462,NDCG@5:0.3269) [0.4 s]
INFO:root:Early stop at 48 based on dev result.
INFO:root:
Best Iter(dev)=   28	 dev=(HR@5:0.4549,NDCG@5:0.3339) [555.3 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.4019,NDCG@5:0.2874,HR@10:0.5124,NDCG@10:0.3232,HR@20:0.6331,NDCG@20:0.3536,HR@50:0.8368,NDCG@50:0.3939)
INFO:root:
--------------------------------------------- END: 2024-12-23 07:54:27 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 08:14:54 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5153 [13.0 s]    dev=(HR@5:0.2584,NDCG@5:0.1735) [0.4 s] *
INFO:root:Epoch 2     loss=0.4240 [11.1 s]    dev=(HR@5:0.3350,NDCG@5:0.2275) [0.4 s] *
INFO:root:Epoch 3     loss=0.3862 [11.2 s]    dev=(HR@5:0.3626,NDCG@5:0.2485) [0.4 s] *
INFO:root:Epoch 4     loss=0.3607 [11.4 s]    dev=(HR@5:0.3868,NDCG@5:0.2702) [0.4 s] *
INFO:root:Epoch 5     loss=0.3357 [11.2 s]    dev=(HR@5:0.4032,NDCG@5:0.2861) [0.4 s] *
INFO:root:Epoch 6     loss=0.3123 [10.7 s]    dev=(HR@5:0.4183,NDCG@5:0.2988) [0.4 s] *
INFO:root:Epoch 7     loss=0.2952 [11.4 s]    dev=(HR@5:0.4210,NDCG@5:0.3017) [0.4 s] *
INFO:root:Epoch 8     loss=0.2808 [11.4 s]    dev=(HR@5:0.4285,NDCG@5:0.3103) [0.4 s] *
INFO:root:Epoch 9     loss=0.2672 [11.5 s]    dev=(HR@5:0.4301,NDCG@5:0.3129) [0.4 s] *
INFO:root:Epoch 10    loss=0.2580 [11.4 s]    dev=(HR@5:0.4356,NDCG@5:0.3183) [0.4 s] *
INFO:root:Epoch 11    loss=0.2469 [11.4 s]    dev=(HR@5:0.4384,NDCG@5:0.3194) [0.4 s] *
INFO:root:Epoch 12    loss=0.2385 [11.4 s]    dev=(HR@5:0.4413,NDCG@5:0.3225) [0.4 s] *
INFO:root:Epoch 13    loss=0.2337 [11.4 s]    dev=(HR@5:0.4457,NDCG@5:0.3274) [0.4 s] *
INFO:root:Epoch 14    loss=0.2293 [11.3 s]    dev=(HR@5:0.4447,NDCG@5:0.3263) [0.4 s]
INFO:root:Epoch 15    loss=0.2251 [11.3 s]    dev=(HR@5:0.4440,NDCG@5:0.3255) [0.4 s]
INFO:root:Epoch 16    loss=0.2218 [11.3 s]    dev=(HR@5:0.4476,NDCG@5:0.3287) [0.4 s] *
INFO:root:Epoch 17    loss=0.2180 [11.3 s]    dev=(HR@5:0.4473,NDCG@5:0.3274) [0.4 s]
INFO:root:Epoch 18    loss=0.2142 [11.2 s]    dev=(HR@5:0.4485,NDCG@5:0.3299) [0.4 s] *
INFO:root:Epoch 19    loss=0.2121 [11.2 s]    dev=(HR@5:0.4463,NDCG@5:0.3282) [0.4 s]
INFO:root:Epoch 20    loss=0.2093 [10.1 s]    dev=(HR@5:0.4479,NDCG@5:0.3312) [0.4 s] *
INFO:root:Epoch 21    loss=0.2062 [11.3 s]    dev=(HR@5:0.4491,NDCG@5:0.3304) [0.4 s]
INFO:root:Epoch 22    loss=0.2065 [11.4 s]    dev=(HR@5:0.4482,NDCG@5:0.3303) [0.4 s]
INFO:root:Epoch 23    loss=0.2067 [11.2 s]    dev=(HR@5:0.4481,NDCG@5:0.3309) [0.3 s]
INFO:root:Epoch 24    loss=0.2059 [11.3 s]    dev=(HR@5:0.4504,NDCG@5:0.3295) [0.4 s]
INFO:root:Epoch 25    loss=0.2016 [10.5 s]    dev=(HR@5:0.4454,NDCG@5:0.3272) [0.3 s]
INFO:root:Epoch 26    loss=0.2026 [11.2 s]    dev=(HR@5:0.4474,NDCG@5:0.3305) [0.4 s]
INFO:root:Epoch 27    loss=0.2026 [11.4 s]    dev=(HR@5:0.4470,NDCG@5:0.3307) [0.4 s]
INFO:root:Epoch 28    loss=0.2022 [11.4 s]    dev=(HR@5:0.4521,NDCG@5:0.3340) [0.4 s] *
INFO:root:Epoch 29    loss=0.2008 [11.5 s]    dev=(HR@5:0.4486,NDCG@5:0.3312) [0.4 s]
INFO:root:Epoch 30    loss=0.2008 [11.5 s]    dev=(HR@5:0.4511,NDCG@5:0.3329) [0.4 s]
INFO:root:Epoch 31    loss=0.1985 [11.4 s]    dev=(HR@5:0.4517,NDCG@5:0.3343) [0.4 s] *
INFO:root:Epoch 32    loss=0.1994 [11.1 s]    dev=(HR@5:0.4517,NDCG@5:0.3328) [0.4 s]
INFO:root:Epoch 33    loss=0.2000 [11.2 s]    dev=(HR@5:0.4538,NDCG@5:0.3363) [0.4 s] *
INFO:root:Epoch 34    loss=0.1993 [11.0 s]    dev=(HR@5:0.4543,NDCG@5:0.3347) [0.4 s]
INFO:root:Epoch 35    loss=0.1987 [10.7 s]    dev=(HR@5:0.4502,NDCG@5:0.3325) [0.4 s]
INFO:root:Epoch 36    loss=0.1973 [11.6 s]    dev=(HR@5:0.4535,NDCG@5:0.3325) [0.4 s]
INFO:root:Epoch 37    loss=0.1978 [11.4 s]    dev=(HR@5:0.4533,NDCG@5:0.3316) [0.4 s]
INFO:root:Epoch 38    loss=0.1983 [11.3 s]    dev=(HR@5:0.4511,NDCG@5:0.3310) [0.4 s]
INFO:root:Epoch 39    loss=0.1981 [11.3 s]    dev=(HR@5:0.4452,NDCG@5:0.3269) [0.4 s]
INFO:root:Epoch 40    loss=0.1972 [10.6 s]    dev=(HR@5:0.4483,NDCG@5:0.3306) [0.4 s]
INFO:root:Epoch 41    loss=0.1981 [10.2 s]    dev=(HR@5:0.4499,NDCG@5:0.3313) [0.4 s]
INFO:root:Epoch 42    loss=0.1973 [10.9 s]    dev=(HR@5:0.4514,NDCG@5:0.3303) [0.4 s]
INFO:root:Epoch 43    loss=0.1962 [11.7 s]    dev=(HR@5:0.4534,NDCG@5:0.3336) [0.4 s]
INFO:root:Epoch 44    loss=0.1975 [11.3 s]    dev=(HR@5:0.4494,NDCG@5:0.3304) [0.4 s]
INFO:root:Epoch 45    loss=0.1947 [11.4 s]    dev=(HR@5:0.4534,NDCG@5:0.3352) [0.4 s]
INFO:root:Epoch 46    loss=0.1955 [11.6 s]    dev=(HR@5:0.4500,NDCG@5:0.3309) [0.4 s]
INFO:root:Epoch 47    loss=0.1962 [10.0 s]    dev=(HR@5:0.4466,NDCG@5:0.3284) [0.4 s]
INFO:root:Epoch 48    loss=0.1960 [10.3 s]    dev=(HR@5:0.4519,NDCG@5:0.3313) [0.4 s]
INFO:root:Epoch 49    loss=0.1940 [11.2 s]    dev=(HR@5:0.4567,NDCG@5:0.3343) [0.3 s]
INFO:root:Epoch 50    loss=0.1970 [11.5 s]    dev=(HR@5:0.4489,NDCG@5:0.3307) [0.4 s]
INFO:root:Epoch 51    loss=0.1947 [11.4 s]    dev=(HR@5:0.4500,NDCG@5:0.3306) [0.4 s]
INFO:root:Epoch 52    loss=0.1961 [11.5 s]    dev=(HR@5:0.4492,NDCG@5:0.3295) [0.4 s]
INFO:root:Epoch 53    loss=0.1949 [11.5 s]    dev=(HR@5:0.4457,NDCG@5:0.3282) [0.4 s]
INFO:root:Early stop at 53 based on dev result.
INFO:root:
Best Iter(dev)=   33	 dev=(HR@5:0.4538,NDCG@5:0.3363) [615.5 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.4038,NDCG@5:0.2901,HR@10:0.5105,NDCG@10:0.3247,HR@20:0.6327,NDCG@20:0.3556,HR@50:0.8409,NDCG@50:0.3968)
INFO:root:
--------------------------------------------- END: 2024-12-23 08:25:13 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 08:48:08 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5156 [12.6 s]    dev=(HR@5:0.2599,NDCG@5:0.1742) [0.4 s] *
INFO:root:Epoch 2     loss=0.4236 [11.3 s]    dev=(HR@5:0.3368,NDCG@5:0.2289) [0.4 s] *
INFO:root:Epoch 3     loss=0.3852 [11.4 s]    dev=(HR@5:0.3671,NDCG@5:0.2531) [0.4 s] *
INFO:root:Epoch 4     loss=0.3589 [10.6 s]    dev=(HR@5:0.3913,NDCG@5:0.2746) [0.4 s] *
INFO:root:Epoch 5     loss=0.3332 [10.7 s]    dev=(HR@5:0.4090,NDCG@5:0.2913) [0.4 s] *
INFO:root:Epoch 6     loss=0.3089 [11.3 s]    dev=(HR@5:0.4244,NDCG@5:0.3041) [0.4 s] *
INFO:root:Epoch 7     loss=0.2910 [10.7 s]    dev=(HR@5:0.4282,NDCG@5:0.3087) [0.4 s] *
INFO:root:Epoch 8     loss=0.2749 [11.1 s]    dev=(HR@5:0.4355,NDCG@5:0.3162) [0.4 s] *
INFO:root:Epoch 9     loss=0.2617 [10.6 s]    dev=(HR@5:0.4353,NDCG@5:0.3183) [0.4 s] *
INFO:root:Epoch 10    loss=0.2522 [10.9 s]    dev=(HR@5:0.4372,NDCG@5:0.3208) [0.4 s] *
INFO:root:Epoch 11    loss=0.2423 [11.4 s]    dev=(HR@5:0.4422,NDCG@5:0.3234) [0.4 s] *
INFO:root:Epoch 12    loss=0.2344 [11.0 s]    dev=(HR@5:0.4427,NDCG@5:0.3247) [0.4 s] *
INFO:root:Epoch 13    loss=0.2309 [11.1 s]    dev=(HR@5:0.4469,NDCG@5:0.3292) [0.4 s] *
INFO:root:Epoch 14    loss=0.2264 [10.6 s]    dev=(HR@5:0.4492,NDCG@5:0.3287) [0.4 s]
INFO:root:Epoch 15    loss=0.2228 [11.1 s]    dev=(HR@5:0.4461,NDCG@5:0.3259) [0.4 s]
INFO:root:Epoch 16    loss=0.2199 [9.2 s]    dev=(HR@5:0.4463,NDCG@5:0.3283) [0.4 s]
INFO:root:Epoch 17    loss=0.2164 [9.9 s]    dev=(HR@5:0.4442,NDCG@5:0.3266) [0.4 s]
INFO:root:Epoch 18    loss=0.2128 [11.5 s]    dev=(HR@5:0.4500,NDCG@5:0.3314) [0.4 s] *
INFO:root:Epoch 19    loss=0.2113 [10.9 s]    dev=(HR@5:0.4477,NDCG@5:0.3290) [0.4 s]
INFO:root:Epoch 20    loss=0.2090 [11.5 s]    dev=(HR@5:0.4474,NDCG@5:0.3315) [0.4 s] *
INFO:root:Epoch 21    loss=0.2061 [11.0 s]    dev=(HR@5:0.4519,NDCG@5:0.3325) [0.4 s] *
INFO:root:Epoch 22    loss=0.2065 [11.1 s]    dev=(HR@5:0.4479,NDCG@5:0.3304) [0.4 s]
INFO:root:Epoch 23    loss=0.2068 [11.2 s]    dev=(HR@5:0.4474,NDCG@5:0.3304) [0.4 s]
INFO:root:Epoch 24    loss=0.2056 [10.6 s]    dev=(HR@5:0.4496,NDCG@5:0.3314) [0.4 s]
INFO:root:Epoch 25    loss=0.2026 [9.5 s]    dev=(HR@5:0.4475,NDCG@5:0.3300) [0.4 s]
INFO:root:Epoch 26    loss=0.2030 [11.2 s]    dev=(HR@5:0.4464,NDCG@5:0.3309) [0.4 s]
INFO:root:Epoch 27    loss=0.2024 [11.1 s]    dev=(HR@5:0.4503,NDCG@5:0.3332) [0.4 s] *
INFO:root:Epoch 28    loss=0.2032 [11.3 s]    dev=(HR@5:0.4540,NDCG@5:0.3356) [0.4 s] *
INFO:root:Epoch 29    loss=0.2010 [11.5 s]    dev=(HR@5:0.4481,NDCG@5:0.3325) [0.4 s]
INFO:root:Epoch 30    loss=0.2015 [10.6 s]    dev=(HR@5:0.4531,NDCG@5:0.3345) [0.4 s]
INFO:root:Epoch 31    loss=0.1990 [10.6 s]    dev=(HR@5:0.4515,NDCG@5:0.3347) [0.4 s]
INFO:root:Epoch 32    loss=0.1999 [11.3 s]    dev=(HR@5:0.4513,NDCG@5:0.3324) [0.4 s]
INFO:root:Epoch 33    loss=0.2006 [10.0 s]    dev=(HR@5:0.4526,NDCG@5:0.3369) [0.4 s] *
INFO:root:Epoch 34    loss=0.2001 [11.2 s]    dev=(HR@5:0.4545,NDCG@5:0.3357) [0.4 s]
INFO:root:Epoch 35    loss=0.1996 [10.6 s]    dev=(HR@5:0.4497,NDCG@5:0.3322) [0.4 s]
INFO:root:Epoch 36    loss=0.1979 [11.2 s]    dev=(HR@5:0.4511,NDCG@5:0.3322) [0.4 s]
INFO:root:Epoch 37    loss=0.1988 [11.2 s]    dev=(HR@5:0.4525,NDCG@5:0.3335) [0.4 s]
INFO:root:Epoch 38    loss=0.1997 [11.2 s]    dev=(HR@5:0.4483,NDCG@5:0.3314) [0.4 s]
INFO:root:Epoch 39    loss=0.1990 [11.2 s]    dev=(HR@5:0.4448,NDCG@5:0.3275) [0.4 s]
INFO:root:Epoch 40    loss=0.1987 [11.2 s]    dev=(HR@5:0.4453,NDCG@5:0.3293) [0.4 s]
INFO:root:Epoch 41    loss=0.1990 [11.2 s]    dev=(HR@5:0.4492,NDCG@5:0.3317) [0.4 s]
INFO:root:Epoch 42    loss=0.1983 [11.4 s]    dev=(HR@5:0.4518,NDCG@5:0.3320) [0.4 s]
INFO:root:Epoch 43    loss=0.1965 [11.3 s]    dev=(HR@5:0.4510,NDCG@5:0.3327) [0.4 s]
INFO:root:Epoch 44    loss=0.1975 [11.3 s]    dev=(HR@5:0.4478,NDCG@5:0.3305) [0.4 s]
INFO:root:Epoch 45    loss=0.1955 [11.5 s]    dev=(HR@5:0.4516,NDCG@5:0.3356) [0.4 s]
INFO:root:Epoch 46    loss=0.1962 [11.2 s]    dev=(HR@5:0.4488,NDCG@5:0.3333) [0.4 s]
INFO:root:Epoch 47    loss=0.1964 [11.3 s]    dev=(HR@5:0.4479,NDCG@5:0.3306) [0.4 s]
INFO:root:Epoch 48    loss=0.1948 [11.2 s]    dev=(HR@5:0.4468,NDCG@5:0.3301) [0.4 s]
INFO:root:Epoch 49    loss=0.1945 [11.5 s]    dev=(HR@5:0.4506,NDCG@5:0.3338) [0.4 s]
INFO:root:Epoch 50    loss=0.1961 [11.3 s]    dev=(HR@5:0.4495,NDCG@5:0.3327) [0.4 s]
INFO:root:Epoch 51    loss=0.1946 [11.1 s]    dev=(HR@5:0.4507,NDCG@5:0.3329) [0.4 s]
INFO:root:Epoch 52    loss=0.1951 [10.7 s]    dev=(HR@5:0.4468,NDCG@5:0.3298) [0.4 s]
INFO:root:Epoch 53    loss=0.1949 [11.1 s]    dev=(HR@5:0.4472,NDCG@5:0.3297) [0.4 s]
INFO:root:Early stop at 53 based on dev result.
INFO:root:
Best Iter(dev)=   33	 dev=(HR@5:0.4526,NDCG@5:0.3369) [605.2 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.4043,NDCG@5:0.2910,HR@10:0.5122,NDCG@10:0.3259,HR@20:0.6310,NDCG@20:0.3558,HR@50:0.8358,NDCG@50:0.3964)
INFO:root:
--------------------------------------------- END: 2024-12-23 08:58:16 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 09:29:22 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5143 [12.4 s]    dev=(HR@5:0.2523,NDCG@5:0.1675) [0.4 s] *
INFO:root:Epoch 2     loss=0.4310 [10.9 s]    dev=(HR@5:0.3169,NDCG@5:0.2143) [0.4 s] *
INFO:root:Epoch 3     loss=0.3977 [11.2 s]    dev=(HR@5:0.3393,NDCG@5:0.2277) [0.4 s] *
INFO:root:Epoch 4     loss=0.3769 [10.3 s]    dev=(HR@5:0.3567,NDCG@5:0.2434) [0.4 s] *
INFO:root:Epoch 5     loss=0.3545 [10.3 s]    dev=(HR@5:0.3695,NDCG@5:0.2547) [0.4 s] *
INFO:root:Epoch 6     loss=0.3330 [11.3 s]    dev=(HR@5:0.3878,NDCG@5:0.2735) [0.4 s] *
INFO:root:Epoch 7     loss=0.3146 [10.5 s]    dev=(HR@5:0.3946,NDCG@5:0.2794) [0.4 s] *
INFO:root:Epoch 8     loss=0.3015 [11.4 s]    dev=(HR@5:0.3990,NDCG@5:0.2851) [0.4 s] *
INFO:root:Epoch 9     loss=0.2879 [11.2 s]    dev=(HR@5:0.3996,NDCG@5:0.2854) [0.4 s] *
INFO:root:Epoch 10    loss=0.2798 [11.3 s]    dev=(HR@5:0.4043,NDCG@5:0.2890) [0.4 s] *
INFO:root:Epoch 11    loss=0.2710 [11.3 s]    dev=(HR@5:0.4085,NDCG@5:0.2910) [0.4 s] *
INFO:root:Epoch 12    loss=0.2632 [11.3 s]    dev=(HR@5:0.4103,NDCG@5:0.2952) [0.4 s] *
INFO:root:Epoch 13    loss=0.2590 [11.2 s]    dev=(HR@5:0.4177,NDCG@5:0.2998) [0.4 s] *
INFO:root:Epoch 14    loss=0.2540 [11.7 s]    dev=(HR@5:0.4148,NDCG@5:0.2978) [0.4 s]
INFO:root:Epoch 15    loss=0.2508 [11.5 s]    dev=(HR@5:0.4145,NDCG@5:0.2976) [0.4 s]
INFO:root:Epoch 16    loss=0.2477 [11.2 s]    dev=(HR@5:0.4177,NDCG@5:0.3009) [0.4 s] *
INFO:root:Epoch 17    loss=0.2439 [11.4 s]    dev=(HR@5:0.4156,NDCG@5:0.2979) [0.4 s]
INFO:root:Epoch 18    loss=0.2397 [10.8 s]    dev=(HR@5:0.4158,NDCG@5:0.2995) [0.4 s]
INFO:root:Epoch 19    loss=0.2365 [11.2 s]    dev=(HR@5:0.4206,NDCG@5:0.3048) [0.4 s] *
INFO:root:Epoch 20    loss=0.2339 [11.1 s]    dev=(HR@5:0.4249,NDCG@5:0.3078) [0.4 s] *
INFO:root:Epoch 21    loss=0.2295 [11.3 s]    dev=(HR@5:0.4267,NDCG@5:0.3087) [0.4 s] *
INFO:root:Epoch 22    loss=0.2279 [10.7 s]    dev=(HR@5:0.4265,NDCG@5:0.3097) [0.4 s] *
INFO:root:Epoch 23    loss=0.2287 [11.4 s]    dev=(HR@5:0.4218,NDCG@5:0.3071) [0.4 s]
INFO:root:Epoch 24    loss=0.2270 [10.4 s]    dev=(HR@5:0.4324,NDCG@5:0.3113) [0.4 s] *
INFO:root:Epoch 25    loss=0.2236 [11.3 s]    dev=(HR@5:0.4278,NDCG@5:0.3115) [0.4 s] *
INFO:root:Epoch 26    loss=0.2238 [11.7 s]    dev=(HR@5:0.4293,NDCG@5:0.3126) [0.4 s] *
INFO:root:Epoch 27    loss=0.2225 [11.3 s]    dev=(HR@5:0.4292,NDCG@5:0.3122) [0.4 s]
INFO:root:Epoch 28    loss=0.2228 [10.5 s]    dev=(HR@5:0.4341,NDCG@5:0.3172) [0.4 s] *
INFO:root:Epoch 29    loss=0.2201 [11.3 s]    dev=(HR@5:0.4319,NDCG@5:0.3162) [0.4 s]
INFO:root:Epoch 30    loss=0.2196 [11.3 s]    dev=(HR@5:0.4328,NDCG@5:0.3164) [0.4 s]
INFO:root:Epoch 31    loss=0.2185 [11.4 s]    dev=(HR@5:0.4338,NDCG@5:0.3171) [0.4 s]
INFO:root:Epoch 32    loss=0.2187 [11.5 s]    dev=(HR@5:0.4308,NDCG@5:0.3133) [0.4 s]
INFO:root:Epoch 33    loss=0.2183 [11.1 s]    dev=(HR@5:0.4357,NDCG@5:0.3181) [0.4 s] *
INFO:root:Epoch 34    loss=0.2175 [11.4 s]    dev=(HR@5:0.4384,NDCG@5:0.3207) [0.4 s] *
INFO:root:Epoch 35    loss=0.2177 [11.4 s]    dev=(HR@5:0.4329,NDCG@5:0.3145) [0.4 s]
INFO:root:Epoch 36    loss=0.2157 [11.3 s]    dev=(HR@5:0.4321,NDCG@5:0.3137) [0.4 s]
INFO:root:Epoch 37    loss=0.2164 [11.0 s]    dev=(HR@5:0.4353,NDCG@5:0.3160) [0.4 s]
INFO:root:Epoch 38    loss=0.2158 [11.3 s]    dev=(HR@5:0.4392,NDCG@5:0.3190) [0.4 s]
INFO:root:Epoch 39    loss=0.2159 [11.3 s]    dev=(HR@5:0.4310,NDCG@5:0.3121) [0.4 s]
INFO:root:Epoch 40    loss=0.2154 [11.1 s]    dev=(HR@5:0.4321,NDCG@5:0.3148) [0.4 s]
INFO:root:Epoch 41    loss=0.2156 [11.1 s]    dev=(HR@5:0.4343,NDCG@5:0.3147) [0.4 s]
INFO:root:Epoch 42    loss=0.2159 [11.2 s]    dev=(HR@5:0.4334,NDCG@5:0.3163) [0.4 s]
INFO:root:Epoch 43    loss=0.2145 [11.2 s]    dev=(HR@5:0.4391,NDCG@5:0.3212) [0.4 s] *
INFO:root:Epoch 44    loss=0.2152 [11.2 s]    dev=(HR@5:0.4375,NDCG@5:0.3182) [0.4 s]
INFO:root:Epoch 45    loss=0.2126 [11.6 s]    dev=(HR@5:0.4396,NDCG@5:0.3204) [0.4 s]
INFO:root:Epoch 46    loss=0.2136 [10.1 s]    dev=(HR@5:0.4307,NDCG@5:0.3141) [0.4 s]
INFO:root:Epoch 47    loss=0.2144 [11.2 s]    dev=(HR@5:0.4361,NDCG@5:0.3164) [0.4 s]
INFO:root:Epoch 48    loss=0.2137 [10.5 s]    dev=(HR@5:0.4356,NDCG@5:0.3174) [0.4 s]
INFO:root:Epoch 49    loss=0.2115 [10.5 s]    dev=(HR@5:0.4420,NDCG@5:0.3216) [0.4 s] *
INFO:root:Epoch 50    loss=0.2123 [11.3 s]    dev=(HR@5:0.4398,NDCG@5:0.3205) [0.4 s]
INFO:root:Epoch 51    loss=0.2118 [11.6 s]    dev=(HR@5:0.4376,NDCG@5:0.3180) [0.4 s]
INFO:root:Epoch 52    loss=0.2117 [11.7 s]    dev=(HR@5:0.4377,NDCG@5:0.3185) [0.4 s]
INFO:root:Epoch 53    loss=0.2126 [11.1 s]    dev=(HR@5:0.4370,NDCG@5:0.3180) [0.4 s]
INFO:root:Epoch 54    loss=0.2093 [11.4 s]    dev=(HR@5:0.4413,NDCG@5:0.3204) [0.4 s]
INFO:root:Epoch 55    loss=0.2106 [11.2 s]    dev=(HR@5:0.4400,NDCG@5:0.3191) [0.4 s]
INFO:root:Epoch 56    loss=0.2104 [11.2 s]    dev=(HR@5:0.4432,NDCG@5:0.3247) [0.4 s] *
INFO:root:Epoch 57    loss=0.2109 [11.2 s]    dev=(HR@5:0.4438,NDCG@5:0.3240) [0.4 s]
INFO:root:Epoch 58    loss=0.2119 [11.2 s]    dev=(HR@5:0.4441,NDCG@5:0.3245) [0.5 s]
INFO:root:Epoch 59    loss=0.2098 [11.5 s]    dev=(HR@5:0.4413,NDCG@5:0.3226) [0.4 s]
INFO:root:Epoch 60    loss=0.2110 [11.2 s]    dev=(HR@5:0.4402,NDCG@5:0.3219) [0.4 s]
INFO:root:Epoch 61    loss=0.2104 [11.1 s]    dev=(HR@5:0.4433,NDCG@5:0.3240) [0.4 s]
INFO:root:Epoch 62    loss=0.2097 [11.3 s]    dev=(HR@5:0.4406,NDCG@5:0.3215) [0.4 s]
INFO:root:Epoch 63    loss=0.2117 [11.2 s]    dev=(HR@5:0.4434,NDCG@5:0.3226) [0.4 s]
INFO:root:Epoch 64    loss=0.2088 [10.8 s]    dev=(HR@5:0.4417,NDCG@5:0.3215) [0.4 s]
INFO:root:Epoch 65    loss=0.2103 [11.0 s]    dev=(HR@5:0.4366,NDCG@5:0.3203) [0.4 s]
INFO:root:Epoch 66    loss=0.2087 [11.4 s]    dev=(HR@5:0.4393,NDCG@5:0.3181) [0.4 s]
INFO:root:Epoch 67    loss=0.2093 [11.3 s]    dev=(HR@5:0.4419,NDCG@5:0.3214) [0.4 s]
INFO:root:Epoch 68    loss=0.2077 [11.2 s]    dev=(HR@5:0.4386,NDCG@5:0.3210) [0.4 s]
INFO:root:Epoch 69    loss=0.2100 [11.2 s]    dev=(HR@5:0.4382,NDCG@5:0.3199) [0.4 s]
INFO:root:Epoch 70    loss=0.2095 [10.8 s]    dev=(HR@5:0.4390,NDCG@5:0.3196) [0.4 s]
INFO:root:Epoch 71    loss=0.2080 [10.4 s]    dev=(HR@5:0.4385,NDCG@5:0.3195) [0.4 s]
INFO:root:Epoch 72    loss=0.2083 [11.1 s]    dev=(HR@5:0.4429,NDCG@5:0.3223) [0.4 s]
INFO:root:Epoch 73    loss=0.2094 [11.1 s]    dev=(HR@5:0.4398,NDCG@5:0.3184) [0.4 s]
INFO:root:Epoch 74    loss=0.2089 [11.3 s]    dev=(HR@5:0.4378,NDCG@5:0.3169) [0.4 s]
INFO:root:Epoch 75    loss=0.2107 [11.1 s]    dev=(HR@5:0.4383,NDCG@5:0.3182) [0.4 s]
INFO:root:Epoch 76    loss=0.2100 [11.2 s]    dev=(HR@5:0.4457,NDCG@5:0.3235) [0.4 s]
INFO:root:Early stop at 76 based on dev result.
INFO:root:
Best Iter(dev)=   56	 dev=(HR@5:0.4432,NDCG@5:0.3247) [877.9 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.3910,NDCG@5:0.2800,HR@10:0.5047,NDCG@10:0.3169,HR@20:0.6298,NDCG@20:0.3484,HR@50:0.8336,NDCG@50:0.3887)
INFO:root:
--------------------------------------------- END: 2024-12-23 09:44:03 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 10:15:48 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5141 [11.7 s]    dev=(HR@5:0.2595,NDCG@5:0.1738) [0.4 s] *
INFO:root:Epoch 2     loss=0.4232 [10.4 s]    dev=(HR@5:0.3349,NDCG@5:0.2288) [0.4 s] *
INFO:root:Epoch 3     loss=0.3871 [11.4 s]    dev=(HR@5:0.3615,NDCG@5:0.2486) [0.4 s] *
INFO:root:Epoch 4     loss=0.3633 [11.2 s]    dev=(HR@5:0.3833,NDCG@5:0.2674) [0.4 s] *
INFO:root:Epoch 5     loss=0.3377 [11.2 s]    dev=(HR@5:0.4022,NDCG@5:0.2845) [0.4 s] *
INFO:root:Epoch 6     loss=0.3121 [11.4 s]    dev=(HR@5:0.4151,NDCG@5:0.2953) [0.4 s] *
INFO:root:Epoch 7     loss=0.2937 [11.3 s]    dev=(HR@5:0.4218,NDCG@5:0.3015) [0.4 s] *
INFO:root:Epoch 8     loss=0.2787 [11.5 s]    dev=(HR@5:0.4291,NDCG@5:0.3090) [0.4 s] *
INFO:root:Epoch 9     loss=0.2657 [10.2 s]    dev=(HR@5:0.4313,NDCG@5:0.3106) [0.4 s] *
INFO:root:Epoch 10    loss=0.2568 [11.3 s]    dev=(HR@5:0.4336,NDCG@5:0.3134) [0.4 s] *
INFO:root:Epoch 11    loss=0.2486 [11.0 s]    dev=(HR@5:0.4361,NDCG@5:0.3154) [0.4 s] *
INFO:root:Epoch 12    loss=0.2427 [11.4 s]    dev=(HR@5:0.4373,NDCG@5:0.3161) [0.4 s] *
INFO:root:Epoch 13    loss=0.2394 [11.4 s]    dev=(HR@5:0.4416,NDCG@5:0.3191) [0.4 s] *
INFO:root:Epoch 14    loss=0.2361 [11.2 s]    dev=(HR@5:0.4395,NDCG@5:0.3169) [0.4 s]
INFO:root:Epoch 15    loss=0.2340 [11.2 s]    dev=(HR@5:0.4382,NDCG@5:0.3159) [0.4 s]
INFO:root:Epoch 16    loss=0.2321 [11.4 s]    dev=(HR@5:0.4362,NDCG@5:0.3158) [0.4 s]
INFO:root:Epoch 17    loss=0.2294 [11.4 s]    dev=(HR@5:0.4422,NDCG@5:0.3191) [0.4 s]
INFO:root:Epoch 18    loss=0.2255 [10.9 s]    dev=(HR@5:0.4379,NDCG@5:0.3188) [0.4 s]
INFO:root:Epoch 19    loss=0.2238 [10.5 s]    dev=(HR@5:0.4389,NDCG@5:0.3200) [0.4 s] *
INFO:root:Epoch 20    loss=0.2220 [11.2 s]    dev=(HR@5:0.4408,NDCG@5:0.3202) [0.4 s] *
INFO:root:Epoch 21    loss=0.2188 [11.1 s]    dev=(HR@5:0.4421,NDCG@5:0.3204) [0.4 s] *
INFO:root:Epoch 22    loss=0.2183 [11.3 s]    dev=(HR@5:0.4400,NDCG@5:0.3194) [0.4 s]
INFO:root:Epoch 23    loss=0.2195 [11.3 s]    dev=(HR@5:0.4354,NDCG@5:0.3172) [0.4 s]
INFO:root:Epoch 24    loss=0.2193 [10.5 s]    dev=(HR@5:0.4425,NDCG@5:0.3200) [0.4 s]
INFO:root:Epoch 25    loss=0.2160 [11.1 s]    dev=(HR@5:0.4397,NDCG@5:0.3183) [0.4 s]
INFO:root:Epoch 26    loss=0.2168 [11.3 s]    dev=(HR@5:0.4402,NDCG@5:0.3192) [0.4 s]
INFO:root:Epoch 27    loss=0.2166 [11.3 s]    dev=(HR@5:0.4383,NDCG@5:0.3183) [0.4 s]
INFO:root:Epoch 28    loss=0.2162 [11.5 s]    dev=(HR@5:0.4403,NDCG@5:0.3220) [0.4 s] *
INFO:root:Epoch 29    loss=0.2147 [11.7 s]    dev=(HR@5:0.4403,NDCG@5:0.3195) [0.4 s]
INFO:root:Epoch 30    loss=0.2140 [11.4 s]    dev=(HR@5:0.4373,NDCG@5:0.3189) [0.4 s]
INFO:root:Epoch 31    loss=0.2135 [11.3 s]    dev=(HR@5:0.4395,NDCG@5:0.3200) [0.4 s]
INFO:root:Epoch 32    loss=0.2142 [11.3 s]    dev=(HR@5:0.4390,NDCG@5:0.3187) [0.4 s]
INFO:root:Epoch 33    loss=0.2141 [10.9 s]    dev=(HR@5:0.4430,NDCG@5:0.3229) [0.4 s] *
INFO:root:Epoch 34    loss=0.2136 [11.0 s]    dev=(HR@5:0.4406,NDCG@5:0.3205) [0.4 s]
INFO:root:Epoch 35    loss=0.2133 [11.3 s]    dev=(HR@5:0.4345,NDCG@5:0.3147) [0.4 s]
INFO:root:Epoch 36    loss=0.2122 [11.3 s]    dev=(HR@5:0.4366,NDCG@5:0.3171) [0.4 s]
INFO:root:Epoch 37    loss=0.2133 [10.6 s]    dev=(HR@5:0.4393,NDCG@5:0.3189) [0.4 s]
INFO:root:Epoch 38    loss=0.2128 [11.2 s]    dev=(HR@5:0.4372,NDCG@5:0.3179) [0.4 s]
INFO:root:Epoch 39    loss=0.2136 [11.5 s]    dev=(HR@5:0.4328,NDCG@5:0.3132) [0.4 s]
INFO:root:Epoch 40    loss=0.2129 [11.4 s]    dev=(HR@5:0.4372,NDCG@5:0.3166) [0.4 s]
INFO:root:Epoch 41    loss=0.2131 [11.1 s]    dev=(HR@5:0.4365,NDCG@5:0.3186) [0.4 s]
INFO:root:Epoch 42    loss=0.2132 [11.2 s]    dev=(HR@5:0.4392,NDCG@5:0.3186) [0.4 s]
INFO:root:Epoch 43    loss=0.2119 [11.2 s]    dev=(HR@5:0.4443,NDCG@5:0.3233) [0.4 s] *
INFO:root:Epoch 44    loss=0.2132 [11.0 s]    dev=(HR@5:0.4376,NDCG@5:0.3187) [0.4 s]
INFO:root:Epoch 45    loss=0.2106 [11.4 s]    dev=(HR@5:0.4423,NDCG@5:0.3221) [0.4 s]
INFO:root:Epoch 46    loss=0.2114 [10.4 s]    dev=(HR@5:0.4336,NDCG@5:0.3154) [0.4 s]
INFO:root:Epoch 47    loss=0.2117 [11.2 s]    dev=(HR@5:0.4363,NDCG@5:0.3159) [0.4 s]
INFO:root:Epoch 48    loss=0.2113 [11.4 s]    dev=(HR@5:0.4371,NDCG@5:0.3182) [0.4 s]
INFO:root:Epoch 49    loss=0.2096 [11.5 s]    dev=(HR@5:0.4401,NDCG@5:0.3210) [0.4 s]
INFO:root:Epoch 50    loss=0.2115 [11.3 s]    dev=(HR@5:0.4373,NDCG@5:0.3194) [0.4 s]
INFO:root:Epoch 51    loss=0.2106 [11.0 s]    dev=(HR@5:0.4388,NDCG@5:0.3197) [0.4 s]
INFO:root:Epoch 52    loss=0.2109 [11.2 s]    dev=(HR@5:0.4424,NDCG@5:0.3209) [0.3 s]
INFO:root:Epoch 53    loss=0.2104 [10.9 s]    dev=(HR@5:0.4351,NDCG@5:0.3164) [0.4 s]
INFO:root:Epoch 54    loss=0.2085 [11.5 s]    dev=(HR@5:0.4368,NDCG@5:0.3170) [0.4 s]
INFO:root:Epoch 55    loss=0.2102 [11.1 s]    dev=(HR@5:0.4385,NDCG@5:0.3191) [0.4 s]
INFO:root:Epoch 56    loss=0.2102 [11.1 s]    dev=(HR@5:0.4399,NDCG@5:0.3217) [0.4 s]
INFO:root:Epoch 57    loss=0.2095 [11.2 s]    dev=(HR@5:0.4384,NDCG@5:0.3196) [0.4 s]
INFO:root:Epoch 58    loss=0.2113 [11.1 s]    dev=(HR@5:0.4422,NDCG@5:0.3235) [0.4 s] *
INFO:root:Epoch 59    loss=0.2104 [11.1 s]    dev=(HR@5:0.4400,NDCG@5:0.3205) [0.4 s]
INFO:root:Epoch 60    loss=0.2104 [11.0 s]    dev=(HR@5:0.4379,NDCG@5:0.3197) [0.4 s]
INFO:root:Epoch 61    loss=0.2103 [11.6 s]    dev=(HR@5:0.4393,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 62    loss=0.2096 [10.2 s]    dev=(HR@5:0.4382,NDCG@5:0.3189) [0.4 s]
INFO:root:Epoch 63    loss=0.2115 [10.3 s]    dev=(HR@5:0.4389,NDCG@5:0.3198) [0.4 s]
INFO:root:Epoch 64    loss=0.2089 [11.1 s]    dev=(HR@5:0.4382,NDCG@5:0.3180) [0.4 s]
INFO:root:Epoch 65    loss=0.2104 [11.3 s]    dev=(HR@5:0.4375,NDCG@5:0.3180) [0.4 s]
INFO:root:Epoch 66    loss=0.2089 [10.5 s]    dev=(HR@5:0.4400,NDCG@5:0.3194) [0.4 s]
INFO:root:Epoch 67    loss=0.2087 [10.8 s]    dev=(HR@5:0.4414,NDCG@5:0.3201) [0.4 s]
INFO:root:Epoch 68    loss=0.2074 [11.1 s]    dev=(HR@5:0.4397,NDCG@5:0.3209) [0.4 s]
INFO:root:Epoch 69    loss=0.2094 [11.3 s]    dev=(HR@5:0.4417,NDCG@5:0.3219) [0.4 s]
INFO:root:Epoch 70    loss=0.2086 [10.8 s]    dev=(HR@5:0.4342,NDCG@5:0.3161) [0.3 s]
INFO:root:Epoch 71    loss=0.2077 [11.3 s]    dev=(HR@5:0.4378,NDCG@5:0.3214) [0.4 s]
INFO:root:Epoch 72    loss=0.2073 [11.4 s]    dev=(HR@5:0.4380,NDCG@5:0.3196) [0.4 s]
INFO:root:Epoch 73    loss=0.2080 [11.3 s]    dev=(HR@5:0.4378,NDCG@5:0.3173) [0.4 s]
INFO:root:Epoch 74    loss=0.2073 [11.3 s]    dev=(HR@5:0.4353,NDCG@5:0.3157) [0.4 s]
INFO:root:Epoch 75    loss=0.2093 [11.1 s]    dev=(HR@5:0.4416,NDCG@5:0.3220) [0.4 s]
INFO:root:Epoch 76    loss=0.2085 [11.1 s]    dev=(HR@5:0.4385,NDCG@5:0.3195) [0.4 s]
INFO:root:Epoch 77    loss=0.2060 [11.1 s]    dev=(HR@5:0.4391,NDCG@5:0.3194) [0.4 s]
INFO:root:Epoch 78    loss=0.2067 [11.0 s]    dev=(HR@5:0.4413,NDCG@5:0.3202) [0.4 s]
INFO:root:Early stop at 78 based on dev result.
INFO:root:
Best Iter(dev)=   58	 dev=(HR@5:0.4422,NDCG@5:0.3235) [899.2 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.3951,NDCG@5:0.2795,HR@10:0.5081,NDCG@10:0.3161,HR@20:0.6333,NDCG@20:0.3477,HR@50:0.8353,NDCG@50:0.3876)
INFO:root:
--------------------------------------------- END: 2024-12-23 10:30:50 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 10:50:34 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5140 [12.0 s]    dev=(HR@5:0.2674,NDCG@5:0.1793) [0.4 s] *
INFO:root:Epoch 2     loss=0.4202 [11.3 s]    dev=(HR@5:0.3413,NDCG@5:0.2333) [0.4 s] *
INFO:root:Epoch 3     loss=0.3830 [11.9 s]    dev=(HR@5:0.3719,NDCG@5:0.2568) [0.4 s] *
INFO:root:Epoch 4     loss=0.3590 [12.0 s]    dev=(HR@5:0.3928,NDCG@5:0.2741) [0.4 s] *
INFO:root:Epoch 5     loss=0.3349 [12.0 s]    dev=(HR@5:0.4060,NDCG@5:0.2884) [0.4 s] *
INFO:root:Epoch 6     loss=0.3094 [12.0 s]    dev=(HR@5:0.4215,NDCG@5:0.3025) [0.4 s] *
INFO:root:Epoch 7     loss=0.2912 [11.3 s]    dev=(HR@5:0.4279,NDCG@5:0.3081) [0.4 s] *
INFO:root:Epoch 8     loss=0.2759 [11.6 s]    dev=(HR@5:0.4316,NDCG@5:0.3125) [0.4 s] *
INFO:root:Epoch 9     loss=0.2628 [12.0 s]    dev=(HR@5:0.4335,NDCG@5:0.3152) [0.4 s] *
INFO:root:Epoch 10    loss=0.2544 [11.9 s]    dev=(HR@5:0.4384,NDCG@5:0.3204) [0.4 s] *
INFO:root:Epoch 11    loss=0.2453 [11.9 s]    dev=(HR@5:0.4419,NDCG@5:0.3221) [0.4 s] *
INFO:root:Epoch 12    loss=0.2378 [11.9 s]    dev=(HR@5:0.4432,NDCG@5:0.3234) [0.4 s] *
INFO:root:Epoch 13    loss=0.2333 [11.8 s]    dev=(HR@5:0.4474,NDCG@5:0.3276) [0.4 s] *
INFO:root:Epoch 14    loss=0.2293 [11.7 s]    dev=(HR@5:0.4481,NDCG@5:0.3272) [0.4 s]
INFO:root:Epoch 15    loss=0.2255 [11.7 s]    dev=(HR@5:0.4460,NDCG@5:0.3274) [0.4 s]
INFO:root:Epoch 16    loss=0.2229 [11.6 s]    dev=(HR@5:0.4455,NDCG@5:0.3280) [0.4 s] *
INFO:root:Epoch 17    loss=0.2196 [11.8 s]    dev=(HR@5:0.4455,NDCG@5:0.3274) [0.4 s]
INFO:root:Epoch 18    loss=0.2150 [11.4 s]    dev=(HR@5:0.4481,NDCG@5:0.3292) [0.4 s] *
INFO:root:Epoch 19    loss=0.2140 [11.2 s]    dev=(HR@5:0.4497,NDCG@5:0.3308) [0.4 s] *
INFO:root:Epoch 20    loss=0.2108 [10.9 s]    dev=(HR@5:0.4477,NDCG@5:0.3301) [0.4 s]
INFO:root:Epoch 21    loss=0.2069 [10.7 s]    dev=(HR@5:0.4489,NDCG@5:0.3307) [0.4 s]
INFO:root:Epoch 22    loss=0.2073 [11.3 s]    dev=(HR@5:0.4461,NDCG@5:0.3297) [0.4 s]
INFO:root:Epoch 23    loss=0.2072 [11.3 s]    dev=(HR@5:0.4425,NDCG@5:0.3290) [0.4 s]
INFO:root:Epoch 24    loss=0.2057 [11.3 s]    dev=(HR@5:0.4477,NDCG@5:0.3297) [0.4 s]
INFO:root:Epoch 25    loss=0.2031 [11.1 s]    dev=(HR@5:0.4442,NDCG@5:0.3283) [0.4 s]
INFO:root:Epoch 26    loss=0.2036 [11.4 s]    dev=(HR@5:0.4448,NDCG@5:0.3284) [0.4 s]
INFO:root:Epoch 27    loss=0.2031 [10.9 s]    dev=(HR@5:0.4481,NDCG@5:0.3304) [0.4 s]
INFO:root:Epoch 28    loss=0.2020 [11.0 s]    dev=(HR@5:0.4493,NDCG@5:0.3328) [0.4 s] *
INFO:root:Epoch 29    loss=0.2008 [11.1 s]    dev=(HR@5:0.4477,NDCG@5:0.3307) [0.4 s]
INFO:root:Epoch 30    loss=0.2009 [11.0 s]    dev=(HR@5:0.4462,NDCG@5:0.3303) [0.4 s]
INFO:root:Epoch 31    loss=0.2002 [11.5 s]    dev=(HR@5:0.4513,NDCG@5:0.3342) [0.4 s] *
INFO:root:Epoch 32    loss=0.2004 [10.8 s]    dev=(HR@5:0.4485,NDCG@5:0.3314) [0.4 s]
INFO:root:Epoch 33    loss=0.2004 [9.5 s]    dev=(HR@5:0.4490,NDCG@5:0.3332) [0.4 s]
INFO:root:Epoch 34    loss=0.2001 [11.3 s]    dev=(HR@5:0.4509,NDCG@5:0.3330) [0.4 s]
INFO:root:Epoch 35    loss=0.2002 [10.4 s]    dev=(HR@5:0.4477,NDCG@5:0.3296) [0.4 s]
INFO:root:Epoch 36    loss=0.1976 [11.6 s]    dev=(HR@5:0.4492,NDCG@5:0.3293) [0.4 s]
INFO:root:Epoch 37    loss=0.1978 [11.3 s]    dev=(HR@5:0.4479,NDCG@5:0.3309) [0.4 s]
INFO:root:Epoch 38    loss=0.1985 [11.0 s]    dev=(HR@5:0.4498,NDCG@5:0.3301) [0.4 s]
INFO:root:Epoch 39    loss=0.1991 [10.8 s]    dev=(HR@5:0.4434,NDCG@5:0.3258) [0.4 s]
INFO:root:Epoch 40    loss=0.1974 [11.2 s]    dev=(HR@5:0.4481,NDCG@5:0.3291) [0.4 s]
INFO:root:Epoch 41    loss=0.1990 [11.3 s]    dev=(HR@5:0.4492,NDCG@5:0.3298) [0.4 s]
INFO:root:Epoch 42    loss=0.1982 [11.1 s]    dev=(HR@5:0.4513,NDCG@5:0.3308) [0.4 s]
INFO:root:Epoch 43    loss=0.1962 [11.2 s]    dev=(HR@5:0.4527,NDCG@5:0.3325) [0.4 s]
INFO:root:Epoch 44    loss=0.1985 [11.2 s]    dev=(HR@5:0.4497,NDCG@5:0.3303) [0.4 s]
INFO:root:Epoch 45    loss=0.1950 [11.4 s]    dev=(HR@5:0.4512,NDCG@5:0.3330) [0.4 s]
INFO:root:Epoch 46    loss=0.1964 [11.0 s]    dev=(HR@5:0.4490,NDCG@5:0.3301) [0.4 s]
INFO:root:Epoch 47    loss=0.1968 [11.2 s]    dev=(HR@5:0.4498,NDCG@5:0.3294) [0.4 s]
INFO:root:Epoch 48    loss=0.1969 [11.1 s]    dev=(HR@5:0.4455,NDCG@5:0.3273) [0.4 s]
INFO:root:Epoch 49    loss=0.1961 [11.5 s]    dev=(HR@5:0.4502,NDCG@5:0.3319) [0.4 s]
INFO:root:Epoch 50    loss=0.1975 [10.8 s]    dev=(HR@5:0.4466,NDCG@5:0.3298) [0.4 s]
INFO:root:Epoch 51    loss=0.1959 [11.4 s]    dev=(HR@5:0.4494,NDCG@5:0.3321) [0.4 s]
INFO:root:Early stop at 51 based on dev result.
INFO:root:
Best Iter(dev)=   31	 dev=(HR@5:0.4513,NDCG@5:0.3342) [597.6 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.4016,NDCG@5:0.2890,HR@10:0.5088,NDCG@10:0.3237,HR@20:0.6312,NDCG@20:0.3546,HR@50:0.8336,NDCG@50:0.3947)
INFO:root:
--------------------------------------------- END: 2024-12-23 11:00:34 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 11:25:48 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5143 [13.1 s]    dev=(HR@5:0.2597,NDCG@5:0.1742) [0.4 s] *
INFO:root:Epoch 2     loss=0.4231 [11.6 s]    dev=(HR@5:0.3358,NDCG@5:0.2283) [0.4 s] *
INFO:root:Epoch 3     loss=0.3858 [11.7 s]    dev=(HR@5:0.3632,NDCG@5:0.2485) [0.4 s] *
INFO:root:Epoch 4     loss=0.3597 [10.9 s]    dev=(HR@5:0.3904,NDCG@5:0.2719) [0.4 s] *
INFO:root:Epoch 5     loss=0.3325 [11.6 s]    dev=(HR@5:0.4068,NDCG@5:0.2891) [0.4 s] *
INFO:root:Epoch 6     loss=0.3074 [10.9 s]    dev=(HR@5:0.4210,NDCG@5:0.3012) [0.4 s] *
INFO:root:Epoch 7     loss=0.2906 [10.8 s]    dev=(HR@5:0.4248,NDCG@5:0.3047) [0.4 s] *
INFO:root:Epoch 8     loss=0.2774 [11.4 s]    dev=(HR@5:0.4295,NDCG@5:0.3109) [0.4 s] *
INFO:root:Epoch 9     loss=0.2653 [11.7 s]    dev=(HR@5:0.4323,NDCG@5:0.3120) [0.4 s] *
INFO:root:Epoch 10    loss=0.2577 [10.9 s]    dev=(HR@5:0.4337,NDCG@5:0.3152) [0.4 s] *
INFO:root:Epoch 11    loss=0.2490 [11.3 s]    dev=(HR@5:0.4368,NDCG@5:0.3163) [0.4 s] *
INFO:root:Epoch 12    loss=0.2419 [11.3 s]    dev=(HR@5:0.4397,NDCG@5:0.3201) [0.4 s] *
INFO:root:Epoch 13    loss=0.2387 [11.3 s]    dev=(HR@5:0.4415,NDCG@5:0.3238) [0.4 s] *
INFO:root:Epoch 14    loss=0.2347 [11.6 s]    dev=(HR@5:0.4425,NDCG@5:0.3222) [0.4 s]
INFO:root:Epoch 15    loss=0.2306 [11.0 s]    dev=(HR@5:0.4398,NDCG@5:0.3208) [0.4 s]
INFO:root:Epoch 16    loss=0.2288 [11.1 s]    dev=(HR@5:0.4402,NDCG@5:0.3225) [0.4 s]
INFO:root:Epoch 17    loss=0.2251 [11.4 s]    dev=(HR@5:0.4383,NDCG@5:0.3217) [0.4 s]
INFO:root:Epoch 18    loss=0.2202 [11.4 s]    dev=(HR@5:0.4442,NDCG@5:0.3245) [0.4 s] *
INFO:root:Epoch 19    loss=0.2196 [11.4 s]    dev=(HR@5:0.4423,NDCG@5:0.3248) [0.4 s] *
INFO:root:Epoch 20    loss=0.2161 [11.4 s]    dev=(HR@5:0.4430,NDCG@5:0.3275) [0.4 s] *
INFO:root:Epoch 21    loss=0.2139 [10.5 s]    dev=(HR@5:0.4441,NDCG@5:0.3268) [0.4 s]
INFO:root:Epoch 22    loss=0.2129 [11.5 s]    dev=(HR@5:0.4395,NDCG@5:0.3265) [0.4 s]
INFO:root:Epoch 23    loss=0.2138 [11.1 s]    dev=(HR@5:0.4421,NDCG@5:0.3271) [0.4 s]
INFO:root:Epoch 24    loss=0.2126 [11.7 s]    dev=(HR@5:0.4440,NDCG@5:0.3256) [0.4 s]
INFO:root:Epoch 25    loss=0.2093 [11.5 s]    dev=(HR@5:0.4433,NDCG@5:0.3261) [0.4 s]
INFO:root:Epoch 26    loss=0.2095 [11.4 s]    dev=(HR@5:0.4432,NDCG@5:0.3276) [0.4 s] *
INFO:root:Epoch 27    loss=0.2102 [11.4 s]    dev=(HR@5:0.4454,NDCG@5:0.3291) [0.4 s] *
INFO:root:Epoch 28    loss=0.2095 [11.5 s]    dev=(HR@5:0.4447,NDCG@5:0.3290) [0.4 s]
INFO:root:Epoch 29    loss=0.2078 [11.4 s]    dev=(HR@5:0.4447,NDCG@5:0.3289) [0.4 s]
INFO:root:Epoch 30    loss=0.2081 [11.0 s]    dev=(HR@5:0.4451,NDCG@5:0.3303) [0.4 s] *
INFO:root:Epoch 31    loss=0.2057 [11.3 s]    dev=(HR@5:0.4464,NDCG@5:0.3323) [0.4 s] *
INFO:root:Epoch 32    loss=0.2071 [11.3 s]    dev=(HR@5:0.4457,NDCG@5:0.3290) [0.4 s]
INFO:root:Epoch 33    loss=0.2069 [11.6 s]    dev=(HR@5:0.4446,NDCG@5:0.3304) [0.4 s]
INFO:root:Epoch 34    loss=0.2065 [11.3 s]    dev=(HR@5:0.4441,NDCG@5:0.3297) [0.4 s]
INFO:root:Epoch 35    loss=0.2061 [11.3 s]    dev=(HR@5:0.4401,NDCG@5:0.3274) [0.4 s]
INFO:root:Epoch 36    loss=0.2045 [11.2 s]    dev=(HR@5:0.4433,NDCG@5:0.3271) [0.4 s]
INFO:root:Epoch 37    loss=0.2051 [11.3 s]    dev=(HR@5:0.4460,NDCG@5:0.3298) [0.4 s]
INFO:root:Epoch 38    loss=0.2053 [11.2 s]    dev=(HR@5:0.4434,NDCG@5:0.3280) [0.4 s]
INFO:root:Epoch 39    loss=0.2053 [11.1 s]    dev=(HR@5:0.4403,NDCG@5:0.3255) [0.4 s]
INFO:root:Epoch 40    loss=0.2048 [10.8 s]    dev=(HR@5:0.4423,NDCG@5:0.3262) [0.4 s]
INFO:root:Epoch 41    loss=0.2046 [10.8 s]    dev=(HR@5:0.4445,NDCG@5:0.3269) [0.4 s]
INFO:root:Epoch 42    loss=0.2048 [11.5 s]    dev=(HR@5:0.4463,NDCG@5:0.3275) [0.4 s]
INFO:root:Epoch 43    loss=0.2031 [10.7 s]    dev=(HR@5:0.4494,NDCG@5:0.3309) [0.4 s]
INFO:root:Epoch 44    loss=0.2048 [11.0 s]    dev=(HR@5:0.4450,NDCG@5:0.3280) [0.4 s]
INFO:root:Epoch 45    loss=0.2024 [11.5 s]    dev=(HR@5:0.4477,NDCG@5:0.3317) [0.4 s]
INFO:root:Epoch 46    loss=0.2033 [11.1 s]    dev=(HR@5:0.4454,NDCG@5:0.3295) [0.4 s]
INFO:root:Epoch 47    loss=0.2033 [11.0 s]    dev=(HR@5:0.4451,NDCG@5:0.3263) [0.4 s]
INFO:root:Epoch 48    loss=0.2028 [11.4 s]    dev=(HR@5:0.4447,NDCG@5:0.3279) [0.4 s]
INFO:root:Epoch 49    loss=0.2010 [10.0 s]    dev=(HR@5:0.4504,NDCG@5:0.3308) [0.4 s]
INFO:root:Epoch 50    loss=0.2031 [11.7 s]    dev=(HR@5:0.4454,NDCG@5:0.3267) [0.4 s]
INFO:root:Epoch 51    loss=0.2015 [11.5 s]    dev=(HR@5:0.4452,NDCG@5:0.3291) [0.4 s]
INFO:root:Early stop at 51 based on dev result.
INFO:root:
Best Iter(dev)=   31	 dev=(HR@5:0.4464,NDCG@5:0.3323) [595.4 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.3999,NDCG@5:0.2885,HR@10:0.5059,NDCG@10:0.3229,HR@20:0.6248,NDCG@20:0.3528,HR@50:0.8332,NDCG@50:0.3941)
INFO:root:
--------------------------------------------- END: 2024-12-23 11:35:46 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 12:01:38 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 4                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5147 [12.6 s]    dev=(HR@5:0.2588,NDCG@5:0.1734) [0.4 s] *
INFO:root:Epoch 2     loss=0.4244 [11.3 s]    dev=(HR@5:0.3323,NDCG@5:0.2257) [0.4 s] *
INFO:root:Epoch 3     loss=0.3870 [11.4 s]    dev=(HR@5:0.3618,NDCG@5:0.2472) [0.4 s] *
INFO:root:Epoch 4     loss=0.3602 [11.3 s]    dev=(HR@5:0.3908,NDCG@5:0.2724) [0.4 s] *
INFO:root:Epoch 5     loss=0.3323 [11.4 s]    dev=(HR@5:0.4052,NDCG@5:0.2886) [0.4 s] *
INFO:root:Epoch 6     loss=0.3072 [11.2 s]    dev=(HR@5:0.4201,NDCG@5:0.3017) [0.4 s] *
INFO:root:Epoch 7     loss=0.2903 [11.2 s]    dev=(HR@5:0.4263,NDCG@5:0.3057) [0.5 s] *
INFO:root:Epoch 8     loss=0.2760 [11.2 s]    dev=(HR@5:0.4307,NDCG@5:0.3116) [0.4 s] *
INFO:root:Epoch 9     loss=0.2631 [11.6 s]    dev=(HR@5:0.4361,NDCG@5:0.3162) [0.4 s] *
INFO:root:Epoch 10    loss=0.2544 [11.4 s]    dev=(HR@5:0.4390,NDCG@5:0.3194) [0.4 s] *
INFO:root:Epoch 11    loss=0.2447 [11.3 s]    dev=(HR@5:0.4403,NDCG@5:0.3208) [0.4 s] *
INFO:root:Epoch 12    loss=0.2360 [11.3 s]    dev=(HR@5:0.4466,NDCG@5:0.3264) [0.4 s] *
INFO:root:Epoch 13    loss=0.2319 [11.3 s]    dev=(HR@5:0.4486,NDCG@5:0.3301) [0.4 s] *
INFO:root:Epoch 14    loss=0.2271 [11.2 s]    dev=(HR@5:0.4479,NDCG@5:0.3282) [0.4 s]
INFO:root:Epoch 15    loss=0.2226 [11.4 s]    dev=(HR@5:0.4487,NDCG@5:0.3284) [0.4 s]
INFO:root:Epoch 16    loss=0.2194 [11.3 s]    dev=(HR@5:0.4474,NDCG@5:0.3303) [0.4 s] *
INFO:root:Epoch 17    loss=0.2156 [11.4 s]    dev=(HR@5:0.4500,NDCG@5:0.3323) [0.4 s] *
INFO:root:Epoch 18    loss=0.2106 [11.5 s]    dev=(HR@5:0.4547,NDCG@5:0.3346) [0.4 s] *
INFO:root:Epoch 19    loss=0.2095 [11.3 s]    dev=(HR@5:0.4530,NDCG@5:0.3340) [0.4 s]
INFO:root:Epoch 20    loss=0.2064 [11.0 s]    dev=(HR@5:0.4536,NDCG@5:0.3360) [0.4 s] *
INFO:root:Epoch 21    loss=0.2027 [11.5 s]    dev=(HR@5:0.4511,NDCG@5:0.3345) [0.4 s]
INFO:root:Epoch 22    loss=0.2018 [11.5 s]    dev=(HR@5:0.4536,NDCG@5:0.3363) [0.4 s] *
INFO:root:Epoch 23    loss=0.2028 [11.5 s]    dev=(HR@5:0.4520,NDCG@5:0.3352) [0.4 s]
INFO:root:Epoch 24    loss=0.2009 [11.6 s]    dev=(HR@5:0.4560,NDCG@5:0.3368) [0.4 s] *
INFO:root:Epoch 25    loss=0.1977 [11.4 s]    dev=(HR@5:0.4534,NDCG@5:0.3352) [0.4 s]
INFO:root:Epoch 26    loss=0.1981 [11.0 s]    dev=(HR@5:0.4523,NDCG@5:0.3357) [0.4 s]
INFO:root:Epoch 27    loss=0.1978 [11.2 s]    dev=(HR@5:0.4547,NDCG@5:0.3377) [0.3 s] *
INFO:root:Epoch 28    loss=0.1979 [11.2 s]    dev=(HR@5:0.4547,NDCG@5:0.3386) [0.4 s] *
INFO:root:Epoch 29    loss=0.1957 [11.1 s]    dev=(HR@5:0.4529,NDCG@5:0.3375) [0.4 s]
INFO:root:Epoch 30    loss=0.1960 [11.3 s]    dev=(HR@5:0.4558,NDCG@5:0.3384) [0.4 s]
INFO:root:Epoch 31    loss=0.1932 [11.1 s]    dev=(HR@5:0.4563,NDCG@5:0.3402) [0.4 s] *
INFO:root:Epoch 32    loss=0.1944 [11.1 s]    dev=(HR@5:0.4565,NDCG@5:0.3379) [0.4 s]
INFO:root:Epoch 33    loss=0.1944 [11.6 s]    dev=(HR@5:0.4566,NDCG@5:0.3392) [0.4 s]
INFO:root:Epoch 34    loss=0.1935 [11.2 s]    dev=(HR@5:0.4549,NDCG@5:0.3384) [0.4 s]
INFO:root:Epoch 35    loss=0.1938 [11.1 s]    dev=(HR@5:0.4554,NDCG@5:0.3385) [0.4 s]
INFO:root:Epoch 36    loss=0.1918 [11.2 s]    dev=(HR@5:0.4552,NDCG@5:0.3364) [0.4 s]
INFO:root:Epoch 37    loss=0.1922 [11.5 s]    dev=(HR@5:0.4563,NDCG@5:0.3376) [0.4 s]
INFO:root:Epoch 38    loss=0.1927 [10.8 s]    dev=(HR@5:0.4575,NDCG@5:0.3372) [0.4 s]
INFO:root:Epoch 39    loss=0.1926 [11.3 s]    dev=(HR@5:0.4524,NDCG@5:0.3348) [0.4 s]
INFO:root:Epoch 40    loss=0.1925 [11.4 s]    dev=(HR@5:0.4549,NDCG@5:0.3359) [0.4 s]
INFO:root:Epoch 41    loss=0.1928 [11.3 s]    dev=(HR@5:0.4564,NDCG@5:0.3375) [0.4 s]
INFO:root:Epoch 42    loss=0.1921 [11.7 s]    dev=(HR@5:0.4569,NDCG@5:0.3363) [0.4 s]
INFO:root:Epoch 43    loss=0.1908 [11.2 s]    dev=(HR@5:0.4567,NDCG@5:0.3382) [0.4 s]
INFO:root:Epoch 44    loss=0.1916 [11.2 s]    dev=(HR@5:0.4566,NDCG@5:0.3377) [0.4 s]
INFO:root:Epoch 45    loss=0.1893 [11.4 s]    dev=(HR@5:0.4585,NDCG@5:0.3413) [0.4 s] *
INFO:root:Epoch 46    loss=0.1907 [10.4 s]    dev=(HR@5:0.4577,NDCG@5:0.3393) [0.4 s]
INFO:root:Epoch 47    loss=0.1911 [11.2 s]    dev=(HR@5:0.4555,NDCG@5:0.3366) [0.4 s]
INFO:root:Epoch 48    loss=0.1897 [11.4 s]    dev=(HR@5:0.4575,NDCG@5:0.3377) [0.4 s]
INFO:root:Epoch 49    loss=0.1890 [11.3 s]    dev=(HR@5:0.4599,NDCG@5:0.3397) [0.4 s]
INFO:root:Epoch 50    loss=0.1914 [11.2 s]    dev=(HR@5:0.4546,NDCG@5:0.3375) [0.4 s]
INFO:root:Epoch 51    loss=0.1888 [10.1 s]    dev=(HR@5:0.4574,NDCG@5:0.3389) [0.4 s]
INFO:root:Epoch 52    loss=0.1892 [10.4 s]    dev=(HR@5:0.4533,NDCG@5:0.3362) [0.4 s]
INFO:root:Epoch 53    loss=0.1897 [10.8 s]    dev=(HR@5:0.4520,NDCG@5:0.3339) [0.4 s]
INFO:root:Epoch 54    loss=0.1875 [11.6 s]    dev=(HR@5:0.4577,NDCG@5:0.3373) [0.4 s]
INFO:root:Epoch 55    loss=0.1885 [11.4 s]    dev=(HR@5:0.4551,NDCG@5:0.3376) [0.4 s]
INFO:root:Epoch 56    loss=0.1884 [11.1 s]    dev=(HR@5:0.4603,NDCG@5:0.3399) [0.4 s]
INFO:root:Epoch 57    loss=0.1891 [11.4 s]    dev=(HR@5:0.4552,NDCG@5:0.3367) [0.4 s]
INFO:root:Epoch 58    loss=0.1902 [11.3 s]    dev=(HR@5:0.4560,NDCG@5:0.3393) [0.4 s]
INFO:root:Epoch 59    loss=0.1891 [11.3 s]    dev=(HR@5:0.4552,NDCG@5:0.3362) [0.4 s]
INFO:root:Epoch 60    loss=0.1897 [11.1 s]    dev=(HR@5:0.4566,NDCG@5:0.3374) [0.4 s]
INFO:root:Epoch 61    loss=0.1895 [11.3 s]    dev=(HR@5:0.4582,NDCG@5:0.3389) [0.4 s]
INFO:root:Epoch 62    loss=0.1886 [11.2 s]    dev=(HR@5:0.4588,NDCG@5:0.3384) [0.4 s]
INFO:root:Epoch 63    loss=0.1900 [11.5 s]    dev=(HR@5:0.4571,NDCG@5:0.3384) [0.4 s]
INFO:root:Epoch 64    loss=0.1879 [11.3 s]    dev=(HR@5:0.4554,NDCG@5:0.3367) [0.4 s]
INFO:root:Epoch 65    loss=0.1885 [11.1 s]    dev=(HR@5:0.4530,NDCG@5:0.3365) [0.4 s]
INFO:root:Early stop at 65 based on dev result.
INFO:root:
Best Iter(dev)=   45	 dev=(HR@5:0.4585,NDCG@5:0.3413) [757.4 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=4.pt
INFO:root:
Test After Training: (HR@5:0.4096,NDCG@5:0.2967,HR@10:0.5197,NDCG@10:0.3322,HR@20:0.6401,NDCG@20:0.3626,HR@50:0.8369,NDCG@50:0.4016)
INFO:root:
--------------------------------------------- END: 2024-12-23 12:14:18 ---------------------------------------------
