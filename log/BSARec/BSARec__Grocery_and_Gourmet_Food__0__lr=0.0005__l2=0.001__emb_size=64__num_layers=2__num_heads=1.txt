INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-04 16:55:26 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [26.2 s]    dev=(HR@5:0.2511,NDCG@5:0.1667) [0.9 s] *
INFO:root:Epoch 2     loss=0.4334 [19.4 s]    dev=(HR@5:0.3201,NDCG@5:0.2170) [0.9 s] *
INFO:root:Epoch 3     loss=0.4007 [19.4 s]    dev=(HR@5:0.3385,NDCG@5:0.2283) [0.9 s] *
INFO:root:Epoch 4     loss=0.3841 [19.4 s]    dev=(HR@5:0.3564,NDCG@5:0.2460) [0.9 s] *
INFO:root:Epoch 5     loss=0.3612 [19.9 s]    dev=(HR@5:0.3734,NDCG@5:0.2584) [0.9 s] *
INFO:root:Epoch 6     loss=0.3363 [19.7 s]    dev=(HR@5:0.3898,NDCG@5:0.2759) [0.9 s] *
INFO:root:Epoch 7     loss=0.3173 [20.0 s]    dev=(HR@5:0.3952,NDCG@5:0.2806) [0.9 s] *
INFO:root:Epoch 8     loss=0.2986 [20.7 s]    dev=(HR@5:0.4058,NDCG@5:0.2902) [0.9 s] *
INFO:root:Epoch 9     loss=0.2825 [19.9 s]    dev=(HR@5:0.4088,NDCG@5:0.2940) [0.9 s] *
INFO:root:Epoch 10    loss=0.2716 [19.9 s]    dev=(HR@5:0.4126,NDCG@5:0.2986) [1.0 s] *
INFO:root:Epoch 11    loss=0.2598 [20.6 s]    dev=(HR@5:0.4184,NDCG@5:0.3023) [0.9 s] *
INFO:root:Early stop manually
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-04 17:01:17 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [22.6 s]    dev=(HR@5:0.2511,NDCG@5:0.1667) [0.9 s] *
INFO:root:Epoch 2     loss=0.4334 [54.5 s]    dev=(HR@5:0.3201,NDCG@5:0.2170) [0.8 s] *
INFO:root:Epoch 3     loss=0.4007 [18.9 s]    dev=(HR@5:0.3385,NDCG@5:0.2283) [0.9 s] *
INFO:root:Epoch 4     loss=0.3841 [18.9 s]    dev=(HR@5:0.3564,NDCG@5:0.2460) [0.8 s] *
INFO:root:Epoch 5     loss=0.3612 [18.8 s]    dev=(HR@5:0.3734,NDCG@5:0.2584) [0.8 s] *
INFO:root:Epoch 6     loss=0.3363 [18.8 s]    dev=(HR@5:0.3898,NDCG@5:0.2759) [0.8 s] *
INFO:root:Epoch 7     loss=0.3173 [18.9 s]    dev=(HR@5:0.3952,NDCG@5:0.2806) [0.8 s] *
INFO:root:Epoch 8     loss=0.2986 [18.8 s]    dev=(HR@5:0.4058,NDCG@5:0.2902) [0.9 s] *
INFO:root:Epoch 9     loss=0.2825 [18.7 s]    dev=(HR@5:0.4088,NDCG@5:0.2940) [0.8 s] *
INFO:root:Epoch 10    loss=0.2716 [18.7 s]    dev=(HR@5:0.4126,NDCG@5:0.2986) [0.8 s] *
INFO:root:Epoch 11    loss=0.2598 [18.8 s]    dev=(HR@5:0.4184,NDCG@5:0.3023) [0.8 s] *
INFO:root:Epoch 12    loss=0.2516 [18.8 s]    dev=(HR@5:0.4210,NDCG@5:0.3067) [0.8 s] *
INFO:root:Epoch 13    loss=0.2471 [18.8 s]    dev=(HR@5:0.4259,NDCG@5:0.3103) [0.9 s] *
INFO:root:Epoch 14    loss=0.2402 [18.8 s]    dev=(HR@5:0.4265,NDCG@5:0.3096) [0.8 s]
INFO:root:Epoch 15    loss=0.2367 [18.8 s]    dev=(HR@5:0.4271,NDCG@5:0.3090) [0.8 s]
INFO:root:Epoch 16    loss=0.2320 [19.0 s]    dev=(HR@5:0.4252,NDCG@5:0.3116) [0.8 s] *
INFO:root:Epoch 17    loss=0.2288 [18.8 s]    dev=(HR@5:0.4242,NDCG@5:0.3109) [0.8 s]
INFO:root:Epoch 18    loss=0.2244 [18.8 s]    dev=(HR@5:0.4284,NDCG@5:0.3139) [0.8 s] *
INFO:root:Epoch 19    loss=0.2215 [18.7 s]    dev=(HR@5:0.4305,NDCG@5:0.3172) [0.9 s] *
INFO:root:Epoch 20    loss=0.2196 [18.7 s]    dev=(HR@5:0.4330,NDCG@5:0.3193) [0.8 s] *
INFO:root:Epoch 21    loss=0.2149 [18.8 s]    dev=(HR@5:0.4359,NDCG@5:0.3204) [0.8 s] *
INFO:root:Epoch 22    loss=0.2133 [18.8 s]    dev=(HR@5:0.4312,NDCG@5:0.3171) [0.8 s]
INFO:root:Epoch 23    loss=0.2133 [18.7 s]    dev=(HR@5:0.4314,NDCG@5:0.3178) [0.8 s]
INFO:root:Epoch 24    loss=0.2123 [18.7 s]    dev=(HR@5:0.4327,NDCG@5:0.3191) [0.8 s]
INFO:root:Epoch 25    loss=0.2098 [18.7 s]    dev=(HR@5:0.4347,NDCG@5:0.3201) [0.8 s]
INFO:root:Epoch 26    loss=0.2098 [18.7 s]    dev=(HR@5:0.4351,NDCG@5:0.3217) [0.8 s] *
INFO:root:Epoch 27    loss=0.2082 [18.7 s]    dev=(HR@5:0.4364,NDCG@5:0.3234) [0.8 s] *
INFO:root:Epoch 28    loss=0.2073 [18.7 s]    dev=(HR@5:0.4393,NDCG@5:0.3246) [0.8 s] *
INFO:root:Epoch 29    loss=0.2059 [18.7 s]    dev=(HR@5:0.4347,NDCG@5:0.3215) [0.8 s]
INFO:root:Epoch 30    loss=0.2055 [18.7 s]    dev=(HR@5:0.4336,NDCG@5:0.3206) [0.8 s]
INFO:root:Epoch 31    loss=0.2031 [18.8 s]    dev=(HR@5:0.4366,NDCG@5:0.3226) [0.8 s]
INFO:root:Epoch 32    loss=0.2043 [18.7 s]    dev=(HR@5:0.4314,NDCG@5:0.3195) [0.8 s]
INFO:root:Epoch 33    loss=0.2033 [18.7 s]    dev=(HR@5:0.4391,NDCG@5:0.3243) [0.9 s]
INFO:root:Epoch 34    loss=0.2020 [18.7 s]    dev=(HR@5:0.4377,NDCG@5:0.3223) [0.8 s]
INFO:root:Epoch 35    loss=0.2037 [18.7 s]    dev=(HR@5:0.4360,NDCG@5:0.3228) [0.8 s]
INFO:root:Epoch 36    loss=0.2000 [18.8 s]    dev=(HR@5:0.4390,NDCG@5:0.3250) [0.8 s] *
INFO:root:Epoch 37    loss=0.2024 [18.7 s]    dev=(HR@5:0.4415,NDCG@5:0.3262) [0.8 s] *
INFO:root:Epoch 38    loss=0.2016 [18.7 s]    dev=(HR@5:0.4387,NDCG@5:0.3241) [0.8 s]
INFO:root:Epoch 39    loss=0.2014 [18.7 s]    dev=(HR@5:0.4368,NDCG@5:0.3231) [0.8 s]
INFO:root:Epoch 40    loss=0.2002 [18.8 s]    dev=(HR@5:0.4343,NDCG@5:0.3213) [0.8 s]
INFO:root:Epoch 41    loss=0.2006 [18.8 s]    dev=(HR@5:0.4327,NDCG@5:0.3200) [0.8 s]
INFO:root:Epoch 42    loss=0.2011 [18.7 s]    dev=(HR@5:0.4380,NDCG@5:0.3230) [0.8 s]
INFO:root:Epoch 43    loss=0.2001 [46.6 s]    dev=(HR@5:0.4430,NDCG@5:0.3280) [0.9 s] *
INFO:root:Epoch 44    loss=0.2012 [19.0 s]    dev=(HR@5:0.4385,NDCG@5:0.3234) [0.8 s]
INFO:root:Epoch 45    loss=0.1977 [18.7 s]    dev=(HR@5:0.4425,NDCG@5:0.3294) [0.8 s] *
INFO:root:Epoch 46    loss=0.1994 [18.7 s]    dev=(HR@5:0.4402,NDCG@5:0.3255) [0.8 s]
INFO:root:Epoch 47    loss=0.2010 [18.7 s]    dev=(HR@5:0.4414,NDCG@5:0.3263) [0.9 s]
INFO:root:Epoch 48    loss=0.1986 [18.7 s]    dev=(HR@5:0.4362,NDCG@5:0.3222) [0.8 s]
INFO:root:Epoch 49    loss=0.1979 [18.7 s]    dev=(HR@5:0.4400,NDCG@5:0.3255) [0.9 s]
INFO:root:Epoch 50    loss=0.1993 [18.7 s]    dev=(HR@5:0.4368,NDCG@5:0.3239) [0.8 s]
INFO:root:Epoch 51    loss=0.1977 [18.8 s]    dev=(HR@5:0.4369,NDCG@5:0.3250) [0.8 s]
INFO:root:Epoch 52    loss=0.1984 [18.7 s]    dev=(HR@5:0.4376,NDCG@5:0.3226) [0.9 s]
INFO:root:Epoch 53    loss=0.1982 [18.8 s]    dev=(HR@5:0.4395,NDCG@5:0.3241) [0.8 s]
INFO:root:Epoch 54    loss=0.1956 [18.7 s]    dev=(HR@5:0.4430,NDCG@5:0.3256) [0.8 s]
INFO:root:Epoch 55    loss=0.1959 [18.7 s]    dev=(HR@5:0.4402,NDCG@5:0.3245) [0.8 s]
INFO:root:Epoch 56    loss=0.1963 [18.7 s]    dev=(HR@5:0.4372,NDCG@5:0.3239) [0.9 s]
INFO:root:Epoch 57    loss=0.1960 [18.7 s]    dev=(HR@5:0.4421,NDCG@5:0.3284) [0.8 s]
INFO:root:Epoch 58    loss=0.1974 [18.7 s]    dev=(HR@5:0.4393,NDCG@5:0.3250) [0.8 s]
INFO:root:Epoch 59    loss=0.1959 [18.7 s]    dev=(HR@5:0.4385,NDCG@5:0.3252) [0.9 s]
INFO:root:Epoch 60    loss=0.1969 [18.8 s]    dev=(HR@5:0.4381,NDCG@5:0.3258) [0.8 s]
INFO:root:Epoch 61    loss=0.1964 [18.7 s]    dev=(HR@5:0.4390,NDCG@5:0.3265) [0.8 s]
INFO:root:Epoch 62    loss=0.1955 [18.7 s]    dev=(HR@5:0.4398,NDCG@5:0.3258) [0.8 s]
INFO:root:Epoch 63    loss=0.1966 [18.8 s]    dev=(HR@5:0.4413,NDCG@5:0.3277) [0.8 s]
INFO:root:Epoch 64    loss=0.1948 [18.7 s]    dev=(HR@5:0.4389,NDCG@5:0.3229) [0.8 s]
INFO:root:Epoch 65    loss=0.1958 [18.7 s]    dev=(HR@5:0.4384,NDCG@5:0.3240) [0.8 s]
INFO:root:Early stop at 65 based on dev result.
INFO:root:
Best Iter(dev)=   45	 dev=(HR@5:0.4425,NDCG@5:0.3294) [1341.9 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.3910,NDCG@5:0.2805,HR@10:0.4955,NDCG@10:0.3143,HR@20:0.6136,NDCG@20:0.3440,HR@50:0.8195,NDCG@50:0.3848)
INFO:root:
--------------------------------------------- END: 2024-12-04 17:23:41 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-05 19:36:52 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [25.1 s]    dev=(HR@5:0.2511,NDCG@5:0.1667) [0.9 s] *
INFO:root:Epoch 2     loss=0.4334 [19.5 s]    dev=(HR@5:0.3201,NDCG@5:0.2170) [0.8 s] *
INFO:root:Epoch 3     loss=0.4007 [19.1 s]    dev=(HR@5:0.3385,NDCG@5:0.2283) [0.9 s] *
INFO:root:Epoch 4     loss=0.3841 [19.2 s]    dev=(HR@5:0.3564,NDCG@5:0.2460) [0.8 s] *
INFO:root:Epoch 5     loss=0.3612 [19.4 s]    dev=(HR@5:0.3734,NDCG@5:0.2584) [0.8 s] *
INFO:root:Epoch 6     loss=0.3363 [20.2 s]    dev=(HR@5:0.3898,NDCG@5:0.2759) [0.9 s] *
INFO:root:Epoch 7     loss=0.3173 [19.9 s]    dev=(HR@5:0.3952,NDCG@5:0.2806) [0.9 s] *
INFO:root:Epoch 8     loss=0.2986 [20.3 s]    dev=(HR@5:0.4058,NDCG@5:0.2902) [0.8 s] *
INFO:root:Epoch 9     loss=0.2825 [19.3 s]    dev=(HR@5:0.4088,NDCG@5:0.2940) [0.8 s] *
INFO:root:Epoch 10    loss=0.2716 [19.5 s]    dev=(HR@5:0.4126,NDCG@5:0.2986) [0.8 s] *
INFO:root:Epoch 11    loss=0.2598 [19.5 s]    dev=(HR@5:0.4184,NDCG@5:0.3023) [0.9 s] *
INFO:root:Epoch 12    loss=0.2516 [20.0 s]    dev=(HR@5:0.4210,NDCG@5:0.3067) [0.9 s] *
INFO:root:Epoch 13    loss=0.2471 [19.4 s]    dev=(HR@5:0.4259,NDCG@5:0.3103) [0.8 s] *
INFO:root:Epoch 14    loss=0.2402 [19.2 s]    dev=(HR@5:0.4265,NDCG@5:0.3096) [0.9 s]
INFO:root:Epoch 15    loss=0.2367 [19.1 s]    dev=(HR@5:0.4271,NDCG@5:0.3090) [0.8 s]
INFO:root:Epoch 16    loss=0.2320 [19.0 s]    dev=(HR@5:0.4252,NDCG@5:0.3116) [0.8 s] *
INFO:root:Epoch 17    loss=0.2288 [19.1 s]    dev=(HR@5:0.4242,NDCG@5:0.3109) [0.8 s]
INFO:root:Epoch 18    loss=0.2244 [19.3 s]    dev=(HR@5:0.4284,NDCG@5:0.3139) [0.9 s] *
INFO:root:Epoch 19    loss=0.2215 [19.3 s]    dev=(HR@5:0.4305,NDCG@5:0.3172) [0.9 s] *
INFO:root:Epoch 20    loss=0.2196 [19.3 s]    dev=(HR@5:0.4330,NDCG@5:0.3193) [0.9 s] *
INFO:root:Epoch 21    loss=0.2149 [19.3 s]    dev=(HR@5:0.4359,NDCG@5:0.3204) [0.8 s] *
INFO:root:Epoch 22    loss=0.2133 [19.2 s]    dev=(HR@5:0.4312,NDCG@5:0.3171) [0.8 s]
INFO:root:Epoch 23    loss=0.2133 [19.3 s]    dev=(HR@5:0.4314,NDCG@5:0.3178) [0.9 s]
INFO:root:Epoch 24    loss=0.2123 [19.9 s]    dev=(HR@5:0.4327,NDCG@5:0.3191) [0.9 s]
INFO:root:Epoch 25    loss=0.2098 [20.0 s]    dev=(HR@5:0.4347,NDCG@5:0.3201) [0.9 s]
INFO:root:Epoch 26    loss=0.2098 [20.3 s]    dev=(HR@5:0.4351,NDCG@5:0.3217) [0.8 s] *
INFO:root:Epoch 27    loss=0.2082 [20.3 s]    dev=(HR@5:0.4364,NDCG@5:0.3234) [0.9 s] *
INFO:root:Epoch 28    loss=0.2073 [20.3 s]    dev=(HR@5:0.4393,NDCG@5:0.3246) [0.9 s] *
INFO:root:Epoch 29    loss=0.2059 [20.1 s]    dev=(HR@5:0.4347,NDCG@5:0.3215) [0.9 s]
INFO:root:Epoch 30    loss=0.2055 [19.9 s]    dev=(HR@5:0.4336,NDCG@5:0.3206) [0.9 s]
INFO:root:Epoch 31    loss=0.2031 [19.4 s]    dev=(HR@5:0.4366,NDCG@5:0.3226) [0.9 s]
INFO:root:Epoch 32    loss=0.2043 [19.5 s]    dev=(HR@5:0.4314,NDCG@5:0.3195) [0.9 s]
INFO:root:Epoch 33    loss=0.2033 [19.8 s]    dev=(HR@5:0.4391,NDCG@5:0.3243) [0.8 s]
INFO:root:Epoch 34    loss=0.2020 [19.4 s]    dev=(HR@5:0.4377,NDCG@5:0.3223) [0.9 s]
INFO:root:Epoch 35    loss=0.2037 [19.2 s]    dev=(HR@5:0.4360,NDCG@5:0.3228) [0.8 s]
INFO:root:Epoch 36    loss=0.2000 [19.3 s]    dev=(HR@5:0.4390,NDCG@5:0.3250) [0.8 s] *
INFO:root:Epoch 37    loss=0.2024 [19.3 s]    dev=(HR@5:0.4415,NDCG@5:0.3262) [0.8 s] *
INFO:root:Epoch 38    loss=0.2016 [19.1 s]    dev=(HR@5:0.4387,NDCG@5:0.3241) [0.9 s]
INFO:root:Epoch 39    loss=0.2014 [19.1 s]    dev=(HR@5:0.4368,NDCG@5:0.3231) [0.8 s]
INFO:root:Epoch 40    loss=0.2002 [19.3 s]    dev=(HR@5:0.4343,NDCG@5:0.3213) [0.8 s]
INFO:root:Epoch 41    loss=0.2006 [19.4 s]    dev=(HR@5:0.4327,NDCG@5:0.3200) [0.8 s]
INFO:root:Epoch 42    loss=0.2011 [19.0 s]    dev=(HR@5:0.4380,NDCG@5:0.3230) [0.8 s]
INFO:root:Epoch 43    loss=0.2001 [19.1 s]    dev=(HR@5:0.4430,NDCG@5:0.3280) [0.8 s] *
INFO:root:Epoch 44    loss=0.2012 [19.6 s]    dev=(HR@5:0.4385,NDCG@5:0.3234) [0.9 s]
INFO:root:Epoch 45    loss=0.1977 [19.1 s]    dev=(HR@5:0.4425,NDCG@5:0.3294) [0.8 s] *
INFO:root:Epoch 46    loss=0.1994 [19.0 s]    dev=(HR@5:0.4402,NDCG@5:0.3255) [0.8 s]
INFO:root:Epoch 47    loss=0.2010 [19.1 s]    dev=(HR@5:0.4414,NDCG@5:0.3263) [0.8 s]
INFO:root:Epoch 48    loss=0.1986 [19.1 s]    dev=(HR@5:0.4362,NDCG@5:0.3222) [0.8 s]
INFO:root:Epoch 49    loss=0.1979 [19.0 s]    dev=(HR@5:0.4400,NDCG@5:0.3255) [0.8 s]
INFO:root:Epoch 50    loss=0.1993 [19.0 s]    dev=(HR@5:0.4368,NDCG@5:0.3239) [0.8 s]
INFO:root:Epoch 51    loss=0.1977 [19.0 s]    dev=(HR@5:0.4369,NDCG@5:0.3250) [0.8 s]
INFO:root:Epoch 52    loss=0.1984 [18.9 s]    dev=(HR@5:0.4376,NDCG@5:0.3226) [0.8 s]
INFO:root:Epoch 53    loss=0.1982 [19.0 s]    dev=(HR@5:0.4395,NDCG@5:0.3241) [0.8 s]
INFO:root:Epoch 54    loss=0.1956 [19.1 s]    dev=(HR@5:0.4430,NDCG@5:0.3256) [0.8 s]
INFO:root:Epoch 55    loss=0.1959 [19.2 s]    dev=(HR@5:0.4402,NDCG@5:0.3245) [0.8 s]
INFO:root:Epoch 56    loss=0.1963 [19.0 s]    dev=(HR@5:0.4372,NDCG@5:0.3239) [0.8 s]
INFO:root:Epoch 57    loss=0.1960 [19.0 s]    dev=(HR@5:0.4421,NDCG@5:0.3284) [0.8 s]
INFO:root:Epoch 58    loss=0.1974 [19.7 s]    dev=(HR@5:0.4393,NDCG@5:0.3250) [0.9 s]
INFO:root:Epoch 59    loss=0.1959 [19.2 s]    dev=(HR@5:0.4385,NDCG@5:0.3252) [0.8 s]
INFO:root:Epoch 60    loss=0.1969 [19.1 s]    dev=(HR@5:0.4381,NDCG@5:0.3258) [0.8 s]
INFO:root:Epoch 61    loss=0.1964 [19.1 s]    dev=(HR@5:0.4390,NDCG@5:0.3265) [0.8 s]
INFO:root:Epoch 62    loss=0.1955 [19.1 s]    dev=(HR@5:0.4398,NDCG@5:0.3258) [0.8 s]
INFO:root:Epoch 63    loss=0.1966 [19.2 s]    dev=(HR@5:0.4413,NDCG@5:0.3277) [0.8 s]
INFO:root:Epoch 64    loss=0.1948 [19.1 s]    dev=(HR@5:0.4389,NDCG@5:0.3229) [0.8 s]
INFO:root:Epoch 65    loss=0.1958 [19.0 s]    dev=(HR@5:0.4384,NDCG@5:0.3240) [0.8 s]
INFO:root:Early stop at 65 based on dev result.
INFO:root:
Best Iter(dev)=   45	 dev=(HR@5:0.4425,NDCG@5:0.3294) [1320.2 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.3910,NDCG@5:0.2805,HR@10:0.4955,NDCG@10:0.3143,HR@20:0.6136,NDCG@20:0.3440,HR@50:0.8195,NDCG@50:0.3848)
INFO:root:
--------------------------------------------- END: 2024-12-05 19:58:55 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-05 20:59:22 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [35.5 s]    dev=(HR@5:0.2513,NDCG@5:0.1669) [1.3 s] *
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-05 22:05:06 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [21.8 s]    dev=(HR@5:0.2514,NDCG@5:0.1670) [0.9 s] *
INFO:root:Epoch 2     loss=0.4329 [19.9 s]    dev=(HR@5:0.3214,NDCG@5:0.2178) [0.9 s] *
INFO:root:Epoch 3     loss=0.4004 [19.7 s]    dev=(HR@5:0.3394,NDCG@5:0.2286) [0.9 s] *
INFO:root:Epoch 4     loss=0.3860 [19.7 s]    dev=(HR@5:0.3502,NDCG@5:0.2396) [0.9 s] *
INFO:root:Epoch 5     loss=0.3663 [19.8 s]    dev=(HR@5:0.3646,NDCG@5:0.2514) [0.9 s] *
INFO:root:Epoch 6     loss=0.3443 [19.6 s]    dev=(HR@5:0.3819,NDCG@5:0.2690) [0.9 s] *
INFO:root:Epoch 7     loss=0.3272 [19.8 s]    dev=(HR@5:0.3835,NDCG@5:0.2712) [0.9 s] *
INFO:root:Epoch 8     loss=0.3118 [19.7 s]    dev=(HR@5:0.3926,NDCG@5:0.2792) [0.9 s] *
INFO:root:Epoch 9     loss=0.2964 [19.8 s]    dev=(HR@5:0.3992,NDCG@5:0.2852) [0.9 s] *
INFO:root:Epoch 10    loss=0.2861 [19.7 s]    dev=(HR@5:0.4041,NDCG@5:0.2902) [0.9 s] *
INFO:root:Epoch 11    loss=0.2744 [19.7 s]    dev=(HR@5:0.4111,NDCG@5:0.2944) [0.9 s] *
INFO:root:Epoch 12    loss=0.2655 [19.7 s]    dev=(HR@5:0.4139,NDCG@5:0.2976) [0.9 s] *
INFO:root:Epoch 13    loss=0.2603 [19.8 s]    dev=(HR@5:0.4219,NDCG@5:0.3051) [0.9 s] *
INFO:root:Epoch 14    loss=0.2545 [19.7 s]    dev=(HR@5:0.4175,NDCG@5:0.3004) [0.9 s]
INFO:root:Epoch 15    loss=0.2506 [19.8 s]    dev=(HR@5:0.4186,NDCG@5:0.3026) [0.9 s]
INFO:root:Epoch 16    loss=0.2472 [19.7 s]    dev=(HR@5:0.4196,NDCG@5:0.3044) [0.9 s]
INFO:root:Epoch 17    loss=0.2437 [19.8 s]    dev=(HR@5:0.4210,NDCG@5:0.3036) [0.9 s]
INFO:root:Epoch 18    loss=0.2393 [19.7 s]    dev=(HR@5:0.4230,NDCG@5:0.3070) [0.9 s] *
INFO:root:Epoch 19    loss=0.2361 [19.8 s]    dev=(HR@5:0.4229,NDCG@5:0.3090) [0.9 s] *
INFO:root:Epoch 20    loss=0.2340 [19.8 s]    dev=(HR@5:0.4274,NDCG@5:0.3123) [0.9 s] *
INFO:root:Epoch 21    loss=0.2296 [19.8 s]    dev=(HR@5:0.4269,NDCG@5:0.3100) [0.9 s]
INFO:root:Epoch 22    loss=0.2287 [19.8 s]    dev=(HR@5:0.4262,NDCG@5:0.3102) [0.9 s]
INFO:root:Epoch 23    loss=0.2276 [19.8 s]    dev=(HR@5:0.4224,NDCG@5:0.3089) [0.9 s]
INFO:root:Epoch 24    loss=0.2273 [19.8 s]    dev=(HR@5:0.4275,NDCG@5:0.3116) [0.9 s]
INFO:root:Epoch 25    loss=0.2243 [19.8 s]    dev=(HR@5:0.4206,NDCG@5:0.3077) [0.9 s]
INFO:root:Epoch 26    loss=0.2233 [19.8 s]    dev=(HR@5:0.4249,NDCG@5:0.3100) [0.9 s]
INFO:root:Epoch 27    loss=0.2224 [19.7 s]    dev=(HR@5:0.4284,NDCG@5:0.3128) [0.9 s] *
INFO:root:Epoch 28    loss=0.2212 [19.9 s]    dev=(HR@5:0.4300,NDCG@5:0.3151) [0.9 s] *
INFO:root:Epoch 29    loss=0.2194 [19.9 s]    dev=(HR@5:0.4248,NDCG@5:0.3099) [0.9 s]
INFO:root:Epoch 30    loss=0.2185 [19.7 s]    dev=(HR@5:0.4255,NDCG@5:0.3104) [0.9 s]
INFO:root:Epoch 31    loss=0.2168 [19.7 s]    dev=(HR@5:0.4267,NDCG@5:0.3129) [0.9 s]
INFO:root:Epoch 32    loss=0.2177 [19.7 s]    dev=(HR@5:0.4265,NDCG@5:0.3111) [0.9 s]
INFO:root:Epoch 33    loss=0.2168 [19.7 s]    dev=(HR@5:0.4297,NDCG@5:0.3144) [0.9 s]
INFO:root:Epoch 34    loss=0.2151 [19.8 s]    dev=(HR@5:0.4281,NDCG@5:0.3122) [0.9 s]
INFO:root:Epoch 35    loss=0.2161 [19.7 s]    dev=(HR@5:0.4244,NDCG@5:0.3083) [0.9 s]
INFO:root:Epoch 36    loss=0.2126 [19.8 s]    dev=(HR@5:0.4273,NDCG@5:0.3117) [0.9 s]
INFO:root:Epoch 37    loss=0.2128 [19.7 s]    dev=(HR@5:0.4295,NDCG@5:0.3130) [0.9 s]
INFO:root:Epoch 38    loss=0.2136 [19.8 s]    dev=(HR@5:0.4313,NDCG@5:0.3134) [0.9 s]
INFO:root:Epoch 39    loss=0.2118 [19.6 s]    dev=(HR@5:0.4231,NDCG@5:0.3073) [0.9 s]
INFO:root:Epoch 40    loss=0.2119 [19.7 s]    dev=(HR@5:0.4273,NDCG@5:0.3124) [0.9 s]
INFO:root:Epoch 41    loss=0.2119 [19.7 s]    dev=(HR@5:0.4282,NDCG@5:0.3118) [0.9 s]
INFO:root:Epoch 42    loss=0.2108 [19.8 s]    dev=(HR@5:0.4304,NDCG@5:0.3127) [0.9 s]
INFO:root:Epoch 43    loss=0.2097 [19.9 s]    dev=(HR@5:0.4325,NDCG@5:0.3177) [0.9 s] *
INFO:root:Epoch 44    loss=0.2106 [19.9 s]    dev=(HR@5:0.4304,NDCG@5:0.3147) [0.9 s]
INFO:root:Epoch 45    loss=0.2063 [19.8 s]    dev=(HR@5:0.4322,NDCG@5:0.3163) [0.9 s]
INFO:root:Epoch 46    loss=0.2079 [19.8 s]    dev=(HR@5:0.4285,NDCG@5:0.3127) [0.9 s]
INFO:root:Epoch 47    loss=0.2077 [19.7 s]    dev=(HR@5:0.4325,NDCG@5:0.3155) [0.9 s]
INFO:root:Epoch 48    loss=0.2063 [19.7 s]    dev=(HR@5:0.4257,NDCG@5:0.3091) [0.9 s]
INFO:root:Epoch 49    loss=0.2053 [19.6 s]    dev=(HR@5:0.4300,NDCG@5:0.3152) [0.9 s]
INFO:root:Epoch 50    loss=0.2073 [19.8 s]    dev=(HR@5:0.4273,NDCG@5:0.3140) [0.9 s]
INFO:root:Epoch 51    loss=0.2054 [19.7 s]    dev=(HR@5:0.4336,NDCG@5:0.3174) [0.9 s]
INFO:root:Epoch 52    loss=0.2047 [19.7 s]    dev=(HR@5:0.4296,NDCG@5:0.3132) [0.9 s]
INFO:root:Epoch 53    loss=0.2036 [19.7 s]    dev=(HR@5:0.4327,NDCG@5:0.3156) [0.9 s]
INFO:root:Epoch 54    loss=0.2018 [19.7 s]    dev=(HR@5:0.4305,NDCG@5:0.3143) [0.9 s]
INFO:root:Epoch 55    loss=0.2030 [19.8 s]    dev=(HR@5:0.4304,NDCG@5:0.3123) [0.9 s]
INFO:root:Epoch 56    loss=0.2022 [19.7 s]    dev=(HR@5:0.4304,NDCG@5:0.3154) [0.9 s]
INFO:root:Epoch 57    loss=0.2019 [19.7 s]    dev=(HR@5:0.4301,NDCG@5:0.3144) [0.9 s]
INFO:root:Epoch 58    loss=0.2037 [19.7 s]    dev=(HR@5:0.4325,NDCG@5:0.3160) [0.9 s]
INFO:root:Epoch 59    loss=0.2014 [19.6 s]    dev=(HR@5:0.4307,NDCG@5:0.3153) [0.9 s]
INFO:root:Epoch 60    loss=0.2024 [19.9 s]    dev=(HR@5:0.4302,NDCG@5:0.3136) [0.9 s]
INFO:root:Epoch 61    loss=0.2020 [19.7 s]    dev=(HR@5:0.4351,NDCG@5:0.3176) [0.9 s]
INFO:root:Epoch 62    loss=0.2004 [19.7 s]    dev=(HR@5:0.4394,NDCG@5:0.3207) [0.9 s] *
INFO:root:Epoch 63    loss=0.2026 [19.8 s]    dev=(HR@5:0.4315,NDCG@5:0.3163) [0.9 s]
INFO:root:Epoch 64    loss=0.2001 [19.7 s]    dev=(HR@5:0.4335,NDCG@5:0.3165) [0.9 s]
INFO:root:Epoch 65    loss=0.2009 [19.7 s]    dev=(HR@5:0.4341,NDCG@5:0.3175) [0.9 s]
INFO:root:Epoch 66    loss=0.1988 [19.7 s]    dev=(HR@5:0.4320,NDCG@5:0.3140) [0.9 s]
INFO:root:Epoch 67    loss=0.1998 [19.7 s]    dev=(HR@5:0.4316,NDCG@5:0.3145) [0.9 s]
INFO:root:Epoch 68    loss=0.1971 [19.7 s]    dev=(HR@5:0.4329,NDCG@5:0.3167) [0.9 s]
INFO:root:Epoch 69    loss=0.1990 [19.7 s]    dev=(HR@5:0.4334,NDCG@5:0.3182) [0.9 s]
INFO:root:Epoch 70    loss=0.1990 [19.7 s]    dev=(HR@5:0.4311,NDCG@5:0.3172) [0.9 s]
INFO:root:Epoch 71    loss=0.1983 [19.8 s]    dev=(HR@5:0.4353,NDCG@5:0.3200) [0.9 s]
INFO:root:Epoch 72    loss=0.1973 [19.7 s]    dev=(HR@5:0.4305,NDCG@5:0.3136) [0.9 s]
INFO:root:Epoch 73    loss=0.1983 [19.8 s]    dev=(HR@5:0.4359,NDCG@5:0.3191) [0.9 s]
INFO:root:Epoch 74    loss=0.1986 [19.7 s]    dev=(HR@5:0.4322,NDCG@5:0.3161) [0.9 s]
INFO:root:Epoch 75    loss=0.2003 [19.8 s]    dev=(HR@5:0.4316,NDCG@5:0.3151) [0.9 s]
INFO:root:Epoch 76    loss=0.1990 [19.8 s]    dev=(HR@5:0.4363,NDCG@5:0.3190) [0.9 s]
INFO:root:Epoch 77    loss=0.1979 [19.8 s]    dev=(HR@5:0.4327,NDCG@5:0.3157) [0.9 s]
INFO:root:Epoch 78    loss=0.1980 [19.7 s]    dev=(HR@5:0.4342,NDCG@5:0.3168) [0.9 s]
INFO:root:Epoch 79    loss=0.1992 [19.7 s]    dev=(HR@5:0.4378,NDCG@5:0.3190) [0.9 s]
INFO:root:Epoch 80    loss=0.1957 [19.8 s]    dev=(HR@5:0.4320,NDCG@5:0.3169) [0.9 s]
INFO:root:Epoch 81    loss=0.1974 [19.7 s]    dev=(HR@5:0.4301,NDCG@5:0.3116) [0.9 s]
INFO:root:Epoch 82    loss=0.1988 [19.8 s]    dev=(HR@5:0.4348,NDCG@5:0.3174) [0.9 s]
INFO:root:Early stop at 82 based on dev result.
INFO:root:
Best Iter(dev)=   62	 dev=(HR@5:0.4394,NDCG@5:0.3207) [1692.9 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.3857,NDCG@5:0.2736,HR@10:0.4965,NDCG@10:0.3095,HR@20:0.6201,NDCG@20:0.3406,HR@50:0.8342,NDCG@50:0.3829)
INFO:root:
--------------------------------------------- END: 2024-12-05 22:33:20 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-05 23:39:17 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [23.2 s]    dev=(HR@5:0.2515,NDCG@5:0.1671) [0.9 s] *
INFO:root:Epoch 2     loss=0.4329 [20.2 s]    dev=(HR@5:0.3216,NDCG@5:0.2179) [0.9 s] *
INFO:root:Epoch 3     loss=0.4004 [20.5 s]    dev=(HR@5:0.3390,NDCG@5:0.2287) [0.9 s] *
INFO:root:Epoch 4     loss=0.3861 [20.2 s]    dev=(HR@5:0.3505,NDCG@5:0.2392) [0.9 s] *
INFO:root:Epoch 5     loss=0.3678 [20.1 s]    dev=(HR@5:0.3618,NDCG@5:0.2492) [0.9 s] *
INFO:root:Epoch 6     loss=0.3461 [19.7 s]    dev=(HR@5:0.3775,NDCG@5:0.2660) [0.9 s] *
INFO:root:Epoch 7     loss=0.3286 [19.7 s]    dev=(HR@5:0.3839,NDCG@5:0.2704) [0.9 s] *
INFO:root:Epoch 8     loss=0.3129 [20.0 s]    dev=(HR@5:0.3928,NDCG@5:0.2784) [0.9 s] *
INFO:root:Epoch 9     loss=0.2975 [20.0 s]    dev=(HR@5:0.3967,NDCG@5:0.2828) [1.0 s] *
INFO:root:Epoch 10    loss=0.2869 [20.1 s]    dev=(HR@5:0.4025,NDCG@5:0.2889) [0.9 s] *
INFO:root:Epoch 11    loss=0.2750 [20.1 s]    dev=(HR@5:0.4105,NDCG@5:0.2931) [1.1 s] *
INFO:root:Epoch 12    loss=0.2660 [19.3 s]    dev=(HR@5:0.4131,NDCG@5:0.2969) [0.9 s] *
INFO:root:Epoch 13    loss=0.2608 [19.7 s]    dev=(HR@5:0.4207,NDCG@5:0.3040) [0.9 s] *
INFO:root:Epoch 14    loss=0.2550 [20.4 s]    dev=(HR@5:0.4169,NDCG@5:0.2999) [0.9 s]
INFO:root:Epoch 15    loss=0.2511 [20.0 s]    dev=(HR@5:0.4191,NDCG@5:0.3022) [0.9 s]
INFO:root:Epoch 16    loss=0.2478 [20.0 s]    dev=(HR@5:0.4201,NDCG@5:0.3043) [0.9 s] *
INFO:root:Epoch 17    loss=0.2442 [19.9 s]    dev=(HR@5:0.4195,NDCG@5:0.3026) [0.9 s]
INFO:root:Epoch 18    loss=0.2396 [19.9 s]    dev=(HR@5:0.4238,NDCG@5:0.3073) [0.8 s] *
INFO:root:Epoch 19    loss=0.2366 [19.5 s]    dev=(HR@5:0.4227,NDCG@5:0.3092) [0.9 s] *
INFO:root:Epoch 20    loss=0.2345 [19.6 s]    dev=(HR@5:0.4267,NDCG@5:0.3120) [0.9 s] *
INFO:root:Epoch 21    loss=0.2302 [19.6 s]    dev=(HR@5:0.4287,NDCG@5:0.3110) [0.9 s]
INFO:root:Epoch 22    loss=0.2292 [19.3 s]    dev=(HR@5:0.4267,NDCG@5:0.3105) [0.9 s]
INFO:root:Epoch 23    loss=0.2281 [19.3 s]    dev=(HR@5:0.4230,NDCG@5:0.3092) [0.9 s]
INFO:root:Epoch 24    loss=0.2278 [19.7 s]    dev=(HR@5:0.4280,NDCG@5:0.3112) [0.9 s]
INFO:root:Epoch 25    loss=0.2246 [19.3 s]    dev=(HR@5:0.4201,NDCG@5:0.3073) [0.9 s]
INFO:root:Epoch 26    loss=0.2235 [19.4 s]    dev=(HR@5:0.4257,NDCG@5:0.3102) [0.9 s]
INFO:root:Epoch 27    loss=0.2227 [19.3 s]    dev=(HR@5:0.4276,NDCG@5:0.3127) [0.9 s] *
INFO:root:Epoch 28    loss=0.2215 [19.3 s]    dev=(HR@5:0.4298,NDCG@5:0.3153) [0.8 s] *
INFO:root:Epoch 29    loss=0.2197 [19.1 s]    dev=(HR@5:0.4235,NDCG@5:0.3090) [0.9 s]
INFO:root:Epoch 30    loss=0.2185 [19.3 s]    dev=(HR@5:0.4262,NDCG@5:0.3115) [0.9 s]
INFO:root:Epoch 31    loss=0.2168 [20.0 s]    dev=(HR@5:0.4272,NDCG@5:0.3135) [0.9 s]
INFO:root:Epoch 32    loss=0.2177 [19.7 s]    dev=(HR@5:0.4271,NDCG@5:0.3117) [0.9 s]
INFO:root:Epoch 33    loss=0.2164 [20.4 s]    dev=(HR@5:0.4301,NDCG@5:0.3142) [0.9 s]
INFO:root:Epoch 34    loss=0.2147 [20.0 s]    dev=(HR@5:0.4295,NDCG@5:0.3136) [0.9 s]
INFO:root:Epoch 35    loss=0.2155 [19.8 s]    dev=(HR@5:0.4255,NDCG@5:0.3079) [0.9 s]
INFO:root:Epoch 36    loss=0.2126 [20.5 s]    dev=(HR@5:0.4283,NDCG@5:0.3130) [0.9 s]
INFO:root:Epoch 37    loss=0.2122 [19.9 s]    dev=(HR@5:0.4329,NDCG@5:0.3154) [0.9 s] *
INFO:root:Epoch 38    loss=0.2133 [19.9 s]    dev=(HR@5:0.4316,NDCG@5:0.3139) [0.9 s]
INFO:root:Epoch 39    loss=0.2115 [19.8 s]    dev=(HR@5:0.4260,NDCG@5:0.3089) [0.9 s]
INFO:root:Epoch 40    loss=0.2111 [19.8 s]    dev=(HR@5:0.4286,NDCG@5:0.3132) [0.9 s]
INFO:root:Epoch 41    loss=0.2117 [20.1 s]    dev=(HR@5:0.4284,NDCG@5:0.3126) [0.8 s]
INFO:root:Epoch 42    loss=0.2103 [19.9 s]    dev=(HR@5:0.4323,NDCG@5:0.3148) [0.9 s]
INFO:root:Epoch 43    loss=0.2094 [19.7 s]    dev=(HR@5:0.4353,NDCG@5:0.3195) [0.9 s] *
INFO:root:Epoch 44    loss=0.2105 [19.8 s]    dev=(HR@5:0.4330,NDCG@5:0.3158) [0.9 s]
INFO:root:Epoch 45    loss=0.2062 [19.9 s]    dev=(HR@5:0.4348,NDCG@5:0.3178) [0.9 s]
INFO:root:Epoch 46    loss=0.2077 [19.9 s]    dev=(HR@5:0.4294,NDCG@5:0.3129) [0.9 s]
INFO:root:Epoch 47    loss=0.2075 [19.6 s]    dev=(HR@5:0.4328,NDCG@5:0.3160) [0.8 s]
INFO:root:Epoch 48    loss=0.2060 [19.6 s]    dev=(HR@5:0.4264,NDCG@5:0.3098) [0.9 s]
INFO:root:Epoch 49    loss=0.2049 [19.6 s]    dev=(HR@5:0.4321,NDCG@5:0.3160) [0.8 s]
INFO:root:Epoch 50    loss=0.2068 [19.7 s]    dev=(HR@5:0.4279,NDCG@5:0.3139) [0.9 s]
INFO:root:Epoch 51    loss=0.2052 [19.8 s]    dev=(HR@5:0.4339,NDCG@5:0.3183) [0.9 s]
INFO:root:Epoch 52    loss=0.2040 [20.1 s]    dev=(HR@5:0.4280,NDCG@5:0.3135) [0.9 s]
INFO:root:Epoch 53    loss=0.2042 [19.5 s]    dev=(HR@5:0.4330,NDCG@5:0.3167) [0.9 s]
INFO:root:Epoch 54    loss=0.2015 [19.5 s]    dev=(HR@5:0.4327,NDCG@5:0.3155) [0.9 s]
INFO:root:Epoch 55    loss=0.2027 [19.6 s]    dev=(HR@5:0.4296,NDCG@5:0.3141) [0.9 s]
INFO:root:Epoch 56    loss=0.2020 [19.6 s]    dev=(HR@5:0.4313,NDCG@5:0.3167) [0.9 s]
INFO:root:Epoch 57    loss=0.2023 [19.5 s]    dev=(HR@5:0.4315,NDCG@5:0.3160) [0.9 s]
INFO:root:Epoch 58    loss=0.2039 [19.9 s]    dev=(HR@5:0.4338,NDCG@5:0.3172) [0.9 s]
INFO:root:Epoch 59    loss=0.2014 [19.6 s]    dev=(HR@5:0.4310,NDCG@5:0.3167) [0.9 s]
INFO:root:Epoch 60    loss=0.2020 [19.7 s]    dev=(HR@5:0.4291,NDCG@5:0.3149) [0.9 s]
INFO:root:Epoch 61    loss=0.2018 [20.0 s]    dev=(HR@5:0.4351,NDCG@5:0.3178) [0.9 s]
INFO:root:Epoch 62    loss=0.2004 [19.9 s]    dev=(HR@5:0.4375,NDCG@5:0.3213) [0.9 s] *
INFO:root:Epoch 63    loss=0.2029 [20.6 s]    dev=(HR@5:0.4331,NDCG@5:0.3173) [0.9 s]
INFO:root:Epoch 64    loss=0.2000 [20.9 s]    dev=(HR@5:0.4368,NDCG@5:0.3193) [1.0 s]
INFO:root:Epoch 65    loss=0.2009 [20.0 s]    dev=(HR@5:0.4351,NDCG@5:0.3179) [1.5 s]
INFO:root:Epoch 66    loss=0.1982 [20.1 s]    dev=(HR@5:0.4350,NDCG@5:0.3160) [0.9 s]
INFO:root:Epoch 67    loss=0.1999 [19.8 s]    dev=(HR@5:0.4311,NDCG@5:0.3131) [0.9 s]
INFO:root:Epoch 68    loss=0.1971 [20.2 s]    dev=(HR@5:0.4328,NDCG@5:0.3173) [0.9 s]
INFO:root:Epoch 69    loss=0.1987 [20.3 s]    dev=(HR@5:0.4316,NDCG@5:0.3161) [0.9 s]
INFO:root:Epoch 70    loss=0.1985 [20.2 s]    dev=(HR@5:0.4339,NDCG@5:0.3165) [0.9 s]
INFO:root:Epoch 71    loss=0.1985 [19.4 s]    dev=(HR@5:0.4333,NDCG@5:0.3179) [0.8 s]
INFO:root:Epoch 72    loss=0.1977 [19.7 s]    dev=(HR@5:0.4306,NDCG@5:0.3133) [0.9 s]
INFO:root:Epoch 73    loss=0.1990 [19.6 s]    dev=(HR@5:0.4354,NDCG@5:0.3190) [0.9 s]
INFO:root:Epoch 74    loss=0.1991 [20.2 s]    dev=(HR@5:0.4316,NDCG@5:0.3142) [0.9 s]
INFO:root:Epoch 75    loss=0.2002 [20.3 s]    dev=(HR@5:0.4314,NDCG@5:0.3165) [0.9 s]
INFO:root:Epoch 76    loss=0.1989 [21.1 s]    dev=(HR@5:0.4295,NDCG@5:0.3158) [1.0 s]
INFO:root:Epoch 77    loss=0.1981 [21.6 s]    dev=(HR@5:0.4316,NDCG@5:0.3151) [0.9 s]
INFO:root:Epoch 78    loss=0.1976 [21.5 s]    dev=(HR@5:0.4330,NDCG@5:0.3162) [0.9 s]
INFO:root:Epoch 79    loss=0.1988 [20.4 s]    dev=(HR@5:0.4326,NDCG@5:0.3159) [0.9 s]
INFO:root:Epoch 80    loss=0.1959 [20.4 s]    dev=(HR@5:0.4321,NDCG@5:0.3163) [0.9 s]
INFO:root:Epoch 81    loss=0.1976 [19.7 s]    dev=(HR@5:0.4298,NDCG@5:0.3141) [0.9 s]
INFO:root:Epoch 82    loss=0.1988 [19.7 s]    dev=(HR@5:0.4299,NDCG@5:0.3155) [0.9 s]
INFO:root:Early stop at 82 based on dev result.
INFO:root:
Best Iter(dev)=   62	 dev=(HR@5:0.4375,NDCG@5:0.3213) [1709.5 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.3900,NDCG@5:0.2770,HR@10:0.4983,NDCG@10:0.3122,HR@20:0.6233,NDCG@20:0.3436,HR@50:0.8343,NDCG@50:0.3854)
INFO:root:
--------------------------------------------- END: 2024-12-06 00:07:49 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 01:12:03 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5165 [21.4 s]    dev=(HR@5:0.2516,NDCG@5:0.1671) [0.9 s] *
INFO:root:Epoch 2     loss=0.4329 [19.4 s]    dev=(HR@5:0.3210,NDCG@5:0.2176) [0.8 s] *
INFO:root:Epoch 3     loss=0.4004 [19.4 s]    dev=(HR@5:0.3394,NDCG@5:0.2289) [0.9 s] *
INFO:root:Epoch 4     loss=0.3860 [19.4 s]    dev=(HR@5:0.3506,NDCG@5:0.2395) [0.9 s] *
INFO:root:Epoch 5     loss=0.3677 [19.3 s]    dev=(HR@5:0.3624,NDCG@5:0.2495) [0.9 s] *
INFO:root:Epoch 6     loss=0.3463 [19.3 s]    dev=(HR@5:0.3777,NDCG@5:0.2662) [0.9 s] *
INFO:root:Epoch 7     loss=0.3284 [19.3 s]    dev=(HR@5:0.3834,NDCG@5:0.2698) [0.8 s] *
INFO:root:Epoch 8     loss=0.3130 [19.3 s]    dev=(HR@5:0.3923,NDCG@5:0.2784) [0.9 s] *
INFO:root:Epoch 9     loss=0.2973 [19.4 s]    dev=(HR@5:0.3963,NDCG@5:0.2829) [0.9 s] *
INFO:root:Epoch 10    loss=0.2871 [19.3 s]    dev=(HR@5:0.4022,NDCG@5:0.2878) [0.9 s] *
INFO:root:Epoch 11    loss=0.2751 [19.4 s]    dev=(HR@5:0.4087,NDCG@5:0.2917) [0.9 s] *
INFO:root:Epoch 12    loss=0.2661 [19.3 s]    dev=(HR@5:0.4137,NDCG@5:0.2969) [0.9 s] *
INFO:root:Epoch 13    loss=0.2609 [19.3 s]    dev=(HR@5:0.4198,NDCG@5:0.3033) [0.9 s] *
INFO:root:Epoch 14    loss=0.2552 [19.3 s]    dev=(HR@5:0.4179,NDCG@5:0.3002) [0.9 s]
INFO:root:Epoch 15    loss=0.2513 [19.4 s]    dev=(HR@5:0.4186,NDCG@5:0.3020) [0.9 s]
INFO:root:Epoch 16    loss=0.2483 [19.4 s]    dev=(HR@5:0.4220,NDCG@5:0.3051) [0.9 s] *
INFO:root:Epoch 17    loss=0.2446 [19.3 s]    dev=(HR@5:0.4201,NDCG@5:0.3029) [0.9 s]
INFO:root:Epoch 18    loss=0.2400 [19.4 s]    dev=(HR@5:0.4242,NDCG@5:0.3082) [0.9 s] *
INFO:root:Epoch 19    loss=0.2368 [19.4 s]    dev=(HR@5:0.4215,NDCG@5:0.3088) [0.9 s] *
INFO:root:Epoch 20    loss=0.2346 [19.4 s]    dev=(HR@5:0.4274,NDCG@5:0.3120) [0.9 s] *
INFO:root:Epoch 21    loss=0.2302 [19.8 s]    dev=(HR@5:0.4292,NDCG@5:0.3118) [0.9 s]
INFO:root:Epoch 22    loss=0.2292 [19.4 s]    dev=(HR@5:0.4269,NDCG@5:0.3107) [0.9 s]
INFO:root:Epoch 23    loss=0.2279 [19.4 s]    dev=(HR@5:0.4221,NDCG@5:0.3087) [0.9 s]
INFO:root:Epoch 24    loss=0.2275 [19.4 s]    dev=(HR@5:0.4280,NDCG@5:0.3115) [0.9 s]
INFO:root:Epoch 25    loss=0.2246 [19.4 s]    dev=(HR@5:0.4225,NDCG@5:0.3088) [0.9 s]
INFO:root:Epoch 26    loss=0.2233 [19.3 s]    dev=(HR@5:0.4261,NDCG@5:0.3109) [0.8 s]
INFO:root:Epoch 27    loss=0.2225 [19.4 s]    dev=(HR@5:0.4276,NDCG@5:0.3130) [0.9 s] *
INFO:root:Epoch 28    loss=0.2214 [19.4 s]    dev=(HR@5:0.4290,NDCG@5:0.3150) [0.9 s] *
INFO:root:Epoch 29    loss=0.2198 [19.5 s]    dev=(HR@5:0.4242,NDCG@5:0.3094) [0.9 s]
INFO:root:Epoch 30    loss=0.2187 [19.5 s]    dev=(HR@5:0.4266,NDCG@5:0.3114) [0.9 s]
INFO:root:Epoch 31    loss=0.2168 [19.5 s]    dev=(HR@5:0.4273,NDCG@5:0.3144) [0.9 s]
INFO:root:Epoch 32    loss=0.2180 [19.4 s]    dev=(HR@5:0.4276,NDCG@5:0.3124) [0.9 s]
INFO:root:Epoch 33    loss=0.2167 [19.5 s]    dev=(HR@5:0.4276,NDCG@5:0.3139) [0.9 s]
INFO:root:Epoch 34    loss=0.2151 [19.4 s]    dev=(HR@5:0.4304,NDCG@5:0.3138) [0.9 s]
INFO:root:Epoch 35    loss=0.2163 [19.4 s]    dev=(HR@5:0.4272,NDCG@5:0.3091) [0.9 s]
INFO:root:Epoch 36    loss=0.2131 [19.4 s]    dev=(HR@5:0.4284,NDCG@5:0.3135) [0.8 s]
INFO:root:Epoch 37    loss=0.2131 [19.5 s]    dev=(HR@5:0.4310,NDCG@5:0.3148) [0.9 s]
INFO:root:Epoch 38    loss=0.2140 [19.4 s]    dev=(HR@5:0.4330,NDCG@5:0.3143) [0.9 s]
INFO:root:Epoch 39    loss=0.2124 [19.8 s]    dev=(HR@5:0.4232,NDCG@5:0.3085) [0.9 s]
INFO:root:Epoch 40    loss=0.2124 [19.7 s]    dev=(HR@5:0.4293,NDCG@5:0.3138) [0.9 s]
INFO:root:Epoch 41    loss=0.2125 [20.0 s]    dev=(HR@5:0.4299,NDCG@5:0.3134) [0.9 s]
INFO:root:Epoch 42    loss=0.2116 [19.8 s]    dev=(HR@5:0.4328,NDCG@5:0.3155) [0.9 s] *
INFO:root:Epoch 43    loss=0.2105 [19.8 s]    dev=(HR@5:0.4344,NDCG@5:0.3190) [0.9 s] *
INFO:root:Epoch 44    loss=0.2113 [20.2 s]    dev=(HR@5:0.4306,NDCG@5:0.3150) [0.9 s]
INFO:root:Epoch 45    loss=0.2074 [19.8 s]    dev=(HR@5:0.4345,NDCG@5:0.3176) [0.9 s]
INFO:root:Epoch 46    loss=0.2087 [19.4 s]    dev=(HR@5:0.4279,NDCG@5:0.3134) [0.9 s]
INFO:root:Epoch 47    loss=0.2089 [19.3 s]    dev=(HR@5:0.4329,NDCG@5:0.3169) [0.9 s]
INFO:root:Epoch 48    loss=0.2071 [19.3 s]    dev=(HR@5:0.4255,NDCG@5:0.3097) [0.9 s]
INFO:root:Epoch 49    loss=0.2064 [19.4 s]    dev=(HR@5:0.4312,NDCG@5:0.3157) [0.9 s]
INFO:root:Epoch 50    loss=0.2080 [19.2 s]    dev=(HR@5:0.4282,NDCG@5:0.3131) [0.9 s]
INFO:root:Epoch 51    loss=0.2066 [19.3 s]    dev=(HR@5:0.4338,NDCG@5:0.3191) [0.8 s] *
INFO:root:Epoch 52    loss=0.2057 [19.4 s]    dev=(HR@5:0.4272,NDCG@5:0.3124) [0.8 s]
INFO:root:Epoch 53    loss=0.2048 [19.4 s]    dev=(HR@5:0.4344,NDCG@5:0.3176) [0.9 s]
INFO:root:Epoch 54    loss=0.2028 [19.3 s]    dev=(HR@5:0.4354,NDCG@5:0.3170) [0.9 s]
INFO:root:Epoch 55    loss=0.2039 [19.4 s]    dev=(HR@5:0.4339,NDCG@5:0.3163) [0.9 s]
INFO:root:Epoch 56    loss=0.2025 [19.2 s]    dev=(HR@5:0.4333,NDCG@5:0.3170) [0.9 s]
INFO:root:Epoch 57    loss=0.2036 [19.3 s]    dev=(HR@5:0.4337,NDCG@5:0.3174) [0.9 s]
INFO:root:Epoch 58    loss=0.2042 [19.4 s]    dev=(HR@5:0.4347,NDCG@5:0.3176) [0.9 s]
INFO:root:Epoch 59    loss=0.2025 [19.3 s]    dev=(HR@5:0.4338,NDCG@5:0.3175) [0.9 s]
INFO:root:Epoch 60    loss=0.2034 [19.4 s]    dev=(HR@5:0.4320,NDCG@5:0.3156) [0.9 s]
INFO:root:Epoch 61    loss=0.2024 [19.4 s]    dev=(HR@5:0.4350,NDCG@5:0.3189) [0.9 s]
INFO:root:Epoch 62    loss=0.2009 [19.4 s]    dev=(HR@5:0.4391,NDCG@5:0.3215) [0.9 s] *
INFO:root:Epoch 63    loss=0.2037 [19.4 s]    dev=(HR@5:0.4326,NDCG@5:0.3169) [0.8 s]
INFO:root:Epoch 64    loss=0.2011 [19.3 s]    dev=(HR@5:0.4322,NDCG@5:0.3145) [0.9 s]
INFO:root:Epoch 65    loss=0.2014 [19.5 s]    dev=(HR@5:0.4315,NDCG@5:0.3166) [0.8 s]
INFO:root:Epoch 66    loss=0.1994 [19.3 s]    dev=(HR@5:0.4310,NDCG@5:0.3141) [0.9 s]
INFO:root:Epoch 67    loss=0.2013 [19.3 s]    dev=(HR@5:0.4371,NDCG@5:0.3182) [0.8 s]
INFO:root:Epoch 68    loss=0.1986 [19.3 s]    dev=(HR@5:0.4338,NDCG@5:0.3162) [0.8 s]
INFO:root:Epoch 69    loss=0.1995 [19.3 s]    dev=(HR@5:0.4351,NDCG@5:0.3197) [0.9 s]
INFO:root:Epoch 70    loss=0.1997 [19.4 s]    dev=(HR@5:0.4333,NDCG@5:0.3171) [0.9 s]
INFO:root:Epoch 71    loss=0.1995 [19.3 s]    dev=(HR@5:0.4344,NDCG@5:0.3194) [0.9 s]
INFO:root:Epoch 72    loss=0.1991 [19.4 s]    dev=(HR@5:0.4337,NDCG@5:0.3165) [0.9 s]
INFO:root:Epoch 73    loss=0.1996 [19.4 s]    dev=(HR@5:0.4324,NDCG@5:0.3181) [0.9 s]
INFO:root:Epoch 74    loss=0.1989 [19.4 s]    dev=(HR@5:0.4297,NDCG@5:0.3140) [0.9 s]
INFO:root:Epoch 75    loss=0.2005 [19.3 s]    dev=(HR@5:0.4333,NDCG@5:0.3170) [0.9 s]
INFO:root:Epoch 76    loss=0.1996 [19.3 s]    dev=(HR@5:0.4343,NDCG@5:0.3175) [0.8 s]
INFO:root:Epoch 77    loss=0.1988 [19.4 s]    dev=(HR@5:0.4329,NDCG@5:0.3173) [0.9 s]
INFO:root:Epoch 78    loss=0.1980 [19.4 s]    dev=(HR@5:0.4329,NDCG@5:0.3158) [0.9 s]
INFO:root:Epoch 79    loss=0.1992 [19.3 s]    dev=(HR@5:0.4343,NDCG@5:0.3169) [0.9 s]
INFO:root:Epoch 80    loss=0.1965 [19.3 s]    dev=(HR@5:0.4321,NDCG@5:0.3163) [0.9 s]
INFO:root:Epoch 81    loss=0.1979 [19.3 s]    dev=(HR@5:0.4336,NDCG@5:0.3154) [0.9 s]
INFO:root:Epoch 82    loss=0.1994 [19.3 s]    dev=(HR@5:0.4378,NDCG@5:0.3194) [0.9 s]
INFO:root:Early stop at 82 based on dev result.
INFO:root:
Best Iter(dev)=   62	 dev=(HR@5:0.4391,NDCG@5:0.3215) [1664.6 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.3915,NDCG@5:0.2799,HR@10:0.4998,NDCG@10:0.3150,HR@20:0.6207,NDCG@20:0.3454,HR@50:0.8351,NDCG@50:0.3879)
INFO:root:
--------------------------------------------- END: 2024-12-06 01:39:50 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 02:42:15 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [21.1 s]    dev=(HR@5:0.2507,NDCG@5:0.1665) [0.9 s] *
INFO:root:Epoch 2     loss=0.4333 [19.1 s]    dev=(HR@5:0.3202,NDCG@5:0.2167) [0.9 s] *
INFO:root:Epoch 3     loss=0.3985 [19.1 s]    dev=(HR@5:0.3434,NDCG@5:0.2315) [0.9 s] *
INFO:root:Epoch 4     loss=0.3785 [19.1 s]    dev=(HR@5:0.3643,NDCG@5:0.2511) [0.9 s] *
INFO:root:Epoch 5     loss=0.3546 [19.0 s]    dev=(HR@5:0.3777,NDCG@5:0.2629) [0.9 s] *
INFO:root:Epoch 6     loss=0.3304 [19.2 s]    dev=(HR@5:0.3903,NDCG@5:0.2766) [0.8 s] *
INFO:root:Epoch 7     loss=0.3110 [19.1 s]    dev=(HR@5:0.3970,NDCG@5:0.2830) [0.9 s] *
INFO:root:Epoch 8     loss=0.2938 [19.1 s]    dev=(HR@5:0.4049,NDCG@5:0.2887) [0.9 s] *
INFO:root:Epoch 9     loss=0.2793 [19.1 s]    dev=(HR@5:0.4068,NDCG@5:0.2930) [0.9 s] *
INFO:root:Epoch 10    loss=0.2691 [19.2 s]    dev=(HR@5:0.4077,NDCG@5:0.2944) [0.9 s] *
INFO:root:Epoch 11    loss=0.2592 [19.2 s]    dev=(HR@5:0.4175,NDCG@5:0.2998) [0.9 s] *
INFO:root:Epoch 12    loss=0.2509 [19.1 s]    dev=(HR@5:0.4156,NDCG@5:0.3010) [0.9 s] *
INFO:root:Epoch 13    loss=0.2475 [19.0 s]    dev=(HR@5:0.4197,NDCG@5:0.3044) [0.9 s] *
INFO:root:Epoch 14    loss=0.2413 [19.0 s]    dev=(HR@5:0.4199,NDCG@5:0.3049) [0.8 s] *
INFO:root:Epoch 15    loss=0.2392 [19.1 s]    dev=(HR@5:0.4184,NDCG@5:0.3038) [0.9 s]
INFO:root:Epoch 16    loss=0.2351 [19.2 s]    dev=(HR@5:0.4228,NDCG@5:0.3066) [0.9 s] *
INFO:root:Epoch 17    loss=0.2318 [19.2 s]    dev=(HR@5:0.4207,NDCG@5:0.3038) [0.9 s]
INFO:root:Epoch 18    loss=0.2279 [19.1 s]    dev=(HR@5:0.4238,NDCG@5:0.3085) [0.8 s] *
INFO:root:Epoch 19    loss=0.2253 [19.1 s]    dev=(HR@5:0.4223,NDCG@5:0.3082) [0.9 s]
INFO:root:Epoch 20    loss=0.2233 [19.2 s]    dev=(HR@5:0.4244,NDCG@5:0.3114) [0.9 s] *
INFO:root:Epoch 21    loss=0.2193 [19.1 s]    dev=(HR@5:0.4279,NDCG@5:0.3122) [0.8 s] *
INFO:root:Epoch 22    loss=0.2180 [19.2 s]    dev=(HR@5:0.4253,NDCG@5:0.3122) [0.8 s]
INFO:root:Epoch 23    loss=0.2179 [19.1 s]    dev=(HR@5:0.4227,NDCG@5:0.3111) [0.8 s]
INFO:root:Epoch 24    loss=0.2169 [19.2 s]    dev=(HR@5:0.4303,NDCG@5:0.3157) [0.8 s] *
INFO:root:Epoch 25    loss=0.2135 [19.1 s]    dev=(HR@5:0.4254,NDCG@5:0.3117) [0.8 s]
INFO:root:Epoch 26    loss=0.2142 [19.2 s]    dev=(HR@5:0.4314,NDCG@5:0.3160) [0.8 s] *
INFO:root:Epoch 27    loss=0.2133 [19.1 s]    dev=(HR@5:0.4314,NDCG@5:0.3168) [0.8 s] *
INFO:root:Epoch 28    loss=0.2134 [19.2 s]    dev=(HR@5:0.4365,NDCG@5:0.3210) [0.8 s] *
INFO:root:Epoch 29    loss=0.2102 [19.2 s]    dev=(HR@5:0.4312,NDCG@5:0.3166) [0.9 s]
INFO:root:Epoch 30    loss=0.2100 [19.1 s]    dev=(HR@5:0.4355,NDCG@5:0.3197) [0.8 s]
INFO:root:Epoch 31    loss=0.2079 [19.2 s]    dev=(HR@5:0.4393,NDCG@5:0.3222) [0.9 s] *
INFO:root:Epoch 32    loss=0.2087 [19.1 s]    dev=(HR@5:0.4306,NDCG@5:0.3158) [0.8 s]
INFO:root:Epoch 33    loss=0.2082 [19.2 s]    dev=(HR@5:0.4335,NDCG@5:0.3190) [0.9 s]
INFO:root:Epoch 34    loss=0.2073 [19.2 s]    dev=(HR@5:0.4350,NDCG@5:0.3201) [0.8 s]
INFO:root:Epoch 35    loss=0.2082 [19.1 s]    dev=(HR@5:0.4360,NDCG@5:0.3176) [0.9 s]
INFO:root:Epoch 36    loss=0.2062 [19.2 s]    dev=(HR@5:0.4377,NDCG@5:0.3206) [0.9 s]
INFO:root:Epoch 37    loss=0.2066 [19.1 s]    dev=(HR@5:0.4366,NDCG@5:0.3194) [0.8 s]
INFO:root:Epoch 38    loss=0.2062 [19.2 s]    dev=(HR@5:0.4393,NDCG@5:0.3209) [0.8 s]
INFO:root:Epoch 39    loss=0.2067 [19.1 s]    dev=(HR@5:0.4320,NDCG@5:0.3144) [0.9 s]
INFO:root:Epoch 40    loss=0.2052 [19.1 s]    dev=(HR@5:0.4348,NDCG@5:0.3180) [0.9 s]
INFO:root:Epoch 41    loss=0.2053 [19.2 s]    dev=(HR@5:0.4324,NDCG@5:0.3150) [0.9 s]
INFO:root:Epoch 42    loss=0.2055 [19.1 s]    dev=(HR@5:0.4383,NDCG@5:0.3194) [0.9 s]
INFO:root:Epoch 43    loss=0.2038 [19.2 s]    dev=(HR@5:0.4389,NDCG@5:0.3231) [0.8 s] *
INFO:root:Epoch 44    loss=0.2049 [19.0 s]    dev=(HR@5:0.4372,NDCG@5:0.3197) [0.8 s]
INFO:root:Epoch 45    loss=0.2005 [19.1 s]    dev=(HR@5:0.4395,NDCG@5:0.3234) [0.9 s] *
INFO:root:Epoch 46    loss=0.2019 [19.2 s]    dev=(HR@5:0.4355,NDCG@5:0.3187) [0.9 s]
INFO:root:Epoch 47    loss=0.2028 [19.1 s]    dev=(HR@5:0.4356,NDCG@5:0.3200) [0.8 s]
INFO:root:Epoch 48    loss=0.2008 [19.3 s]    dev=(HR@5:0.4296,NDCG@5:0.3143) [0.8 s]
INFO:root:Epoch 49    loss=0.1997 [19.1 s]    dev=(HR@5:0.4406,NDCG@5:0.3217) [0.8 s]
INFO:root:Epoch 50    loss=0.2015 [19.1 s]    dev=(HR@5:0.4348,NDCG@5:0.3193) [0.9 s]
INFO:root:Epoch 51    loss=0.1996 [19.1 s]    dev=(HR@5:0.4385,NDCG@5:0.3209) [0.8 s]
INFO:root:Epoch 52    loss=0.1996 [19.1 s]    dev=(HR@5:0.4391,NDCG@5:0.3203) [0.9 s]
INFO:root:Epoch 53    loss=0.1996 [19.2 s]    dev=(HR@5:0.4391,NDCG@5:0.3215) [0.8 s]
INFO:root:Epoch 54    loss=0.1964 [19.2 s]    dev=(HR@5:0.4419,NDCG@5:0.3244) [0.8 s] *
INFO:root:Epoch 55    loss=0.1969 [19.1 s]    dev=(HR@5:0.4395,NDCG@5:0.3212) [0.8 s]
INFO:root:Epoch 56    loss=0.1964 [19.1 s]    dev=(HR@5:0.4407,NDCG@5:0.3241) [0.9 s]
INFO:root:Epoch 57    loss=0.1973 [19.1 s]    dev=(HR@5:0.4381,NDCG@5:0.3218) [0.9 s]
INFO:root:Epoch 58    loss=0.1978 [19.1 s]    dev=(HR@5:0.4412,NDCG@5:0.3218) [0.9 s]
INFO:root:Epoch 59    loss=0.1959 [19.1 s]    dev=(HR@5:0.4389,NDCG@5:0.3224) [0.9 s]
INFO:root:Epoch 60    loss=0.1965 [19.1 s]    dev=(HR@5:0.4392,NDCG@5:0.3229) [0.9 s]
INFO:root:Epoch 61    loss=0.1964 [19.1 s]    dev=(HR@5:0.4462,NDCG@5:0.3259) [0.8 s] *
INFO:root:Epoch 62    loss=0.1958 [19.1 s]    dev=(HR@5:0.4451,NDCG@5:0.3261) [0.8 s] *
INFO:root:Epoch 63    loss=0.1962 [19.2 s]    dev=(HR@5:0.4434,NDCG@5:0.3239) [0.8 s]
INFO:root:Epoch 64    loss=0.1944 [19.0 s]    dev=(HR@5:0.4378,NDCG@5:0.3194) [0.9 s]
INFO:root:Epoch 65    loss=0.1959 [19.2 s]    dev=(HR@5:0.4405,NDCG@5:0.3233) [0.9 s]
INFO:root:Epoch 66    loss=0.1937 [19.3 s]    dev=(HR@5:0.4404,NDCG@5:0.3227) [0.8 s]
INFO:root:Epoch 67    loss=0.1943 [19.1 s]    dev=(HR@5:0.4394,NDCG@5:0.3223) [0.9 s]
INFO:root:Epoch 68    loss=0.1923 [19.1 s]    dev=(HR@5:0.4404,NDCG@5:0.3223) [0.9 s]
INFO:root:Epoch 69    loss=0.1946 [19.2 s]    dev=(HR@5:0.4419,NDCG@5:0.3240) [0.8 s]
INFO:root:Epoch 70    loss=0.1933 [19.2 s]    dev=(HR@5:0.4394,NDCG@5:0.3244) [0.9 s]
INFO:root:Epoch 71    loss=0.1922 [19.1 s]    dev=(HR@5:0.4385,NDCG@5:0.3240) [0.9 s]
INFO:root:Epoch 72    loss=0.1924 [19.2 s]    dev=(HR@5:0.4417,NDCG@5:0.3252) [0.9 s]
INFO:root:Epoch 73    loss=0.1938 [19.1 s]    dev=(HR@5:0.4417,NDCG@5:0.3233) [0.8 s]
INFO:root:Epoch 74    loss=0.1943 [19.1 s]    dev=(HR@5:0.4387,NDCG@5:0.3213) [0.9 s]
INFO:root:Epoch 75    loss=0.1948 [19.1 s]    dev=(HR@5:0.4402,NDCG@5:0.3219) [0.8 s]
INFO:root:Epoch 76    loss=0.1942 [19.1 s]    dev=(HR@5:0.4475,NDCG@5:0.3279) [0.8 s] *
INFO:root:Epoch 77    loss=0.1925 [19.1 s]    dev=(HR@5:0.4460,NDCG@5:0.3265) [0.8 s]
INFO:root:Epoch 78    loss=0.1922 [19.2 s]    dev=(HR@5:0.4451,NDCG@5:0.3251) [0.9 s]
INFO:root:Epoch 79    loss=0.1938 [19.1 s]    dev=(HR@5:0.4417,NDCG@5:0.3223) [0.8 s]
INFO:root:Epoch 80    loss=0.1915 [19.2 s]    dev=(HR@5:0.4428,NDCG@5:0.3238) [0.9 s]
INFO:root:Epoch 81    loss=0.1922 [19.1 s]    dev=(HR@5:0.4327,NDCG@5:0.3175) [0.8 s]
INFO:root:Epoch 82    loss=0.1938 [19.1 s]    dev=(HR@5:0.4367,NDCG@5:0.3197) [0.8 s]
INFO:root:Epoch 83    loss=0.1915 [19.1 s]    dev=(HR@5:0.4423,NDCG@5:0.3226) [0.8 s]
INFO:root:Epoch 84    loss=0.1910 [19.2 s]    dev=(HR@5:0.4418,NDCG@5:0.3234) [0.9 s]
INFO:root:Epoch 85    loss=0.1932 [19.2 s]    dev=(HR@5:0.4434,NDCG@5:0.3247) [0.8 s]
INFO:root:Epoch 86    loss=0.1927 [19.2 s]    dev=(HR@5:0.4408,NDCG@5:0.3239) [0.8 s]
INFO:root:Epoch 87    loss=0.1917 [19.1 s]    dev=(HR@5:0.4397,NDCG@5:0.3232) [0.8 s]
INFO:root:Epoch 88    loss=0.1922 [19.5 s]    dev=(HR@5:0.4433,NDCG@5:0.3238) [0.9 s]
INFO:root:Epoch 89    loss=0.1916 [20.2 s]    dev=(HR@5:0.4404,NDCG@5:0.3226) [0.9 s]
INFO:root:Epoch 90    loss=0.1920 [20.4 s]    dev=(HR@5:0.4449,NDCG@5:0.3276) [1.0 s]
INFO:root:Epoch 91    loss=0.1915 [20.8 s]    dev=(HR@5:0.4432,NDCG@5:0.3260) [0.9 s]
INFO:root:Epoch 92    loss=0.1904 [19.1 s]    dev=(HR@5:0.4443,NDCG@5:0.3261) [0.8 s]
INFO:root:Epoch 93    loss=0.1919 [19.2 s]    dev=(HR@5:0.4383,NDCG@5:0.3211) [0.8 s]
INFO:root:Epoch 94    loss=0.1913 [19.2 s]    dev=(HR@5:0.4423,NDCG@5:0.3253) [0.8 s]
INFO:root:Epoch 95    loss=0.1914 [19.1 s]    dev=(HR@5:0.4421,NDCG@5:0.3252) [0.8 s]
INFO:root:Epoch 96    loss=0.1895 [19.2 s]    dev=(HR@5:0.4422,NDCG@5:0.3251) [0.9 s]
INFO:root:Early stop at 96 based on dev result.
INFO:root:
Best Iter(dev)=   76	 dev=(HR@5:0.4475,NDCG@5:0.3279) [1925.5 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.3953,NDCG@5:0.2819,HR@10:0.5043,NDCG@10:0.3172,HR@20:0.6238,NDCG@20:0.3474,HR@50:0.8295,NDCG@50:0.3881)
INFO:root:
--------------------------------------------- END: 2024-12-06 03:14:23 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 04:25:27 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [21.2 s]    dev=(HR@5:0.2515,NDCG@5:0.1672) [0.8 s] *
INFO:root:Epoch 2     loss=0.4314 [19.2 s]    dev=(HR@5:0.3220,NDCG@5:0.2190) [0.8 s] *
INFO:root:Epoch 3     loss=0.3941 [19.2 s]    dev=(HR@5:0.3526,NDCG@5:0.2401) [0.8 s] *
INFO:root:Epoch 4     loss=0.3717 [19.3 s]    dev=(HR@5:0.3691,NDCG@5:0.2557) [0.8 s] *
INFO:root:Epoch 5     loss=0.3482 [19.3 s]    dev=(HR@5:0.3862,NDCG@5:0.2701) [0.8 s] *
INFO:root:Epoch 6     loss=0.3236 [19.2 s]    dev=(HR@5:0.4029,NDCG@5:0.2863) [0.8 s] *
INFO:root:Epoch 7     loss=0.3049 [19.3 s]    dev=(HR@5:0.4076,NDCG@5:0.2912) [0.9 s] *
INFO:root:Epoch 8     loss=0.2883 [19.3 s]    dev=(HR@5:0.4146,NDCG@5:0.2975) [0.9 s] *
INFO:root:Epoch 9     loss=0.2739 [19.3 s]    dev=(HR@5:0.4174,NDCG@5:0.3000) [0.9 s] *
INFO:root:Epoch 10    loss=0.2649 [19.2 s]    dev=(HR@5:0.4231,NDCG@5:0.3049) [0.8 s] *
INFO:root:Epoch 11    loss=0.2550 [19.2 s]    dev=(HR@5:0.4261,NDCG@5:0.3058) [0.9 s] *
INFO:root:Epoch 12    loss=0.2478 [19.3 s]    dev=(HR@5:0.4279,NDCG@5:0.3093) [0.8 s] *
INFO:root:Epoch 13    loss=0.2439 [19.4 s]    dev=(HR@5:0.4309,NDCG@5:0.3131) [0.8 s] *
INFO:root:Epoch 14    loss=0.2384 [19.2 s]    dev=(HR@5:0.4338,NDCG@5:0.3131) [0.8 s]
INFO:root:Epoch 15    loss=0.2356 [19.1 s]    dev=(HR@5:0.4302,NDCG@5:0.3100) [0.9 s]
INFO:root:Epoch 16    loss=0.2333 [19.2 s]    dev=(HR@5:0.4329,NDCG@5:0.3151) [0.8 s] *
INFO:root:Epoch 17    loss=0.2296 [19.2 s]    dev=(HR@5:0.4299,NDCG@5:0.3112) [0.9 s]
INFO:root:Epoch 18    loss=0.2254 [19.3 s]    dev=(HR@5:0.4329,NDCG@5:0.3134) [0.9 s]
INFO:root:Epoch 19    loss=0.2236 [19.2 s]    dev=(HR@5:0.4353,NDCG@5:0.3170) [0.9 s] *
INFO:root:Epoch 20    loss=0.2216 [19.2 s]    dev=(HR@5:0.4368,NDCG@5:0.3191) [0.9 s] *
INFO:root:Epoch 21    loss=0.2174 [19.2 s]    dev=(HR@5:0.4383,NDCG@5:0.3188) [0.8 s]
INFO:root:Epoch 22    loss=0.2162 [19.2 s]    dev=(HR@5:0.4363,NDCG@5:0.3192) [0.8 s] *
INFO:root:Epoch 23    loss=0.2173 [19.2 s]    dev=(HR@5:0.4370,NDCG@5:0.3188) [0.8 s]
INFO:root:Epoch 24    loss=0.2160 [19.2 s]    dev=(HR@5:0.4411,NDCG@5:0.3204) [0.9 s] *
INFO:root:Epoch 25    loss=0.2132 [19.2 s]    dev=(HR@5:0.4361,NDCG@5:0.3184) [0.9 s]
INFO:root:Epoch 26    loss=0.2135 [19.3 s]    dev=(HR@5:0.4410,NDCG@5:0.3213) [0.8 s] *
INFO:root:Epoch 27    loss=0.2123 [19.2 s]    dev=(HR@5:0.4425,NDCG@5:0.3236) [0.8 s] *
INFO:root:Epoch 28    loss=0.2126 [19.2 s]    dev=(HR@5:0.4428,NDCG@5:0.3242) [0.8 s] *
INFO:root:Epoch 29    loss=0.2096 [19.2 s]    dev=(HR@5:0.4417,NDCG@5:0.3230) [0.8 s]
INFO:root:Epoch 30    loss=0.2098 [19.2 s]    dev=(HR@5:0.4427,NDCG@5:0.3229) [0.8 s]
INFO:root:Epoch 31    loss=0.2080 [19.2 s]    dev=(HR@5:0.4455,NDCG@5:0.3264) [0.8 s] *
INFO:root:Epoch 32    loss=0.2088 [19.2 s]    dev=(HR@5:0.4418,NDCG@5:0.3234) [0.9 s]
INFO:root:Epoch 33    loss=0.2077 [19.3 s]    dev=(HR@5:0.4421,NDCG@5:0.3243) [0.9 s]
INFO:root:Epoch 34    loss=0.2073 [19.2 s]    dev=(HR@5:0.4409,NDCG@5:0.3228) [0.9 s]
INFO:root:Epoch 35    loss=0.2070 [19.3 s]    dev=(HR@5:0.4400,NDCG@5:0.3216) [0.9 s]
INFO:root:Epoch 36    loss=0.2053 [19.2 s]    dev=(HR@5:0.4412,NDCG@5:0.3235) [0.9 s]
INFO:root:Epoch 37    loss=0.2052 [19.2 s]    dev=(HR@5:0.4417,NDCG@5:0.3227) [0.9 s]
INFO:root:Epoch 38    loss=0.2054 [19.2 s]    dev=(HR@5:0.4421,NDCG@5:0.3228) [0.9 s]
INFO:root:Epoch 39    loss=0.2048 [19.1 s]    dev=(HR@5:0.4374,NDCG@5:0.3185) [0.9 s]
INFO:root:Epoch 40    loss=0.2042 [19.2 s]    dev=(HR@5:0.4423,NDCG@5:0.3228) [0.9 s]
INFO:root:Epoch 41    loss=0.2049 [19.2 s]    dev=(HR@5:0.4440,NDCG@5:0.3230) [0.9 s]
INFO:root:Epoch 42    loss=0.2047 [19.2 s]    dev=(HR@5:0.4463,NDCG@5:0.3240) [0.9 s]
INFO:root:Epoch 43    loss=0.2030 [19.2 s]    dev=(HR@5:0.4464,NDCG@5:0.3260) [0.9 s]
INFO:root:Epoch 44    loss=0.2037 [19.2 s]    dev=(HR@5:0.4434,NDCG@5:0.3241) [0.9 s]
INFO:root:Epoch 45    loss=0.2008 [19.2 s]    dev=(HR@5:0.4460,NDCG@5:0.3265) [0.9 s] *
INFO:root:Epoch 46    loss=0.2015 [19.2 s]    dev=(HR@5:0.4429,NDCG@5:0.3241) [0.9 s]
INFO:root:Epoch 47    loss=0.2014 [19.2 s]    dev=(HR@5:0.4448,NDCG@5:0.3254) [0.9 s]
INFO:root:Epoch 48    loss=0.2007 [19.2 s]    dev=(HR@5:0.4425,NDCG@5:0.3232) [0.9 s]
INFO:root:Epoch 49    loss=0.1994 [19.2 s]    dev=(HR@5:0.4481,NDCG@5:0.3279) [0.8 s] *
INFO:root:Epoch 50    loss=0.2005 [19.1 s]    dev=(HR@5:0.4398,NDCG@5:0.3228) [0.8 s]
INFO:root:Epoch 51    loss=0.1987 [19.1 s]    dev=(HR@5:0.4460,NDCG@5:0.3265) [0.8 s]
INFO:root:Epoch 52    loss=0.1996 [19.1 s]    dev=(HR@5:0.4449,NDCG@5:0.3249) [0.8 s]
INFO:root:Epoch 53    loss=0.1990 [19.1 s]    dev=(HR@5:0.4438,NDCG@5:0.3262) [0.9 s]
INFO:root:Epoch 54    loss=0.1973 [19.2 s]    dev=(HR@5:0.4477,NDCG@5:0.3273) [0.9 s]
INFO:root:Epoch 55    loss=0.1979 [19.2 s]    dev=(HR@5:0.4470,NDCG@5:0.3250) [0.9 s]
INFO:root:Epoch 56    loss=0.1967 [19.3 s]    dev=(HR@5:0.4486,NDCG@5:0.3290) [0.9 s] *
INFO:root:Epoch 57    loss=0.1968 [19.1 s]    dev=(HR@5:0.4468,NDCG@5:0.3281) [0.9 s]
INFO:root:Epoch 58    loss=0.1982 [19.2 s]    dev=(HR@5:0.4485,NDCG@5:0.3291) [0.8 s] *
INFO:root:Epoch 59    loss=0.1968 [19.2 s]    dev=(HR@5:0.4441,NDCG@5:0.3262) [0.8 s]
INFO:root:Epoch 60    loss=0.1966 [19.2 s]    dev=(HR@5:0.4485,NDCG@5:0.3275) [0.8 s]
INFO:root:Epoch 61    loss=0.1960 [19.1 s]    dev=(HR@5:0.4515,NDCG@5:0.3313) [0.8 s] *
INFO:root:Epoch 62    loss=0.1961 [19.2 s]    dev=(HR@5:0.4501,NDCG@5:0.3313) [0.8 s]
INFO:root:Epoch 63    loss=0.1963 [19.2 s]    dev=(HR@5:0.4519,NDCG@5:0.3307) [0.8 s]
INFO:root:Epoch 64    loss=0.1942 [19.2 s]    dev=(HR@5:0.4476,NDCG@5:0.3278) [0.8 s]
INFO:root:Epoch 65    loss=0.1952 [19.1 s]    dev=(HR@5:0.4480,NDCG@5:0.3279) [0.8 s]
INFO:root:Epoch 66    loss=0.1941 [19.2 s]    dev=(HR@5:0.4496,NDCG@5:0.3284) [0.9 s]
INFO:root:Epoch 67    loss=0.1940 [19.2 s]    dev=(HR@5:0.4442,NDCG@5:0.3240) [0.9 s]
INFO:root:Epoch 68    loss=0.1926 [19.3 s]    dev=(HR@5:0.4470,NDCG@5:0.3262) [0.8 s]
INFO:root:Epoch 69    loss=0.1937 [19.2 s]    dev=(HR@5:0.4483,NDCG@5:0.3300) [0.8 s]
INFO:root:Epoch 70    loss=0.1934 [19.3 s]    dev=(HR@5:0.4442,NDCG@5:0.3262) [0.9 s]
INFO:root:Epoch 71    loss=0.1927 [19.2 s]    dev=(HR@5:0.4466,NDCG@5:0.3286) [0.9 s]
INFO:root:Epoch 72    loss=0.1919 [19.2 s]    dev=(HR@5:0.4445,NDCG@5:0.3267) [0.8 s]
INFO:root:Epoch 73    loss=0.1926 [19.2 s]    dev=(HR@5:0.4472,NDCG@5:0.3274) [0.8 s]
INFO:root:Epoch 74    loss=0.1932 [19.1 s]    dev=(HR@5:0.4451,NDCG@5:0.3243) [0.9 s]
INFO:root:Epoch 75    loss=0.1939 [19.1 s]    dev=(HR@5:0.4471,NDCG@5:0.3279) [0.8 s]
INFO:root:Epoch 76    loss=0.1930 [19.2 s]    dev=(HR@5:0.4493,NDCG@5:0.3291) [0.9 s]
INFO:root:Epoch 77    loss=0.1917 [19.1 s]    dev=(HR@5:0.4483,NDCG@5:0.3273) [0.9 s]
INFO:root:Epoch 78    loss=0.1922 [19.2 s]    dev=(HR@5:0.4473,NDCG@5:0.3248) [0.9 s]
INFO:root:Epoch 79    loss=0.1925 [19.3 s]    dev=(HR@5:0.4504,NDCG@5:0.3286) [0.9 s]
INFO:root:Epoch 80    loss=0.1905 [19.3 s]    dev=(HR@5:0.4500,NDCG@5:0.3291) [0.8 s]
INFO:root:Epoch 81    loss=0.1909 [19.1 s]    dev=(HR@5:0.4455,NDCG@5:0.3239) [0.8 s]
INFO:root:Early stop at 81 based on dev result.
INFO:root:
Best Iter(dev)=   61	 dev=(HR@5:0.4515,NDCG@5:0.3313) [1626.7 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.4009,NDCG@5:0.2851,HR@10:0.5136,NDCG@10:0.3216,HR@20:0.6340,NDCG@20:0.3519,HR@50:0.8377,NDCG@50:0.3923)
INFO:root:
--------------------------------------------- END: 2024-12-06 04:52:36 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 06:08:52 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5163 [21.4 s]    dev=(HR@5:0.2536,NDCG@5:0.1689) [0.8 s] *
INFO:root:Epoch 2     loss=0.4297 [19.2 s]    dev=(HR@5:0.3265,NDCG@5:0.2224) [0.8 s] *
INFO:root:Epoch 3     loss=0.3933 [19.2 s]    dev=(HR@5:0.3537,NDCG@5:0.2417) [0.8 s] *
INFO:root:Epoch 4     loss=0.3726 [19.2 s]    dev=(HR@5:0.3678,NDCG@5:0.2547) [0.9 s] *
INFO:root:Epoch 5     loss=0.3498 [19.1 s]    dev=(HR@5:0.3887,NDCG@5:0.2711) [0.8 s] *
INFO:root:Epoch 6     loss=0.3250 [19.2 s]    dev=(HR@5:0.4047,NDCG@5:0.2869) [0.8 s] *
INFO:root:Epoch 7     loss=0.3068 [19.2 s]    dev=(HR@5:0.4113,NDCG@5:0.2919) [0.9 s] *
INFO:root:Epoch 8     loss=0.2910 [19.2 s]    dev=(HR@5:0.4194,NDCG@5:0.2998) [0.9 s] *
INFO:root:Epoch 9     loss=0.2771 [19.1 s]    dev=(HR@5:0.4219,NDCG@5:0.3025) [0.9 s] *
INFO:root:Epoch 10    loss=0.2689 [19.1 s]    dev=(HR@5:0.4245,NDCG@5:0.3054) [0.9 s] *
INFO:root:Epoch 11    loss=0.2591 [19.1 s]    dev=(HR@5:0.4274,NDCG@5:0.3068) [0.9 s] *
INFO:root:Epoch 12    loss=0.2520 [19.2 s]    dev=(HR@5:0.4312,NDCG@5:0.3104) [0.8 s] *
INFO:root:Epoch 13    loss=0.2486 [19.3 s]    dev=(HR@5:0.4372,NDCG@5:0.3168) [0.8 s] *
INFO:root:Epoch 14    loss=0.2431 [19.2 s]    dev=(HR@5:0.4359,NDCG@5:0.3137) [0.8 s]
INFO:root:Epoch 15    loss=0.2403 [19.2 s]    dev=(HR@5:0.4331,NDCG@5:0.3123) [0.8 s]
INFO:root:Epoch 16    loss=0.2375 [19.2 s]    dev=(HR@5:0.4381,NDCG@5:0.3175) [0.9 s] *
INFO:root:Epoch 17    loss=0.2339 [19.2 s]    dev=(HR@5:0.4333,NDCG@5:0.3147) [0.8 s]
INFO:root:Epoch 18    loss=0.2284 [19.3 s]    dev=(HR@5:0.4399,NDCG@5:0.3204) [0.9 s] *
INFO:root:Epoch 19    loss=0.2264 [19.1 s]    dev=(HR@5:0.4394,NDCG@5:0.3205) [0.9 s] *
INFO:root:Epoch 20    loss=0.2234 [19.1 s]    dev=(HR@5:0.4435,NDCG@5:0.3236) [0.9 s] *
INFO:root:Epoch 21    loss=0.2197 [19.1 s]    dev=(HR@5:0.4403,NDCG@5:0.3215) [0.9 s]
INFO:root:Epoch 22    loss=0.2181 [19.1 s]    dev=(HR@5:0.4423,NDCG@5:0.3217) [0.9 s]
INFO:root:Epoch 23    loss=0.2193 [19.2 s]    dev=(HR@5:0.4412,NDCG@5:0.3227) [0.8 s]
INFO:root:Epoch 24    loss=0.2183 [19.1 s]    dev=(HR@5:0.4440,NDCG@5:0.3227) [0.8 s]
INFO:root:Epoch 25    loss=0.2144 [19.3 s]    dev=(HR@5:0.4403,NDCG@5:0.3215) [0.8 s]
INFO:root:Epoch 26    loss=0.2149 [19.2 s]    dev=(HR@5:0.4446,NDCG@5:0.3245) [0.8 s] *
INFO:root:Epoch 27    loss=0.2134 [19.2 s]    dev=(HR@5:0.4445,NDCG@5:0.3252) [0.8 s] *
INFO:root:Epoch 28    loss=0.2143 [19.2 s]    dev=(HR@5:0.4463,NDCG@5:0.3269) [0.9 s] *
INFO:root:Epoch 29    loss=0.2116 [19.1 s]    dev=(HR@5:0.4432,NDCG@5:0.3238) [0.8 s]
INFO:root:Epoch 30    loss=0.2111 [19.5 s]    dev=(HR@5:0.4466,NDCG@5:0.3271) [0.9 s] *
INFO:root:Epoch 31    loss=0.2093 [19.7 s]    dev=(HR@5:0.4455,NDCG@5:0.3272) [0.8 s] *
INFO:root:Epoch 32    loss=0.2103 [19.3 s]    dev=(HR@5:0.4438,NDCG@5:0.3249) [0.9 s]
INFO:root:Epoch 33    loss=0.2095 [19.1 s]    dev=(HR@5:0.4442,NDCG@5:0.3252) [0.9 s]
INFO:root:Epoch 34    loss=0.2092 [19.1 s]    dev=(HR@5:0.4451,NDCG@5:0.3269) [0.8 s]
INFO:root:Epoch 35    loss=0.2099 [19.1 s]    dev=(HR@5:0.4418,NDCG@5:0.3226) [0.8 s]
INFO:root:Epoch 36    loss=0.2075 [19.1 s]    dev=(HR@5:0.4433,NDCG@5:0.3232) [0.9 s]
INFO:root:Epoch 37    loss=0.2077 [19.2 s]    dev=(HR@5:0.4430,NDCG@5:0.3230) [0.8 s]
INFO:root:Epoch 38    loss=0.2077 [19.2 s]    dev=(HR@5:0.4440,NDCG@5:0.3231) [0.9 s]
INFO:root:Epoch 39    loss=0.2071 [19.2 s]    dev=(HR@5:0.4406,NDCG@5:0.3199) [0.8 s]
INFO:root:Epoch 40    loss=0.2071 [19.1 s]    dev=(HR@5:0.4419,NDCG@5:0.3226) [0.8 s]
INFO:root:Epoch 41    loss=0.2077 [19.2 s]    dev=(HR@5:0.4419,NDCG@5:0.3206) [0.9 s]
INFO:root:Epoch 42    loss=0.2077 [19.2 s]    dev=(HR@5:0.4469,NDCG@5:0.3239) [0.9 s]
INFO:root:Epoch 43    loss=0.2055 [19.2 s]    dev=(HR@5:0.4471,NDCG@5:0.3249) [0.8 s]
INFO:root:Epoch 44    loss=0.2063 [19.2 s]    dev=(HR@5:0.4449,NDCG@5:0.3237) [0.9 s]
INFO:root:Epoch 45    loss=0.2039 [19.2 s]    dev=(HR@5:0.4462,NDCG@5:0.3272) [0.9 s]
INFO:root:Epoch 46    loss=0.2045 [19.2 s]    dev=(HR@5:0.4427,NDCG@5:0.3231) [0.8 s]
INFO:root:Epoch 47    loss=0.2053 [19.1 s]    dev=(HR@5:0.4441,NDCG@5:0.3234) [0.8 s]
INFO:root:Epoch 48    loss=0.2047 [19.3 s]    dev=(HR@5:0.4411,NDCG@5:0.3221) [0.9 s]
INFO:root:Epoch 49    loss=0.2027 [19.2 s]    dev=(HR@5:0.4468,NDCG@5:0.3262) [0.8 s]
INFO:root:Epoch 50    loss=0.2049 [19.2 s]    dev=(HR@5:0.4431,NDCG@5:0.3236) [0.8 s]
INFO:root:Epoch 51    loss=0.2031 [19.1 s]    dev=(HR@5:0.4427,NDCG@5:0.3236) [0.9 s]
INFO:root:Early stop at 51 based on dev result.
INFO:root:
Best Iter(dev)=   31	 dev=(HR@5:0.4455,NDCG@5:0.3272) [1024.5 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.3970,NDCG@5:0.2818,HR@10:0.5099,NDCG@10:0.3183,HR@20:0.6338,NDCG@20:0.3496,HR@50:0.8410,NDCG@50:0.3906)
INFO:root:
--------------------------------------------- END: 2024-12-06 06:25:58 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 07:08:09 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [21.6 s]    dev=(HR@5:0.2531,NDCG@5:0.1687) [0.9 s] *
INFO:root:Epoch 2     loss=0.4299 [19.6 s]    dev=(HR@5:0.3250,NDCG@5:0.2218) [0.9 s] *
INFO:root:Epoch 3     loss=0.3940 [19.6 s]    dev=(HR@5:0.3510,NDCG@5:0.2397) [0.9 s] *
INFO:root:Epoch 4     loss=0.3739 [19.7 s]    dev=(HR@5:0.3669,NDCG@5:0.2543) [0.9 s] *
INFO:root:Epoch 5     loss=0.3529 [19.6 s]    dev=(HR@5:0.3842,NDCG@5:0.2669) [0.8 s] *
INFO:root:Epoch 6     loss=0.3322 [19.6 s]    dev=(HR@5:0.3989,NDCG@5:0.2814) [0.9 s] *
INFO:root:Epoch 7     loss=0.3150 [19.5 s]    dev=(HR@5:0.4064,NDCG@5:0.2879) [0.9 s] *
INFO:root:Epoch 8     loss=0.2973 [19.6 s]    dev=(HR@5:0.4171,NDCG@5:0.2969) [0.9 s] *
INFO:root:Epoch 9     loss=0.2803 [19.6 s]    dev=(HR@5:0.4203,NDCG@5:0.3008) [0.9 s] *
INFO:root:Epoch 10    loss=0.2697 [19.5 s]    dev=(HR@5:0.4288,NDCG@5:0.3066) [0.9 s] *
INFO:root:Epoch 11    loss=0.2586 [19.5 s]    dev=(HR@5:0.4280,NDCG@5:0.3072) [0.9 s] *
INFO:root:Epoch 12    loss=0.2497 [19.5 s]    dev=(HR@5:0.4322,NDCG@5:0.3109) [0.9 s] *
INFO:root:Epoch 13    loss=0.2451 [19.6 s]    dev=(HR@5:0.4391,NDCG@5:0.3192) [0.8 s] *
INFO:root:Epoch 14    loss=0.2389 [19.6 s]    dev=(HR@5:0.4363,NDCG@5:0.3153) [0.9 s]
INFO:root:Epoch 15    loss=0.2356 [19.6 s]    dev=(HR@5:0.4366,NDCG@5:0.3146) [0.9 s]
INFO:root:Epoch 16    loss=0.2331 [19.6 s]    dev=(HR@5:0.4357,NDCG@5:0.3175) [0.9 s]
INFO:root:Epoch 17    loss=0.2291 [19.5 s]    dev=(HR@5:0.4339,NDCG@5:0.3148) [0.8 s]
INFO:root:Epoch 18    loss=0.2244 [19.5 s]    dev=(HR@5:0.4372,NDCG@5:0.3181) [0.9 s]
INFO:root:Epoch 19    loss=0.2231 [19.5 s]    dev=(HR@5:0.4370,NDCG@5:0.3187) [0.9 s]
INFO:root:Epoch 20    loss=0.2204 [19.6 s]    dev=(HR@5:0.4404,NDCG@5:0.3224) [0.9 s] *
INFO:root:Epoch 21    loss=0.2163 [19.7 s]    dev=(HR@5:0.4409,NDCG@5:0.3220) [0.9 s]
INFO:root:Epoch 22    loss=0.2154 [19.6 s]    dev=(HR@5:0.4434,NDCG@5:0.3236) [0.8 s] *
INFO:root:Epoch 23    loss=0.2166 [19.6 s]    dev=(HR@5:0.4376,NDCG@5:0.3210) [0.9 s]
INFO:root:Epoch 24    loss=0.2157 [19.5 s]    dev=(HR@5:0.4432,NDCG@5:0.3228) [0.8 s]
INFO:root:Epoch 25    loss=0.2121 [19.7 s]    dev=(HR@5:0.4404,NDCG@5:0.3202) [0.9 s]
INFO:root:Epoch 26    loss=0.2121 [19.6 s]    dev=(HR@5:0.4417,NDCG@5:0.3224) [0.9 s]
INFO:root:Epoch 27    loss=0.2115 [19.7 s]    dev=(HR@5:0.4391,NDCG@5:0.3216) [0.9 s]
INFO:root:Epoch 28    loss=0.2116 [19.6 s]    dev=(HR@5:0.4433,NDCG@5:0.3256) [0.8 s] *
INFO:root:Epoch 29    loss=0.2091 [19.5 s]    dev=(HR@5:0.4400,NDCG@5:0.3211) [0.9 s]
INFO:root:Epoch 30    loss=0.2088 [19.6 s]    dev=(HR@5:0.4421,NDCG@5:0.3250) [0.9 s]
INFO:root:Epoch 31    loss=0.2077 [19.5 s]    dev=(HR@5:0.4443,NDCG@5:0.3253) [0.9 s]
INFO:root:Epoch 32    loss=0.2086 [19.8 s]    dev=(HR@5:0.4434,NDCG@5:0.3239) [0.8 s]
INFO:root:Epoch 33    loss=0.2077 [19.6 s]    dev=(HR@5:0.4451,NDCG@5:0.3246) [0.9 s]
INFO:root:Epoch 34    loss=0.2075 [19.7 s]    dev=(HR@5:0.4443,NDCG@5:0.3262) [0.8 s] *
INFO:root:Epoch 35    loss=0.2080 [19.5 s]    dev=(HR@5:0.4419,NDCG@5:0.3230) [0.8 s]
INFO:root:Epoch 36    loss=0.2056 [19.6 s]    dev=(HR@5:0.4410,NDCG@5:0.3223) [0.9 s]
INFO:root:Epoch 37    loss=0.2062 [19.7 s]    dev=(HR@5:0.4447,NDCG@5:0.3243) [0.9 s]
INFO:root:Epoch 38    loss=0.2059 [19.6 s]    dev=(HR@5:0.4424,NDCG@5:0.3219) [0.8 s]
INFO:root:Epoch 39    loss=0.2057 [19.5 s]    dev=(HR@5:0.4348,NDCG@5:0.3156) [0.8 s]
INFO:root:Epoch 40    loss=0.2053 [19.6 s]    dev=(HR@5:0.4382,NDCG@5:0.3191) [0.8 s]
INFO:root:Epoch 41    loss=0.2073 [19.7 s]    dev=(HR@5:0.4393,NDCG@5:0.3184) [0.8 s]
INFO:root:Epoch 42    loss=0.2061 [19.5 s]    dev=(HR@5:0.4436,NDCG@5:0.3217) [0.8 s]
INFO:root:Epoch 43    loss=0.2041 [19.5 s]    dev=(HR@5:0.4439,NDCG@5:0.3244) [0.8 s]
INFO:root:Epoch 44    loss=0.2052 [19.6 s]    dev=(HR@5:0.4408,NDCG@5:0.3219) [0.8 s]
INFO:root:Epoch 45    loss=0.2034 [19.6 s]    dev=(HR@5:0.4445,NDCG@5:0.3254) [0.8 s]
INFO:root:Epoch 46    loss=0.2041 [19.6 s]    dev=(HR@5:0.4408,NDCG@5:0.3220) [0.8 s]
INFO:root:Epoch 47    loss=0.2051 [19.6 s]    dev=(HR@5:0.4410,NDCG@5:0.3223) [0.9 s]
INFO:root:Epoch 48    loss=0.2045 [19.6 s]    dev=(HR@5:0.4404,NDCG@5:0.3207) [0.9 s]
INFO:root:Epoch 49    loss=0.2027 [19.6 s]    dev=(HR@5:0.4445,NDCG@5:0.3238) [0.9 s]
INFO:root:Epoch 50    loss=0.2043 [19.6 s]    dev=(HR@5:0.4408,NDCG@5:0.3234) [0.9 s]
INFO:root:Epoch 51    loss=0.2030 [19.6 s]    dev=(HR@5:0.4442,NDCG@5:0.3228) [0.9 s]
INFO:root:Epoch 52    loss=0.2032 [19.5 s]    dev=(HR@5:0.4436,NDCG@5:0.3232) [0.8 s]
INFO:root:Epoch 53    loss=0.2035 [19.5 s]    dev=(HR@5:0.4413,NDCG@5:0.3215) [0.8 s]
INFO:root:Epoch 54    loss=0.2010 [19.6 s]    dev=(HR@5:0.4436,NDCG@5:0.3218) [0.8 s]
INFO:root:Early stop at 54 based on dev result.
INFO:root:
Best Iter(dev)=   34	 dev=(HR@5:0.4443,NDCG@5:0.3262) [1106.2 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.3956,NDCG@5:0.2801,HR@10:0.5053,NDCG@10:0.3156,HR@20:0.6307,NDCG@20:0.3472,HR@50:0.8391,NDCG@50:0.3884)
INFO:root:
--------------------------------------------- END: 2024-12-06 07:26:37 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 08:11:53 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5166 [21.2 s]    dev=(HR@5:0.2523,NDCG@5:0.1679) [0.9 s] *
INFO:root:Epoch 2     loss=0.4308 [19.3 s]    dev=(HR@5:0.3238,NDCG@5:0.2199) [0.9 s] *
INFO:root:Epoch 3     loss=0.3953 [19.2 s]    dev=(HR@5:0.3466,NDCG@5:0.2358) [0.9 s] *
INFO:root:Epoch 4     loss=0.3752 [19.2 s]    dev=(HR@5:0.3663,NDCG@5:0.2533) [0.9 s] *
INFO:root:Epoch 5     loss=0.3533 [19.2 s]    dev=(HR@5:0.3799,NDCG@5:0.2644) [0.8 s] *
INFO:root:Epoch 6     loss=0.3318 [19.2 s]    dev=(HR@5:0.3970,NDCG@5:0.2805) [0.9 s] *
INFO:root:Epoch 7     loss=0.3136 [19.2 s]    dev=(HR@5:0.4065,NDCG@5:0.2877) [0.8 s] *
INFO:root:Epoch 8     loss=0.2967 [19.2 s]    dev=(HR@5:0.4124,NDCG@5:0.2942) [0.8 s] *
INFO:root:Epoch 9     loss=0.2802 [19.2 s]    dev=(HR@5:0.4201,NDCG@5:0.3005) [0.8 s] *
INFO:root:Epoch 10    loss=0.2695 [19.2 s]    dev=(HR@5:0.4261,NDCG@5:0.3051) [0.9 s] *
INFO:root:Epoch 11    loss=0.2583 [19.2 s]    dev=(HR@5:0.4254,NDCG@5:0.3060) [0.8 s] *
INFO:root:Epoch 12    loss=0.2491 [19.1 s]    dev=(HR@5:0.4297,NDCG@5:0.3115) [0.8 s] *
INFO:root:Epoch 13    loss=0.2444 [19.0 s]    dev=(HR@5:0.4389,NDCG@5:0.3176) [0.8 s] *
INFO:root:Epoch 14    loss=0.2383 [19.1 s]    dev=(HR@5:0.4362,NDCG@5:0.3156) [0.8 s]
INFO:root:Epoch 15    loss=0.2345 [19.1 s]    dev=(HR@5:0.4383,NDCG@5:0.3163) [0.8 s]
INFO:root:Epoch 16    loss=0.2321 [19.1 s]    dev=(HR@5:0.4339,NDCG@5:0.3164) [0.9 s]
INFO:root:Epoch 17    loss=0.2283 [19.2 s]    dev=(HR@5:0.4375,NDCG@5:0.3180) [0.9 s] *
INFO:root:Epoch 18    loss=0.2237 [19.2 s]    dev=(HR@5:0.4380,NDCG@5:0.3193) [0.9 s] *
INFO:root:Epoch 19    loss=0.2221 [19.2 s]    dev=(HR@5:0.4396,NDCG@5:0.3204) [0.8 s] *
INFO:root:Epoch 20    loss=0.2203 [19.1 s]    dev=(HR@5:0.4427,NDCG@5:0.3239) [0.9 s] *
INFO:root:Epoch 21    loss=0.2154 [19.7 s]    dev=(HR@5:0.4424,NDCG@5:0.3241) [0.9 s] *
INFO:root:Epoch 22    loss=0.2155 [19.5 s]    dev=(HR@5:0.4417,NDCG@5:0.3232) [0.9 s]
INFO:root:Epoch 23    loss=0.2156 [19.4 s]    dev=(HR@5:0.4389,NDCG@5:0.3226) [0.9 s]
INFO:root:Epoch 24    loss=0.2152 [19.2 s]    dev=(HR@5:0.4416,NDCG@5:0.3212) [0.9 s]
INFO:root:Epoch 25    loss=0.2119 [19.1 s]    dev=(HR@5:0.4376,NDCG@5:0.3199) [0.9 s]
INFO:root:Epoch 26    loss=0.2116 [19.3 s]    dev=(HR@5:0.4417,NDCG@5:0.3235) [0.9 s]
INFO:root:Epoch 27    loss=0.2117 [19.2 s]    dev=(HR@5:0.4413,NDCG@5:0.3232) [0.9 s]
INFO:root:Epoch 28    loss=0.2110 [19.2 s]    dev=(HR@5:0.4419,NDCG@5:0.3253) [0.9 s] *
INFO:root:Epoch 29    loss=0.2087 [19.2 s]    dev=(HR@5:0.4406,NDCG@5:0.3230) [0.9 s]
INFO:root:Epoch 30    loss=0.2084 [19.3 s]    dev=(HR@5:0.4413,NDCG@5:0.3249) [0.9 s]
INFO:root:Epoch 31    loss=0.2075 [19.2 s]    dev=(HR@5:0.4426,NDCG@5:0.3259) [0.9 s] *
INFO:root:Epoch 32    loss=0.2083 [19.2 s]    dev=(HR@5:0.4427,NDCG@5:0.3247) [0.9 s]
INFO:root:Epoch 33    loss=0.2074 [19.3 s]    dev=(HR@5:0.4434,NDCG@5:0.3257) [0.9 s]
INFO:root:Epoch 34    loss=0.2072 [19.1 s]    dev=(HR@5:0.4444,NDCG@5:0.3272) [0.9 s] *
INFO:root:Epoch 35    loss=0.2078 [19.1 s]    dev=(HR@5:0.4415,NDCG@5:0.3227) [0.9 s]
INFO:root:Epoch 36    loss=0.2052 [19.1 s]    dev=(HR@5:0.4422,NDCG@5:0.3242) [0.9 s]
INFO:root:Epoch 37    loss=0.2059 [19.1 s]    dev=(HR@5:0.4417,NDCG@5:0.3234) [0.9 s]
INFO:root:Epoch 38    loss=0.2057 [19.1 s]    dev=(HR@5:0.4425,NDCG@5:0.3243) [0.9 s]
INFO:root:Epoch 39    loss=0.2055 [19.1 s]    dev=(HR@5:0.4393,NDCG@5:0.3206) [0.9 s]
INFO:root:Epoch 40    loss=0.2049 [19.2 s]    dev=(HR@5:0.4404,NDCG@5:0.3208) [0.9 s]
INFO:root:Epoch 41    loss=0.2067 [19.2 s]    dev=(HR@5:0.4393,NDCG@5:0.3200) [0.9 s]
INFO:root:Epoch 42    loss=0.2060 [19.2 s]    dev=(HR@5:0.4438,NDCG@5:0.3234) [0.9 s]
INFO:root:Epoch 43    loss=0.2041 [19.2 s]    dev=(HR@5:0.4436,NDCG@5:0.3260) [0.9 s]
INFO:root:Epoch 44    loss=0.2049 [19.2 s]    dev=(HR@5:0.4425,NDCG@5:0.3240) [0.9 s]
INFO:root:Epoch 45    loss=0.2024 [19.1 s]    dev=(HR@5:0.4474,NDCG@5:0.3285) [0.9 s] *
INFO:root:Epoch 46    loss=0.2039 [19.2 s]    dev=(HR@5:0.4415,NDCG@5:0.3225) [0.9 s]
INFO:root:Epoch 47    loss=0.2045 [19.2 s]    dev=(HR@5:0.4419,NDCG@5:0.3237) [0.9 s]
INFO:root:Epoch 48    loss=0.2037 [19.1 s]    dev=(HR@5:0.4402,NDCG@5:0.3221) [0.9 s]
INFO:root:Epoch 49    loss=0.2022 [19.1 s]    dev=(HR@5:0.4432,NDCG@5:0.3246) [0.9 s]
INFO:root:Epoch 50    loss=0.2036 [19.2 s]    dev=(HR@5:0.4421,NDCG@5:0.3255) [0.8 s]
INFO:root:Epoch 51    loss=0.2027 [19.2 s]    dev=(HR@5:0.4470,NDCG@5:0.3264) [0.8 s]
INFO:root:Epoch 52    loss=0.2025 [19.2 s]    dev=(HR@5:0.4445,NDCG@5:0.3244) [0.9 s]
INFO:root:Epoch 53    loss=0.2025 [19.1 s]    dev=(HR@5:0.4434,NDCG@5:0.3228) [0.9 s]
INFO:root:Epoch 54    loss=0.2006 [19.1 s]    dev=(HR@5:0.4443,NDCG@5:0.3246) [0.9 s]
INFO:root:Epoch 55    loss=0.2006 [19.1 s]    dev=(HR@5:0.4474,NDCG@5:0.3277) [0.9 s]
INFO:root:Epoch 56    loss=0.2010 [19.2 s]    dev=(HR@5:0.4455,NDCG@5:0.3278) [0.9 s]
INFO:root:Epoch 57    loss=0.2008 [19.1 s]    dev=(HR@5:0.4443,NDCG@5:0.3269) [0.9 s]
INFO:root:Epoch 58    loss=0.2018 [19.1 s]    dev=(HR@5:0.4483,NDCG@5:0.3293) [0.9 s] *
INFO:root:Epoch 59    loss=0.1999 [19.3 s]    dev=(HR@5:0.4447,NDCG@5:0.3256) [0.9 s]
INFO:root:Epoch 60    loss=0.2001 [19.2 s]    dev=(HR@5:0.4410,NDCG@5:0.3214) [0.9 s]
INFO:root:Epoch 61    loss=0.2001 [19.2 s]    dev=(HR@5:0.4459,NDCG@5:0.3280) [0.9 s]
INFO:root:Epoch 62    loss=0.1996 [19.3 s]    dev=(HR@5:0.4463,NDCG@5:0.3273) [0.8 s]
INFO:root:Epoch 63    loss=0.2008 [19.1 s]    dev=(HR@5:0.4464,NDCG@5:0.3258) [0.8 s]
INFO:root:Epoch 64    loss=0.1989 [19.2 s]    dev=(HR@5:0.4457,NDCG@5:0.3239) [0.8 s]
INFO:root:Epoch 65    loss=0.1996 [19.2 s]    dev=(HR@5:0.4481,NDCG@5:0.3266) [0.9 s]
INFO:root:Epoch 66    loss=0.1977 [19.3 s]    dev=(HR@5:0.4449,NDCG@5:0.3255) [0.9 s]
INFO:root:Epoch 67    loss=0.1982 [19.2 s]    dev=(HR@5:0.4467,NDCG@5:0.3246) [0.8 s]
INFO:root:Epoch 68    loss=0.1959 [19.2 s]    dev=(HR@5:0.4434,NDCG@5:0.3246) [0.8 s]
INFO:root:Epoch 69    loss=0.1988 [19.2 s]    dev=(HR@5:0.4428,NDCG@5:0.3243) [0.9 s]
INFO:root:Epoch 70    loss=0.1979 [19.2 s]    dev=(HR@5:0.4405,NDCG@5:0.3235) [0.8 s]
INFO:root:Epoch 71    loss=0.1970 [19.2 s]    dev=(HR@5:0.4444,NDCG@5:0.3254) [0.9 s]
INFO:root:Epoch 72    loss=0.1965 [19.2 s]    dev=(HR@5:0.4421,NDCG@5:0.3248) [0.9 s]
INFO:root:Epoch 73    loss=0.1976 [19.2 s]    dev=(HR@5:0.4435,NDCG@5:0.3262) [0.8 s]
INFO:root:Epoch 74    loss=0.1978 [19.2 s]    dev=(HR@5:0.4418,NDCG@5:0.3233) [0.9 s]
INFO:root:Epoch 75    loss=0.1992 [19.3 s]    dev=(HR@5:0.4461,NDCG@5:0.3253) [0.9 s]
INFO:root:Epoch 76    loss=0.1974 [19.1 s]    dev=(HR@5:0.4495,NDCG@5:0.3292) [0.9 s]
INFO:root:Epoch 77    loss=0.1967 [19.2 s]    dev=(HR@5:0.4456,NDCG@5:0.3249) [0.8 s]
INFO:root:Epoch 78    loss=0.1967 [19.3 s]    dev=(HR@5:0.4442,NDCG@5:0.3231) [0.9 s]
INFO:root:Early stop at 78 based on dev result.
INFO:root:
Best Iter(dev)=   58	 dev=(HR@5:0.4483,NDCG@5:0.3293) [1565.7 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.3978,NDCG@5:0.2839,HR@10:0.5067,NDCG@10:0.3192,HR@20:0.6310,NDCG@20:0.3505,HR@50:0.8360,NDCG@50:0.3911)
INFO:root:
--------------------------------------------- END: 2024-12-06 08:38:01 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 09:18:00 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5159 [21.2 s]    dev=(HR@5:0.2501,NDCG@5:0.1664) [0.9 s] *
INFO:root:Epoch 2     loss=0.4334 [19.2 s]    dev=(HR@5:0.3171,NDCG@5:0.2139) [0.9 s] *
INFO:root:Epoch 3     loss=0.3984 [20.0 s]    dev=(HR@5:0.3432,NDCG@5:0.2306) [0.9 s] *
INFO:root:Epoch 4     loss=0.3761 [19.2 s]    dev=(HR@5:0.3640,NDCG@5:0.2508) [0.9 s] *
INFO:root:Epoch 5     loss=0.3503 [19.3 s]    dev=(HR@5:0.3801,NDCG@5:0.2658) [0.9 s] *
INFO:root:Epoch 6     loss=0.3258 [19.2 s]    dev=(HR@5:0.3913,NDCG@5:0.2782) [0.9 s] *
INFO:root:Epoch 7     loss=0.3067 [19.2 s]    dev=(HR@5:0.3968,NDCG@5:0.2834) [0.9 s] *
INFO:root:Epoch 8     loss=0.2903 [19.2 s]    dev=(HR@5:0.4024,NDCG@5:0.2894) [0.9 s] *
INFO:root:Epoch 9     loss=0.2756 [19.3 s]    dev=(HR@5:0.4003,NDCG@5:0.2918) [0.8 s] *
INFO:root:Epoch 10    loss=0.2648 [19.2 s]    dev=(HR@5:0.4068,NDCG@5:0.2955) [0.9 s] *
INFO:root:Epoch 11    loss=0.2553 [19.2 s]    dev=(HR@5:0.4162,NDCG@5:0.3018) [0.8 s] *
INFO:root:Epoch 12    loss=0.2461 [19.1 s]    dev=(HR@5:0.4164,NDCG@5:0.3031) [0.9 s] *
INFO:root:Epoch 13    loss=0.2420 [19.3 s]    dev=(HR@5:0.4243,NDCG@5:0.3091) [0.9 s] *
INFO:root:Epoch 14    loss=0.2358 [19.3 s]    dev=(HR@5:0.4207,NDCG@5:0.3068) [0.9 s]
INFO:root:Epoch 15    loss=0.2333 [19.3 s]    dev=(HR@5:0.4241,NDCG@5:0.3077) [0.9 s]
INFO:root:Epoch 16    loss=0.2294 [19.2 s]    dev=(HR@5:0.4217,NDCG@5:0.3085) [0.9 s]
INFO:root:Epoch 17    loss=0.2263 [19.4 s]    dev=(HR@5:0.4190,NDCG@5:0.3052) [0.8 s]
INFO:root:Epoch 18    loss=0.2218 [19.3 s]    dev=(HR@5:0.4234,NDCG@5:0.3104) [0.8 s] *
INFO:root:Epoch 19    loss=0.2199 [19.2 s]    dev=(HR@5:0.4272,NDCG@5:0.3124) [0.8 s] *
INFO:root:Epoch 20    loss=0.2178 [19.2 s]    dev=(HR@5:0.4297,NDCG@5:0.3143) [0.9 s] *
INFO:root:Epoch 21    loss=0.2135 [19.3 s]    dev=(HR@5:0.4310,NDCG@5:0.3141) [0.9 s]
INFO:root:Epoch 22    loss=0.2120 [19.3 s]    dev=(HR@5:0.4309,NDCG@5:0.3162) [0.9 s] *
INFO:root:Epoch 23    loss=0.2125 [19.2 s]    dev=(HR@5:0.4220,NDCG@5:0.3105) [0.8 s]
INFO:root:Epoch 24    loss=0.2110 [19.3 s]    dev=(HR@5:0.4301,NDCG@5:0.3152) [0.9 s]
INFO:root:Epoch 25    loss=0.2084 [19.3 s]    dev=(HR@5:0.4313,NDCG@5:0.3152) [0.8 s]
INFO:root:Epoch 26    loss=0.2081 [19.2 s]    dev=(HR@5:0.4308,NDCG@5:0.3148) [0.8 s]
INFO:root:Epoch 27    loss=0.2074 [19.2 s]    dev=(HR@5:0.4304,NDCG@5:0.3156) [0.9 s]
INFO:root:Epoch 28    loss=0.2074 [19.2 s]    dev=(HR@5:0.4363,NDCG@5:0.3200) [0.8 s] *
INFO:root:Epoch 29    loss=0.2050 [19.1 s]    dev=(HR@5:0.4322,NDCG@5:0.3170) [0.8 s]
INFO:root:Epoch 30    loss=0.2047 [19.3 s]    dev=(HR@5:0.4317,NDCG@5:0.3163) [0.8 s]
INFO:root:Epoch 31    loss=0.2025 [19.3 s]    dev=(HR@5:0.4361,NDCG@5:0.3204) [0.8 s] *
INFO:root:Epoch 32    loss=0.2032 [19.3 s]    dev=(HR@5:0.4326,NDCG@5:0.3174) [0.8 s]
INFO:root:Epoch 33    loss=0.2025 [19.2 s]    dev=(HR@5:0.4373,NDCG@5:0.3208) [0.8 s] *
INFO:root:Epoch 34    loss=0.2014 [19.4 s]    dev=(HR@5:0.4370,NDCG@5:0.3188) [0.9 s]
INFO:root:Epoch 35    loss=0.2015 [19.3 s]    dev=(HR@5:0.4385,NDCG@5:0.3184) [0.9 s]
INFO:root:Epoch 36    loss=0.2003 [19.3 s]    dev=(HR@5:0.4368,NDCG@5:0.3172) [0.8 s]
INFO:root:Epoch 37    loss=0.2002 [19.3 s]    dev=(HR@5:0.4394,NDCG@5:0.3208) [0.8 s]
INFO:root:Epoch 38    loss=0.1998 [19.2 s]    dev=(HR@5:0.4389,NDCG@5:0.3193) [0.8 s]
INFO:root:Epoch 39    loss=0.1999 [19.2 s]    dev=(HR@5:0.4322,NDCG@5:0.3147) [0.9 s]
INFO:root:Epoch 40    loss=0.1989 [19.2 s]    dev=(HR@5:0.4387,NDCG@5:0.3204) [0.9 s]
INFO:root:Epoch 41    loss=0.1995 [19.2 s]    dev=(HR@5:0.4326,NDCG@5:0.3159) [0.9 s]
INFO:root:Epoch 42    loss=0.1995 [19.2 s]    dev=(HR@5:0.4400,NDCG@5:0.3202) [0.9 s]
INFO:root:Epoch 43    loss=0.1975 [19.3 s]    dev=(HR@5:0.4430,NDCG@5:0.3244) [0.8 s] *
INFO:root:Epoch 44    loss=0.1996 [19.2 s]    dev=(HR@5:0.4393,NDCG@5:0.3210) [0.8 s]
INFO:root:Epoch 45    loss=0.1950 [19.2 s]    dev=(HR@5:0.4408,NDCG@5:0.3241) [0.9 s]
INFO:root:Epoch 46    loss=0.1971 [19.3 s]    dev=(HR@5:0.4417,NDCG@5:0.3213) [0.9 s]
INFO:root:Epoch 47    loss=0.1972 [19.3 s]    dev=(HR@5:0.4434,NDCG@5:0.3238) [0.9 s]
INFO:root:Epoch 48    loss=0.1962 [19.3 s]    dev=(HR@5:0.4418,NDCG@5:0.3209) [0.9 s]
INFO:root:Epoch 49    loss=0.1951 [19.4 s]    dev=(HR@5:0.4478,NDCG@5:0.3271) [0.9 s] *
INFO:root:Epoch 50    loss=0.1959 [19.2 s]    dev=(HR@5:0.4393,NDCG@5:0.3223) [0.9 s]
INFO:root:Epoch 51    loss=0.1944 [19.1 s]    dev=(HR@5:0.4447,NDCG@5:0.3248) [0.9 s]
INFO:root:Epoch 52    loss=0.1951 [19.3 s]    dev=(HR@5:0.4414,NDCG@5:0.3224) [0.9 s]
INFO:root:Epoch 53    loss=0.1947 [19.2 s]    dev=(HR@5:0.4479,NDCG@5:0.3275) [0.8 s] *
INFO:root:Epoch 54    loss=0.1931 [19.2 s]    dev=(HR@5:0.4441,NDCG@5:0.3244) [0.9 s]
INFO:root:Epoch 55    loss=0.1928 [19.2 s]    dev=(HR@5:0.4447,NDCG@5:0.3234) [0.8 s]
INFO:root:Epoch 56    loss=0.1926 [19.3 s]    dev=(HR@5:0.4448,NDCG@5:0.3262) [0.8 s]
INFO:root:Epoch 57    loss=0.1936 [19.2 s]    dev=(HR@5:0.4460,NDCG@5:0.3272) [0.8 s]
INFO:root:Epoch 58    loss=0.1945 [19.1 s]    dev=(HR@5:0.4455,NDCG@5:0.3275) [0.8 s]
INFO:root:Epoch 59    loss=0.1935 [19.2 s]    dev=(HR@5:0.4445,NDCG@5:0.3245) [0.8 s]
INFO:root:Epoch 60    loss=0.1936 [19.2 s]    dev=(HR@5:0.4438,NDCG@5:0.3260) [0.8 s]
INFO:root:Epoch 61    loss=0.1927 [19.3 s]    dev=(HR@5:0.4488,NDCG@5:0.3294) [0.8 s] *
INFO:root:Epoch 62    loss=0.1927 [19.3 s]    dev=(HR@5:0.4490,NDCG@5:0.3287) [0.8 s]
INFO:root:Epoch 63    loss=0.1935 [19.2 s]    dev=(HR@5:0.4474,NDCG@5:0.3286) [0.9 s]
INFO:root:Epoch 64    loss=0.1919 [19.2 s]    dev=(HR@5:0.4425,NDCG@5:0.3250) [0.9 s]
INFO:root:Epoch 65    loss=0.1932 [19.3 s]    dev=(HR@5:0.4462,NDCG@5:0.3259) [0.9 s]
INFO:root:Epoch 66    loss=0.1915 [19.3 s]    dev=(HR@5:0.4459,NDCG@5:0.3257) [0.9 s]
INFO:root:Epoch 67    loss=0.1925 [19.2 s]    dev=(HR@5:0.4448,NDCG@5:0.3261) [0.8 s]
INFO:root:Epoch 68    loss=0.1906 [19.2 s]    dev=(HR@5:0.4481,NDCG@5:0.3296) [0.8 s] *
INFO:root:Epoch 69    loss=0.1921 [19.3 s]    dev=(HR@5:0.4447,NDCG@5:0.3258) [0.8 s]
INFO:root:Epoch 70    loss=0.1906 [19.2 s]    dev=(HR@5:0.4503,NDCG@5:0.3289) [0.8 s]
INFO:root:Epoch 71    loss=0.1906 [19.3 s]    dev=(HR@5:0.4426,NDCG@5:0.3264) [0.9 s]
INFO:root:Epoch 72    loss=0.1904 [19.2 s]    dev=(HR@5:0.4430,NDCG@5:0.3266) [0.9 s]
INFO:root:Epoch 73    loss=0.1904 [19.3 s]    dev=(HR@5:0.4453,NDCG@5:0.3282) [0.9 s]
INFO:root:Epoch 74    loss=0.1918 [19.1 s]    dev=(HR@5:0.4441,NDCG@5:0.3261) [0.9 s]
INFO:root:Epoch 75    loss=0.1922 [19.2 s]    dev=(HR@5:0.4424,NDCG@5:0.3249) [0.8 s]
INFO:root:Epoch 76    loss=0.1917 [19.2 s]    dev=(HR@5:0.4494,NDCG@5:0.3301) [0.8 s] *
INFO:root:Epoch 77    loss=0.1896 [19.1 s]    dev=(HR@5:0.4466,NDCG@5:0.3262) [0.8 s]
INFO:root:Epoch 78    loss=0.1899 [19.4 s]    dev=(HR@5:0.4490,NDCG@5:0.3267) [0.9 s]
INFO:root:Epoch 79    loss=0.1904 [19.2 s]    dev=(HR@5:0.4490,NDCG@5:0.3290) [0.8 s]
INFO:root:Epoch 80    loss=0.1889 [19.2 s]    dev=(HR@5:0.4487,NDCG@5:0.3283) [0.8 s]
INFO:root:Epoch 81    loss=0.1892 [19.2 s]    dev=(HR@5:0.4429,NDCG@5:0.3244) [0.9 s]
INFO:root:Epoch 82    loss=0.1919 [19.1 s]    dev=(HR@5:0.4468,NDCG@5:0.3281) [0.8 s]
INFO:root:Epoch 83    loss=0.1887 [19.3 s]    dev=(HR@5:0.4535,NDCG@5:0.3316) [0.9 s] *
INFO:root:Epoch 84    loss=0.1893 [19.3 s]    dev=(HR@5:0.4496,NDCG@5:0.3285) [0.8 s]
INFO:root:Epoch 85    loss=0.1903 [19.2 s]    dev=(HR@5:0.4509,NDCG@5:0.3304) [0.9 s]
INFO:root:Epoch 86    loss=0.1906 [19.2 s]    dev=(HR@5:0.4477,NDCG@5:0.3292) [0.9 s]
INFO:root:Epoch 87    loss=0.1896 [19.2 s]    dev=(HR@5:0.4497,NDCG@5:0.3282) [0.8 s]
INFO:root:Epoch 88    loss=0.1895 [19.2 s]    dev=(HR@5:0.4490,NDCG@5:0.3292) [0.8 s]
INFO:root:Epoch 89    loss=0.1894 [19.2 s]    dev=(HR@5:0.4451,NDCG@5:0.3279) [0.9 s]
INFO:root:Epoch 90    loss=0.1892 [19.2 s]    dev=(HR@5:0.4536,NDCG@5:0.3332) [0.8 s] *
INFO:root:Epoch 91    loss=0.1885 [19.2 s]    dev=(HR@5:0.4529,NDCG@5:0.3335) [0.8 s] *
INFO:root:Epoch 92    loss=0.1879 [19.2 s]    dev=(HR@5:0.4496,NDCG@5:0.3284) [0.9 s]
INFO:root:Epoch 93    loss=0.1897 [19.2 s]    dev=(HR@5:0.4453,NDCG@5:0.3253) [0.8 s]
INFO:root:Epoch 94    loss=0.1890 [19.2 s]    dev=(HR@5:0.4474,NDCG@5:0.3291) [0.9 s]
INFO:root:Epoch 95    loss=0.1891 [19.3 s]    dev=(HR@5:0.4489,NDCG@5:0.3280) [0.8 s]
INFO:root:Epoch 96    loss=0.1874 [19.4 s]    dev=(HR@5:0.4451,NDCG@5:0.3272) [0.8 s]
INFO:root:Epoch 97    loss=0.1882 [19.2 s]    dev=(HR@5:0.4484,NDCG@5:0.3270) [0.8 s]
INFO:root:Epoch 98    loss=0.1876 [19.1 s]    dev=(HR@5:0.4442,NDCG@5:0.3244) [0.8 s]
INFO:root:Epoch 99    loss=0.1889 [19.2 s]    dev=(HR@5:0.4498,NDCG@5:0.3283) [0.9 s]
INFO:root:Epoch 100   loss=0.1888 [19.2 s]    dev=(HR@5:0.4489,NDCG@5:0.3297) [0.9 s]
INFO:root:Epoch 101   loss=0.1900 [19.2 s]    dev=(HR@5:0.4494,NDCG@5:0.3298) [0.8 s]
INFO:root:Epoch 102   loss=0.1892 [19.2 s]    dev=(HR@5:0.4478,NDCG@5:0.3305) [0.9 s]
INFO:root:Epoch 103   loss=0.1884 [19.2 s]    dev=(HR@5:0.4468,NDCG@5:0.3277) [0.8 s]
INFO:root:Epoch 104   loss=0.1885 [19.2 s]    dev=(HR@5:0.4485,NDCG@5:0.3279) [0.8 s]
INFO:root:Epoch 105   loss=0.1882 [19.2 s]    dev=(HR@5:0.4474,NDCG@5:0.3275) [0.9 s]
INFO:root:Epoch 106   loss=0.1882 [19.2 s]    dev=(HR@5:0.4440,NDCG@5:0.3252) [0.8 s]
INFO:root:Epoch 107   loss=0.1893 [19.3 s]    dev=(HR@5:0.4464,NDCG@5:0.3266) [0.8 s]
INFO:root:Epoch 108   loss=0.1880 [19.2 s]    dev=(HR@5:0.4484,NDCG@5:0.3279) [0.8 s]
INFO:root:Epoch 109   loss=0.1875 [19.2 s]    dev=(HR@5:0.4496,NDCG@5:0.3319) [0.9 s]
INFO:root:Epoch 110   loss=0.1868 [19.4 s]    dev=(HR@5:0.4526,NDCG@5:0.3337) [0.9 s] *
INFO:root:Epoch 111   loss=0.1879 [19.2 s]    dev=(HR@5:0.4495,NDCG@5:0.3305) [0.9 s]
INFO:root:Epoch 112   loss=0.1897 [19.3 s]    dev=(HR@5:0.4507,NDCG@5:0.3320) [0.9 s]
INFO:root:Epoch 113   loss=0.1890 [19.3 s]    dev=(HR@5:0.4493,NDCG@5:0.3304) [0.9 s]
INFO:root:Epoch 114   loss=0.1877 [19.2 s]    dev=(HR@5:0.4442,NDCG@5:0.3272) [0.9 s]
INFO:root:Epoch 115   loss=0.1866 [19.2 s]    dev=(HR@5:0.4478,NDCG@5:0.3293) [0.9 s]
INFO:root:Epoch 116   loss=0.1878 [19.2 s]    dev=(HR@5:0.4477,NDCG@5:0.3281) [0.9 s]
INFO:root:Epoch 117   loss=0.1881 [19.2 s]    dev=(HR@5:0.4438,NDCG@5:0.3254) [0.9 s]
INFO:root:Epoch 118   loss=0.1885 [19.2 s]    dev=(HR@5:0.4494,NDCG@5:0.3321) [0.9 s]
INFO:root:Epoch 119   loss=0.1881 [19.2 s]    dev=(HR@5:0.4492,NDCG@5:0.3300) [0.9 s]
INFO:root:Epoch 120   loss=0.1879 [19.2 s]    dev=(HR@5:0.4494,NDCG@5:0.3311) [0.9 s]
INFO:root:Epoch 121   loss=0.1867 [19.3 s]    dev=(HR@5:0.4551,NDCG@5:0.3327) [0.8 s]
INFO:root:Epoch 122   loss=0.1883 [19.3 s]    dev=(HR@5:0.4486,NDCG@5:0.3304) [0.8 s]
INFO:root:Epoch 123   loss=0.1891 [19.2 s]    dev=(HR@5:0.4495,NDCG@5:0.3321) [0.8 s]
INFO:root:Epoch 124   loss=0.1864 [19.2 s]    dev=(HR@5:0.4465,NDCG@5:0.3287) [0.8 s]
INFO:root:Epoch 125   loss=0.1887 [19.3 s]    dev=(HR@5:0.4460,NDCG@5:0.3286) [0.9 s]
INFO:root:Epoch 126   loss=0.1893 [19.3 s]    dev=(HR@5:0.4480,NDCG@5:0.3291) [0.9 s]
INFO:root:Epoch 127   loss=0.1871 [19.2 s]    dev=(HR@5:0.4499,NDCG@5:0.3314) [0.9 s]
INFO:root:Epoch 128   loss=0.1885 [19.3 s]    dev=(HR@5:0.4435,NDCG@5:0.3275) [0.8 s]
INFO:root:Epoch 129   loss=0.1890 [19.3 s]    dev=(HR@5:0.4434,NDCG@5:0.3245) [0.8 s]
INFO:root:Epoch 130   loss=0.1861 [19.3 s]    dev=(HR@5:0.4426,NDCG@5:0.3257) [0.9 s]
INFO:root:Early stop at 130 based on dev result.
INFO:root:
Best Iter(dev)=  110	 dev=(HR@5:0.4526,NDCG@5:0.3337) [2614.5 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.4054,NDCG@5:0.2912,HR@10:0.5115,NDCG@10:0.3255,HR@20:0.6350,NDCG@20:0.3567,HR@50:0.8360,NDCG@50:0.3965)
INFO:root:
--------------------------------------------- END: 2024-12-06 10:01:36 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 11:10:03 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5162 [21.4 s]    dev=(HR@5:0.2515,NDCG@5:0.1675) [0.9 s] *
INFO:root:Epoch 2     loss=0.4304 [19.2 s]    dev=(HR@5:0.3224,NDCG@5:0.2191) [0.8 s] *
INFO:root:Epoch 3     loss=0.3932 [19.2 s]    dev=(HR@5:0.3514,NDCG@5:0.2386) [0.9 s] *
INFO:root:Epoch 4     loss=0.3696 [19.2 s]    dev=(HR@5:0.3716,NDCG@5:0.2566) [0.8 s] *
INFO:root:Epoch 5     loss=0.3441 [19.2 s]    dev=(HR@5:0.3915,NDCG@5:0.2746) [0.9 s] *
INFO:root:Epoch 6     loss=0.3181 [19.3 s]    dev=(HR@5:0.4103,NDCG@5:0.2917) [0.8 s] *
INFO:root:Epoch 7     loss=0.2982 [19.1 s]    dev=(HR@5:0.4154,NDCG@5:0.2965) [0.8 s] *
INFO:root:Epoch 8     loss=0.2824 [19.3 s]    dev=(HR@5:0.4201,NDCG@5:0.3028) [0.8 s] *
INFO:root:Epoch 9     loss=0.2687 [19.2 s]    dev=(HR@5:0.4220,NDCG@5:0.3064) [0.8 s] *
INFO:root:Epoch 10    loss=0.2607 [19.2 s]    dev=(HR@5:0.4235,NDCG@5:0.3068) [0.8 s] *
INFO:root:Epoch 11    loss=0.2518 [19.2 s]    dev=(HR@5:0.4299,NDCG@5:0.3118) [0.8 s] *
INFO:root:Epoch 12    loss=0.2451 [19.2 s]    dev=(HR@5:0.4323,NDCG@5:0.3143) [0.8 s] *
INFO:root:Epoch 13    loss=0.2412 [19.2 s]    dev=(HR@5:0.4351,NDCG@5:0.3168) [0.8 s] *
INFO:root:Epoch 14    loss=0.2374 [19.1 s]    dev=(HR@5:0.4336,NDCG@5:0.3149) [0.9 s]
INFO:root:Epoch 15    loss=0.2348 [19.9 s]    dev=(HR@5:0.4310,NDCG@5:0.3130) [0.9 s]
INFO:root:Epoch 16    loss=0.2328 [19.2 s]    dev=(HR@5:0.4340,NDCG@5:0.3150) [0.9 s]
INFO:root:Epoch 17    loss=0.2290 [19.3 s]    dev=(HR@5:0.4329,NDCG@5:0.3123) [0.8 s]
INFO:root:Epoch 18    loss=0.2250 [19.1 s]    dev=(HR@5:0.4389,NDCG@5:0.3186) [0.8 s] *
INFO:root:Epoch 19    loss=0.2238 [19.2 s]    dev=(HR@5:0.4346,NDCG@5:0.3156) [0.8 s]
INFO:root:Epoch 20    loss=0.2208 [19.2 s]    dev=(HR@5:0.4400,NDCG@5:0.3215) [0.9 s] *
INFO:root:Epoch 21    loss=0.2173 [19.1 s]    dev=(HR@5:0.4354,NDCG@5:0.3168) [0.8 s]
INFO:root:Epoch 22    loss=0.2164 [19.2 s]    dev=(HR@5:0.4384,NDCG@5:0.3197) [0.9 s]
INFO:root:Epoch 23    loss=0.2168 [19.3 s]    dev=(HR@5:0.4356,NDCG@5:0.3191) [0.9 s]
INFO:root:Epoch 24    loss=0.2152 [19.1 s]    dev=(HR@5:0.4355,NDCG@5:0.3172) [0.8 s]
INFO:root:Epoch 25    loss=0.2127 [19.2 s]    dev=(HR@5:0.4364,NDCG@5:0.3181) [0.9 s]
INFO:root:Epoch 26    loss=0.2123 [19.3 s]    dev=(HR@5:0.4417,NDCG@5:0.3214) [0.9 s]
INFO:root:Epoch 27    loss=0.2119 [19.2 s]    dev=(HR@5:0.4390,NDCG@5:0.3198) [0.9 s]
INFO:root:Epoch 28    loss=0.2121 [19.1 s]    dev=(HR@5:0.4403,NDCG@5:0.3222) [0.8 s] *
INFO:root:Epoch 29    loss=0.2092 [19.1 s]    dev=(HR@5:0.4358,NDCG@5:0.3198) [0.8 s]
INFO:root:Epoch 30    loss=0.2077 [19.3 s]    dev=(HR@5:0.4331,NDCG@5:0.3164) [0.8 s]
INFO:root:Epoch 31    loss=0.2078 [19.2 s]    dev=(HR@5:0.4411,NDCG@5:0.3232) [0.9 s] *
INFO:root:Epoch 32    loss=0.2078 [19.2 s]    dev=(HR@5:0.4359,NDCG@5:0.3187) [0.9 s]
INFO:root:Epoch 33    loss=0.2073 [19.2 s]    dev=(HR@5:0.4376,NDCG@5:0.3210) [0.8 s]
INFO:root:Epoch 34    loss=0.2060 [19.2 s]    dev=(HR@5:0.4403,NDCG@5:0.3226) [0.8 s]
INFO:root:Epoch 35    loss=0.2072 [19.2 s]    dev=(HR@5:0.4330,NDCG@5:0.3179) [0.8 s]
INFO:root:Epoch 36    loss=0.2050 [19.3 s]    dev=(HR@5:0.4393,NDCG@5:0.3199) [0.9 s]
INFO:root:Epoch 37    loss=0.2052 [19.1 s]    dev=(HR@5:0.4400,NDCG@5:0.3201) [0.9 s]
INFO:root:Epoch 38    loss=0.2046 [19.1 s]    dev=(HR@5:0.4374,NDCG@5:0.3180) [0.9 s]
INFO:root:Epoch 39    loss=0.2048 [19.2 s]    dev=(HR@5:0.4312,NDCG@5:0.3148) [0.9 s]
INFO:root:Epoch 40    loss=0.2040 [19.2 s]    dev=(HR@5:0.4357,NDCG@5:0.3189) [0.9 s]
INFO:root:Epoch 41    loss=0.2051 [19.2 s]    dev=(HR@5:0.4328,NDCG@5:0.3160) [0.9 s]
INFO:root:Epoch 42    loss=0.2042 [19.2 s]    dev=(HR@5:0.4388,NDCG@5:0.3199) [0.9 s]
INFO:root:Epoch 43    loss=0.2025 [19.1 s]    dev=(HR@5:0.4400,NDCG@5:0.3228) [0.9 s]
INFO:root:Epoch 44    loss=0.2043 [19.2 s]    dev=(HR@5:0.4340,NDCG@5:0.3191) [0.9 s]
INFO:root:Epoch 45    loss=0.2006 [19.1 s]    dev=(HR@5:0.4397,NDCG@5:0.3224) [0.9 s]
INFO:root:Epoch 46    loss=0.2024 [19.2 s]    dev=(HR@5:0.4359,NDCG@5:0.3192) [0.9 s]
INFO:root:Epoch 47    loss=0.2023 [19.2 s]    dev=(HR@5:0.4359,NDCG@5:0.3174) [0.9 s]
INFO:root:Epoch 48    loss=0.2020 [19.2 s]    dev=(HR@5:0.4340,NDCG@5:0.3156) [0.9 s]
INFO:root:Epoch 49    loss=0.2007 [19.1 s]    dev=(HR@5:0.4390,NDCG@5:0.3195) [0.9 s]
INFO:root:Epoch 50    loss=0.2023 [19.2 s]    dev=(HR@5:0.4359,NDCG@5:0.3181) [0.9 s]
INFO:root:Epoch 51    loss=0.2013 [19.1 s]    dev=(HR@5:0.4404,NDCG@5:0.3218) [0.9 s]
INFO:root:Early stop at 51 based on dev result.
INFO:root:
Best Iter(dev)=   31	 dev=(HR@5:0.4411,NDCG@5:0.3232) [1025.1 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.3866,NDCG@5:0.2764,HR@10:0.4977,NDCG@10:0.3123,HR@20:0.6177,NDCG@20:0.3426,HR@50:0.8268,NDCG@50:0.3841)
INFO:root:
--------------------------------------------- END: 2024-12-06 11:27:10 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 12:17:46 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [26.5 s]    dev=(HR@5:0.2524,NDCG@5:0.1680) [1.0 s] *
INFO:root:Epoch 2     loss=0.4296 [21.1 s]    dev=(HR@5:0.3265,NDCG@5:0.2215) [1.2 s] *
INFO:root:Epoch 3     loss=0.3915 [19.6 s]    dev=(HR@5:0.3549,NDCG@5:0.2414) [0.9 s] *
INFO:root:Epoch 4     loss=0.3668 [19.2 s]    dev=(HR@5:0.3768,NDCG@5:0.2617) [0.9 s] *
INFO:root:Epoch 5     loss=0.3415 [19.4 s]    dev=(HR@5:0.3955,NDCG@5:0.2783) [0.9 s] *
INFO:root:Epoch 6     loss=0.3165 [19.5 s]    dev=(HR@5:0.4171,NDCG@5:0.2981) [0.9 s] *
INFO:root:Epoch 7     loss=0.2972 [19.2 s]    dev=(HR@5:0.4239,NDCG@5:0.3030) [0.9 s] *
INFO:root:Epoch 8     loss=0.2809 [19.3 s]    dev=(HR@5:0.4288,NDCG@5:0.3101) [0.8 s] *
INFO:root:Epoch 9     loss=0.2661 [19.3 s]    dev=(HR@5:0.4331,NDCG@5:0.3147) [0.9 s] *
INFO:root:Epoch 10    loss=0.2560 [19.1 s]    dev=(HR@5:0.4372,NDCG@5:0.3174) [0.9 s] *
INFO:root:Epoch 11    loss=0.2464 [19.0 s]    dev=(HR@5:0.4459,NDCG@5:0.3231) [0.8 s] *
INFO:root:Epoch 12    loss=0.2375 [19.4 s]    dev=(HR@5:0.4455,NDCG@5:0.3247) [0.9 s] *
INFO:root:Epoch 13    loss=0.2331 [19.9 s]    dev=(HR@5:0.4496,NDCG@5:0.3294) [0.9 s] *
INFO:root:Epoch 14    loss=0.2273 [19.6 s]    dev=(HR@5:0.4488,NDCG@5:0.3265) [0.9 s]
INFO:root:Epoch 15    loss=0.2241 [19.7 s]    dev=(HR@5:0.4483,NDCG@5:0.3252) [0.9 s]
INFO:root:Epoch 16    loss=0.2213 [19.8 s]    dev=(HR@5:0.4516,NDCG@5:0.3282) [0.9 s]
INFO:root:Epoch 17    loss=0.2178 [20.3 s]    dev=(HR@5:0.4489,NDCG@5:0.3270) [0.9 s]
INFO:root:Epoch 18    loss=0.2135 [19.3 s]    dev=(HR@5:0.4541,NDCG@5:0.3320) [0.9 s] *
INFO:root:Epoch 19    loss=0.2120 [19.4 s]    dev=(HR@5:0.4543,NDCG@5:0.3333) [0.9 s] *
INFO:root:Epoch 20    loss=0.2086 [19.5 s]    dev=(HR@5:0.4566,NDCG@5:0.3364) [0.9 s] *
INFO:root:Epoch 21    loss=0.2057 [19.6 s]    dev=(HR@5:0.4550,NDCG@5:0.3332) [0.9 s]
INFO:root:Epoch 22    loss=0.2050 [19.8 s]    dev=(HR@5:0.4549,NDCG@5:0.3338) [0.9 s]
INFO:root:Epoch 23    loss=0.2050 [19.5 s]    dev=(HR@5:0.4513,NDCG@5:0.3316) [0.9 s]
INFO:root:Epoch 24    loss=0.2043 [20.0 s]    dev=(HR@5:0.4543,NDCG@5:0.3328) [0.9 s]
INFO:root:Epoch 25    loss=0.2009 [19.9 s]    dev=(HR@5:0.4532,NDCG@5:0.3329) [0.9 s]
INFO:root:Epoch 26    loss=0.2004 [19.4 s]    dev=(HR@5:0.4529,NDCG@5:0.3336) [0.9 s]
INFO:root:Epoch 27    loss=0.1995 [20.0 s]    dev=(HR@5:0.4554,NDCG@5:0.3358) [0.9 s]
INFO:root:Epoch 28    loss=0.1998 [19.8 s]    dev=(HR@5:0.4597,NDCG@5:0.3391) [0.9 s] *
INFO:root:Epoch 29    loss=0.1976 [19.6 s]    dev=(HR@5:0.4538,NDCG@5:0.3339) [0.9 s]
INFO:root:Epoch 30    loss=0.1959 [19.8 s]    dev=(HR@5:0.4541,NDCG@5:0.3350) [0.9 s]
INFO:root:Epoch 31    loss=0.1958 [19.8 s]    dev=(HR@5:0.4588,NDCG@5:0.3376) [0.9 s]
INFO:root:Epoch 32    loss=0.1950 [19.8 s]    dev=(HR@5:0.4567,NDCG@5:0.3358) [0.9 s]
INFO:root:Epoch 33    loss=0.1948 [19.7 s]    dev=(HR@5:0.4545,NDCG@5:0.3363) [0.9 s]
INFO:root:Epoch 34    loss=0.1942 [19.6 s]    dev=(HR@5:0.4590,NDCG@5:0.3371) [0.8 s]
INFO:root:Epoch 35    loss=0.1947 [19.7 s]    dev=(HR@5:0.4543,NDCG@5:0.3353) [0.9 s]
INFO:root:Epoch 36    loss=0.1922 [19.4 s]    dev=(HR@5:0.4525,NDCG@5:0.3331) [0.9 s]
INFO:root:Epoch 37    loss=0.1929 [20.0 s]    dev=(HR@5:0.4507,NDCG@5:0.3323) [0.9 s]
INFO:root:Epoch 38    loss=0.1928 [19.9 s]    dev=(HR@5:0.4555,NDCG@5:0.3345) [0.9 s]
INFO:root:Epoch 39    loss=0.1927 [19.6 s]    dev=(HR@5:0.4483,NDCG@5:0.3293) [0.9 s]
INFO:root:Epoch 40    loss=0.1924 [19.6 s]    dev=(HR@5:0.4505,NDCG@5:0.3321) [0.9 s]
INFO:root:Epoch 41    loss=0.1931 [19.8 s]    dev=(HR@5:0.4536,NDCG@5:0.3323) [0.8 s]
INFO:root:Epoch 42    loss=0.1917 [19.4 s]    dev=(HR@5:0.4547,NDCG@5:0.3327) [0.9 s]
INFO:root:Epoch 43    loss=0.1901 [19.4 s]    dev=(HR@5:0.4572,NDCG@5:0.3367) [0.9 s]
INFO:root:Epoch 44    loss=0.1924 [19.7 s]    dev=(HR@5:0.4511,NDCG@5:0.3335) [0.9 s]
INFO:root:Epoch 45    loss=0.1888 [19.9 s]    dev=(HR@5:0.4563,NDCG@5:0.3390) [0.9 s]
INFO:root:Epoch 46    loss=0.1906 [19.1 s]    dev=(HR@5:0.4524,NDCG@5:0.3351) [0.9 s]
INFO:root:Epoch 47    loss=0.1900 [20.1 s]    dev=(HR@5:0.4523,NDCG@5:0.3333) [0.9 s]
INFO:root:Epoch 48    loss=0.1899 [20.3 s]    dev=(HR@5:0.4490,NDCG@5:0.3322) [0.9 s]
INFO:root:Early stop at 48 based on dev result.
INFO:root:
Best Iter(dev)=   28	 dev=(HR@5:0.4597,NDCG@5:0.3391) [993.0 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.4081,NDCG@5:0.2930,HR@10:0.5207,NDCG@10:0.3294,HR@20:0.6391,NDCG@20:0.3592,HR@50:0.8437,NDCG@50:0.3998)
INFO:root:
--------------------------------------------- END: 2024-12-06 12:34:22 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 13:16:54 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5166 [22.1 s]    dev=(HR@5:0.2535,NDCG@5:0.1693) [0.9 s] *
INFO:root:Epoch 2     loss=0.4281 [19.0 s]    dev=(HR@5:0.3316,NDCG@5:0.2256) [0.8 s] *
INFO:root:Epoch 3     loss=0.3888 [19.0 s]    dev=(HR@5:0.3624,NDCG@5:0.2491) [0.8 s] *
INFO:root:Epoch 4     loss=0.3631 [19.1 s]    dev=(HR@5:0.3867,NDCG@5:0.2699) [0.9 s] *
INFO:root:Epoch 5     loss=0.3379 [19.2 s]    dev=(HR@5:0.4013,NDCG@5:0.2827) [0.9 s] *
INFO:root:Epoch 6     loss=0.3135 [19.5 s]    dev=(HR@5:0.4176,NDCG@5:0.2997) [0.9 s] *
INFO:root:Epoch 7     loss=0.2946 [19.3 s]    dev=(HR@5:0.4245,NDCG@5:0.3046) [0.9 s] *
INFO:root:Epoch 8     loss=0.2796 [18.9 s]    dev=(HR@5:0.4322,NDCG@5:0.3130) [0.8 s] *
INFO:root:Epoch 9     loss=0.2659 [19.0 s]    dev=(HR@5:0.4357,NDCG@5:0.3156) [0.8 s] *
INFO:root:Epoch 10    loss=0.2573 [19.1 s]    dev=(HR@5:0.4359,NDCG@5:0.3165) [0.9 s] *
INFO:root:Epoch 11    loss=0.2486 [19.0 s]    dev=(HR@5:0.4373,NDCG@5:0.3184) [0.9 s] *
INFO:root:Epoch 12    loss=0.2408 [19.0 s]    dev=(HR@5:0.4385,NDCG@5:0.3190) [0.8 s] *
INFO:root:Epoch 13    loss=0.2373 [19.0 s]    dev=(HR@5:0.4446,NDCG@5:0.3247) [0.9 s] *
INFO:root:Epoch 14    loss=0.2324 [18.9 s]    dev=(HR@5:0.4451,NDCG@5:0.3232) [0.8 s]
INFO:root:Epoch 15    loss=0.2297 [19.0 s]    dev=(HR@5:0.4434,NDCG@5:0.3225) [0.8 s]
INFO:root:Epoch 16    loss=0.2277 [19.1 s]    dev=(HR@5:0.4440,NDCG@5:0.3244) [0.9 s]
INFO:root:Epoch 17    loss=0.2246 [18.9 s]    dev=(HR@5:0.4412,NDCG@5:0.3215) [0.9 s]
INFO:root:Epoch 18    loss=0.2202 [18.9 s]    dev=(HR@5:0.4468,NDCG@5:0.3273) [0.8 s] *
INFO:root:Epoch 19    loss=0.2193 [19.0 s]    dev=(HR@5:0.4468,NDCG@5:0.3273) [0.9 s]
INFO:root:Epoch 20    loss=0.2156 [19.8 s]    dev=(HR@5:0.4472,NDCG@5:0.3284) [0.9 s] *
INFO:root:Epoch 21    loss=0.2129 [19.4 s]    dev=(HR@5:0.4470,NDCG@5:0.3269) [0.8 s]
INFO:root:Epoch 22    loss=0.2123 [19.0 s]    dev=(HR@5:0.4457,NDCG@5:0.3255) [0.9 s]
INFO:root:Epoch 23    loss=0.2133 [19.0 s]    dev=(HR@5:0.4436,NDCG@5:0.3256) [0.9 s]
INFO:root:Epoch 24    loss=0.2127 [18.9 s]    dev=(HR@5:0.4481,NDCG@5:0.3278) [0.8 s]
INFO:root:Epoch 25    loss=0.2090 [19.0 s]    dev=(HR@5:0.4444,NDCG@5:0.3265) [0.8 s]
INFO:root:Epoch 26    loss=0.2088 [19.1 s]    dev=(HR@5:0.4469,NDCG@5:0.3283) [0.8 s]
INFO:root:Epoch 27    loss=0.2086 [18.9 s]    dev=(HR@5:0.4464,NDCG@5:0.3285) [0.9 s] *
INFO:root:Epoch 28    loss=0.2087 [19.0 s]    dev=(HR@5:0.4514,NDCG@5:0.3323) [0.8 s] *
INFO:root:Epoch 29    loss=0.2066 [19.0 s]    dev=(HR@5:0.4492,NDCG@5:0.3296) [0.9 s]
INFO:root:Epoch 30    loss=0.2046 [19.0 s]    dev=(HR@5:0.4451,NDCG@5:0.3280) [0.8 s]
INFO:root:Epoch 31    loss=0.2045 [19.0 s]    dev=(HR@5:0.4498,NDCG@5:0.3311) [0.9 s]
INFO:root:Epoch 32    loss=0.2045 [19.0 s]    dev=(HR@5:0.4474,NDCG@5:0.3270) [0.9 s]
INFO:root:Epoch 33    loss=0.2041 [18.9 s]    dev=(HR@5:0.4479,NDCG@5:0.3294) [0.8 s]
INFO:root:Epoch 34    loss=0.2038 [18.9 s]    dev=(HR@5:0.4468,NDCG@5:0.3295) [0.9 s]
INFO:root:Epoch 35    loss=0.2041 [18.9 s]    dev=(HR@5:0.4458,NDCG@5:0.3266) [0.8 s]
INFO:root:Epoch 36    loss=0.2011 [19.1 s]    dev=(HR@5:0.4452,NDCG@5:0.3256) [0.8 s]
INFO:root:Epoch 37    loss=0.2023 [19.1 s]    dev=(HR@5:0.4427,NDCG@5:0.3253) [0.9 s]
INFO:root:Epoch 38    loss=0.2021 [19.0 s]    dev=(HR@5:0.4487,NDCG@5:0.3291) [0.8 s]
INFO:root:Epoch 39    loss=0.2026 [19.0 s]    dev=(HR@5:0.4382,NDCG@5:0.3209) [0.8 s]
INFO:root:Epoch 40    loss=0.2016 [19.1 s]    dev=(HR@5:0.4420,NDCG@5:0.3239) [0.9 s]
INFO:root:Epoch 41    loss=0.2017 [19.1 s]    dev=(HR@5:0.4426,NDCG@5:0.3234) [0.9 s]
INFO:root:Epoch 42    loss=0.2012 [19.1 s]    dev=(HR@5:0.4487,NDCG@5:0.3285) [0.9 s]
INFO:root:Epoch 43    loss=0.1990 [19.0 s]    dev=(HR@5:0.4476,NDCG@5:0.3292) [0.8 s]
INFO:root:Epoch 44    loss=0.2009 [19.1 s]    dev=(HR@5:0.4442,NDCG@5:0.3259) [0.9 s]
INFO:root:Epoch 45    loss=0.1981 [19.0 s]    dev=(HR@5:0.4457,NDCG@5:0.3283) [0.9 s]
INFO:root:Epoch 46    loss=0.1989 [18.9 s]    dev=(HR@5:0.4427,NDCG@5:0.3258) [0.8 s]
INFO:root:Epoch 47    loss=0.1991 [19.1 s]    dev=(HR@5:0.4450,NDCG@5:0.3258) [0.8 s]
INFO:root:Epoch 48    loss=0.1990 [18.9 s]    dev=(HR@5:0.4410,NDCG@5:0.3236) [0.8 s]
INFO:root:Early stop at 48 based on dev result.
INFO:root:
Best Iter(dev)=   28	 dev=(HR@5:0.4514,NDCG@5:0.3323) [958.4 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.4018,NDCG@5:0.2870,HR@10:0.5103,NDCG@10:0.3221,HR@20:0.6323,NDCG@20:0.3529,HR@50:0.8401,NDCG@50:0.3940)
INFO:root:
--------------------------------------------- END: 2024-12-06 13:32:54 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 14:08:28 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5166 [21.2 s]    dev=(HR@5:0.2550,NDCG@5:0.1703) [0.9 s] *
INFO:root:Epoch 2     loss=0.4272 [19.5 s]    dev=(HR@5:0.3325,NDCG@5:0.2269) [0.9 s] *
INFO:root:Epoch 3     loss=0.3879 [19.3 s]    dev=(HR@5:0.3640,NDCG@5:0.2492) [0.9 s] *
INFO:root:Epoch 4     loss=0.3635 [19.3 s]    dev=(HR@5:0.3844,NDCG@5:0.2662) [0.9 s] *
INFO:root:Epoch 5     loss=0.3409 [19.4 s]    dev=(HR@5:0.3978,NDCG@5:0.2797) [0.9 s] *
INFO:root:Epoch 6     loss=0.3186 [19.3 s]    dev=(HR@5:0.4123,NDCG@5:0.2960) [0.9 s] *
INFO:root:Epoch 7     loss=0.3016 [19.4 s]    dev=(HR@5:0.4162,NDCG@5:0.2993) [0.9 s] *
INFO:root:Epoch 8     loss=0.2874 [19.2 s]    dev=(HR@5:0.4271,NDCG@5:0.3071) [0.9 s] *
INFO:root:Epoch 9     loss=0.2738 [19.2 s]    dev=(HR@5:0.4292,NDCG@5:0.3114) [0.8 s] *
INFO:root:Epoch 10    loss=0.2649 [19.2 s]    dev=(HR@5:0.4303,NDCG@5:0.3122) [0.9 s] *
INFO:root:Epoch 11    loss=0.2558 [19.2 s]    dev=(HR@5:0.4325,NDCG@5:0.3142) [0.8 s] *
INFO:root:Epoch 12    loss=0.2479 [19.3 s]    dev=(HR@5:0.4353,NDCG@5:0.3168) [0.9 s] *
INFO:root:Epoch 13    loss=0.2443 [19.3 s]    dev=(HR@5:0.4390,NDCG@5:0.3212) [0.9 s] *
INFO:root:Epoch 14    loss=0.2395 [19.4 s]    dev=(HR@5:0.4427,NDCG@5:0.3217) [0.9 s] *
INFO:root:Epoch 15    loss=0.2364 [19.2 s]    dev=(HR@5:0.4371,NDCG@5:0.3185) [0.9 s]
INFO:root:Epoch 16    loss=0.2350 [19.2 s]    dev=(HR@5:0.4389,NDCG@5:0.3208) [0.9 s]
INFO:root:Epoch 17    loss=0.2314 [19.3 s]    dev=(HR@5:0.4359,NDCG@5:0.3177) [0.9 s]
INFO:root:Epoch 18    loss=0.2273 [19.3 s]    dev=(HR@5:0.4416,NDCG@5:0.3230) [0.9 s] *
INFO:root:Epoch 19    loss=0.2265 [19.2 s]    dev=(HR@5:0.4383,NDCG@5:0.3208) [0.9 s]
INFO:root:Epoch 20    loss=0.2233 [19.2 s]    dev=(HR@5:0.4400,NDCG@5:0.3239) [0.9 s] *
INFO:root:Epoch 21    loss=0.2200 [20.0 s]    dev=(HR@5:0.4395,NDCG@5:0.3231) [0.9 s]
INFO:root:Epoch 22    loss=0.2200 [19.3 s]    dev=(HR@5:0.4378,NDCG@5:0.3223) [0.9 s]
INFO:root:Epoch 23    loss=0.2206 [19.2 s]    dev=(HR@5:0.4380,NDCG@5:0.3219) [0.9 s]
INFO:root:Epoch 24    loss=0.2200 [19.2 s]    dev=(HR@5:0.4419,NDCG@5:0.3228) [0.8 s]
INFO:root:Epoch 25    loss=0.2165 [19.2 s]    dev=(HR@5:0.4391,NDCG@5:0.3216) [0.9 s]
INFO:root:Epoch 26    loss=0.2167 [19.2 s]    dev=(HR@5:0.4408,NDCG@5:0.3226) [0.9 s]
INFO:root:Epoch 27    loss=0.2171 [19.4 s]    dev=(HR@5:0.4408,NDCG@5:0.3236) [0.9 s]
INFO:root:Epoch 28    loss=0.2167 [19.3 s]    dev=(HR@5:0.4424,NDCG@5:0.3257) [0.9 s] *
INFO:root:Epoch 29    loss=0.2143 [19.3 s]    dev=(HR@5:0.4399,NDCG@5:0.3233) [0.9 s]
INFO:root:Epoch 30    loss=0.2137 [19.3 s]    dev=(HR@5:0.4419,NDCG@5:0.3228) [0.9 s]
INFO:root:Epoch 31    loss=0.2136 [19.2 s]    dev=(HR@5:0.4427,NDCG@5:0.3257) [0.9 s]
INFO:root:Epoch 32    loss=0.2137 [19.3 s]    dev=(HR@5:0.4400,NDCG@5:0.3231) [0.8 s]
INFO:root:Epoch 33    loss=0.2134 [19.3 s]    dev=(HR@5:0.4400,NDCG@5:0.3241) [0.8 s]
INFO:root:Epoch 34    loss=0.2125 [19.2 s]    dev=(HR@5:0.4442,NDCG@5:0.3262) [0.9 s] *
INFO:root:Epoch 35    loss=0.2135 [19.2 s]    dev=(HR@5:0.4378,NDCG@5:0.3201) [0.9 s]
INFO:root:Epoch 36    loss=0.2109 [19.3 s]    dev=(HR@5:0.4413,NDCG@5:0.3228) [0.8 s]
INFO:root:Epoch 37    loss=0.2121 [19.2 s]    dev=(HR@5:0.4403,NDCG@5:0.3208) [0.9 s]
INFO:root:Epoch 38    loss=0.2120 [19.3 s]    dev=(HR@5:0.4387,NDCG@5:0.3212) [0.9 s]
INFO:root:Epoch 39    loss=0.2126 [19.2 s]    dev=(HR@5:0.4367,NDCG@5:0.3175) [0.9 s]
INFO:root:Epoch 40    loss=0.2116 [19.3 s]    dev=(HR@5:0.4377,NDCG@5:0.3191) [0.9 s]
INFO:root:Epoch 41    loss=0.2115 [19.3 s]    dev=(HR@5:0.4361,NDCG@5:0.3173) [0.9 s]
INFO:root:Epoch 42    loss=0.2112 [19.3 s]    dev=(HR@5:0.4434,NDCG@5:0.3224) [0.9 s]
INFO:root:Epoch 43    loss=0.2097 [19.2 s]    dev=(HR@5:0.4436,NDCG@5:0.3242) [0.9 s]
INFO:root:Epoch 44    loss=0.2109 [19.3 s]    dev=(HR@5:0.4369,NDCG@5:0.3183) [0.9 s]
INFO:root:Epoch 45    loss=0.2076 [19.5 s]    dev=(HR@5:0.4434,NDCG@5:0.3240) [0.9 s]
INFO:root:Epoch 46    loss=0.2096 [19.3 s]    dev=(HR@5:0.4392,NDCG@5:0.3207) [0.8 s]
INFO:root:Epoch 47    loss=0.2093 [19.3 s]    dev=(HR@5:0.4398,NDCG@5:0.3215) [0.9 s]
INFO:root:Epoch 48    loss=0.2089 [19.2 s]    dev=(HR@5:0.4365,NDCG@5:0.3181) [0.9 s]
INFO:root:Epoch 49    loss=0.2081 [19.3 s]    dev=(HR@5:0.4421,NDCG@5:0.3230) [0.9 s]
INFO:root:Epoch 50    loss=0.2091 [19.3 s]    dev=(HR@5:0.4400,NDCG@5:0.3215) [0.9 s]
INFO:root:Epoch 51    loss=0.2078 [19.2 s]    dev=(HR@5:0.4455,NDCG@5:0.3263) [0.9 s] *
INFO:root:Epoch 52    loss=0.2074 [19.3 s]    dev=(HR@5:0.4392,NDCG@5:0.3200) [0.9 s]
INFO:root:Epoch 53    loss=0.2070 [19.3 s]    dev=(HR@5:0.4408,NDCG@5:0.3221) [0.9 s]
INFO:root:Epoch 54    loss=0.2051 [19.2 s]    dev=(HR@5:0.4413,NDCG@5:0.3211) [0.9 s]
INFO:root:Epoch 55    loss=0.2053 [19.3 s]    dev=(HR@5:0.4393,NDCG@5:0.3201) [0.9 s]
INFO:root:Epoch 56    loss=0.2051 [19.3 s]    dev=(HR@5:0.4409,NDCG@5:0.3225) [0.8 s]
INFO:root:Epoch 57    loss=0.2052 [19.2 s]    dev=(HR@5:0.4411,NDCG@5:0.3223) [0.9 s]
INFO:root:Epoch 58    loss=0.2066 [19.3 s]    dev=(HR@5:0.4429,NDCG@5:0.3252) [0.8 s]
INFO:root:Epoch 59    loss=0.2059 [19.3 s]    dev=(HR@5:0.4402,NDCG@5:0.3216) [0.9 s]
INFO:root:Epoch 60    loss=0.2051 [19.2 s]    dev=(HR@5:0.4425,NDCG@5:0.3233) [0.9 s]
INFO:root:Epoch 61    loss=0.2057 [19.3 s]    dev=(HR@5:0.4438,NDCG@5:0.3246) [0.9 s]
INFO:root:Epoch 62    loss=0.2041 [19.3 s]    dev=(HR@5:0.4413,NDCG@5:0.3217) [0.9 s]
INFO:root:Epoch 63    loss=0.2055 [19.2 s]    dev=(HR@5:0.4437,NDCG@5:0.3225) [0.8 s]
INFO:root:Epoch 64    loss=0.2034 [19.3 s]    dev=(HR@5:0.4393,NDCG@5:0.3203) [0.9 s]
INFO:root:Epoch 65    loss=0.2044 [19.2 s]    dev=(HR@5:0.4378,NDCG@5:0.3201) [0.8 s]
INFO:root:Epoch 66    loss=0.2028 [19.2 s]    dev=(HR@5:0.4383,NDCG@5:0.3192) [0.9 s]
INFO:root:Epoch 67    loss=0.2038 [19.2 s]    dev=(HR@5:0.4382,NDCG@5:0.3193) [0.9 s]
INFO:root:Epoch 68    loss=0.2018 [19.2 s]    dev=(HR@5:0.4391,NDCG@5:0.3193) [0.9 s]
INFO:root:Epoch 69    loss=0.2036 [19.2 s]    dev=(HR@5:0.4408,NDCG@5:0.3197) [0.9 s]
INFO:root:Epoch 70    loss=0.2027 [19.2 s]    dev=(HR@5:0.4396,NDCG@5:0.3222) [0.9 s]
INFO:root:Epoch 71    loss=0.2024 [19.2 s]    dev=(HR@5:0.4384,NDCG@5:0.3215) [0.9 s]
INFO:root:Early stop at 71 based on dev result.
INFO:root:
Best Iter(dev)=   51	 dev=(HR@5:0.4455,NDCG@5:0.3263) [1431.5 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.4000,NDCG@5:0.2844,HR@10:0.5105,NDCG@10:0.3202,HR@20:0.6340,NDCG@20:0.3514,HR@50:0.8412,NDCG@50:0.3924)
INFO:root:
--------------------------------------------- END: 2024-12-06 14:32:21 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 15:20:21 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5152 [21.6 s]    dev=(HR@5:0.2529,NDCG@5:0.1682) [0.9 s] *
INFO:root:Epoch 2     loss=0.4312 [19.5 s]    dev=(HR@5:0.3216,NDCG@5:0.2170) [0.9 s] *
INFO:root:Epoch 3     loss=0.3962 [19.5 s]    dev=(HR@5:0.3463,NDCG@5:0.2341) [0.9 s] *
INFO:root:Epoch 4     loss=0.3738 [19.4 s]    dev=(HR@5:0.3652,NDCG@5:0.2515) [0.9 s] *
INFO:root:Epoch 5     loss=0.3512 [19.4 s]    dev=(HR@5:0.3784,NDCG@5:0.2651) [0.9 s] *
INFO:root:Epoch 6     loss=0.3293 [19.4 s]    dev=(HR@5:0.3947,NDCG@5:0.2809) [0.9 s] *
INFO:root:Epoch 7     loss=0.3113 [19.3 s]    dev=(HR@5:0.3970,NDCG@5:0.2836) [0.9 s] *
INFO:root:Epoch 8     loss=0.2963 [19.3 s]    dev=(HR@5:0.4028,NDCG@5:0.2903) [0.9 s] *
INFO:root:Epoch 9     loss=0.2814 [19.4 s]    dev=(HR@5:0.4058,NDCG@5:0.2932) [0.9 s] *
INFO:root:Epoch 10    loss=0.2716 [19.5 s]    dev=(HR@5:0.4088,NDCG@5:0.2957) [0.9 s] *
INFO:root:Epoch 11    loss=0.2615 [19.4 s]    dev=(HR@5:0.4161,NDCG@5:0.2992) [0.9 s] *
INFO:root:Epoch 12    loss=0.2525 [19.5 s]    dev=(HR@5:0.4205,NDCG@5:0.3053) [0.9 s] *
INFO:root:Epoch 13    loss=0.2489 [19.4 s]    dev=(HR@5:0.4269,NDCG@5:0.3091) [0.9 s] *
INFO:root:Epoch 14    loss=0.2441 [19.3 s]    dev=(HR@5:0.4201,NDCG@5:0.3038) [0.9 s]
INFO:root:Epoch 15    loss=0.2409 [19.3 s]    dev=(HR@5:0.4262,NDCG@5:0.3074) [0.9 s]
INFO:root:Epoch 16    loss=0.2376 [19.4 s]    dev=(HR@5:0.4257,NDCG@5:0.3070) [0.9 s]
INFO:root:Epoch 17    loss=0.2345 [19.5 s]    dev=(HR@5:0.4220,NDCG@5:0.3066) [0.9 s]
INFO:root:Epoch 18    loss=0.2295 [19.3 s]    dev=(HR@5:0.4253,NDCG@5:0.3080) [0.9 s]
INFO:root:Epoch 19    loss=0.2275 [19.3 s]    dev=(HR@5:0.4272,NDCG@5:0.3112) [0.9 s] *
INFO:root:Epoch 20    loss=0.2255 [19.4 s]    dev=(HR@5:0.4301,NDCG@5:0.3124) [0.9 s] *
INFO:root:Epoch 21    loss=0.2218 [19.4 s]    dev=(HR@5:0.4312,NDCG@5:0.3118) [0.9 s]
INFO:root:Epoch 22    loss=0.2211 [19.3 s]    dev=(HR@5:0.4253,NDCG@5:0.3094) [0.9 s]
INFO:root:Epoch 23    loss=0.2216 [19.4 s]    dev=(HR@5:0.4265,NDCG@5:0.3108) [0.8 s]
INFO:root:Epoch 24    loss=0.2204 [19.3 s]    dev=(HR@5:0.4348,NDCG@5:0.3151) [0.9 s] *
INFO:root:Epoch 25    loss=0.2168 [19.3 s]    dev=(HR@5:0.4293,NDCG@5:0.3122) [0.9 s]
INFO:root:Epoch 26    loss=0.2176 [19.4 s]    dev=(HR@5:0.4373,NDCG@5:0.3167) [0.9 s] *
INFO:root:Epoch 27    loss=0.2168 [19.4 s]    dev=(HR@5:0.4308,NDCG@5:0.3127) [0.9 s]
INFO:root:Epoch 28    loss=0.2167 [19.4 s]    dev=(HR@5:0.4370,NDCG@5:0.3179) [0.9 s] *
INFO:root:Epoch 29    loss=0.2141 [19.5 s]    dev=(HR@5:0.4334,NDCG@5:0.3149) [0.9 s]
INFO:root:Epoch 30    loss=0.2139 [19.4 s]    dev=(HR@5:0.4294,NDCG@5:0.3143) [0.8 s]
INFO:root:Epoch 31    loss=0.2124 [19.5 s]    dev=(HR@5:0.4351,NDCG@5:0.3196) [0.9 s] *
INFO:root:Epoch 32    loss=0.2140 [19.4 s]    dev=(HR@5:0.4321,NDCG@5:0.3150) [0.9 s]
INFO:root:Epoch 33    loss=0.2124 [19.4 s]    dev=(HR@5:0.4321,NDCG@5:0.3157) [0.9 s]
INFO:root:Epoch 34    loss=0.2120 [19.4 s]    dev=(HR@5:0.4330,NDCG@5:0.3150) [0.9 s]
INFO:root:Epoch 35    loss=0.2122 [19.5 s]    dev=(HR@5:0.4307,NDCG@5:0.3116) [0.9 s]
INFO:root:Epoch 36    loss=0.2104 [19.3 s]    dev=(HR@5:0.4349,NDCG@5:0.3155) [0.9 s]
INFO:root:Epoch 37    loss=0.2104 [19.4 s]    dev=(HR@5:0.4336,NDCG@5:0.3139) [0.9 s]
INFO:root:Epoch 38    loss=0.2104 [19.4 s]    dev=(HR@5:0.4357,NDCG@5:0.3165) [0.9 s]
INFO:root:Epoch 39    loss=0.2113 [19.3 s]    dev=(HR@5:0.4294,NDCG@5:0.3113) [0.9 s]
INFO:root:Epoch 40    loss=0.2105 [19.4 s]    dev=(HR@5:0.4334,NDCG@5:0.3150) [0.9 s]
INFO:root:Epoch 41    loss=0.2115 [19.4 s]    dev=(HR@5:0.4325,NDCG@5:0.3136) [0.9 s]
INFO:root:Epoch 42    loss=0.2117 [19.3 s]    dev=(HR@5:0.4323,NDCG@5:0.3142) [0.9 s]
INFO:root:Epoch 43    loss=0.2095 [19.4 s]    dev=(HR@5:0.4355,NDCG@5:0.3187) [0.9 s]
INFO:root:Epoch 44    loss=0.2111 [19.4 s]    dev=(HR@5:0.4329,NDCG@5:0.3155) [0.9 s]
INFO:root:Epoch 45    loss=0.2072 [19.4 s]    dev=(HR@5:0.4349,NDCG@5:0.3190) [0.9 s]
INFO:root:Epoch 46    loss=0.2088 [19.5 s]    dev=(HR@5:0.4299,NDCG@5:0.3143) [0.9 s]
INFO:root:Epoch 47    loss=0.2093 [19.4 s]    dev=(HR@5:0.4338,NDCG@5:0.3148) [0.9 s]
INFO:root:Epoch 48    loss=0.2086 [19.3 s]    dev=(HR@5:0.4329,NDCG@5:0.3140) [0.9 s]
INFO:root:Epoch 49    loss=0.2071 [19.3 s]    dev=(HR@5:0.4376,NDCG@5:0.3181) [0.9 s]
INFO:root:Epoch 50    loss=0.2080 [19.4 s]    dev=(HR@5:0.4314,NDCG@5:0.3160) [0.9 s]
INFO:root:Epoch 51    loss=0.2068 [19.4 s]    dev=(HR@5:0.4375,NDCG@5:0.3179) [0.9 s]
INFO:root:Early stop at 51 based on dev result.
INFO:root:
Best Iter(dev)=   31	 dev=(HR@5:0.4351,NDCG@5:0.3196) [1035.0 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.3844,NDCG@5:0.2749,HR@10:0.4926,NDCG@10:0.3099,HR@20:0.6168,NDCG@20:0.3411,HR@50:0.8261,NDCG@50:0.3825)
INFO:root:
--------------------------------------------- END: 2024-12-06 15:37:38 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 16:34:30 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5151 [21.3 s]    dev=(HR@5:0.2548,NDCG@5:0.1702) [0.9 s] *
INFO:root:Epoch 2     loss=0.4264 [19.3 s]    dev=(HR@5:0.3286,NDCG@5:0.2233) [0.9 s] *
INFO:root:Epoch 3     loss=0.3890 [19.3 s]    dev=(HR@5:0.3576,NDCG@5:0.2422) [0.9 s] *
INFO:root:Epoch 4     loss=0.3655 [19.4 s]    dev=(HR@5:0.3760,NDCG@5:0.2599) [0.9 s] *
INFO:root:Epoch 5     loss=0.3420 [19.3 s]    dev=(HR@5:0.3949,NDCG@5:0.2770) [0.9 s] *
INFO:root:Epoch 6     loss=0.3185 [19.3 s]    dev=(HR@5:0.4102,NDCG@5:0.2922) [0.9 s] *
INFO:root:Epoch 7     loss=0.3007 [19.3 s]    dev=(HR@5:0.4156,NDCG@5:0.2954) [0.9 s] *
INFO:root:Epoch 8     loss=0.2857 [19.3 s]    dev=(HR@5:0.4225,NDCG@5:0.3031) [0.9 s] *
INFO:root:Epoch 9     loss=0.2717 [19.3 s]    dev=(HR@5:0.4263,NDCG@5:0.3062) [0.9 s] *
INFO:root:Epoch 10    loss=0.2613 [19.3 s]    dev=(HR@5:0.4290,NDCG@5:0.3090) [0.9 s] *
INFO:root:Epoch 11    loss=0.2500 [19.3 s]    dev=(HR@5:0.4350,NDCG@5:0.3144) [0.9 s] *
INFO:root:Epoch 12    loss=0.2415 [19.4 s]    dev=(HR@5:0.4372,NDCG@5:0.3184) [0.9 s] *
INFO:root:Epoch 13    loss=0.2364 [19.3 s]    dev=(HR@5:0.4445,NDCG@5:0.3237) [0.9 s] *
INFO:root:Epoch 14    loss=0.2312 [19.4 s]    dev=(HR@5:0.4417,NDCG@5:0.3217) [0.9 s]
INFO:root:Epoch 15    loss=0.2266 [19.2 s]    dev=(HR@5:0.4430,NDCG@5:0.3229) [0.9 s]
INFO:root:Epoch 16    loss=0.2231 [19.4 s]    dev=(HR@5:0.4431,NDCG@5:0.3237) [0.9 s] *
INFO:root:Epoch 17    loss=0.2192 [19.3 s]    dev=(HR@5:0.4421,NDCG@5:0.3216) [0.9 s]
INFO:root:Epoch 18    loss=0.2143 [19.4 s]    dev=(HR@5:0.4440,NDCG@5:0.3244) [0.9 s] *
INFO:root:Epoch 19    loss=0.2117 [19.3 s]    dev=(HR@5:0.4468,NDCG@5:0.3263) [0.9 s] *
INFO:root:Epoch 20    loss=0.2094 [19.4 s]    dev=(HR@5:0.4510,NDCG@5:0.3297) [0.9 s] *
INFO:root:Epoch 21    loss=0.2059 [19.2 s]    dev=(HR@5:0.4485,NDCG@5:0.3280) [0.9 s]
INFO:root:Epoch 22    loss=0.2050 [19.4 s]    dev=(HR@5:0.4496,NDCG@5:0.3291) [0.9 s]
INFO:root:Epoch 23    loss=0.2057 [19.3 s]    dev=(HR@5:0.4433,NDCG@5:0.3268) [0.9 s]
INFO:root:Epoch 24    loss=0.2053 [19.3 s]    dev=(HR@5:0.4462,NDCG@5:0.3262) [0.8 s]
INFO:root:Epoch 25    loss=0.2007 [19.4 s]    dev=(HR@5:0.4448,NDCG@5:0.3249) [0.9 s]
INFO:root:Epoch 26    loss=0.2017 [19.3 s]    dev=(HR@5:0.4487,NDCG@5:0.3286) [0.9 s]
INFO:root:Epoch 27    loss=0.2008 [19.4 s]    dev=(HR@5:0.4486,NDCG@5:0.3286) [0.9 s]
INFO:root:Epoch 28    loss=0.2008 [19.4 s]    dev=(HR@5:0.4524,NDCG@5:0.3322) [0.9 s] *
INFO:root:Epoch 29    loss=0.1985 [19.5 s]    dev=(HR@5:0.4462,NDCG@5:0.3261) [0.8 s]
INFO:root:Epoch 30    loss=0.1988 [19.4 s]    dev=(HR@5:0.4444,NDCG@5:0.3267) [0.9 s]
INFO:root:Epoch 31    loss=0.1971 [19.3 s]    dev=(HR@5:0.4504,NDCG@5:0.3313) [0.9 s]
INFO:root:Epoch 32    loss=0.1978 [19.4 s]    dev=(HR@5:0.4487,NDCG@5:0.3285) [0.9 s]
INFO:root:Epoch 33    loss=0.1976 [19.3 s]    dev=(HR@5:0.4500,NDCG@5:0.3309) [0.9 s]
INFO:root:Epoch 34    loss=0.1967 [19.4 s]    dev=(HR@5:0.4470,NDCG@5:0.3265) [0.8 s]
INFO:root:Epoch 35    loss=0.1976 [19.4 s]    dev=(HR@5:0.4428,NDCG@5:0.3235) [0.9 s]
INFO:root:Epoch 36    loss=0.1951 [19.3 s]    dev=(HR@5:0.4454,NDCG@5:0.3263) [0.9 s]
INFO:root:Epoch 37    loss=0.1962 [19.4 s]    dev=(HR@5:0.4481,NDCG@5:0.3273) [0.9 s]
INFO:root:Epoch 38    loss=0.1952 [19.3 s]    dev=(HR@5:0.4476,NDCG@5:0.3255) [0.9 s]
INFO:root:Epoch 39    loss=0.1959 [19.3 s]    dev=(HR@5:0.4426,NDCG@5:0.3219) [0.9 s]
INFO:root:Epoch 40    loss=0.1952 [19.3 s]    dev=(HR@5:0.4457,NDCG@5:0.3264) [0.9 s]
INFO:root:Epoch 41    loss=0.1959 [19.3 s]    dev=(HR@5:0.4469,NDCG@5:0.3248) [0.9 s]
INFO:root:Epoch 42    loss=0.1959 [19.3 s]    dev=(HR@5:0.4494,NDCG@5:0.3290) [0.9 s]
INFO:root:Epoch 43    loss=0.1936 [19.3 s]    dev=(HR@5:0.4473,NDCG@5:0.3279) [0.9 s]
INFO:root:Epoch 44    loss=0.1958 [19.4 s]    dev=(HR@5:0.4438,NDCG@5:0.3251) [0.9 s]
INFO:root:Epoch 45    loss=0.1921 [19.3 s]    dev=(HR@5:0.4505,NDCG@5:0.3302) [0.9 s]
INFO:root:Epoch 46    loss=0.1943 [19.4 s]    dev=(HR@5:0.4460,NDCG@5:0.3263) [0.9 s]
INFO:root:Epoch 47    loss=0.1942 [19.4 s]    dev=(HR@5:0.4460,NDCG@5:0.3258) [0.9 s]
INFO:root:Epoch 48    loss=0.1941 [19.4 s]    dev=(HR@5:0.4449,NDCG@5:0.3248) [0.9 s]
INFO:root:Early stop at 48 based on dev result.
INFO:root:
Best Iter(dev)=   28	 dev=(HR@5:0.4524,NDCG@5:0.3322) [971.6 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.4022,NDCG@5:0.2870,HR@10:0.5109,NDCG@10:0.3222,HR@20:0.6316,NDCG@20:0.3527,HR@50:0.8361,NDCG@50:0.3932)
INFO:root:
--------------------------------------------- END: 2024-12-06 16:50:43 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 17:27:38 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5153 [21.5 s]    dev=(HR@5:0.2557,NDCG@5:0.1711) [0.9 s] *
INFO:root:Epoch 2     loss=0.4254 [19.4 s]    dev=(HR@5:0.3317,NDCG@5:0.2255) [0.9 s] *
INFO:root:Epoch 3     loss=0.3869 [19.4 s]    dev=(HR@5:0.3628,NDCG@5:0.2477) [0.9 s] *
INFO:root:Epoch 4     loss=0.3611 [19.5 s]    dev=(HR@5:0.3853,NDCG@5:0.2689) [0.9 s] *
INFO:root:Epoch 5     loss=0.3355 [19.3 s]    dev=(HR@5:0.4028,NDCG@5:0.2865) [0.9 s] *
INFO:root:Epoch 6     loss=0.3108 [19.5 s]    dev=(HR@5:0.4198,NDCG@5:0.2999) [0.9 s] *
INFO:root:Epoch 7     loss=0.2929 [19.3 s]    dev=(HR@5:0.4237,NDCG@5:0.3024) [0.9 s] *
INFO:root:Epoch 8     loss=0.2782 [19.3 s]    dev=(HR@5:0.4286,NDCG@5:0.3099) [0.9 s] *
INFO:root:Epoch 9     loss=0.2649 [19.3 s]    dev=(HR@5:0.4359,NDCG@5:0.3149) [0.9 s] *
INFO:root:Epoch 10    loss=0.2550 [19.5 s]    dev=(HR@5:0.4353,NDCG@5:0.3169) [0.9 s] *
INFO:root:Epoch 11    loss=0.2458 [19.5 s]    dev=(HR@5:0.4385,NDCG@5:0.3180) [0.9 s] *
INFO:root:Epoch 12    loss=0.2379 [19.5 s]    dev=(HR@5:0.4383,NDCG@5:0.3199) [0.9 s] *
INFO:root:Epoch 13    loss=0.2337 [19.5 s]    dev=(HR@5:0.4462,NDCG@5:0.3259) [0.9 s] *
INFO:root:Epoch 14    loss=0.2297 [19.4 s]    dev=(HR@5:0.4472,NDCG@5:0.3254) [0.9 s]
INFO:root:Epoch 15    loss=0.2263 [19.3 s]    dev=(HR@5:0.4442,NDCG@5:0.3230) [0.9 s]
INFO:root:Epoch 16    loss=0.2228 [19.4 s]    dev=(HR@5:0.4461,NDCG@5:0.3263) [0.9 s] *
INFO:root:Epoch 17    loss=0.2193 [19.4 s]    dev=(HR@5:0.4445,NDCG@5:0.3239) [0.9 s]
INFO:root:Epoch 18    loss=0.2155 [19.4 s]    dev=(HR@5:0.4439,NDCG@5:0.3269) [0.9 s] *
INFO:root:Epoch 19    loss=0.2131 [19.4 s]    dev=(HR@5:0.4457,NDCG@5:0.3278) [0.9 s] *
INFO:root:Epoch 20    loss=0.2106 [19.4 s]    dev=(HR@5:0.4505,NDCG@5:0.3309) [0.8 s] *
INFO:root:Epoch 21    loss=0.2076 [19.4 s]    dev=(HR@5:0.4481,NDCG@5:0.3293) [0.9 s]
INFO:root:Epoch 22    loss=0.2072 [19.4 s]    dev=(HR@5:0.4479,NDCG@5:0.3307) [0.9 s]
INFO:root:Epoch 23    loss=0.2077 [19.3 s]    dev=(HR@5:0.4425,NDCG@5:0.3259) [0.9 s]
INFO:root:Epoch 24    loss=0.2068 [19.3 s]    dev=(HR@5:0.4460,NDCG@5:0.3263) [0.9 s]
INFO:root:Epoch 25    loss=0.2028 [19.4 s]    dev=(HR@5:0.4465,NDCG@5:0.3259) [0.9 s]
INFO:root:Epoch 26    loss=0.2035 [19.3 s]    dev=(HR@5:0.4485,NDCG@5:0.3289) [0.9 s]
INFO:root:Epoch 27    loss=0.2029 [19.5 s]    dev=(HR@5:0.4480,NDCG@5:0.3294) [0.9 s]
INFO:root:Epoch 28    loss=0.2032 [19.4 s]    dev=(HR@5:0.4541,NDCG@5:0.3328) [0.9 s] *
INFO:root:Epoch 29    loss=0.2013 [19.4 s]    dev=(HR@5:0.4477,NDCG@5:0.3289) [0.9 s]
INFO:root:Epoch 30    loss=0.2003 [19.4 s]    dev=(HR@5:0.4502,NDCG@5:0.3314) [0.9 s]
INFO:root:Epoch 31    loss=0.1993 [19.4 s]    dev=(HR@5:0.4526,NDCG@5:0.3331) [0.9 s] *
INFO:root:Epoch 32    loss=0.1992 [19.4 s]    dev=(HR@5:0.4540,NDCG@5:0.3325) [0.9 s]
INFO:root:Epoch 33    loss=0.1992 [19.5 s]    dev=(HR@5:0.4492,NDCG@5:0.3317) [0.9 s]
INFO:root:Epoch 34    loss=0.1985 [19.4 s]    dev=(HR@5:0.4457,NDCG@5:0.3270) [0.9 s]
INFO:root:Epoch 35    loss=0.1987 [19.3 s]    dev=(HR@5:0.4471,NDCG@5:0.3275) [0.9 s]
INFO:root:Epoch 36    loss=0.1962 [19.4 s]    dev=(HR@5:0.4509,NDCG@5:0.3305) [0.9 s]
INFO:root:Epoch 37    loss=0.1973 [19.5 s]    dev=(HR@5:0.4504,NDCG@5:0.3297) [0.9 s]
INFO:root:Epoch 38    loss=0.1971 [19.4 s]    dev=(HR@5:0.4489,NDCG@5:0.3285) [0.8 s]
INFO:root:Epoch 39    loss=0.1970 [19.4 s]    dev=(HR@5:0.4441,NDCG@5:0.3241) [0.9 s]
INFO:root:Epoch 40    loss=0.1962 [19.5 s]    dev=(HR@5:0.4460,NDCG@5:0.3275) [0.9 s]
INFO:root:Epoch 41    loss=0.1959 [19.4 s]    dev=(HR@5:0.4464,NDCG@5:0.3253) [0.9 s]
INFO:root:Epoch 42    loss=0.1959 [19.4 s]    dev=(HR@5:0.4477,NDCG@5:0.3280) [0.9 s]
INFO:root:Epoch 43    loss=0.1942 [19.4 s]    dev=(HR@5:0.4492,NDCG@5:0.3299) [0.8 s]
INFO:root:Epoch 44    loss=0.1953 [19.3 s]    dev=(HR@5:0.4474,NDCG@5:0.3275) [0.9 s]
INFO:root:Epoch 45    loss=0.1939 [19.3 s]    dev=(HR@5:0.4520,NDCG@5:0.3322) [0.9 s]
INFO:root:Epoch 46    loss=0.1942 [19.4 s]    dev=(HR@5:0.4460,NDCG@5:0.3263) [0.9 s]
INFO:root:Epoch 47    loss=0.1942 [19.4 s]    dev=(HR@5:0.4443,NDCG@5:0.3261) [0.9 s]
INFO:root:Epoch 48    loss=0.1936 [19.3 s]    dev=(HR@5:0.4434,NDCG@5:0.3254) [0.9 s]
INFO:root:Epoch 49    loss=0.1923 [19.6 s]    dev=(HR@5:0.4490,NDCG@5:0.3294) [0.9 s]
INFO:root:Epoch 50    loss=0.1947 [19.4 s]    dev=(HR@5:0.4460,NDCG@5:0.3284) [0.9 s]
INFO:root:Epoch 51    loss=0.1930 [19.4 s]    dev=(HR@5:0.4485,NDCG@5:0.3288) [0.9 s]
INFO:root:Early stop at 51 based on dev result.
INFO:root:
Best Iter(dev)=   31	 dev=(HR@5:0.4526,NDCG@5:0.3331) [1035.4 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.4039,NDCG@5:0.2893,HR@10:0.5105,NDCG@10:0.3238,HR@20:0.6314,NDCG@20:0.3541,HR@50:0.8364,NDCG@50:0.3947)
INFO:root:
--------------------------------------------- END: 2024-12-06 17:44:56 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 18:23:53 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5154 [21.5 s]    dev=(HR@5:0.2584,NDCG@5:0.1733) [0.9 s] *
INFO:root:Epoch 2     loss=0.4240 [19.4 s]    dev=(HR@5:0.3357,NDCG@5:0.2280) [0.9 s] *
INFO:root:Epoch 3     loss=0.3860 [19.4 s]    dev=(HR@5:0.3631,NDCG@5:0.2488) [0.8 s] *
INFO:root:Epoch 4     loss=0.3601 [19.3 s]    dev=(HR@5:0.3868,NDCG@5:0.2703) [0.9 s] *
INFO:root:Epoch 5     loss=0.3349 [19.2 s]    dev=(HR@5:0.4039,NDCG@5:0.2866) [0.9 s] *
INFO:root:Epoch 6     loss=0.3114 [19.3 s]    dev=(HR@5:0.4216,NDCG@5:0.3007) [0.9 s] *
INFO:root:Epoch 7     loss=0.2942 [19.4 s]    dev=(HR@5:0.4203,NDCG@5:0.3018) [0.9 s] *
INFO:root:Epoch 8     loss=0.2797 [19.4 s]    dev=(HR@5:0.4288,NDCG@5:0.3108) [0.9 s] *
INFO:root:Epoch 9     loss=0.2660 [19.4 s]    dev=(HR@5:0.4311,NDCG@5:0.3136) [0.8 s] *
INFO:root:Epoch 10    loss=0.2567 [19.4 s]    dev=(HR@5:0.4362,NDCG@5:0.3186) [0.9 s] *
INFO:root:Epoch 11    loss=0.2463 [19.4 s]    dev=(HR@5:0.4395,NDCG@5:0.3196) [0.9 s] *
INFO:root:Epoch 12    loss=0.2376 [19.3 s]    dev=(HR@5:0.4427,NDCG@5:0.3238) [0.8 s] *
INFO:root:Epoch 13    loss=0.2329 [19.5 s]    dev=(HR@5:0.4462,NDCG@5:0.3276) [0.8 s] *
INFO:root:Epoch 14    loss=0.2287 [19.4 s]    dev=(HR@5:0.4481,NDCG@5:0.3275) [0.9 s]
INFO:root:Epoch 15    loss=0.2248 [19.4 s]    dev=(HR@5:0.4449,NDCG@5:0.3253) [0.9 s]
INFO:root:Epoch 16    loss=0.2215 [19.4 s]    dev=(HR@5:0.4500,NDCG@5:0.3291) [0.9 s] *
INFO:root:Epoch 17    loss=0.2176 [19.4 s]    dev=(HR@5:0.4495,NDCG@5:0.3286) [0.9 s]
INFO:root:Epoch 18    loss=0.2139 [19.4 s]    dev=(HR@5:0.4470,NDCG@5:0.3293) [0.9 s] *
INFO:root:Epoch 19    loss=0.2119 [19.4 s]    dev=(HR@5:0.4489,NDCG@5:0.3295) [0.9 s] *
INFO:root:Epoch 20    loss=0.2094 [19.3 s]    dev=(HR@5:0.4525,NDCG@5:0.3331) [0.9 s] *
INFO:root:Epoch 21    loss=0.2062 [19.4 s]    dev=(HR@5:0.4532,NDCG@5:0.3329) [0.9 s]
INFO:root:Epoch 22    loss=0.2064 [19.4 s]    dev=(HR@5:0.4470,NDCG@5:0.3305) [0.9 s]
INFO:root:Epoch 23    loss=0.2066 [19.3 s]    dev=(HR@5:0.4487,NDCG@5:0.3314) [0.9 s]
INFO:root:Epoch 24    loss=0.2059 [19.4 s]    dev=(HR@5:0.4507,NDCG@5:0.3299) [0.9 s]
INFO:root:Epoch 25    loss=0.2015 [19.5 s]    dev=(HR@5:0.4486,NDCG@5:0.3284) [0.9 s]
INFO:root:Epoch 26    loss=0.2025 [19.4 s]    dev=(HR@5:0.4472,NDCG@5:0.3299) [0.9 s]
INFO:root:Epoch 27    loss=0.2025 [19.5 s]    dev=(HR@5:0.4508,NDCG@5:0.3322) [0.9 s]
INFO:root:Epoch 28    loss=0.2022 [19.4 s]    dev=(HR@5:0.4525,NDCG@5:0.3337) [0.9 s] *
INFO:root:Epoch 29    loss=0.2007 [19.3 s]    dev=(HR@5:0.4523,NDCG@5:0.3333) [0.8 s]
INFO:root:Epoch 30    loss=0.2005 [19.7 s]    dev=(HR@5:0.4524,NDCG@5:0.3327) [0.9 s]
INFO:root:Epoch 31    loss=0.1987 [19.4 s]    dev=(HR@5:0.4507,NDCG@5:0.3342) [0.9 s] *
INFO:root:Epoch 32    loss=0.1994 [19.4 s]    dev=(HR@5:0.4517,NDCG@5:0.3326) [0.9 s]
INFO:root:Epoch 33    loss=0.1997 [20.0 s]    dev=(HR@5:0.4547,NDCG@5:0.3373) [0.9 s] *
INFO:root:Epoch 34    loss=0.1992 [20.5 s]    dev=(HR@5:0.4527,NDCG@5:0.3332) [0.9 s]
INFO:root:Epoch 35    loss=0.1988 [19.6 s]    dev=(HR@5:0.4492,NDCG@5:0.3308) [0.9 s]
INFO:root:Epoch 36    loss=0.1972 [19.4 s]    dev=(HR@5:0.4511,NDCG@5:0.3302) [0.9 s]
INFO:root:Epoch 37    loss=0.1979 [19.5 s]    dev=(HR@5:0.4527,NDCG@5:0.3312) [0.8 s]
INFO:root:Epoch 38    loss=0.1981 [19.3 s]    dev=(HR@5:0.4503,NDCG@5:0.3303) [0.8 s]
INFO:root:Epoch 39    loss=0.1981 [19.4 s]    dev=(HR@5:0.4470,NDCG@5:0.3271) [0.8 s]
INFO:root:Epoch 40    loss=0.1972 [19.4 s]    dev=(HR@5:0.4472,NDCG@5:0.3286) [0.9 s]
INFO:root:Epoch 41    loss=0.1980 [19.3 s]    dev=(HR@5:0.4511,NDCG@5:0.3303) [0.9 s]
INFO:root:Epoch 42    loss=0.1974 [19.4 s]    dev=(HR@5:0.4514,NDCG@5:0.3295) [0.9 s]
INFO:root:Epoch 43    loss=0.1962 [19.4 s]    dev=(HR@5:0.4517,NDCG@5:0.3315) [0.9 s]
INFO:root:Epoch 44    loss=0.1975 [19.3 s]    dev=(HR@5:0.4495,NDCG@5:0.3299) [0.9 s]
INFO:root:Epoch 45    loss=0.1947 [19.4 s]    dev=(HR@5:0.4547,NDCG@5:0.3348) [0.9 s]
INFO:root:Epoch 46    loss=0.1959 [19.4 s]    dev=(HR@5:0.4480,NDCG@5:0.3298) [0.9 s]
INFO:root:Epoch 47    loss=0.1960 [19.5 s]    dev=(HR@5:0.4477,NDCG@5:0.3277) [0.9 s]
INFO:root:Epoch 48    loss=0.1960 [19.4 s]    dev=(HR@5:0.4519,NDCG@5:0.3298) [0.9 s]
INFO:root:Epoch 49    loss=0.1943 [19.3 s]    dev=(HR@5:0.4543,NDCG@5:0.3328) [0.9 s]
INFO:root:Epoch 50    loss=0.1970 [19.3 s]    dev=(HR@5:0.4481,NDCG@5:0.3297) [0.9 s]
INFO:root:Epoch 51    loss=0.1948 [19.4 s]    dev=(HR@5:0.4495,NDCG@5:0.3309) [0.9 s]
INFO:root:Epoch 52    loss=0.1962 [19.4 s]    dev=(HR@5:0.4501,NDCG@5:0.3297) [0.9 s]
INFO:root:Epoch 53    loss=0.1952 [19.3 s]    dev=(HR@5:0.4464,NDCG@5:0.3278) [0.9 s]
INFO:root:Early stop at 53 based on dev result.
INFO:root:
Best Iter(dev)=   33	 dev=(HR@5:0.4547,NDCG@5:0.3373) [1077.8 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.4034,NDCG@5:0.2901,HR@10:0.5097,NDCG@10:0.3247,HR@20:0.6324,NDCG@20:0.3557,HR@50:0.8414,NDCG@50:0.3971)
INFO:root:
--------------------------------------------- END: 2024-12-06 18:41:52 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 19:21:31 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5157 [23.0 s]    dev=(HR@5:0.2597,NDCG@5:0.1741) [0.9 s] *
INFO:root:Epoch 2     loss=0.4236 [23.2 s]    dev=(HR@5:0.3372,NDCG@5:0.2294) [1.0 s] *
INFO:root:Epoch 3     loss=0.3851 [22.6 s]    dev=(HR@5:0.3673,NDCG@5:0.2532) [1.0 s] *
INFO:root:Epoch 4     loss=0.3586 [22.1 s]    dev=(HR@5:0.3906,NDCG@5:0.2743) [1.0 s] *
INFO:root:Epoch 5     loss=0.3330 [20.5 s]    dev=(HR@5:0.4075,NDCG@5:0.2899) [0.9 s] *
INFO:root:Epoch 6     loss=0.3092 [20.5 s]    dev=(HR@5:0.4225,NDCG@5:0.3032) [0.9 s] *
INFO:root:Epoch 7     loss=0.2917 [20.3 s]    dev=(HR@5:0.4280,NDCG@5:0.3080) [0.9 s] *
INFO:root:Epoch 8     loss=0.2757 [19.6 s]    dev=(HR@5:0.4349,NDCG@5:0.3156) [0.9 s] *
INFO:root:Epoch 9     loss=0.2622 [19.5 s]    dev=(HR@5:0.4362,NDCG@5:0.3186) [0.9 s] *
INFO:root:Epoch 10    loss=0.2524 [19.6 s]    dev=(HR@5:0.4357,NDCG@5:0.3199) [0.9 s] *
INFO:root:Epoch 11    loss=0.2424 [19.6 s]    dev=(HR@5:0.4427,NDCG@5:0.3233) [0.9 s] *
INFO:root:Epoch 12    loss=0.2343 [19.6 s]    dev=(HR@5:0.4440,NDCG@5:0.3245) [0.9 s] *
INFO:root:Epoch 13    loss=0.2306 [19.6 s]    dev=(HR@5:0.4481,NDCG@5:0.3296) [0.9 s] *
INFO:root:Epoch 14    loss=0.2262 [19.5 s]    dev=(HR@5:0.4489,NDCG@5:0.3291) [0.9 s]
INFO:root:Epoch 15    loss=0.2228 [19.6 s]    dev=(HR@5:0.4452,NDCG@5:0.3262) [0.9 s]
INFO:root:Epoch 16    loss=0.2199 [19.5 s]    dev=(HR@5:0.4466,NDCG@5:0.3281) [0.9 s]
INFO:root:Epoch 17    loss=0.2164 [19.5 s]    dev=(HR@5:0.4450,NDCG@5:0.3267) [0.9 s]
INFO:root:Epoch 18    loss=0.2130 [19.6 s]    dev=(HR@5:0.4500,NDCG@5:0.3310) [0.9 s] *
INFO:root:Epoch 19    loss=0.2113 [19.6 s]    dev=(HR@5:0.4479,NDCG@5:0.3296) [0.9 s]
INFO:root:Epoch 20    loss=0.2088 [19.5 s]    dev=(HR@5:0.4468,NDCG@5:0.3305) [0.9 s]
INFO:root:Epoch 21    loss=0.2060 [19.5 s]    dev=(HR@5:0.4507,NDCG@5:0.3323) [0.9 s] *
INFO:root:Epoch 22    loss=0.2064 [19.5 s]    dev=(HR@5:0.4474,NDCG@5:0.3297) [0.9 s]
INFO:root:Epoch 23    loss=0.2068 [19.4 s]    dev=(HR@5:0.4472,NDCG@5:0.3305) [0.9 s]
INFO:root:Epoch 24    loss=0.2058 [19.5 s]    dev=(HR@5:0.4498,NDCG@5:0.3306) [0.9 s]
INFO:root:Epoch 25    loss=0.2026 [19.4 s]    dev=(HR@5:0.4477,NDCG@5:0.3301) [0.9 s]
INFO:root:Epoch 26    loss=0.2031 [19.5 s]    dev=(HR@5:0.4481,NDCG@5:0.3314) [0.9 s]
INFO:root:Epoch 27    loss=0.2023 [19.5 s]    dev=(HR@5:0.4526,NDCG@5:0.3335) [0.9 s] *
INFO:root:Epoch 28    loss=0.2030 [19.4 s]    dev=(HR@5:0.4530,NDCG@5:0.3353) [0.9 s] *
INFO:root:Epoch 29    loss=0.2008 [19.4 s]    dev=(HR@5:0.4517,NDCG@5:0.3341) [0.9 s]
INFO:root:Epoch 30    loss=0.2015 [19.5 s]    dev=(HR@5:0.4545,NDCG@5:0.3351) [0.9 s]
INFO:root:Epoch 31    loss=0.1991 [19.6 s]    dev=(HR@5:0.4536,NDCG@5:0.3358) [0.9 s] *
INFO:root:Epoch 32    loss=0.2000 [19.4 s]    dev=(HR@5:0.4517,NDCG@5:0.3325) [0.9 s]
INFO:root:Epoch 33    loss=0.2006 [19.6 s]    dev=(HR@5:0.4541,NDCG@5:0.3369) [0.9 s] *
INFO:root:Epoch 34    loss=0.2000 [19.4 s]    dev=(HR@5:0.4527,NDCG@5:0.3346) [0.9 s]
INFO:root:Epoch 35    loss=0.1995 [19.5 s]    dev=(HR@5:0.4499,NDCG@5:0.3322) [0.9 s]
INFO:root:Epoch 36    loss=0.1982 [19.4 s]    dev=(HR@5:0.4526,NDCG@5:0.3322) [0.9 s]
INFO:root:Epoch 37    loss=0.1988 [19.5 s]    dev=(HR@5:0.4530,NDCG@5:0.3336) [0.9 s]
INFO:root:Epoch 38    loss=0.1995 [19.4 s]    dev=(HR@5:0.4498,NDCG@5:0.3323) [0.9 s]
INFO:root:Epoch 39    loss=0.1988 [19.5 s]    dev=(HR@5:0.4473,NDCG@5:0.3285) [0.8 s]
INFO:root:Epoch 40    loss=0.1986 [19.4 s]    dev=(HR@5:0.4473,NDCG@5:0.3308) [0.9 s]
INFO:root:Epoch 41    loss=0.1990 [19.4 s]    dev=(HR@5:0.4506,NDCG@5:0.3322) [0.9 s]
INFO:root:Epoch 42    loss=0.1983 [19.4 s]    dev=(HR@5:0.4523,NDCG@5:0.3321) [0.9 s]
INFO:root:Epoch 43    loss=0.1966 [19.5 s]    dev=(HR@5:0.4526,NDCG@5:0.3335) [0.9 s]
INFO:root:Epoch 44    loss=0.1978 [19.5 s]    dev=(HR@5:0.4485,NDCG@5:0.3304) [0.9 s]
INFO:root:Epoch 45    loss=0.1956 [19.3 s]    dev=(HR@5:0.4513,NDCG@5:0.3352) [0.9 s]
INFO:root:Epoch 46    loss=0.1965 [19.4 s]    dev=(HR@5:0.4500,NDCG@5:0.3334) [0.9 s]
INFO:root:Epoch 47    loss=0.1965 [19.4 s]    dev=(HR@5:0.4515,NDCG@5:0.3319) [0.8 s]
INFO:root:Epoch 48    loss=0.1954 [19.5 s]    dev=(HR@5:0.4468,NDCG@5:0.3292) [0.9 s]
INFO:root:Epoch 49    loss=0.1947 [19.4 s]    dev=(HR@5:0.4519,NDCG@5:0.3334) [0.9 s]
INFO:root:Epoch 50    loss=0.1963 [19.4 s]    dev=(HR@5:0.4498,NDCG@5:0.3327) [0.9 s]
INFO:root:Epoch 51    loss=0.1950 [19.4 s]    dev=(HR@5:0.4513,NDCG@5:0.3329) [0.9 s]
INFO:root:Epoch 52    loss=0.1954 [19.5 s]    dev=(HR@5:0.4470,NDCG@5:0.3295) [0.9 s]
INFO:root:Epoch 53    loss=0.1948 [19.4 s]    dev=(HR@5:0.4493,NDCG@5:0.3311) [0.8 s]
INFO:root:Early stop at 53 based on dev result.
INFO:root:
Best Iter(dev)=   33	 dev=(HR@5:0.4541,NDCG@5:0.3369) [1094.9 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.4035,NDCG@5:0.2909,HR@10:0.5098,NDCG@10:0.3253,HR@20:0.6310,NDCG@20:0.3558,HR@50:0.8369,NDCG@50:0.3966)
INFO:root:
--------------------------------------------- END: 2024-12-06 19:39:48 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 20:19:11 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5143 [21.5 s]    dev=(HR@5:0.2519,NDCG@5:0.1674) [0.9 s] *
INFO:root:Epoch 2     loss=0.4312 [19.5 s]    dev=(HR@5:0.3171,NDCG@5:0.2139) [0.9 s] *
INFO:root:Epoch 3     loss=0.3979 [19.4 s]    dev=(HR@5:0.3397,NDCG@5:0.2282) [0.9 s] *
INFO:root:Epoch 4     loss=0.3767 [19.3 s]    dev=(HR@5:0.3567,NDCG@5:0.2435) [0.9 s] *
INFO:root:Epoch 5     loss=0.3546 [19.4 s]    dev=(HR@5:0.3697,NDCG@5:0.2545) [0.9 s] *
INFO:root:Epoch 6     loss=0.3338 [19.4 s]    dev=(HR@5:0.3860,NDCG@5:0.2730) [0.8 s] *
INFO:root:Epoch 7     loss=0.3156 [19.3 s]    dev=(HR@5:0.3943,NDCG@5:0.2792) [0.9 s] *
INFO:root:Epoch 8     loss=0.3011 [19.3 s]    dev=(HR@5:0.3977,NDCG@5:0.2845) [0.8 s] *
INFO:root:Epoch 9     loss=0.2865 [19.3 s]    dev=(HR@5:0.4000,NDCG@5:0.2857) [0.9 s] *
INFO:root:Epoch 10    loss=0.2778 [19.3 s]    dev=(HR@5:0.4035,NDCG@5:0.2893) [0.9 s] *
INFO:root:Epoch 11    loss=0.2685 [19.3 s]    dev=(HR@5:0.4054,NDCG@5:0.2900) [0.9 s] *
INFO:root:Epoch 12    loss=0.2604 [19.4 s]    dev=(HR@5:0.4111,NDCG@5:0.2964) [0.9 s] *
INFO:root:Epoch 13    loss=0.2562 [19.5 s]    dev=(HR@5:0.4178,NDCG@5:0.3005) [0.9 s] *
INFO:root:Epoch 14    loss=0.2514 [19.5 s]    dev=(HR@5:0.4166,NDCG@5:0.2996) [0.9 s]
INFO:root:Epoch 15    loss=0.2482 [19.5 s]    dev=(HR@5:0.4175,NDCG@5:0.3001) [0.9 s]
INFO:root:Epoch 16    loss=0.2458 [19.5 s]    dev=(HR@5:0.4182,NDCG@5:0.3026) [0.9 s] *
INFO:root:Epoch 17    loss=0.2422 [19.5 s]    dev=(HR@5:0.4167,NDCG@5:0.2995) [0.9 s]
INFO:root:Epoch 18    loss=0.2386 [19.5 s]    dev=(HR@5:0.4152,NDCG@5:0.3005) [0.9 s]
INFO:root:Epoch 19    loss=0.2355 [19.5 s]    dev=(HR@5:0.4199,NDCG@5:0.3044) [0.8 s] *
INFO:root:Epoch 20    loss=0.2336 [19.5 s]    dev=(HR@5:0.4235,NDCG@5:0.3072) [0.9 s] *
INFO:root:Epoch 21    loss=0.2289 [19.6 s]    dev=(HR@5:0.4263,NDCG@5:0.3095) [0.8 s] *
INFO:root:Epoch 22    loss=0.2276 [19.5 s]    dev=(HR@5:0.4248,NDCG@5:0.3091) [0.9 s]
INFO:root:Epoch 23    loss=0.2282 [19.6 s]    dev=(HR@5:0.4210,NDCG@5:0.3065) [0.9 s]
INFO:root:Epoch 24    loss=0.2267 [19.5 s]    dev=(HR@5:0.4334,NDCG@5:0.3129) [0.9 s] *
INFO:root:Epoch 25    loss=0.2231 [19.6 s]    dev=(HR@5:0.4261,NDCG@5:0.3106) [1.0 s]
INFO:root:Epoch 26    loss=0.2235 [19.7 s]    dev=(HR@5:0.4292,NDCG@5:0.3124) [0.9 s]
INFO:root:Epoch 27    loss=0.2226 [19.9 s]    dev=(HR@5:0.4280,NDCG@5:0.3118) [0.9 s]
INFO:root:Epoch 28    loss=0.2230 [20.3 s]    dev=(HR@5:0.4327,NDCG@5:0.3162) [0.9 s] *
INFO:root:Epoch 29    loss=0.2202 [20.2 s]    dev=(HR@5:0.4299,NDCG@5:0.3147) [0.9 s]
INFO:root:Epoch 30    loss=0.2200 [20.2 s]    dev=(HR@5:0.4304,NDCG@5:0.3148) [0.9 s]
INFO:root:Epoch 31    loss=0.2187 [20.2 s]    dev=(HR@5:0.4314,NDCG@5:0.3160) [1.1 s]
INFO:root:Epoch 32    loss=0.2189 [20.2 s]    dev=(HR@5:0.4295,NDCG@5:0.3122) [0.9 s]
INFO:root:Epoch 33    loss=0.2189 [20.1 s]    dev=(HR@5:0.4320,NDCG@5:0.3164) [0.9 s] *
INFO:root:Epoch 34    loss=0.2180 [20.2 s]    dev=(HR@5:0.4357,NDCG@5:0.3186) [0.9 s] *
INFO:root:Epoch 35    loss=0.2180 [20.2 s]    dev=(HR@5:0.4318,NDCG@5:0.3134) [0.9 s]
INFO:root:Epoch 36    loss=0.2158 [20.3 s]    dev=(HR@5:0.4301,NDCG@5:0.3119) [0.9 s]
INFO:root:Epoch 37    loss=0.2166 [20.3 s]    dev=(HR@5:0.4342,NDCG@5:0.3150) [0.9 s]
INFO:root:Epoch 38    loss=0.2159 [20.9 s]    dev=(HR@5:0.4359,NDCG@5:0.3180) [0.9 s]
INFO:root:Epoch 39    loss=0.2166 [19.6 s]    dev=(HR@5:0.4271,NDCG@5:0.3100) [0.9 s]
INFO:root:Epoch 40    loss=0.2164 [20.1 s]    dev=(HR@5:0.4314,NDCG@5:0.3150) [0.9 s]
INFO:root:Epoch 41    loss=0.2160 [19.8 s]    dev=(HR@5:0.4316,NDCG@5:0.3131) [0.9 s]
INFO:root:Epoch 42    loss=0.2164 [19.8 s]    dev=(HR@5:0.4323,NDCG@5:0.3152) [0.9 s]
INFO:root:Epoch 43    loss=0.2146 [19.7 s]    dev=(HR@5:0.4368,NDCG@5:0.3196) [0.9 s] *
INFO:root:Epoch 44    loss=0.2158 [19.7 s]    dev=(HR@5:0.4342,NDCG@5:0.3157) [0.9 s]
INFO:root:Epoch 45    loss=0.2131 [19.8 s]    dev=(HR@5:0.4370,NDCG@5:0.3185) [0.9 s]
INFO:root:Epoch 46    loss=0.2139 [19.8 s]    dev=(HR@5:0.4316,NDCG@5:0.3134) [0.9 s]
INFO:root:Epoch 47    loss=0.2149 [19.6 s]    dev=(HR@5:0.4348,NDCG@5:0.3150) [0.9 s]
INFO:root:Epoch 48    loss=0.2143 [20.0 s]    dev=(HR@5:0.4357,NDCG@5:0.3166) [0.9 s]
INFO:root:Epoch 49    loss=0.2121 [20.1 s]    dev=(HR@5:0.4398,NDCG@5:0.3206) [0.9 s] *
INFO:root:Epoch 50    loss=0.2132 [20.0 s]    dev=(HR@5:0.4380,NDCG@5:0.3189) [0.9 s]
INFO:root:Epoch 51    loss=0.2123 [19.8 s]    dev=(HR@5:0.4375,NDCG@5:0.3182) [0.9 s]
INFO:root:Epoch 52    loss=0.2123 [20.2 s]    dev=(HR@5:0.4370,NDCG@5:0.3185) [0.9 s]
INFO:root:Epoch 53    loss=0.2132 [20.0 s]    dev=(HR@5:0.4335,NDCG@5:0.3163) [0.9 s]
INFO:root:Epoch 54    loss=0.2100 [20.2 s]    dev=(HR@5:0.4412,NDCG@5:0.3197) [0.9 s]
INFO:root:Epoch 55    loss=0.2112 [19.4 s]    dev=(HR@5:0.4386,NDCG@5:0.3187) [0.9 s]
INFO:root:Epoch 56    loss=0.2110 [19.4 s]    dev=(HR@5:0.4425,NDCG@5:0.3236) [0.8 s] *
INFO:root:Epoch 57    loss=0.2110 [19.4 s]    dev=(HR@5:0.4427,NDCG@5:0.3239) [0.9 s] *
INFO:root:Epoch 58    loss=0.2122 [19.4 s]    dev=(HR@5:0.4426,NDCG@5:0.3238) [0.9 s]
INFO:root:Epoch 59    loss=0.2102 [19.4 s]    dev=(HR@5:0.4389,NDCG@5:0.3215) [0.9 s]
INFO:root:Epoch 60    loss=0.2116 [19.4 s]    dev=(HR@5:0.4409,NDCG@5:0.3207) [0.9 s]
INFO:root:Epoch 61    loss=0.2108 [19.4 s]    dev=(HR@5:0.4404,NDCG@5:0.3231) [0.8 s]
INFO:root:Epoch 62    loss=0.2099 [19.5 s]    dev=(HR@5:0.4419,NDCG@5:0.3207) [0.9 s]
INFO:root:Epoch 63    loss=0.2120 [19.5 s]    dev=(HR@5:0.4432,NDCG@5:0.3221) [0.9 s]
INFO:root:Epoch 64    loss=0.2092 [19.4 s]    dev=(HR@5:0.4381,NDCG@5:0.3192) [0.9 s]
INFO:root:Epoch 65    loss=0.2106 [19.4 s]    dev=(HR@5:0.4371,NDCG@5:0.3189) [0.9 s]
INFO:root:Epoch 66    loss=0.2092 [19.5 s]    dev=(HR@5:0.4396,NDCG@5:0.3181) [0.9 s]
INFO:root:Epoch 67    loss=0.2095 [19.4 s]    dev=(HR@5:0.4425,NDCG@5:0.3219) [0.9 s]
INFO:root:Epoch 68    loss=0.2083 [19.4 s]    dev=(HR@5:0.4383,NDCG@5:0.3212) [0.9 s]
INFO:root:Epoch 69    loss=0.2102 [19.4 s]    dev=(HR@5:0.4378,NDCG@5:0.3193) [0.9 s]
INFO:root:Epoch 70    loss=0.2099 [19.3 s]    dev=(HR@5:0.4381,NDCG@5:0.3197) [0.9 s]
INFO:root:Epoch 71    loss=0.2084 [19.3 s]    dev=(HR@5:0.4361,NDCG@5:0.3194) [0.9 s]
INFO:root:Epoch 72    loss=0.2088 [19.4 s]    dev=(HR@5:0.4407,NDCG@5:0.3217) [0.9 s]
INFO:root:Epoch 73    loss=0.2094 [19.4 s]    dev=(HR@5:0.4359,NDCG@5:0.3173) [0.9 s]
INFO:root:Epoch 74    loss=0.2091 [19.8 s]    dev=(HR@5:0.4384,NDCG@5:0.3182) [0.9 s]
INFO:root:Epoch 75    loss=0.2110 [20.0 s]    dev=(HR@5:0.4375,NDCG@5:0.3189) [1.0 s]
INFO:root:Epoch 76    loss=0.2103 [20.0 s]    dev=(HR@5:0.4440,NDCG@5:0.3228) [0.9 s]
INFO:root:Epoch 77    loss=0.2090 [19.8 s]    dev=(HR@5:0.4395,NDCG@5:0.3208) [0.9 s]
INFO:root:Early stop at 77 based on dev result.
INFO:root:
Best Iter(dev)=   57	 dev=(HR@5:0.4427,NDCG@5:0.3239) [1585.1 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.3913,NDCG@5:0.2787,HR@10:0.5014,NDCG@10:0.3143,HR@20:0.6236,NDCG@20:0.3451,HR@50:0.8291,NDCG@50:0.3858)
INFO:root:
--------------------------------------------- END: 2024-12-06 20:45:38 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 21:45:06 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5140 [24.0 s]    dev=(HR@5:0.2626,NDCG@5:0.1757) [0.9 s] *
INFO:root:Epoch 2     loss=0.4226 [20.3 s]    dev=(HR@5:0.3345,NDCG@5:0.2285) [0.9 s] *
INFO:root:Epoch 3     loss=0.3862 [20.3 s]    dev=(HR@5:0.3652,NDCG@5:0.2503) [0.9 s] *
INFO:root:Epoch 4     loss=0.3626 [20.2 s]    dev=(HR@5:0.3827,NDCG@5:0.2661) [0.9 s] *
INFO:root:Epoch 5     loss=0.3376 [19.8 s]    dev=(HR@5:0.4015,NDCG@5:0.2815) [0.9 s] *
INFO:root:Epoch 6     loss=0.3130 [19.6 s]    dev=(HR@5:0.4122,NDCG@5:0.2922) [0.9 s] *
INFO:root:Epoch 7     loss=0.2957 [19.9 s]    dev=(HR@5:0.4167,NDCG@5:0.2972) [0.9 s] *
INFO:root:Epoch 8     loss=0.2816 [59.0 s]    dev=(HR@5:0.4254,NDCG@5:0.3064) [0.9 s] *
INFO:root:Epoch 9     loss=0.2680 [20.2 s]    dev=(HR@5:0.4272,NDCG@5:0.3077) [0.9 s] *
INFO:root:Epoch 10    loss=0.2584 [20.4 s]    dev=(HR@5:0.4338,NDCG@5:0.3130) [0.9 s] *
INFO:root:Epoch 11    loss=0.2492 [20.1 s]    dev=(HR@5:0.4359,NDCG@5:0.3154) [0.9 s] *
INFO:root:Epoch 12    loss=0.2416 [20.1 s]    dev=(HR@5:0.4359,NDCG@5:0.3162) [0.9 s] *
INFO:root:Epoch 13    loss=0.2372 [20.4 s]    dev=(HR@5:0.4425,NDCG@5:0.3210) [0.9 s] *
INFO:root:Epoch 14    loss=0.2329 [19.7 s]    dev=(HR@5:0.4413,NDCG@5:0.3196) [0.9 s]
INFO:root:Epoch 15    loss=0.2302 [19.8 s]    dev=(HR@5:0.4389,NDCG@5:0.3186) [0.9 s]
INFO:root:Epoch 16    loss=0.2277 [19.8 s]    dev=(HR@5:0.4397,NDCG@5:0.3195) [0.9 s]
INFO:root:Epoch 17    loss=0.2241 [19.8 s]    dev=(HR@5:0.4412,NDCG@5:0.3197) [0.9 s]
INFO:root:Epoch 18    loss=0.2198 [19.8 s]    dev=(HR@5:0.4411,NDCG@5:0.3214) [0.9 s] *
INFO:root:Epoch 19    loss=0.2180 [19.8 s]    dev=(HR@5:0.4413,NDCG@5:0.3202) [0.9 s]
INFO:root:Epoch 20    loss=0.2164 [19.8 s]    dev=(HR@5:0.4436,NDCG@5:0.3233) [0.9 s] *
INFO:root:Epoch 21    loss=0.2125 [20.3 s]    dev=(HR@5:0.4423,NDCG@5:0.3218) [0.9 s]
INFO:root:Epoch 22    loss=0.2122 [20.0 s]    dev=(HR@5:0.4419,NDCG@5:0.3215) [1.0 s]
INFO:root:Epoch 23    loss=0.2128 [20.0 s]    dev=(HR@5:0.4410,NDCG@5:0.3213) [0.9 s]
INFO:root:Epoch 24    loss=0.2125 [20.0 s]    dev=(HR@5:0.4449,NDCG@5:0.3221) [0.9 s]
INFO:root:Epoch 25    loss=0.2092 [20.0 s]    dev=(HR@5:0.4395,NDCG@5:0.3189) [0.9 s]
INFO:root:Epoch 26    loss=0.2097 [19.8 s]    dev=(HR@5:0.4396,NDCG@5:0.3184) [0.9 s]
INFO:root:Epoch 27    loss=0.2087 [20.9 s]    dev=(HR@5:0.4406,NDCG@5:0.3198) [0.9 s]
INFO:root:Epoch 28    loss=0.2090 [20.4 s]    dev=(HR@5:0.4433,NDCG@5:0.3246) [0.9 s] *
INFO:root:Epoch 29    loss=0.2074 [20.0 s]    dev=(HR@5:0.4410,NDCG@5:0.3208) [0.9 s]
INFO:root:Epoch 30    loss=0.2064 [20.5 s]    dev=(HR@5:0.4404,NDCG@5:0.3221) [1.0 s]
INFO:root:Epoch 31    loss=0.2062 [20.1 s]    dev=(HR@5:0.4407,NDCG@5:0.3221) [0.9 s]
INFO:root:Epoch 32    loss=0.2062 [19.5 s]    dev=(HR@5:0.4400,NDCG@5:0.3211) [0.9 s]
INFO:root:Epoch 33    loss=0.2068 [20.0 s]    dev=(HR@5:0.4407,NDCG@5:0.3233) [0.9 s]
INFO:root:Epoch 34    loss=0.2055 [19.8 s]    dev=(HR@5:0.4440,NDCG@5:0.3236) [0.9 s]
INFO:root:Epoch 35    loss=0.2063 [19.3 s]    dev=(HR@5:0.4371,NDCG@5:0.3180) [0.9 s]
INFO:root:Epoch 36    loss=0.2047 [19.4 s]    dev=(HR@5:0.4406,NDCG@5:0.3199) [0.9 s]
INFO:root:Epoch 37    loss=0.2057 [19.9 s]    dev=(HR@5:0.4406,NDCG@5:0.3203) [0.9 s]
INFO:root:Epoch 38    loss=0.2053 [19.4 s]    dev=(HR@5:0.4398,NDCG@5:0.3208) [0.9 s]
INFO:root:Epoch 39    loss=0.2059 [19.4 s]    dev=(HR@5:0.4343,NDCG@5:0.3150) [0.9 s]
INFO:root:Epoch 40    loss=0.2051 [19.4 s]    dev=(HR@5:0.4395,NDCG@5:0.3187) [0.9 s]
INFO:root:Epoch 41    loss=0.2055 [19.4 s]    dev=(HR@5:0.4415,NDCG@5:0.3212) [0.9 s]
INFO:root:Epoch 42    loss=0.2052 [19.5 s]    dev=(HR@5:0.4434,NDCG@5:0.3222) [0.9 s]
INFO:root:Epoch 43    loss=0.2041 [20.1 s]    dev=(HR@5:0.4437,NDCG@5:0.3243) [0.9 s]
INFO:root:Epoch 44    loss=0.2048 [19.6 s]    dev=(HR@5:0.4398,NDCG@5:0.3209) [0.9 s]
INFO:root:Epoch 45    loss=0.2019 [19.5 s]    dev=(HR@5:0.4432,NDCG@5:0.3238) [0.9 s]
INFO:root:Epoch 46    loss=0.2033 [19.4 s]    dev=(HR@5:0.4369,NDCG@5:0.3175) [0.9 s]
INFO:root:Epoch 47    loss=0.2034 [19.4 s]    dev=(HR@5:0.4391,NDCG@5:0.3195) [0.9 s]
INFO:root:Epoch 48    loss=0.2029 [19.5 s]    dev=(HR@5:0.4371,NDCG@5:0.3190) [0.9 s]
INFO:root:Early stop at 48 based on dev result.
INFO:root:
Best Iter(dev)=   28	 dev=(HR@5:0.4433,NDCG@5:0.3246) [1039.9 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.3957,NDCG@5:0.2802,HR@10:0.5077,NDCG@10:0.3166,HR@20:0.6298,NDCG@20:0.3473,HR@50:0.8344,NDCG@50:0.3878)
INFO:root:
--------------------------------------------- END: 2024-12-06 22:02:27 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 22:44:48 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5141 [22.2 s]    dev=(HR@5:0.2652,NDCG@5:0.1775) [0.9 s] *
INFO:root:Epoch 2     loss=0.4210 [19.3 s]    dev=(HR@5:0.3395,NDCG@5:0.2323) [0.9 s] *
INFO:root:Epoch 3     loss=0.3835 [19.7 s]    dev=(HR@5:0.3708,NDCG@5:0.2556) [0.9 s] *
INFO:root:Epoch 4     loss=0.3596 [20.0 s]    dev=(HR@5:0.3914,NDCG@5:0.2722) [0.9 s] *
INFO:root:Epoch 5     loss=0.3360 [19.9 s]    dev=(HR@5:0.4030,NDCG@5:0.2856) [0.9 s] *
INFO:root:Epoch 6     loss=0.3105 [20.0 s]    dev=(HR@5:0.4202,NDCG@5:0.3010) [0.9 s] *
INFO:root:Epoch 7     loss=0.2924 [19.8 s]    dev=(HR@5:0.4263,NDCG@5:0.3067) [0.9 s] *
INFO:root:Epoch 8     loss=0.2772 [19.9 s]    dev=(HR@5:0.4308,NDCG@5:0.3120) [0.8 s] *
INFO:root:Epoch 9     loss=0.2640 [20.0 s]    dev=(HR@5:0.4344,NDCG@5:0.3150) [0.9 s] *
INFO:root:Epoch 10    loss=0.2553 [20.2 s]    dev=(HR@5:0.4365,NDCG@5:0.3188) [0.9 s] *
INFO:root:Epoch 11    loss=0.2460 [19.8 s]    dev=(HR@5:0.4407,NDCG@5:0.3214) [0.9 s] *
INFO:root:Epoch 12    loss=0.2384 [20.1 s]    dev=(HR@5:0.4436,NDCG@5:0.3235) [0.9 s] *
INFO:root:Epoch 13    loss=0.2338 [19.7 s]    dev=(HR@5:0.4464,NDCG@5:0.3275) [0.9 s] *
INFO:root:Epoch 14    loss=0.2299 [20.0 s]    dev=(HR@5:0.4464,NDCG@5:0.3271) [0.9 s]
INFO:root:Epoch 15    loss=0.2262 [19.4 s]    dev=(HR@5:0.4448,NDCG@5:0.3267) [0.8 s]
INFO:root:Epoch 16    loss=0.2235 [19.4 s]    dev=(HR@5:0.4484,NDCG@5:0.3289) [0.9 s] *
INFO:root:Epoch 17    loss=0.2200 [19.9 s]    dev=(HR@5:0.4455,NDCG@5:0.3281) [0.9 s]
INFO:root:Epoch 18    loss=0.2157 [20.2 s]    dev=(HR@5:0.4496,NDCG@5:0.3302) [0.9 s] *
INFO:root:Epoch 19    loss=0.2142 [19.8 s]    dev=(HR@5:0.4506,NDCG@5:0.3316) [0.9 s] *
INFO:root:Epoch 20    loss=0.2111 [19.8 s]    dev=(HR@5:0.4491,NDCG@5:0.3309) [0.9 s]
INFO:root:Epoch 21    loss=0.2072 [19.9 s]    dev=(HR@5:0.4486,NDCG@5:0.3305) [0.9 s]
INFO:root:Epoch 22    loss=0.2071 [20.1 s]    dev=(HR@5:0.4444,NDCG@5:0.3297) [0.9 s]
INFO:root:Epoch 23    loss=0.2074 [20.0 s]    dev=(HR@5:0.4415,NDCG@5:0.3286) [0.9 s]
INFO:root:Epoch 24    loss=0.2060 [20.2 s]    dev=(HR@5:0.4464,NDCG@5:0.3292) [0.9 s]
INFO:root:Epoch 25    loss=0.2031 [20.1 s]    dev=(HR@5:0.4447,NDCG@5:0.3290) [0.9 s]
INFO:root:Epoch 26    loss=0.2038 [20.8 s]    dev=(HR@5:0.4465,NDCG@5:0.3292) [0.9 s]
INFO:root:Epoch 27    loss=0.2032 [19.9 s]    dev=(HR@5:0.4472,NDCG@5:0.3298) [0.9 s]
INFO:root:Epoch 28    loss=0.2023 [19.6 s]    dev=(HR@5:0.4510,NDCG@5:0.3340) [0.9 s] *
INFO:root:Epoch 29    loss=0.2009 [19.7 s]    dev=(HR@5:0.4462,NDCG@5:0.3307) [0.9 s]
INFO:root:Epoch 30    loss=0.2010 [19.8 s]    dev=(HR@5:0.4466,NDCG@5:0.3305) [0.9 s]
INFO:root:Epoch 31    loss=0.2005 [20.1 s]    dev=(HR@5:0.4509,NDCG@5:0.3344) [0.9 s] *
INFO:root:Epoch 32    loss=0.2006 [19.6 s]    dev=(HR@5:0.4493,NDCG@5:0.3315) [0.9 s]
INFO:root:Epoch 33    loss=0.2009 [20.3 s]    dev=(HR@5:0.4496,NDCG@5:0.3340) [0.9 s]
INFO:root:Epoch 34    loss=0.2004 [21.8 s]    dev=(HR@5:0.4489,NDCG@5:0.3329) [1.0 s]
INFO:root:Epoch 35    loss=0.2006 [20.3 s]    dev=(HR@5:0.4476,NDCG@5:0.3293) [0.9 s]
INFO:root:Epoch 36    loss=0.1979 [19.6 s]    dev=(HR@5:0.4486,NDCG@5:0.3298) [0.9 s]
INFO:root:Epoch 37    loss=0.1981 [19.3 s]    dev=(HR@5:0.4479,NDCG@5:0.3315) [0.9 s]
INFO:root:Epoch 38    loss=0.1988 [19.3 s]    dev=(HR@5:0.4497,NDCG@5:0.3310) [0.9 s]
INFO:root:Epoch 39    loss=0.1995 [19.6 s]    dev=(HR@5:0.4438,NDCG@5:0.3251) [1.0 s]
INFO:root:Epoch 40    loss=0.1978 [20.2 s]    dev=(HR@5:0.4469,NDCG@5:0.3297) [0.9 s]
INFO:root:Epoch 41    loss=0.1995 [19.4 s]    dev=(HR@5:0.4490,NDCG@5:0.3303) [0.9 s]
INFO:root:Epoch 42    loss=0.1984 [19.2 s]    dev=(HR@5:0.4500,NDCG@5:0.3303) [0.9 s]
INFO:root:Epoch 43    loss=0.1965 [19.4 s]    dev=(HR@5:0.4504,NDCG@5:0.3331) [0.9 s]
INFO:root:Epoch 44    loss=0.1989 [19.2 s]    dev=(HR@5:0.4509,NDCG@5:0.3310) [0.9 s]
INFO:root:Epoch 45    loss=0.1953 [19.2 s]    dev=(HR@5:0.4507,NDCG@5:0.3326) [0.9 s]
INFO:root:Epoch 46    loss=0.1967 [19.6 s]    dev=(HR@5:0.4490,NDCG@5:0.3305) [0.9 s]
INFO:root:Epoch 47    loss=0.1968 [19.3 s]    dev=(HR@5:0.4470,NDCG@5:0.3293) [0.9 s]
INFO:root:Epoch 48    loss=0.1970 [19.3 s]    dev=(HR@5:0.4451,NDCG@5:0.3276) [0.9 s]
INFO:root:Epoch 49    loss=0.1961 [19.2 s]    dev=(HR@5:0.4521,NDCG@5:0.3327) [0.9 s]
INFO:root:Epoch 50    loss=0.1975 [19.3 s]    dev=(HR@5:0.4491,NDCG@5:0.3308) [0.9 s]
INFO:root:Epoch 51    loss=0.1959 [19.2 s]    dev=(HR@5:0.4479,NDCG@5:0.3317) [0.9 s]
INFO:root:Early stop at 51 based on dev result.
INFO:root:
Best Iter(dev)=   31	 dev=(HR@5:0.4509,NDCG@5:0.3344) [1056.7 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.4031,NDCG@5:0.2893,HR@10:0.5097,NDCG@10:0.3238,HR@20:0.6302,NDCG@20:0.3542,HR@50:0.8332,NDCG@50:0.3944)
INFO:root:
--------------------------------------------- END: 2024-12-06 23:02:26 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-06 23:39:29 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5143 [21.3 s]    dev=(HR@5:0.2595,NDCG@5:0.1741) [0.9 s] *
INFO:root:Epoch 2     loss=0.4231 [19.2 s]    dev=(HR@5:0.3353,NDCG@5:0.2281) [0.9 s] *
INFO:root:Epoch 3     loss=0.3857 [19.1 s]    dev=(HR@5:0.3632,NDCG@5:0.2481) [0.9 s] *
INFO:root:Epoch 4     loss=0.3595 [19.2 s]    dev=(HR@5:0.3901,NDCG@5:0.2718) [0.8 s] *
INFO:root:Epoch 5     loss=0.3329 [19.2 s]    dev=(HR@5:0.4047,NDCG@5:0.2875) [0.9 s] *
INFO:root:Epoch 6     loss=0.3084 [19.2 s]    dev=(HR@5:0.4204,NDCG@5:0.3006) [0.8 s] *
INFO:root:Epoch 7     loss=0.2916 [19.1 s]    dev=(HR@5:0.4247,NDCG@5:0.3046) [0.9 s] *
INFO:root:Epoch 8     loss=0.2783 [19.2 s]    dev=(HR@5:0.4294,NDCG@5:0.3100) [0.9 s] *
INFO:root:Epoch 9     loss=0.2661 [19.2 s]    dev=(HR@5:0.4314,NDCG@5:0.3115) [0.9 s] *
INFO:root:Epoch 10    loss=0.2582 [19.2 s]    dev=(HR@5:0.4336,NDCG@5:0.3148) [0.8 s] *
INFO:root:Epoch 11    loss=0.2495 [19.2 s]    dev=(HR@5:0.4378,NDCG@5:0.3160) [0.8 s] *
INFO:root:Epoch 12    loss=0.2424 [19.2 s]    dev=(HR@5:0.4387,NDCG@5:0.3195) [0.8 s] *
INFO:root:Epoch 13    loss=0.2391 [19.2 s]    dev=(HR@5:0.4429,NDCG@5:0.3234) [0.8 s] *
INFO:root:Epoch 14    loss=0.2351 [19.4 s]    dev=(HR@5:0.4421,NDCG@5:0.3220) [0.9 s]
INFO:root:Epoch 15    loss=0.2310 [19.1 s]    dev=(HR@5:0.4406,NDCG@5:0.3214) [0.9 s]
INFO:root:Epoch 16    loss=0.2292 [19.1 s]    dev=(HR@5:0.4410,NDCG@5:0.3228) [0.9 s]
INFO:root:Epoch 17    loss=0.2256 [19.1 s]    dev=(HR@5:0.4375,NDCG@5:0.3209) [0.9 s]
INFO:root:Epoch 18    loss=0.2209 [19.1 s]    dev=(HR@5:0.4431,NDCG@5:0.3238) [0.8 s] *
INFO:root:Epoch 19    loss=0.2202 [19.2 s]    dev=(HR@5:0.4415,NDCG@5:0.3236) [0.8 s]
INFO:root:Epoch 20    loss=0.2165 [19.1 s]    dev=(HR@5:0.4427,NDCG@5:0.3269) [0.8 s] *
INFO:root:Epoch 21    loss=0.2143 [19.1 s]    dev=(HR@5:0.4438,NDCG@5:0.3258) [0.9 s]
INFO:root:Epoch 22    loss=0.2134 [19.3 s]    dev=(HR@5:0.4403,NDCG@5:0.3260) [0.9 s]
INFO:root:Epoch 23    loss=0.2141 [19.2 s]    dev=(HR@5:0.4419,NDCG@5:0.3269) [0.9 s]
INFO:root:Epoch 24    loss=0.2133 [19.1 s]    dev=(HR@5:0.4425,NDCG@5:0.3252) [0.8 s]
INFO:root:Epoch 25    loss=0.2097 [19.2 s]    dev=(HR@5:0.4429,NDCG@5:0.3252) [0.9 s]
INFO:root:Epoch 26    loss=0.2100 [19.2 s]    dev=(HR@5:0.4419,NDCG@5:0.3265) [0.8 s]
INFO:root:Epoch 27    loss=0.2106 [19.1 s]    dev=(HR@5:0.4429,NDCG@5:0.3275) [0.8 s] *
INFO:root:Epoch 28    loss=0.2100 [19.2 s]    dev=(HR@5:0.4433,NDCG@5:0.3285) [0.8 s] *
INFO:root:Epoch 29    loss=0.2083 [19.2 s]    dev=(HR@5:0.4415,NDCG@5:0.3267) [0.9 s]
INFO:root:Epoch 30    loss=0.2088 [19.1 s]    dev=(HR@5:0.4432,NDCG@5:0.3294) [0.9 s] *
INFO:root:Epoch 31    loss=0.2063 [19.1 s]    dev=(HR@5:0.4442,NDCG@5:0.3307) [0.8 s] *
INFO:root:Epoch 32    loss=0.2075 [19.1 s]    dev=(HR@5:0.4447,NDCG@5:0.3281) [0.9 s]
INFO:root:Epoch 33    loss=0.2071 [19.1 s]    dev=(HR@5:0.4423,NDCG@5:0.3298) [0.8 s]
INFO:root:Epoch 34    loss=0.2072 [19.1 s]    dev=(HR@5:0.4432,NDCG@5:0.3294) [0.9 s]
INFO:root:Epoch 35    loss=0.2070 [19.1 s]    dev=(HR@5:0.4410,NDCG@5:0.3265) [0.9 s]
INFO:root:Epoch 36    loss=0.2050 [19.1 s]    dev=(HR@5:0.4413,NDCG@5:0.3263) [0.9 s]
INFO:root:Epoch 37    loss=0.2052 [19.1 s]    dev=(HR@5:0.4459,NDCG@5:0.3295) [0.9 s]
INFO:root:Epoch 38    loss=0.2058 [19.2 s]    dev=(HR@5:0.4430,NDCG@5:0.3272) [0.8 s]
INFO:root:Epoch 39    loss=0.2060 [19.1 s]    dev=(HR@5:0.4383,NDCG@5:0.3239) [0.8 s]
INFO:root:Epoch 40    loss=0.2049 [19.1 s]    dev=(HR@5:0.4383,NDCG@5:0.3252) [0.8 s]
INFO:root:Epoch 41    loss=0.2052 [19.1 s]    dev=(HR@5:0.4448,NDCG@5:0.3270) [0.9 s]
INFO:root:Epoch 42    loss=0.2051 [19.1 s]    dev=(HR@5:0.4447,NDCG@5:0.3260) [0.9 s]
INFO:root:Epoch 43    loss=0.2036 [19.1 s]    dev=(HR@5:0.4479,NDCG@5:0.3288) [0.8 s]
INFO:root:Epoch 44    loss=0.2051 [19.1 s]    dev=(HR@5:0.4442,NDCG@5:0.3269) [0.8 s]
INFO:root:Epoch 45    loss=0.2026 [19.1 s]    dev=(HR@5:0.4473,NDCG@5:0.3321) [0.8 s] *
INFO:root:Epoch 46    loss=0.2037 [19.2 s]    dev=(HR@5:0.4437,NDCG@5:0.3281) [0.8 s]
INFO:root:Epoch 47    loss=0.2038 [19.1 s]    dev=(HR@5:0.4436,NDCG@5:0.3266) [0.8 s]
INFO:root:Epoch 48    loss=0.2033 [19.2 s]    dev=(HR@5:0.4445,NDCG@5:0.3275) [0.9 s]
INFO:root:Epoch 49    loss=0.2014 [19.2 s]    dev=(HR@5:0.4479,NDCG@5:0.3304) [0.9 s]
INFO:root:Epoch 50    loss=0.2035 [19.2 s]    dev=(HR@5:0.4438,NDCG@5:0.3264) [0.8 s]
INFO:root:Epoch 51    loss=0.2019 [19.1 s]    dev=(HR@5:0.4436,NDCG@5:0.3281) [0.8 s]
INFO:root:Epoch 52    loss=0.2026 [19.2 s]    dev=(HR@5:0.4444,NDCG@5:0.3281) [0.9 s]
INFO:root:Epoch 53    loss=0.2023 [19.1 s]    dev=(HR@5:0.4414,NDCG@5:0.3245) [0.8 s]
INFO:root:Epoch 54    loss=0.2011 [19.3 s]    dev=(HR@5:0.4449,NDCG@5:0.3257) [0.9 s]
INFO:root:Epoch 55    loss=0.2006 [19.2 s]    dev=(HR@5:0.4442,NDCG@5:0.3277) [0.9 s]
INFO:root:Epoch 56    loss=0.2011 [19.1 s]    dev=(HR@5:0.4460,NDCG@5:0.3283) [0.9 s]
INFO:root:Epoch 57    loss=0.2014 [19.1 s]    dev=(HR@5:0.4427,NDCG@5:0.3275) [0.8 s]
INFO:root:Epoch 58    loss=0.2019 [19.2 s]    dev=(HR@5:0.4464,NDCG@5:0.3303) [0.8 s]
INFO:root:Epoch 59    loss=0.2014 [19.3 s]    dev=(HR@5:0.4449,NDCG@5:0.3285) [0.9 s]
INFO:root:Epoch 60    loss=0.2016 [19.2 s]    dev=(HR@5:0.4464,NDCG@5:0.3311) [0.8 s]
INFO:root:Epoch 61    loss=0.2009 [19.2 s]    dev=(HR@5:0.4478,NDCG@5:0.3306) [0.9 s]
INFO:root:Epoch 62    loss=0.2000 [19.1 s]    dev=(HR@5:0.4480,NDCG@5:0.3297) [0.9 s]
INFO:root:Epoch 63    loss=0.2016 [19.2 s]    dev=(HR@5:0.4487,NDCG@5:0.3304) [0.9 s]
INFO:root:Epoch 64    loss=0.1983 [19.2 s]    dev=(HR@5:0.4430,NDCG@5:0.3262) [0.9 s]
INFO:root:Epoch 65    loss=0.2000 [19.2 s]    dev=(HR@5:0.4429,NDCG@5:0.3260) [0.9 s]
INFO:root:Early stop at 65 based on dev result.
INFO:root:
Best Iter(dev)=   45	 dev=(HR@5:0.4473,NDCG@5:0.3321) [1303.4 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.4005,NDCG@5:0.2892,HR@10:0.5060,NDCG@10:0.3233,HR@20:0.6316,NDCG@20:0.3551,HR@50:0.8359,NDCG@50:0.3955)
INFO:root:
--------------------------------------------- END: 2024-12-07 00:01:14 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-07 00:37:32 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5146 [23.7 s]    dev=(HR@5:0.2592,NDCG@5:0.1736) [0.9 s] *
INFO:root:Epoch 2     loss=0.4243 [19.3 s]    dev=(HR@5:0.3327,NDCG@5:0.2259) [0.9 s] *
INFO:root:Epoch 3     loss=0.3870 [20.7 s]    dev=(HR@5:0.3612,NDCG@5:0.2472) [0.9 s] *
INFO:root:Epoch 4     loss=0.3604 [19.8 s]    dev=(HR@5:0.3893,NDCG@5:0.2711) [0.9 s] *
INFO:root:Epoch 5     loss=0.3333 [19.7 s]    dev=(HR@5:0.4040,NDCG@5:0.2867) [0.9 s] *
INFO:root:Epoch 6     loss=0.3089 [19.5 s]    dev=(HR@5:0.4179,NDCG@5:0.3001) [0.9 s] *
INFO:root:Epoch 7     loss=0.2925 [19.6 s]    dev=(HR@5:0.4218,NDCG@5:0.3026) [0.9 s] *
INFO:root:Epoch 8     loss=0.2784 [19.3 s]    dev=(HR@5:0.4260,NDCG@5:0.3080) [0.9 s] *
INFO:root:Epoch 9     loss=0.2656 [19.4 s]    dev=(HR@5:0.4306,NDCG@5:0.3118) [0.9 s] *
INFO:root:Epoch 10    loss=0.2574 [19.7 s]    dev=(HR@5:0.4338,NDCG@5:0.3146) [0.9 s] *
INFO:root:Epoch 11    loss=0.2480 [19.2 s]    dev=(HR@5:0.4385,NDCG@5:0.3175) [0.9 s] *
INFO:root:Epoch 12    loss=0.2395 [19.2 s]    dev=(HR@5:0.4410,NDCG@5:0.3215) [0.9 s] *
INFO:root:Epoch 13    loss=0.2357 [19.9 s]    dev=(HR@5:0.4425,NDCG@5:0.3236) [0.9 s] *
INFO:root:Epoch 14    loss=0.2316 [19.5 s]    dev=(HR@5:0.4415,NDCG@5:0.3222) [0.9 s]
INFO:root:Epoch 15    loss=0.2276 [19.5 s]    dev=(HR@5:0.4408,NDCG@5:0.3220) [0.9 s]
INFO:root:Epoch 16    loss=0.2250 [19.5 s]    dev=(HR@5:0.4410,NDCG@5:0.3233) [0.9 s]
INFO:root:Epoch 17    loss=0.2214 [20.1 s]    dev=(HR@5:0.4415,NDCG@5:0.3247) [0.9 s] *
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 11:37:56 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cpu
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [148.9 s]    dev=(HR@5:0.2513,NDCG@5:0.1669) [7.1 s] *
INFO:root:Epoch 2     loss=0.4330 [156.1 s]    dev=(HR@5:0.3236,NDCG@5:0.2191) [6.2 s] *
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 13:41:15 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cpu
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [132.8 s]    dev=(HR@5:0.2513,NDCG@5:0.1669) [6.6 s] *
INFO:root:Epoch 2     loss=0.4330 [139.0 s]    dev=(HR@5:0.3236,NDCG@5:0.2191) [5.4 s] *
INFO:root:Epoch 3     loss=0.3995 [132.0 s]    dev=(HR@5:0.3443,NDCG@5:0.2328) [5.5 s] *
INFO:root:Epoch 4     loss=0.3811 [131.4 s]    dev=(HR@5:0.3619,NDCG@5:0.2480) [5.3 s] *
INFO:root:Epoch 5     loss=0.3579 [135.1 s]    dev=(HR@5:0.3803,NDCG@5:0.2646) [5.7 s] *
INFO:root:Epoch 6     loss=0.3352 [133.4 s]    dev=(HR@5:0.3931,NDCG@5:0.2789) [5.4 s] *
INFO:root:Epoch 7     loss=0.3175 [132.6 s]    dev=(HR@5:0.4005,NDCG@5:0.2831) [5.4 s] *
INFO:root:Epoch 8     loss=0.3002 [133.4 s]    dev=(HR@5:0.4092,NDCG@5:0.2930) [5.5 s] *
INFO:root:Epoch 9     loss=0.2841 [134.1 s]    dev=(HR@5:0.4143,NDCG@5:0.2973) [5.4 s] *
INFO:root:Epoch 10    loss=0.2733 [133.6 s]    dev=(HR@5:0.4173,NDCG@5:0.3003) [5.5 s] *
INFO:root:Epoch 11    loss=0.2622 [131.5 s]    dev=(HR@5:0.4211,NDCG@5:0.3052) [5.3 s] *
INFO:root:Epoch 12    loss=0.2532 [131.8 s]    dev=(HR@5:0.4257,NDCG@5:0.3110) [5.3 s] *
INFO:root:Epoch 13    loss=0.2474 [131.5 s]    dev=(HR@5:0.4271,NDCG@5:0.3115) [5.6 s] *
INFO:root:Epoch 14    loss=0.2415 [130.3 s]    dev=(HR@5:0.4239,NDCG@5:0.3102) [5.3 s]
INFO:root:Epoch 15    loss=0.2384 [130.9 s]    dev=(HR@5:0.4248,NDCG@5:0.3097) [5.3 s]
INFO:root:Epoch 16    loss=0.2342 [130.5 s]    dev=(HR@5:0.4233,NDCG@5:0.3090) [5.3 s]
INFO:root:Epoch 17    loss=0.2301 [133.2 s]    dev=(HR@5:0.4269,NDCG@5:0.3134) [5.6 s] *
INFO:root:Epoch 18    loss=0.2259 [129.8 s]    dev=(HR@5:0.4263,NDCG@5:0.3120) [5.4 s]
INFO:root:Epoch 19    loss=0.2223 [129.8 s]    dev=(HR@5:0.4301,NDCG@5:0.3162) [5.7 s] *
INFO:root:Epoch 20    loss=0.2208 [131.8 s]    dev=(HR@5:0.4319,NDCG@5:0.3184) [5.4 s] *
INFO:root:Epoch 21    loss=0.2159 [133.8 s]    dev=(HR@5:0.4297,NDCG@5:0.3147) [5.5 s]
INFO:root:Epoch 22    loss=0.2140 [142.1 s]    dev=(HR@5:0.4266,NDCG@5:0.3138) [6.1 s]
INFO:root:Epoch 23    loss=0.2135 [134.1 s]    dev=(HR@5:0.4313,NDCG@5:0.3185) [5.4 s] *
INFO:root:Epoch 24    loss=0.2130 [132.5 s]    dev=(HR@5:0.4348,NDCG@5:0.3198) [5.6 s] *
INFO:root:Epoch 25    loss=0.2095 [133.0 s]    dev=(HR@5:0.4291,NDCG@5:0.3159) [5.4 s]
INFO:root:Epoch 26    loss=0.2092 [136.9 s]    dev=(HR@5:0.4332,NDCG@5:0.3176) [6.2 s]
INFO:root:Epoch 27    loss=0.2073 [131.9 s]    dev=(HR@5:0.4340,NDCG@5:0.3201) [5.4 s] *
INFO:root:Epoch 28    loss=0.2080 [131.6 s]    dev=(HR@5:0.4331,NDCG@5:0.3202) [5.3 s] *
INFO:root:Epoch 29    loss=0.2054 [132.5 s]    dev=(HR@5:0.4341,NDCG@5:0.3216) [5.6 s] *
INFO:root:Epoch 30    loss=0.2051 [131.1 s]    dev=(HR@5:0.4340,NDCG@5:0.3209) [5.4 s]
INFO:root:Epoch 31    loss=0.2034 [132.5 s]    dev=(HR@5:0.4404,NDCG@5:0.3243) [5.5 s] *
INFO:root:Epoch 32    loss=0.2038 [131.4 s]    dev=(HR@5:0.4353,NDCG@5:0.3212) [5.5 s]
INFO:root:Epoch 33    loss=0.2028 [131.6 s]    dev=(HR@5:0.4357,NDCG@5:0.3215) [5.5 s]
INFO:root:Epoch 34    loss=0.2023 [130.8 s]    dev=(HR@5:0.4373,NDCG@5:0.3240) [5.5 s]
INFO:root:Epoch 35    loss=0.2035 [131.1 s]    dev=(HR@5:0.4380,NDCG@5:0.3230) [5.5 s]
INFO:root:Epoch 36    loss=0.2002 [131.2 s]    dev=(HR@5:0.4377,NDCG@5:0.3231) [5.3 s]
INFO:root:Epoch 37    loss=0.2010 [131.0 s]    dev=(HR@5:0.4394,NDCG@5:0.3237) [5.3 s]
INFO:root:Epoch 38    loss=0.2005 [130.7 s]    dev=(HR@5:0.4382,NDCG@5:0.3241) [5.3 s]
INFO:root:Epoch 39    loss=0.2004 [440.2 s]    dev=(HR@5:0.4387,NDCG@5:0.3238) [5.3 s]
INFO:root:Epoch 40    loss=0.1991 [134.4 s]    dev=(HR@5:0.4422,NDCG@5:0.3275) [5.7 s] *
INFO:root:Epoch 41    loss=0.1998 [136.9 s]    dev=(HR@5:0.4388,NDCG@5:0.3230) [5.7 s]
INFO:root:Epoch 42    loss=0.1996 [134.1 s]    dev=(HR@5:0.4415,NDCG@5:0.3257) [5.4 s]
INFO:root:Epoch 43    loss=0.1982 [134.9 s]    dev=(HR@5:0.4437,NDCG@5:0.3260) [5.5 s]
INFO:root:Epoch 44    loss=0.1999 [142.1 s]    dev=(HR@5:0.4430,NDCG@5:0.3263) [5.9 s]
INFO:root:Epoch 45    loss=0.1968 [135.0 s]    dev=(HR@5:0.4435,NDCG@5:0.3274) [5.4 s]
INFO:root:Epoch 46    loss=0.1985 [137.3 s]    dev=(HR@5:0.4389,NDCG@5:0.3243) [5.6 s]
INFO:root:Epoch 47    loss=0.1990 [135.4 s]    dev=(HR@5:0.4398,NDCG@5:0.3219) [5.4 s]
INFO:root:Epoch 48    loss=0.1973 [136.1 s]    dev=(HR@5:0.4393,NDCG@5:0.3236) [5.5 s]
INFO:root:Epoch 49    loss=0.1961 [135.5 s]    dev=(HR@5:0.4443,NDCG@5:0.3259) [5.6 s]
INFO:root:Epoch 50    loss=0.1983 [135.3 s]    dev=(HR@5:0.4416,NDCG@5:0.3257) [5.3 s]
INFO:root:Epoch 51    loss=0.1974 [135.1 s]    dev=(HR@5:0.4369,NDCG@5:0.3220) [5.4 s]
INFO:root:Epoch 52    loss=0.1975 [135.8 s]    dev=(HR@5:0.4418,NDCG@5:0.3243) [5.6 s]
INFO:root:Epoch 53    loss=0.1969 [138.2 s]    dev=(HR@5:0.4431,NDCG@5:0.3258) [5.9 s]
INFO:root:Epoch 54    loss=0.1942 [139.2 s]    dev=(HR@5:0.4417,NDCG@5:0.3241) [6.0 s]
INFO:root:Epoch 55    loss=0.1951 [141.3 s]    dev=(HR@5:0.4391,NDCG@5:0.3225) [5.7 s]
INFO:root:Epoch 56    loss=0.1954 [139.3 s]    dev=(HR@5:0.4399,NDCG@5:0.3254) [5.6 s]
INFO:root:Epoch 57    loss=0.1953 [136.3 s]    dev=(HR@5:0.4441,NDCG@5:0.3276) [5.5 s] *
INFO:root:Epoch 58    loss=0.1967 [142.4 s]    dev=(HR@5:0.4434,NDCG@5:0.3273) [6.0 s]
INFO:root:Epoch 59    loss=0.1959 [135.9 s]    dev=(HR@5:0.4362,NDCG@5:0.3217) [5.4 s]
INFO:root:Epoch 60    loss=0.1956 [134.3 s]    dev=(HR@5:0.4382,NDCG@5:0.3228) [5.4 s]
INFO:root:Epoch 61    loss=0.1950 [134.8 s]    dev=(HR@5:0.4402,NDCG@5:0.3243) [5.3 s]
INFO:root:Epoch 62    loss=0.1946 [141.5 s]    dev=(HR@5:0.4402,NDCG@5:0.3239) [6.0 s]
INFO:root:Epoch 63    loss=0.1956 [139.4 s]    dev=(HR@5:0.4436,NDCG@5:0.3267) [5.8 s]
INFO:root:Epoch 64    loss=0.1949 [140.8 s]    dev=(HR@5:0.4375,NDCG@5:0.3206) [5.6 s]
INFO:root:Epoch 65    loss=0.1949 [139.6 s]    dev=(HR@5:0.4423,NDCG@5:0.3248) [5.4 s]
INFO:root:Epoch 66    loss=0.1940 [138.2 s]    dev=(HR@5:0.4438,NDCG@5:0.3257) [5.5 s]
INFO:root:Epoch 67    loss=0.1949 [141.9 s]    dev=(HR@5:0.4477,NDCG@5:0.3279) [5.4 s] *
INFO:root:Epoch 68    loss=0.1928 [135.7 s]    dev=(HR@5:0.4402,NDCG@5:0.3236) [5.7 s]
INFO:root:Epoch 69    loss=0.1941 [138.8 s]    dev=(HR@5:0.4442,NDCG@5:0.3272) [5.5 s]
INFO:root:Epoch 70    loss=0.1931 [135.9 s]    dev=(HR@5:0.4447,NDCG@5:0.3262) [6.1 s]
INFO:root:Epoch 71    loss=0.1935 [143.3 s]    dev=(HR@5:0.4451,NDCG@5:0.3297) [5.5 s] *
INFO:root:Epoch 72    loss=0.1932 [135.2 s]    dev=(HR@5:0.4365,NDCG@5:0.3219) [5.4 s]
INFO:root:Epoch 73    loss=0.1944 [137.1 s]    dev=(HR@5:0.4373,NDCG@5:0.3226) [5.9 s]
INFO:root:Epoch 74    loss=0.1944 [142.4 s]    dev=(HR@5:0.4434,NDCG@5:0.3255) [6.2 s]
INFO:root:Epoch 75    loss=0.1945 [142.0 s]    dev=(HR@5:0.4421,NDCG@5:0.3254) [6.1 s]
INFO:root:Epoch 76    loss=0.1945 [139.0 s]    dev=(HR@5:0.4464,NDCG@5:0.3270) [5.5 s]
INFO:root:Epoch 77    loss=0.1925 [140.3 s]    dev=(HR@5:0.4413,NDCG@5:0.3241) [6.1 s]
INFO:root:Epoch 78    loss=0.1922 [144.2 s]    dev=(HR@5:0.4432,NDCG@5:0.3246) [5.7 s]
INFO:root:Epoch 79    loss=0.1940 [142.3 s]    dev=(HR@5:0.4374,NDCG@5:0.3199) [5.7 s]
INFO:root:Epoch 80    loss=0.1921 [140.7 s]    dev=(HR@5:0.4413,NDCG@5:0.3243) [5.6 s]
INFO:root:Epoch 81    loss=0.1922 [139.8 s]    dev=(HR@5:0.4391,NDCG@5:0.3237) [5.8 s]
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:17:45 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cpu
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5165 [275.0 s]    dev=(HR@5:0.2512,NDCG@5:0.1669) [14.8 s] *
INFO:root:Early stop manually
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:30:42 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:30:52 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:31:02 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:31:13 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:31:23 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:31:32 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:31:41 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:31:50 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:32:00 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:32:09 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:32:18 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:32:29 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:32:40 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:32:49 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:32:58 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:33:07 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:33:17 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:33:26 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:33:36 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:33:45 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:33:55 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:34:04 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:34:13 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:34:23 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:34:33 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:38:19 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:38:30 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:38:40 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:38:49 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:38:58 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:39:07 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:39:17 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:39:26 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:39:35 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:39:44 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:39:53 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:40:03 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:40:14 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:40:24 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:40:33 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:40:42 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:40:51 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:41:01 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:41:09 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-21 20:41:18 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-22 12:20:44 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cpu
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Early stop manually
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-22 12:22:17 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [12.4 s]    dev=(HR@5:0.2509,NDCG@5:0.1669) [0.4 s] *
INFO:root:Epoch 2     loss=0.4330 [9.9 s]    dev=(HR@5:0.3201,NDCG@5:0.2167) [0.4 s] *
INFO:root:Epoch 3     loss=0.4005 [10.8 s]    dev=(HR@5:0.3385,NDCG@5:0.2281) [0.4 s] *
INFO:root:Epoch 4     loss=0.3848 [9.7 s]    dev=(HR@5:0.3532,NDCG@5:0.2426) [0.4 s] *
INFO:root:Epoch 5     loss=0.3649 [9.7 s]    dev=(HR@5:0.3675,NDCG@5:0.2535) [0.4 s] *
INFO:root:Epoch 6     loss=0.3429 [11.1 s]    dev=(HR@5:0.3832,NDCG@5:0.2697) [0.4 s] *
INFO:root:Epoch 7     loss=0.3261 [10.7 s]    dev=(HR@5:0.3899,NDCG@5:0.2732) [0.4 s] *
INFO:root:Epoch 8     loss=0.3089 [9.3 s]    dev=(HR@5:0.3950,NDCG@5:0.2813) [0.4 s] *
INFO:root:Epoch 9     loss=0.2925 [10.9 s]    dev=(HR@5:0.4015,NDCG@5:0.2875) [0.4 s] *
INFO:root:Epoch 10    loss=0.2807 [10.7 s]    dev=(HR@5:0.4048,NDCG@5:0.2927) [0.4 s] *
INFO:root:Epoch 11    loss=0.2680 [11.1 s]    dev=(HR@5:0.4127,NDCG@5:0.2982) [0.4 s] *
INFO:root:Epoch 12    loss=0.2583 [10.9 s]    dev=(HR@5:0.4126,NDCG@5:0.3008) [0.4 s] *
INFO:root:Epoch 13    loss=0.2522 [9.9 s]    dev=(HR@5:0.4196,NDCG@5:0.3065) [0.4 s] *
INFO:root:Epoch 14    loss=0.2454 [10.7 s]    dev=(HR@5:0.4191,NDCG@5:0.3061) [0.4 s]
INFO:root:Epoch 15    loss=0.2404 [10.5 s]    dev=(HR@5:0.4213,NDCG@5:0.3059) [0.4 s]
INFO:root:Epoch 16    loss=0.2360 [11.1 s]    dev=(HR@5:0.4222,NDCG@5:0.3089) [0.4 s] *
INFO:root:Epoch 17    loss=0.2322 [9.3 s]    dev=(HR@5:0.4223,NDCG@5:0.3075) [0.4 s]
INFO:root:Epoch 18    loss=0.2282 [9.5 s]    dev=(HR@5:0.4261,NDCG@5:0.3114) [0.4 s] *
INFO:root:Epoch 19    loss=0.2243 [10.6 s]    dev=(HR@5:0.4258,NDCG@5:0.3147) [0.4 s] *
INFO:root:Epoch 20    loss=0.2229 [10.3 s]    dev=(HR@5:0.4289,NDCG@5:0.3149) [0.4 s] *
INFO:root:Epoch 21    loss=0.2179 [10.5 s]    dev=(HR@5:0.4306,NDCG@5:0.3171) [0.4 s] *
INFO:root:Epoch 22    loss=0.2165 [9.7 s]    dev=(HR@5:0.4265,NDCG@5:0.3134) [0.4 s]
INFO:root:Epoch 23    loss=0.2159 [10.1 s]    dev=(HR@5:0.4272,NDCG@5:0.3152) [0.4 s]
INFO:root:Epoch 24    loss=0.2147 [10.0 s]    dev=(HR@5:0.4304,NDCG@5:0.3173) [0.4 s] *
INFO:root:Epoch 25    loss=0.2129 [10.4 s]    dev=(HR@5:0.4304,NDCG@5:0.3176) [0.4 s] *
INFO:root:Epoch 26    loss=0.2125 [10.2 s]    dev=(HR@5:0.4307,NDCG@5:0.3179) [0.4 s] *
INFO:root:Epoch 27    loss=0.2111 [9.9 s]    dev=(HR@5:0.4356,NDCG@5:0.3222) [0.4 s] *
INFO:root:Epoch 28    loss=0.2096 [10.4 s]    dev=(HR@5:0.4348,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 29    loss=0.2087 [10.7 s]    dev=(HR@5:0.4335,NDCG@5:0.3200) [0.4 s]
INFO:root:Epoch 30    loss=0.2076 [10.4 s]    dev=(HR@5:0.4341,NDCG@5:0.3221) [0.4 s]
INFO:root:Epoch 31    loss=0.2065 [10.2 s]    dev=(HR@5:0.4331,NDCG@5:0.3197) [0.4 s]
INFO:root:Epoch 32    loss=0.2071 [10.2 s]    dev=(HR@5:0.4333,NDCG@5:0.3203) [0.4 s]
INFO:root:Epoch 33    loss=0.2059 [10.3 s]    dev=(HR@5:0.4338,NDCG@5:0.3206) [0.3 s]
INFO:root:Epoch 34    loss=0.2042 [10.6 s]    dev=(HR@5:0.4340,NDCG@5:0.3197) [0.4 s]
INFO:root:Epoch 35    loss=0.2058 [10.9 s]    dev=(HR@5:0.4302,NDCG@5:0.3181) [0.4 s]
INFO:root:Epoch 36    loss=0.2024 [9.4 s]    dev=(HR@5:0.4351,NDCG@5:0.3200) [0.4 s]
INFO:root:Epoch 37    loss=0.2040 [9.7 s]    dev=(HR@5:0.4386,NDCG@5:0.3240) [0.4 s] *
INFO:root:Epoch 38    loss=0.2035 [10.4 s]    dev=(HR@5:0.4349,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 39    loss=0.2033 [10.8 s]    dev=(HR@5:0.4348,NDCG@5:0.3196) [0.4 s]
INFO:root:Epoch 40    loss=0.2016 [10.5 s]    dev=(HR@5:0.4300,NDCG@5:0.3185) [0.4 s]
INFO:root:Epoch 41    loss=0.2029 [9.8 s]    dev=(HR@5:0.4334,NDCG@5:0.3204) [0.4 s]
INFO:root:Epoch 42    loss=0.2029 [10.8 s]    dev=(HR@5:0.4408,NDCG@5:0.3234) [0.4 s]
INFO:root:Epoch 43    loss=0.2013 [10.1 s]    dev=(HR@5:0.4408,NDCG@5:0.3261) [0.3 s] *
INFO:root:Epoch 44    loss=0.2032 [10.3 s]    dev=(HR@5:0.4385,NDCG@5:0.3229) [0.4 s]
INFO:root:Epoch 45    loss=0.1987 [11.0 s]    dev=(HR@5:0.4422,NDCG@5:0.3282) [0.3 s] *
INFO:root:Epoch 46    loss=0.2009 [9.9 s]    dev=(HR@5:0.4374,NDCG@5:0.3232) [0.4 s]
INFO:root:Epoch 47    loss=0.2020 [10.3 s]    dev=(HR@5:0.4374,NDCG@5:0.3222) [0.4 s]
INFO:root:Epoch 48    loss=0.1992 [9.7 s]    dev=(HR@5:0.4321,NDCG@5:0.3200) [0.4 s]
INFO:root:Epoch 49    loss=0.1989 [10.5 s]    dev=(HR@5:0.4387,NDCG@5:0.3230) [0.4 s]
INFO:root:Epoch 50    loss=0.1996 [8.8 s]    dev=(HR@5:0.4367,NDCG@5:0.3235) [0.4 s]
INFO:root:Epoch 51    loss=0.1987 [10.6 s]    dev=(HR@5:0.4390,NDCG@5:0.3264) [0.4 s]
INFO:root:Epoch 52    loss=0.1987 [11.0 s]    dev=(HR@5:0.4362,NDCG@5:0.3229) [0.4 s]
INFO:root:Epoch 53    loss=0.1978 [10.3 s]    dev=(HR@5:0.4385,NDCG@5:0.3235) [0.4 s]
INFO:root:Epoch 54    loss=0.1958 [9.8 s]    dev=(HR@5:0.4406,NDCG@5:0.3250) [0.4 s]
INFO:root:Epoch 55    loss=0.1969 [9.7 s]    dev=(HR@5:0.4395,NDCG@5:0.3247) [0.4 s]
INFO:root:Epoch 56    loss=0.1961 [10.2 s]    dev=(HR@5:0.4368,NDCG@5:0.3241) [0.4 s]
INFO:root:Epoch 57    loss=0.1959 [10.0 s]    dev=(HR@5:0.4408,NDCG@5:0.3267) [0.5 s]
INFO:root:Epoch 58    loss=0.1972 [10.8 s]    dev=(HR@5:0.4421,NDCG@5:0.3259) [0.4 s]
INFO:root:Epoch 59    loss=0.1957 [10.1 s]    dev=(HR@5:0.4354,NDCG@5:0.3218) [0.4 s]
INFO:root:Epoch 60    loss=0.1966 [10.4 s]    dev=(HR@5:0.4389,NDCG@5:0.3268) [0.4 s]
INFO:root:Epoch 61    loss=0.1960 [9.7 s]    dev=(HR@5:0.4380,NDCG@5:0.3250) [0.4 s]
INFO:root:Epoch 62    loss=0.1950 [10.7 s]    dev=(HR@5:0.4430,NDCG@5:0.3266) [0.4 s]
INFO:root:Epoch 63    loss=0.1964 [11.0 s]    dev=(HR@5:0.4437,NDCG@5:0.3283) [0.4 s] *
INFO:root:Epoch 64    loss=0.1954 [10.4 s]    dev=(HR@5:0.4408,NDCG@5:0.3251) [0.4 s]
INFO:root:Epoch 65    loss=0.1956 [10.5 s]    dev=(HR@5:0.4355,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 66    loss=0.1941 [10.4 s]    dev=(HR@5:0.4404,NDCG@5:0.3247) [0.4 s]
INFO:root:Epoch 67    loss=0.1945 [10.2 s]    dev=(HR@5:0.4394,NDCG@5:0.3240) [0.4 s]
INFO:root:Epoch 68    loss=0.1933 [10.0 s]    dev=(HR@5:0.4387,NDCG@5:0.3240) [0.4 s]
INFO:root:Epoch 69    loss=0.1937 [10.4 s]    dev=(HR@5:0.4376,NDCG@5:0.3235) [0.4 s]
INFO:root:Epoch 70    loss=0.1943 [10.4 s]    dev=(HR@5:0.4385,NDCG@5:0.3247) [0.4 s]
INFO:root:Epoch 71    loss=0.1933 [9.5 s]    dev=(HR@5:0.4378,NDCG@5:0.3253) [0.4 s]
INFO:root:Epoch 72    loss=0.1920 [10.5 s]    dev=(HR@5:0.4415,NDCG@5:0.3245) [0.4 s]
INFO:root:Epoch 73    loss=0.1942 [11.2 s]    dev=(HR@5:0.4372,NDCG@5:0.3220) [0.4 s]
INFO:root:Epoch 74    loss=0.1937 [10.2 s]    dev=(HR@5:0.4352,NDCG@5:0.3200) [0.4 s]
INFO:root:Epoch 75    loss=0.1946 [11.1 s]    dev=(HR@5:0.4375,NDCG@5:0.3242) [0.4 s]
INFO:root:Epoch 76    loss=0.1932 [10.1 s]    dev=(HR@5:0.4355,NDCG@5:0.3216) [0.4 s]
INFO:root:Epoch 77    loss=0.1925 [9.9 s]    dev=(HR@5:0.4379,NDCG@5:0.3241) [0.4 s]
INFO:root:Epoch 78    loss=0.1925 [10.8 s]    dev=(HR@5:0.4387,NDCG@5:0.3245) [0.4 s]
INFO:root:Epoch 79    loss=0.1929 [11.3 s]    dev=(HR@5:0.4364,NDCG@5:0.3228) [0.4 s]
INFO:root:Epoch 80    loss=0.1911 [10.6 s]    dev=(HR@5:0.4353,NDCG@5:0.3212) [0.4 s]
INFO:root:Epoch 81    loss=0.1925 [11.1 s]    dev=(HR@5:0.4345,NDCG@5:0.3203) [0.4 s]
INFO:root:Epoch 82    loss=0.1937 [10.5 s]    dev=(HR@5:0.4387,NDCG@5:0.3239) [0.4 s]
INFO:root:Epoch 83    loss=0.1919 [11.1 s]    dev=(HR@5:0.4391,NDCG@5:0.3236) [0.4 s]
INFO:root:Early stop at 83 based on dev result.
INFO:root:
Best Iter(dev)=   63	 dev=(HR@5:0.4437,NDCG@5:0.3283) [891.6 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.3890,NDCG@5:0.2809,HR@10:0.4962,NDCG@10:0.3156,HR@20:0.6154,NDCG@20:0.3455,HR@50:0.8228,NDCG@50:0.3866)
INFO:root:
--------------------------------------------- END: 2024-12-22 12:37:12 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-22 12:58:09 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [11.8 s]    dev=(HR@5:0.2511,NDCG@5:0.1670) [0.4 s] *
INFO:root:Epoch 2     loss=0.4324 [11.1 s]    dev=(HR@5:0.3202,NDCG@5:0.2172) [0.4 s] *
INFO:root:Epoch 3     loss=0.4001 [10.3 s]    dev=(HR@5:0.3388,NDCG@5:0.2287) [0.4 s] *
INFO:root:Epoch 4     loss=0.3847 [11.2 s]    dev=(HR@5:0.3533,NDCG@5:0.2419) [0.4 s] *
INFO:root:Epoch 5     loss=0.3655 [10.8 s]    dev=(HR@5:0.3652,NDCG@5:0.2502) [0.3 s] *
INFO:root:Epoch 6     loss=0.3447 [11.1 s]    dev=(HR@5:0.3800,NDCG@5:0.2667) [0.4 s] *
INFO:root:Epoch 7     loss=0.3272 [11.1 s]    dev=(HR@5:0.3874,NDCG@5:0.2709) [0.4 s] *
INFO:root:Epoch 8     loss=0.3091 [10.7 s]    dev=(HR@5:0.3976,NDCG@5:0.2809) [0.4 s] *
INFO:root:Epoch 9     loss=0.2916 [10.5 s]    dev=(HR@5:0.4022,NDCG@5:0.2859) [0.4 s] *
INFO:root:Epoch 10    loss=0.2806 [11.1 s]    dev=(HR@5:0.4079,NDCG@5:0.2920) [0.4 s] *
INFO:root:Epoch 11    loss=0.2680 [10.5 s]    dev=(HR@5:0.4131,NDCG@5:0.2955) [0.4 s] *
INFO:root:Epoch 12    loss=0.2582 [10.6 s]    dev=(HR@5:0.4141,NDCG@5:0.2984) [0.4 s] *
INFO:root:Epoch 13    loss=0.2523 [11.1 s]    dev=(HR@5:0.4207,NDCG@5:0.3045) [0.4 s] *
INFO:root:Epoch 14    loss=0.2456 [10.0 s]    dev=(HR@5:0.4221,NDCG@5:0.3046) [0.4 s] *
INFO:root:Epoch 15    loss=0.2403 [9.7 s]    dev=(HR@5:0.4210,NDCG@5:0.3046) [0.4 s]
INFO:root:Epoch 16    loss=0.2370 [9.8 s]    dev=(HR@5:0.4201,NDCG@5:0.3066) [0.4 s] *
INFO:root:Epoch 17    loss=0.2331 [10.0 s]    dev=(HR@5:0.4197,NDCG@5:0.3041) [0.3 s]
INFO:root:Epoch 18    loss=0.2276 [10.7 s]    dev=(HR@5:0.4234,NDCG@5:0.3084) [0.4 s] *
INFO:root:Epoch 19    loss=0.2244 [9.2 s]    dev=(HR@5:0.4232,NDCG@5:0.3100) [0.4 s] *
INFO:root:Epoch 20    loss=0.2228 [10.1 s]    dev=(HR@5:0.4242,NDCG@5:0.3122) [0.4 s] *
INFO:root:Epoch 21    loss=0.2184 [10.0 s]    dev=(HR@5:0.4301,NDCG@5:0.3132) [0.4 s] *
INFO:root:Epoch 22    loss=0.2167 [8.3 s]    dev=(HR@5:0.4297,NDCG@5:0.3132) [0.4 s] *
INFO:root:Epoch 23    loss=0.2167 [9.4 s]    dev=(HR@5:0.4263,NDCG@5:0.3122) [0.4 s]
INFO:root:Epoch 24    loss=0.2158 [9.9 s]    dev=(HR@5:0.4307,NDCG@5:0.3151) [0.4 s] *
INFO:root:Epoch 25    loss=0.2125 [10.2 s]    dev=(HR@5:0.4242,NDCG@5:0.3109) [0.4 s]
INFO:root:Epoch 26    loss=0.2125 [9.3 s]    dev=(HR@5:0.4301,NDCG@5:0.3157) [0.4 s] *
INFO:root:Epoch 27    loss=0.2114 [10.5 s]    dev=(HR@5:0.4310,NDCG@5:0.3160) [0.4 s] *
INFO:root:Epoch 28    loss=0.2113 [9.6 s]    dev=(HR@5:0.4343,NDCG@5:0.3186) [0.4 s] *
INFO:root:Epoch 29    loss=0.2093 [10.5 s]    dev=(HR@5:0.4304,NDCG@5:0.3148) [0.4 s]
INFO:root:Epoch 30    loss=0.2083 [9.7 s]    dev=(HR@5:0.4325,NDCG@5:0.3174) [0.4 s]
INFO:root:Epoch 31    loss=0.2076 [11.1 s]    dev=(HR@5:0.4329,NDCG@5:0.3168) [0.4 s]
INFO:root:Epoch 32    loss=0.2079 [11.2 s]    dev=(HR@5:0.4333,NDCG@5:0.3177) [0.4 s]
INFO:root:Epoch 33    loss=0.2068 [10.2 s]    dev=(HR@5:0.4309,NDCG@5:0.3164) [0.4 s]
INFO:root:Epoch 34    loss=0.2049 [10.0 s]    dev=(HR@5:0.4338,NDCG@5:0.3175) [0.4 s]
INFO:root:Epoch 35    loss=0.2067 [10.4 s]    dev=(HR@5:0.4306,NDCG@5:0.3150) [0.3 s]
INFO:root:Epoch 36    loss=0.2042 [10.9 s]    dev=(HR@5:0.4343,NDCG@5:0.3169) [0.4 s]
INFO:root:Epoch 37    loss=0.2053 [10.4 s]    dev=(HR@5:0.4384,NDCG@5:0.3197) [0.4 s] *
INFO:root:Epoch 38    loss=0.2048 [10.4 s]    dev=(HR@5:0.4364,NDCG@5:0.3186) [0.4 s]
INFO:root:Epoch 39    loss=0.2043 [11.2 s]    dev=(HR@5:0.4343,NDCG@5:0.3164) [0.4 s]
INFO:root:Epoch 40    loss=0.2034 [10.7 s]    dev=(HR@5:0.4355,NDCG@5:0.3187) [0.3 s]
INFO:root:Epoch 41    loss=0.2044 [11.0 s]    dev=(HR@5:0.4327,NDCG@5:0.3165) [0.4 s]
INFO:root:Epoch 42    loss=0.2045 [10.4 s]    dev=(HR@5:0.4358,NDCG@5:0.3170) [0.3 s]
INFO:root:Epoch 43    loss=0.2032 [10.6 s]    dev=(HR@5:0.4391,NDCG@5:0.3224) [0.4 s] *
INFO:root:Epoch 44    loss=0.2053 [10.6 s]    dev=(HR@5:0.4359,NDCG@5:0.3193) [0.4 s]
INFO:root:Epoch 45    loss=0.2006 [10.8 s]    dev=(HR@5:0.4396,NDCG@5:0.3255) [0.4 s] *
INFO:root:Epoch 46    loss=0.2026 [9.6 s]    dev=(HR@5:0.4351,NDCG@5:0.3191) [0.4 s]
INFO:root:Epoch 47    loss=0.2034 [11.1 s]    dev=(HR@5:0.4355,NDCG@5:0.3177) [0.4 s]
INFO:root:Epoch 48    loss=0.2006 [10.4 s]    dev=(HR@5:0.4305,NDCG@5:0.3144) [0.4 s]
INFO:root:Epoch 49    loss=0.2000 [11.2 s]    dev=(HR@5:0.4357,NDCG@5:0.3209) [0.4 s]
INFO:root:Epoch 50    loss=0.2014 [10.0 s]    dev=(HR@5:0.4339,NDCG@5:0.3200) [0.4 s]
INFO:root:Epoch 51    loss=0.2005 [10.9 s]    dev=(HR@5:0.4375,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 52    loss=0.2005 [10.7 s]    dev=(HR@5:0.4338,NDCG@5:0.3164) [0.4 s]
INFO:root:Epoch 53    loss=0.1998 [10.5 s]    dev=(HR@5:0.4360,NDCG@5:0.3185) [0.4 s]
INFO:root:Epoch 54    loss=0.1980 [11.0 s]    dev=(HR@5:0.4399,NDCG@5:0.3203) [0.4 s]
INFO:root:Epoch 55    loss=0.1984 [10.2 s]    dev=(HR@5:0.4367,NDCG@5:0.3193) [0.4 s]
INFO:root:Epoch 56    loss=0.1979 [10.5 s]    dev=(HR@5:0.4367,NDCG@5:0.3205) [0.4 s]
INFO:root:Epoch 57    loss=0.1986 [9.6 s]    dev=(HR@5:0.4404,NDCG@5:0.3243) [0.4 s]
INFO:root:Epoch 58    loss=0.1988 [9.9 s]    dev=(HR@5:0.4397,NDCG@5:0.3227) [0.4 s]
INFO:root:Epoch 59    loss=0.1975 [10.2 s]    dev=(HR@5:0.4396,NDCG@5:0.3222) [0.4 s]
INFO:root:Epoch 60    loss=0.1984 [9.9 s]    dev=(HR@5:0.4380,NDCG@5:0.3216) [0.4 s]
INFO:root:Epoch 61    loss=0.1977 [9.9 s]    dev=(HR@5:0.4383,NDCG@5:0.3231) [0.4 s]
INFO:root:Epoch 62    loss=0.1966 [10.2 s]    dev=(HR@5:0.4415,NDCG@5:0.3232) [0.4 s]
INFO:root:Epoch 63    loss=0.1979 [10.4 s]    dev=(HR@5:0.4406,NDCG@5:0.3236) [0.4 s]
INFO:root:Epoch 64    loss=0.1973 [10.1 s]    dev=(HR@5:0.4413,NDCG@5:0.3228) [0.4 s]
INFO:root:Epoch 65    loss=0.1976 [9.1 s]    dev=(HR@5:0.4380,NDCG@5:0.3199) [0.4 s]
INFO:root:Early stop at 65 based on dev result.
INFO:root:
Best Iter(dev)=   45	 dev=(HR@5:0.4396,NDCG@5:0.3255) [698.7 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.3859,NDCG@5:0.2762,HR@10:0.4922,NDCG@10:0.3106,HR@20:0.6171,NDCG@20:0.3421,HR@50:0.8222,NDCG@50:0.3827)
INFO:root:
--------------------------------------------- END: 2024-12-22 13:09:51 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-22 13:39:57 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [11.9 s]    dev=(HR@5:0.2509,NDCG@5:0.1671) [0.3 s] *
INFO:root:Epoch 2     loss=0.4324 [10.2 s]    dev=(HR@5:0.3201,NDCG@5:0.2173) [0.4 s] *
INFO:root:Epoch 3     loss=0.4002 [10.4 s]    dev=(HR@5:0.3391,NDCG@5:0.2282) [0.4 s] *
INFO:root:Epoch 4     loss=0.3851 [10.8 s]    dev=(HR@5:0.3526,NDCG@5:0.2411) [0.4 s] *
INFO:root:Epoch 5     loss=0.3660 [10.9 s]    dev=(HR@5:0.3642,NDCG@5:0.2496) [0.4 s] *
INFO:root:Epoch 6     loss=0.3457 [10.9 s]    dev=(HR@5:0.3810,NDCG@5:0.2662) [0.4 s] *
INFO:root:Epoch 7     loss=0.3279 [10.4 s]    dev=(HR@5:0.3870,NDCG@5:0.2704) [0.4 s] *
INFO:root:Epoch 8     loss=0.3092 [10.7 s]    dev=(HR@5:0.3991,NDCG@5:0.2819) [0.4 s] *
INFO:root:Epoch 9     loss=0.2917 [11.2 s]    dev=(HR@5:0.4065,NDCG@5:0.2885) [0.4 s] *
INFO:root:Epoch 10    loss=0.2807 [10.0 s]    dev=(HR@5:0.4104,NDCG@5:0.2932) [0.4 s] *
INFO:root:Epoch 11    loss=0.2683 [10.3 s]    dev=(HR@5:0.4147,NDCG@5:0.2973) [0.4 s] *
INFO:root:Epoch 12    loss=0.2593 [11.3 s]    dev=(HR@5:0.4180,NDCG@5:0.3026) [0.4 s] *
INFO:root:Epoch 13    loss=0.2534 [10.6 s]    dev=(HR@5:0.4257,NDCG@5:0.3084) [0.4 s] *
INFO:root:Epoch 14    loss=0.2471 [10.8 s]    dev=(HR@5:0.4263,NDCG@5:0.3081) [0.4 s]
INFO:root:Epoch 15    loss=0.2431 [11.4 s]    dev=(HR@5:0.4269,NDCG@5:0.3087) [0.4 s] *
INFO:root:Epoch 16    loss=0.2402 [10.7 s]    dev=(HR@5:0.4263,NDCG@5:0.3101) [0.4 s] *
INFO:root:Epoch 17    loss=0.2358 [10.5 s]    dev=(HR@5:0.4244,NDCG@5:0.3095) [0.4 s]
INFO:root:Epoch 18    loss=0.2310 [11.1 s]    dev=(HR@5:0.4290,NDCG@5:0.3132) [0.4 s] *
INFO:root:Epoch 19    loss=0.2276 [11.0 s]    dev=(HR@5:0.4289,NDCG@5:0.3162) [0.4 s] *
INFO:root:Epoch 20    loss=0.2260 [11.6 s]    dev=(HR@5:0.4306,NDCG@5:0.3172) [0.4 s] *
INFO:root:Epoch 21    loss=0.2215 [10.9 s]    dev=(HR@5:0.4332,NDCG@5:0.3174) [0.4 s] *
INFO:root:Epoch 22    loss=0.2194 [10.5 s]    dev=(HR@5:0.4305,NDCG@5:0.3162) [0.4 s]
INFO:root:Epoch 23    loss=0.2197 [10.7 s]    dev=(HR@5:0.4294,NDCG@5:0.3173) [0.4 s]
INFO:root:Epoch 24    loss=0.2193 [10.7 s]    dev=(HR@5:0.4348,NDCG@5:0.3192) [0.4 s] *
INFO:root:Epoch 25    loss=0.2162 [11.0 s]    dev=(HR@5:0.4313,NDCG@5:0.3175) [0.4 s]
INFO:root:Epoch 26    loss=0.2158 [9.6 s]    dev=(HR@5:0.4347,NDCG@5:0.3201) [0.3 s] *
INFO:root:Epoch 27    loss=0.2144 [11.4 s]    dev=(HR@5:0.4329,NDCG@5:0.3193) [0.4 s]
INFO:root:Epoch 28    loss=0.2149 [10.2 s]    dev=(HR@5:0.4316,NDCG@5:0.3194) [0.4 s]
INFO:root:Epoch 29    loss=0.2120 [11.3 s]    dev=(HR@5:0.4300,NDCG@5:0.3170) [0.4 s]
INFO:root:Epoch 30    loss=0.2113 [10.5 s]    dev=(HR@5:0.4308,NDCG@5:0.3173) [0.4 s]
INFO:root:Epoch 31    loss=0.2102 [10.9 s]    dev=(HR@5:0.4336,NDCG@5:0.3188) [0.4 s]
INFO:root:Epoch 32    loss=0.2110 [10.2 s]    dev=(HR@5:0.4338,NDCG@5:0.3193) [0.4 s]
INFO:root:Epoch 33    loss=0.2092 [10.6 s]    dev=(HR@5:0.4333,NDCG@5:0.3210) [0.4 s] *
INFO:root:Epoch 34    loss=0.2080 [11.0 s]    dev=(HR@5:0.4348,NDCG@5:0.3196) [0.4 s]
INFO:root:Epoch 35    loss=0.2088 [10.7 s]    dev=(HR@5:0.4340,NDCG@5:0.3180) [0.4 s]
INFO:root:Epoch 36    loss=0.2063 [10.6 s]    dev=(HR@5:0.4321,NDCG@5:0.3197) [0.4 s]
INFO:root:Epoch 37    loss=0.2070 [11.3 s]    dev=(HR@5:0.4337,NDCG@5:0.3192) [0.4 s]
INFO:root:Epoch 38    loss=0.2064 [10.5 s]    dev=(HR@5:0.4366,NDCG@5:0.3206) [0.4 s]
INFO:root:Epoch 39    loss=0.2067 [10.4 s]    dev=(HR@5:0.4320,NDCG@5:0.3187) [0.4 s]
INFO:root:Epoch 40    loss=0.2054 [11.3 s]    dev=(HR@5:0.4301,NDCG@5:0.3177) [0.5 s]
INFO:root:Epoch 41    loss=0.2060 [9.7 s]    dev=(HR@5:0.4299,NDCG@5:0.3162) [0.4 s]
INFO:root:Epoch 42    loss=0.2057 [11.1 s]    dev=(HR@5:0.4353,NDCG@5:0.3190) [0.4 s]
INFO:root:Epoch 43    loss=0.2044 [11.1 s]    dev=(HR@5:0.4395,NDCG@5:0.3241) [0.4 s] *
INFO:root:Epoch 44    loss=0.2058 [9.1 s]    dev=(HR@5:0.4321,NDCG@5:0.3173) [0.4 s]
INFO:root:Epoch 45    loss=0.2023 [9.0 s]    dev=(HR@5:0.4398,NDCG@5:0.3248) [0.4 s] *
INFO:root:Epoch 46    loss=0.2035 [11.2 s]    dev=(HR@5:0.4304,NDCG@5:0.3158) [0.5 s]
INFO:root:Epoch 47    loss=0.2039 [10.9 s]    dev=(HR@5:0.4345,NDCG@5:0.3182) [0.4 s]
INFO:root:Epoch 48    loss=0.2021 [11.3 s]    dev=(HR@5:0.4310,NDCG@5:0.3158) [0.4 s]
INFO:root:Epoch 49    loss=0.2013 [10.9 s]    dev=(HR@5:0.4388,NDCG@5:0.3219) [0.4 s]
INFO:root:Epoch 50    loss=0.2029 [10.9 s]    dev=(HR@5:0.4355,NDCG@5:0.3198) [0.3 s]
INFO:root:Epoch 51    loss=0.2006 [11.2 s]    dev=(HR@5:0.4387,NDCG@5:0.3230) [0.3 s]
INFO:root:Epoch 52    loss=0.2018 [9.8 s]    dev=(HR@5:0.4378,NDCG@5:0.3202) [0.4 s]
INFO:root:Epoch 53    loss=0.2008 [10.8 s]    dev=(HR@5:0.4355,NDCG@5:0.3194) [0.4 s]
INFO:root:Early stop manually
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-22 13:55:29 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-22 13:55:35 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [11.6 s]    dev=(HR@5:0.2509,NDCG@5:0.1669) [0.4 s] *
INFO:root:Epoch 2     loss=0.4330 [10.5 s]    dev=(HR@5:0.3201,NDCG@5:0.2167) [0.3 s] *
INFO:root:Epoch 3     loss=0.4005 [10.5 s]    dev=(HR@5:0.3385,NDCG@5:0.2281) [0.4 s] *
INFO:root:Epoch 4     loss=0.3848 [9.2 s]    dev=(HR@5:0.3532,NDCG@5:0.2426) [0.4 s] *
INFO:root:Epoch 5     loss=0.3649 [7.9 s]    dev=(HR@5:0.3675,NDCG@5:0.2535) [0.4 s] *
INFO:root:Epoch 6     loss=0.3429 [10.4 s]    dev=(HR@5:0.3832,NDCG@5:0.2697) [0.4 s] *
INFO:root:Epoch 7     loss=0.3261 [10.1 s]    dev=(HR@5:0.3899,NDCG@5:0.2732) [0.4 s] *
INFO:root:Early stop manually
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-22 13:57:07 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [11.3 s]    dev=(HR@5:0.2509,NDCG@5:0.1669) [0.4 s] *
INFO:root:Epoch 2     loss=0.4330 [10.1 s]    dev=(HR@5:0.3201,NDCG@5:0.2167) [0.4 s] *
INFO:root:Epoch 3     loss=0.4005 [10.0 s]    dev=(HR@5:0.3385,NDCG@5:0.2281) [0.4 s] *
INFO:root:Epoch 4     loss=0.3848 [9.8 s]    dev=(HR@5:0.3532,NDCG@5:0.2426) [0.4 s] *
INFO:root:Epoch 5     loss=0.3649 [10.4 s]    dev=(HR@5:0.3675,NDCG@5:0.2535) [0.3 s] *
INFO:root:Epoch 6     loss=0.3429 [8.7 s]    dev=(HR@5:0.3832,NDCG@5:0.2697) [0.4 s] *
INFO:root:Epoch 7     loss=0.3261 [10.1 s]    dev=(HR@5:0.3899,NDCG@5:0.2732) [0.4 s] *
INFO:root:Epoch 8     loss=0.3089 [10.3 s]    dev=(HR@5:0.3950,NDCG@5:0.2813) [0.4 s] *
INFO:root:Epoch 9     loss=0.2925 [10.2 s]    dev=(HR@5:0.4015,NDCG@5:0.2875) [0.4 s] *
INFO:root:Epoch 10    loss=0.2807 [11.2 s]    dev=(HR@5:0.4048,NDCG@5:0.2927) [0.4 s] *
INFO:root:Epoch 11    loss=0.2680 [9.7 s]    dev=(HR@5:0.4127,NDCG@5:0.2982) [0.4 s] *
INFO:root:Epoch 12    loss=0.2583 [11.1 s]    dev=(HR@5:0.4126,NDCG@5:0.3008) [0.4 s] *
INFO:root:Epoch 13    loss=0.2522 [9.9 s]    dev=(HR@5:0.4196,NDCG@5:0.3065) [0.4 s] *
INFO:root:Epoch 14    loss=0.2454 [10.9 s]    dev=(HR@5:0.4191,NDCG@5:0.3061) [0.4 s]
INFO:root:Epoch 15    loss=0.2404 [10.1 s]    dev=(HR@5:0.4213,NDCG@5:0.3059) [0.3 s]
INFO:root:Epoch 16    loss=0.2360 [10.4 s]    dev=(HR@5:0.4222,NDCG@5:0.3089) [0.3 s] *
INFO:root:Epoch 17    loss=0.2322 [10.7 s]    dev=(HR@5:0.4223,NDCG@5:0.3075) [0.4 s]
INFO:root:Epoch 18    loss=0.2282 [10.6 s]    dev=(HR@5:0.4261,NDCG@5:0.3114) [0.5 s] *
INFO:root:Epoch 19    loss=0.2243 [10.5 s]    dev=(HR@5:0.4258,NDCG@5:0.3147) [0.4 s] *
INFO:root:Epoch 20    loss=0.2229 [10.2 s]    dev=(HR@5:0.4289,NDCG@5:0.3149) [0.4 s] *
INFO:root:Epoch 21    loss=0.2179 [9.8 s]    dev=(HR@5:0.4306,NDCG@5:0.3171) [0.4 s] *
INFO:root:Epoch 22    loss=0.2165 [10.6 s]    dev=(HR@5:0.4265,NDCG@5:0.3134) [0.4 s]
INFO:root:Epoch 23    loss=0.2159 [10.2 s]    dev=(HR@5:0.4272,NDCG@5:0.3152) [0.4 s]
INFO:root:Epoch 24    loss=0.2147 [11.0 s]    dev=(HR@5:0.4304,NDCG@5:0.3173) [0.4 s] *
INFO:root:Epoch 25    loss=0.2129 [9.8 s]    dev=(HR@5:0.4304,NDCG@5:0.3176) [0.4 s] *
INFO:root:Epoch 26    loss=0.2125 [11.4 s]    dev=(HR@5:0.4307,NDCG@5:0.3179) [0.4 s] *
INFO:root:Epoch 27    loss=0.2111 [10.0 s]    dev=(HR@5:0.4356,NDCG@5:0.3222) [0.4 s] *
INFO:root:Epoch 28    loss=0.2096 [10.6 s]    dev=(HR@5:0.4348,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 29    loss=0.2087 [10.2 s]    dev=(HR@5:0.4335,NDCG@5:0.3200) [0.4 s]
INFO:root:Epoch 30    loss=0.2076 [10.9 s]    dev=(HR@5:0.4341,NDCG@5:0.3221) [0.4 s]
INFO:root:Epoch 31    loss=0.2065 [10.2 s]    dev=(HR@5:0.4331,NDCG@5:0.3197) [0.4 s]
INFO:root:Epoch 32    loss=0.2071 [11.1 s]    dev=(HR@5:0.4333,NDCG@5:0.3203) [0.4 s]
INFO:root:Epoch 33    loss=0.2059 [9.7 s]    dev=(HR@5:0.4338,NDCG@5:0.3206) [0.4 s]
INFO:root:Epoch 34    loss=0.2042 [11.0 s]    dev=(HR@5:0.4340,NDCG@5:0.3197) [0.4 s]
INFO:root:Epoch 35    loss=0.2058 [11.2 s]    dev=(HR@5:0.4302,NDCG@5:0.3181) [0.4 s]
INFO:root:Epoch 36    loss=0.2024 [10.1 s]    dev=(HR@5:0.4351,NDCG@5:0.3200) [0.4 s]
INFO:root:Epoch 37    loss=0.2040 [10.0 s]    dev=(HR@5:0.4386,NDCG@5:0.3240) [0.4 s] *
INFO:root:Epoch 38    loss=0.2035 [10.6 s]    dev=(HR@5:0.4349,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 39    loss=0.2033 [10.6 s]    dev=(HR@5:0.4348,NDCG@5:0.3196) [0.4 s]
INFO:root:Epoch 40    loss=0.2016 [10.3 s]    dev=(HR@5:0.4300,NDCG@5:0.3185) [0.4 s]
INFO:root:Epoch 41    loss=0.2029 [9.4 s]    dev=(HR@5:0.4334,NDCG@5:0.3204) [0.4 s]
INFO:root:Epoch 42    loss=0.2029 [9.9 s]    dev=(HR@5:0.4408,NDCG@5:0.3234) [0.4 s]
INFO:root:Epoch 43    loss=0.2013 [10.2 s]    dev=(HR@5:0.4408,NDCG@5:0.3261) [0.4 s] *
INFO:root:Epoch 44    loss=0.2032 [10.1 s]    dev=(HR@5:0.4385,NDCG@5:0.3229) [0.4 s]
INFO:root:Epoch 45    loss=0.1987 [11.0 s]    dev=(HR@5:0.4422,NDCG@5:0.3282) [0.4 s] *
INFO:root:Epoch 46    loss=0.2009 [9.8 s]    dev=(HR@5:0.4374,NDCG@5:0.3232) [0.4 s]
INFO:root:Epoch 47    loss=0.2020 [10.1 s]    dev=(HR@5:0.4374,NDCG@5:0.3222) [0.4 s]
INFO:root:Epoch 48    loss=0.1992 [10.6 s]    dev=(HR@5:0.4321,NDCG@5:0.3200) [0.4 s]
INFO:root:Epoch 49    loss=0.1989 [10.2 s]    dev=(HR@5:0.4387,NDCG@5:0.3230) [0.4 s]
INFO:root:Epoch 50    loss=0.1996 [10.0 s]    dev=(HR@5:0.4367,NDCG@5:0.3235) [0.4 s]
INFO:root:Epoch 51    loss=0.1987 [10.4 s]    dev=(HR@5:0.4390,NDCG@5:0.3264) [0.4 s]
INFO:root:Epoch 52    loss=0.1987 [11.0 s]    dev=(HR@5:0.4362,NDCG@5:0.3229) [0.4 s]
INFO:root:Epoch 53    loss=0.1978 [9.3 s]    dev=(HR@5:0.4385,NDCG@5:0.3235) [0.4 s]
INFO:root:Epoch 54    loss=0.1958 [10.4 s]    dev=(HR@5:0.4406,NDCG@5:0.3250) [0.4 s]
INFO:root:Epoch 55    loss=0.1969 [10.0 s]    dev=(HR@5:0.4395,NDCG@5:0.3247) [0.4 s]
INFO:root:Epoch 56    loss=0.1961 [10.0 s]    dev=(HR@5:0.4368,NDCG@5:0.3241) [0.4 s]
INFO:root:Epoch 57    loss=0.1959 [10.7 s]    dev=(HR@5:0.4408,NDCG@5:0.3267) [0.4 s]
INFO:root:Epoch 58    loss=0.1972 [10.8 s]    dev=(HR@5:0.4421,NDCG@5:0.3259) [0.4 s]
INFO:root:Epoch 59    loss=0.1957 [10.5 s]    dev=(HR@5:0.4354,NDCG@5:0.3218) [0.4 s]
INFO:root:Epoch 60    loss=0.1966 [9.9 s]    dev=(HR@5:0.4389,NDCG@5:0.3268) [0.4 s]
INFO:root:Epoch 61    loss=0.1960 [11.1 s]    dev=(HR@5:0.4380,NDCG@5:0.3250) [0.4 s]
INFO:root:Epoch 62    loss=0.1950 [11.1 s]    dev=(HR@5:0.4430,NDCG@5:0.3266) [0.4 s]
INFO:root:Epoch 63    loss=0.1964 [10.3 s]    dev=(HR@5:0.4437,NDCG@5:0.3283) [0.5 s] *
INFO:root:Epoch 64    loss=0.1954 [10.9 s]    dev=(HR@5:0.4408,NDCG@5:0.3251) [0.4 s]
INFO:root:Epoch 65    loss=0.1956 [10.2 s]    dev=(HR@5:0.4355,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 66    loss=0.1941 [10.1 s]    dev=(HR@5:0.4404,NDCG@5:0.3247) [0.4 s]
INFO:root:Epoch 67    loss=0.1945 [9.9 s]    dev=(HR@5:0.4394,NDCG@5:0.3240) [0.4 s]
INFO:root:Epoch 68    loss=0.1933 [10.0 s]    dev=(HR@5:0.4387,NDCG@5:0.3240) [0.4 s]
INFO:root:Epoch 69    loss=0.1937 [10.6 s]    dev=(HR@5:0.4376,NDCG@5:0.3235) [0.4 s]
INFO:root:Epoch 70    loss=0.1943 [11.0 s]    dev=(HR@5:0.4385,NDCG@5:0.3247) [0.4 s]
INFO:root:Epoch 71    loss=0.1933 [10.9 s]    dev=(HR@5:0.4378,NDCG@5:0.3253) [0.4 s]
INFO:root:Epoch 72    loss=0.1920 [11.0 s]    dev=(HR@5:0.4415,NDCG@5:0.3245) [0.4 s]
INFO:root:Epoch 73    loss=0.1942 [10.8 s]    dev=(HR@5:0.4372,NDCG@5:0.3220) [0.5 s]
INFO:root:Epoch 74    loss=0.1937 [10.7 s]    dev=(HR@5:0.4352,NDCG@5:0.3200) [0.4 s]
INFO:root:Epoch 75    loss=0.1946 [11.0 s]    dev=(HR@5:0.4375,NDCG@5:0.3242) [0.4 s]
INFO:root:Epoch 76    loss=0.1932 [10.3 s]    dev=(HR@5:0.4355,NDCG@5:0.3216) [0.4 s]
INFO:root:Epoch 77    loss=0.1925 [10.2 s]    dev=(HR@5:0.4379,NDCG@5:0.3241) [0.4 s]
INFO:root:Epoch 78    loss=0.1925 [11.2 s]    dev=(HR@5:0.4387,NDCG@5:0.3245) [0.4 s]
INFO:root:Epoch 79    loss=0.1929 [10.9 s]    dev=(HR@5:0.4364,NDCG@5:0.3228) [0.4 s]
INFO:root:Epoch 80    loss=0.1911 [11.1 s]    dev=(HR@5:0.4353,NDCG@5:0.3212) [0.4 s]
INFO:root:Epoch 81    loss=0.1925 [11.1 s]    dev=(HR@5:0.4345,NDCG@5:0.3203) [0.4 s]
INFO:root:Epoch 82    loss=0.1937 [11.1 s]    dev=(HR@5:0.4387,NDCG@5:0.3239) [0.4 s]
INFO:root:Epoch 83    loss=0.1919 [11.2 s]    dev=(HR@5:0.4391,NDCG@5:0.3236) [0.4 s]
INFO:root:Early stop at 83 based on dev result.
INFO:root:
Best Iter(dev)=   63	 dev=(HR@5:0.4437,NDCG@5:0.3283) [898.7 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.3890,NDCG@5:0.2809,HR@10:0.4962,NDCG@10:0.3156,HR@20:0.6154,NDCG@20:0.3455,HR@50:0.8228,NDCG@50:0.3866)
INFO:root:
--------------------------------------------- END: 2024-12-22 14:12:09 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-22 14:33:32 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [12.8 s]    dev=(HR@5:0.2511,NDCG@5:0.1670) [0.4 s] *
INFO:root:Epoch 2     loss=0.4324 [11.2 s]    dev=(HR@5:0.3202,NDCG@5:0.2172) [0.4 s] *
INFO:root:Epoch 3     loss=0.4001 [10.3 s]    dev=(HR@5:0.3388,NDCG@5:0.2287) [0.4 s] *
INFO:root:Epoch 4     loss=0.3847 [10.4 s]    dev=(HR@5:0.3533,NDCG@5:0.2419) [0.4 s] *
INFO:root:Epoch 5     loss=0.3655 [11.3 s]    dev=(HR@5:0.3652,NDCG@5:0.2502) [0.4 s] *
INFO:root:Epoch 6     loss=0.3447 [11.1 s]    dev=(HR@5:0.3800,NDCG@5:0.2667) [0.4 s] *
INFO:root:Epoch 7     loss=0.3272 [11.3 s]    dev=(HR@5:0.3874,NDCG@5:0.2709) [0.4 s] *
INFO:root:Epoch 8     loss=0.3091 [11.6 s]    dev=(HR@5:0.3976,NDCG@5:0.2809) [0.4 s] *
INFO:root:Epoch 9     loss=0.2916 [11.1 s]    dev=(HR@5:0.4022,NDCG@5:0.2859) [0.4 s] *
INFO:root:Epoch 10    loss=0.2806 [10.8 s]    dev=(HR@5:0.4079,NDCG@5:0.2920) [0.4 s] *
INFO:root:Epoch 11    loss=0.2680 [11.6 s]    dev=(HR@5:0.4131,NDCG@5:0.2955) [0.3 s] *
INFO:root:Epoch 12    loss=0.2582 [11.4 s]    dev=(HR@5:0.4141,NDCG@5:0.2984) [0.3 s] *
INFO:root:Epoch 13    loss=0.2523 [11.3 s]    dev=(HR@5:0.4207,NDCG@5:0.3045) [0.4 s] *
INFO:root:Epoch 14    loss=0.2456 [10.8 s]    dev=(HR@5:0.4221,NDCG@5:0.3046) [0.3 s] *
INFO:root:Epoch 15    loss=0.2403 [10.7 s]    dev=(HR@5:0.4210,NDCG@5:0.3046) [0.4 s]
INFO:root:Epoch 16    loss=0.2370 [11.6 s]    dev=(HR@5:0.4201,NDCG@5:0.3066) [0.4 s] *
INFO:root:Epoch 17    loss=0.2331 [10.8 s]    dev=(HR@5:0.4197,NDCG@5:0.3041) [0.4 s]
INFO:root:Epoch 18    loss=0.2276 [11.4 s]    dev=(HR@5:0.4234,NDCG@5:0.3084) [0.4 s] *
INFO:root:Epoch 19    loss=0.2244 [10.1 s]    dev=(HR@5:0.4232,NDCG@5:0.3100) [0.4 s] *
INFO:root:Epoch 20    loss=0.2228 [10.9 s]    dev=(HR@5:0.4242,NDCG@5:0.3122) [0.4 s] *
INFO:root:Epoch 21    loss=0.2184 [10.9 s]    dev=(HR@5:0.4301,NDCG@5:0.3132) [0.3 s] *
INFO:root:Epoch 22    loss=0.2167 [11.1 s]    dev=(HR@5:0.4297,NDCG@5:0.3132) [0.4 s] *
INFO:root:Epoch 23    loss=0.2167 [11.4 s]    dev=(HR@5:0.4263,NDCG@5:0.3122) [0.4 s]
INFO:root:Epoch 24    loss=0.2158 [11.6 s]    dev=(HR@5:0.4307,NDCG@5:0.3151) [0.4 s] *
INFO:root:Epoch 25    loss=0.2125 [11.1 s]    dev=(HR@5:0.4242,NDCG@5:0.3109) [0.3 s]
INFO:root:Epoch 26    loss=0.2125 [11.1 s]    dev=(HR@5:0.4301,NDCG@5:0.3157) [0.4 s] *
INFO:root:Epoch 27    loss=0.2114 [10.1 s]    dev=(HR@5:0.4310,NDCG@5:0.3160) [0.3 s] *
INFO:root:Epoch 28    loss=0.2113 [10.6 s]    dev=(HR@5:0.4343,NDCG@5:0.3186) [0.4 s] *
INFO:root:Epoch 29    loss=0.2093 [11.3 s]    dev=(HR@5:0.4304,NDCG@5:0.3148) [0.4 s]
INFO:root:Epoch 30    loss=0.2083 [11.6 s]    dev=(HR@5:0.4325,NDCG@5:0.3174) [0.4 s]
INFO:root:Epoch 31    loss=0.2076 [11.0 s]    dev=(HR@5:0.4329,NDCG@5:0.3168) [0.4 s]
INFO:root:Epoch 32    loss=0.2079 [11.1 s]    dev=(HR@5:0.4333,NDCG@5:0.3177) [0.4 s]
INFO:root:Epoch 33    loss=0.2068 [10.5 s]    dev=(HR@5:0.4309,NDCG@5:0.3164) [0.4 s]
INFO:root:Epoch 34    loss=0.2049 [11.0 s]    dev=(HR@5:0.4338,NDCG@5:0.3175) [0.5 s]
INFO:root:Epoch 35    loss=0.2067 [11.4 s]    dev=(HR@5:0.4306,NDCG@5:0.3150) [0.4 s]
INFO:root:Epoch 36    loss=0.2042 [11.3 s]    dev=(HR@5:0.4343,NDCG@5:0.3169) [0.4 s]
INFO:root:Epoch 37    loss=0.2053 [10.3 s]    dev=(HR@5:0.4384,NDCG@5:0.3197) [0.4 s] *
INFO:root:Epoch 38    loss=0.2048 [11.4 s]    dev=(HR@5:0.4364,NDCG@5:0.3186) [0.4 s]
INFO:root:Epoch 39    loss=0.2043 [11.2 s]    dev=(HR@5:0.4343,NDCG@5:0.3164) [0.4 s]
INFO:root:Epoch 40    loss=0.2034 [10.0 s]    dev=(HR@5:0.4355,NDCG@5:0.3187) [0.4 s]
INFO:root:Epoch 41    loss=0.2044 [10.9 s]    dev=(HR@5:0.4327,NDCG@5:0.3165) [0.4 s]
INFO:root:Epoch 42    loss=0.2045 [11.4 s]    dev=(HR@5:0.4358,NDCG@5:0.3170) [0.4 s]
INFO:root:Epoch 43    loss=0.2032 [11.5 s]    dev=(HR@5:0.4391,NDCG@5:0.3224) [0.4 s] *
INFO:root:Epoch 44    loss=0.2053 [10.9 s]    dev=(HR@5:0.4359,NDCG@5:0.3193) [0.4 s]
INFO:root:Epoch 45    loss=0.2006 [12.7 s]    dev=(HR@5:0.4396,NDCG@5:0.3255) [0.4 s] *
INFO:root:Epoch 46    loss=0.2026 [10.8 s]    dev=(HR@5:0.4351,NDCG@5:0.3191) [0.4 s]
INFO:root:Epoch 47    loss=0.2034 [10.6 s]    dev=(HR@5:0.4355,NDCG@5:0.3177) [0.4 s]
INFO:root:Epoch 48    loss=0.2006 [11.5 s]    dev=(HR@5:0.4305,NDCG@5:0.3144) [0.4 s]
INFO:root:Epoch 49    loss=0.2000 [11.3 s]    dev=(HR@5:0.4357,NDCG@5:0.3209) [0.4 s]
INFO:root:Epoch 50    loss=0.2014 [10.7 s]    dev=(HR@5:0.4339,NDCG@5:0.3200) [0.4 s]
INFO:root:Epoch 51    loss=0.2005 [10.9 s]    dev=(HR@5:0.4375,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 52    loss=0.2005 [11.0 s]    dev=(HR@5:0.4338,NDCG@5:0.3164) [0.3 s]
INFO:root:Epoch 53    loss=0.1998 [10.5 s]    dev=(HR@5:0.4360,NDCG@5:0.3185) [0.4 s]
INFO:root:Epoch 54    loss=0.1980 [10.1 s]    dev=(HR@5:0.4399,NDCG@5:0.3203) [0.3 s]
INFO:root:Epoch 55    loss=0.1984 [10.6 s]    dev=(HR@5:0.4367,NDCG@5:0.3193) [0.4 s]
INFO:root:Epoch 56    loss=0.1979 [10.2 s]    dev=(HR@5:0.4367,NDCG@5:0.3205) [0.3 s]
INFO:root:Epoch 57    loss=0.1986 [11.4 s]    dev=(HR@5:0.4404,NDCG@5:0.3243) [0.4 s]
INFO:root:Epoch 58    loss=0.1988 [11.5 s]    dev=(HR@5:0.4397,NDCG@5:0.3227) [0.4 s]
INFO:root:Epoch 59    loss=0.1975 [9.7 s]    dev=(HR@5:0.4396,NDCG@5:0.3222) [0.4 s]
INFO:root:Epoch 60    loss=0.1984 [10.1 s]    dev=(HR@5:0.4380,NDCG@5:0.3216) [0.3 s]
INFO:root:Epoch 61    loss=0.1977 [10.4 s]    dev=(HR@5:0.4383,NDCG@5:0.3231) [0.3 s]
INFO:root:Epoch 62    loss=0.1966 [10.7 s]    dev=(HR@5:0.4415,NDCG@5:0.3232) [0.4 s]
INFO:root:Epoch 63    loss=0.1979 [10.7 s]    dev=(HR@5:0.4406,NDCG@5:0.3236) [0.3 s]
INFO:root:Epoch 64    loss=0.1973 [10.5 s]    dev=(HR@5:0.4413,NDCG@5:0.3228) [0.4 s]
INFO:root:Epoch 65    loss=0.1976 [10.3 s]    dev=(HR@5:0.4380,NDCG@5:0.3199) [0.4 s]
INFO:root:Early stop at 65 based on dev result.
INFO:root:
Best Iter(dev)=   45	 dev=(HR@5:0.4396,NDCG@5:0.3255) [737.7 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.3859,NDCG@5:0.2762,HR@10:0.4922,NDCG@10:0.3106,HR@20:0.6171,NDCG@20:0.3421,HR@50:0.8222,NDCG@50:0.3827)
INFO:root:
--------------------------------------------- END: 2024-12-22 14:45:52 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-22 15:16:35 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [11.0 s]    dev=(HR@5:0.2509,NDCG@5:0.1671) [0.4 s] *
INFO:root:Epoch 2     loss=0.4324 [10.8 s]    dev=(HR@5:0.3201,NDCG@5:0.2173) [0.4 s] *
INFO:root:Epoch 3     loss=0.4002 [10.1 s]    dev=(HR@5:0.3391,NDCG@5:0.2282) [0.4 s] *
INFO:root:Epoch 4     loss=0.3851 [10.7 s]    dev=(HR@5:0.3526,NDCG@5:0.2411) [0.4 s] *
INFO:root:Epoch 5     loss=0.3660 [10.1 s]    dev=(HR@5:0.3642,NDCG@5:0.2496) [0.4 s] *
INFO:root:Epoch 6     loss=0.3457 [8.7 s]    dev=(HR@5:0.3810,NDCG@5:0.2662) [0.4 s] *
INFO:root:Epoch 7     loss=0.3279 [10.1 s]    dev=(HR@5:0.3870,NDCG@5:0.2704) [0.3 s] *
INFO:root:Epoch 8     loss=0.3092 [10.1 s]    dev=(HR@5:0.3991,NDCG@5:0.2819) [0.4 s] *
INFO:root:Epoch 9     loss=0.2917 [11.1 s]    dev=(HR@5:0.4065,NDCG@5:0.2885) [0.4 s] *
INFO:root:Epoch 10    loss=0.2807 [10.3 s]    dev=(HR@5:0.4104,NDCG@5:0.2932) [0.4 s] *
INFO:root:Epoch 11    loss=0.2683 [9.8 s]    dev=(HR@5:0.4147,NDCG@5:0.2973) [0.4 s] *
INFO:root:Epoch 12    loss=0.2593 [11.0 s]    dev=(HR@5:0.4180,NDCG@5:0.3026) [0.4 s] *
INFO:root:Epoch 13    loss=0.2534 [10.4 s]    dev=(HR@5:0.4257,NDCG@5:0.3084) [0.4 s] *
INFO:root:Epoch 14    loss=0.2471 [10.5 s]    dev=(HR@5:0.4263,NDCG@5:0.3081) [0.4 s]
INFO:root:Epoch 15    loss=0.2431 [11.0 s]    dev=(HR@5:0.4269,NDCG@5:0.3087) [0.4 s] *
INFO:root:Epoch 16    loss=0.2402 [9.8 s]    dev=(HR@5:0.4263,NDCG@5:0.3101) [0.4 s] *
INFO:root:Epoch 17    loss=0.2358 [11.2 s]    dev=(HR@5:0.4244,NDCG@5:0.3095) [0.4 s]
INFO:root:Epoch 18    loss=0.2310 [10.4 s]    dev=(HR@5:0.4290,NDCG@5:0.3132) [0.4 s] *
INFO:root:Epoch 19    loss=0.2276 [9.9 s]    dev=(HR@5:0.4289,NDCG@5:0.3162) [0.4 s] *
INFO:root:Epoch 20    loss=0.2260 [10.6 s]    dev=(HR@5:0.4306,NDCG@5:0.3172) [0.4 s] *
INFO:root:Epoch 21    loss=0.2215 [9.6 s]    dev=(HR@5:0.4332,NDCG@5:0.3174) [0.4 s] *
INFO:root:Epoch 22    loss=0.2194 [11.1 s]    dev=(HR@5:0.4305,NDCG@5:0.3162) [0.4 s]
INFO:root:Epoch 23    loss=0.2197 [9.9 s]    dev=(HR@5:0.4294,NDCG@5:0.3173) [0.4 s]
INFO:root:Epoch 24    loss=0.2193 [10.7 s]    dev=(HR@5:0.4348,NDCG@5:0.3192) [0.3 s] *
INFO:root:Epoch 25    loss=0.2162 [9.6 s]    dev=(HR@5:0.4313,NDCG@5:0.3175) [0.3 s]
INFO:root:Epoch 26    loss=0.2158 [11.1 s]    dev=(HR@5:0.4347,NDCG@5:0.3201) [0.4 s] *
INFO:root:Epoch 27    loss=0.2144 [9.9 s]    dev=(HR@5:0.4329,NDCG@5:0.3193) [0.4 s]
INFO:root:Epoch 28    loss=0.2149 [11.0 s]    dev=(HR@5:0.4316,NDCG@5:0.3194) [0.4 s]
INFO:root:Epoch 29    loss=0.2120 [10.1 s]    dev=(HR@5:0.4300,NDCG@5:0.3170) [0.4 s]
INFO:root:Epoch 30    loss=0.2113 [9.9 s]    dev=(HR@5:0.4308,NDCG@5:0.3173) [0.4 s]
INFO:root:Epoch 31    loss=0.2102 [11.0 s]    dev=(HR@5:0.4336,NDCG@5:0.3188) [0.4 s]
INFO:root:Epoch 32    loss=0.2110 [9.9 s]    dev=(HR@5:0.4338,NDCG@5:0.3193) [0.4 s]
INFO:root:Epoch 33    loss=0.2092 [10.5 s]    dev=(HR@5:0.4333,NDCG@5:0.3210) [0.5 s] *
INFO:root:Epoch 34    loss=0.2080 [11.0 s]    dev=(HR@5:0.4348,NDCG@5:0.3196) [0.3 s]
INFO:root:Epoch 35    loss=0.2088 [10.3 s]    dev=(HR@5:0.4340,NDCG@5:0.3180) [0.4 s]
INFO:root:Epoch 36    loss=0.2063 [11.1 s]    dev=(HR@5:0.4321,NDCG@5:0.3197) [0.4 s]
INFO:root:Epoch 37    loss=0.2070 [10.1 s]    dev=(HR@5:0.4337,NDCG@5:0.3192) [0.4 s]
INFO:root:Epoch 38    loss=0.2064 [11.0 s]    dev=(HR@5:0.4366,NDCG@5:0.3206) [0.4 s]
INFO:root:Epoch 39    loss=0.2067 [10.6 s]    dev=(HR@5:0.4320,NDCG@5:0.3187) [0.4 s]
INFO:root:Epoch 40    loss=0.2054 [10.9 s]    dev=(HR@5:0.4301,NDCG@5:0.3177) [0.4 s]
INFO:root:Epoch 41    loss=0.2060 [10.1 s]    dev=(HR@5:0.4299,NDCG@5:0.3162) [0.4 s]
INFO:root:Epoch 42    loss=0.2057 [10.9 s]    dev=(HR@5:0.4353,NDCG@5:0.3190) [0.4 s]
INFO:root:Epoch 43    loss=0.2044 [10.1 s]    dev=(HR@5:0.4395,NDCG@5:0.3241) [0.4 s] *
INFO:root:Epoch 44    loss=0.2058 [9.9 s]    dev=(HR@5:0.4321,NDCG@5:0.3173) [0.4 s]
INFO:root:Epoch 45    loss=0.2023 [9.5 s]    dev=(HR@5:0.4398,NDCG@5:0.3248) [0.4 s] *
INFO:root:Epoch 46    loss=0.2035 [10.6 s]    dev=(HR@5:0.4304,NDCG@5:0.3158) [0.4 s]
INFO:root:Epoch 47    loss=0.2039 [10.8 s]    dev=(HR@5:0.4345,NDCG@5:0.3182) [0.4 s]
INFO:root:Epoch 48    loss=0.2021 [11.3 s]    dev=(HR@5:0.4310,NDCG@5:0.3158) [0.4 s]
INFO:root:Epoch 49    loss=0.2013 [10.3 s]    dev=(HR@5:0.4388,NDCG@5:0.3219) [0.4 s]
INFO:root:Epoch 50    loss=0.2029 [10.5 s]    dev=(HR@5:0.4355,NDCG@5:0.3198) [0.4 s]
INFO:root:Epoch 51    loss=0.2006 [11.0 s]    dev=(HR@5:0.4387,NDCG@5:0.3230) [0.4 s]
INFO:root:Epoch 52    loss=0.2018 [10.0 s]    dev=(HR@5:0.4378,NDCG@5:0.3202) [0.4 s]
INFO:root:Epoch 53    loss=0.2008 [10.8 s]    dev=(HR@5:0.4355,NDCG@5:0.3194) [0.4 s]
INFO:root:Epoch 54    loss=0.1992 [10.6 s]    dev=(HR@5:0.4370,NDCG@5:0.3193) [0.4 s]
INFO:root:Epoch 55    loss=0.1990 [11.0 s]    dev=(HR@5:0.4378,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 56    loss=0.1992 [11.4 s]    dev=(HR@5:0.4382,NDCG@5:0.3228) [0.4 s]
INFO:root:Epoch 57    loss=0.1993 [10.4 s]    dev=(HR@5:0.4406,NDCG@5:0.3253) [0.4 s] *
INFO:root:Epoch 58    loss=0.2004 [9.7 s]    dev=(HR@5:0.4377,NDCG@5:0.3235) [0.4 s]
INFO:root:Epoch 59    loss=0.1986 [11.0 s]    dev=(HR@5:0.4363,NDCG@5:0.3215) [0.4 s]
INFO:root:Epoch 60    loss=0.1993 [11.1 s]    dev=(HR@5:0.4381,NDCG@5:0.3231) [0.4 s]
INFO:root:Epoch 61    loss=0.1981 [9.7 s]    dev=(HR@5:0.4383,NDCG@5:0.3233) [0.4 s]
INFO:root:Epoch 62    loss=0.1986 [10.2 s]    dev=(HR@5:0.4398,NDCG@5:0.3249) [0.4 s]
INFO:root:Epoch 63    loss=0.1995 [10.8 s]    dev=(HR@5:0.4403,NDCG@5:0.3256) [0.4 s] *
INFO:root:Epoch 64    loss=0.1977 [9.9 s]    dev=(HR@5:0.4398,NDCG@5:0.3229) [0.4 s]
INFO:root:Epoch 65    loss=0.1979 [10.7 s]    dev=(HR@5:0.4370,NDCG@5:0.3220) [0.4 s]
INFO:root:Epoch 66    loss=0.1964 [11.4 s]    dev=(HR@5:0.4380,NDCG@5:0.3221) [0.4 s]
INFO:root:Epoch 67    loss=0.1969 [8.7 s]    dev=(HR@5:0.4381,NDCG@5:0.3209) [0.4 s]
INFO:root:Epoch 68    loss=0.1954 [10.6 s]    dev=(HR@5:0.4421,NDCG@5:0.3230) [0.4 s]
INFO:root:Epoch 69    loss=0.1970 [9.2 s]    dev=(HR@5:0.4385,NDCG@5:0.3230) [0.4 s]
INFO:root:Epoch 70    loss=0.1961 [10.2 s]    dev=(HR@5:0.4387,NDCG@5:0.3226) [0.4 s]
INFO:root:Epoch 71    loss=0.1959 [11.1 s]    dev=(HR@5:0.4404,NDCG@5:0.3252) [0.4 s]
INFO:root:Epoch 72    loss=0.1954 [10.3 s]    dev=(HR@5:0.4357,NDCG@5:0.3232) [0.3 s]
INFO:root:Epoch 73    loss=0.1963 [10.9 s]    dev=(HR@5:0.4399,NDCG@5:0.3236) [0.4 s]
INFO:root:Epoch 74    loss=0.1963 [11.2 s]    dev=(HR@5:0.4372,NDCG@5:0.3214) [0.4 s]
INFO:root:Epoch 75    loss=0.1977 [10.3 s]    dev=(HR@5:0.4369,NDCG@5:0.3222) [0.4 s]
INFO:root:Epoch 76    loss=0.1960 [10.4 s]    dev=(HR@5:0.4376,NDCG@5:0.3224) [0.4 s]
INFO:root:Epoch 77    loss=0.1950 [11.0 s]    dev=(HR@5:0.4394,NDCG@5:0.3242) [0.4 s]
INFO:root:Epoch 78    loss=0.1951 [11.0 s]    dev=(HR@5:0.4373,NDCG@5:0.3214) [0.4 s]
INFO:root:Epoch 79    loss=0.1955 [10.1 s]    dev=(HR@5:0.4403,NDCG@5:0.3251) [0.4 s]
INFO:root:Epoch 80    loss=0.1940 [11.0 s]    dev=(HR@5:0.4386,NDCG@5:0.3222) [0.4 s]
INFO:root:Epoch 81    loss=0.1947 [9.9 s]    dev=(HR@5:0.4348,NDCG@5:0.3176) [0.4 s]
INFO:root:Epoch 82    loss=0.1959 [9.9 s]    dev=(HR@5:0.4343,NDCG@5:0.3204) [0.4 s]
INFO:root:Epoch 83    loss=0.1936 [10.7 s]    dev=(HR@5:0.4382,NDCG@5:0.3234) [0.4 s]
INFO:root:Early stop at 83 based on dev result.
INFO:root:
Best Iter(dev)=   63	 dev=(HR@5:0.4403,NDCG@5:0.3256) [899.7 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.3913,NDCG@5:0.2810,HR@10:0.4971,NDCG@10:0.3152,HR@20:0.6188,NDCG@20:0.3459,HR@50:0.8294,NDCG@50:0.3876)
INFO:root:
--------------------------------------------- END: 2024-12-22 15:31:37 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-22 16:04:12 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5165 [12.0 s]    dev=(HR@5:0.2512,NDCG@5:0.1672) [0.4 s] *
INFO:root:Epoch 2     loss=0.4324 [10.3 s]    dev=(HR@5:0.3194,NDCG@5:0.2170) [0.4 s] *
INFO:root:Epoch 3     loss=0.4003 [11.1 s]    dev=(HR@5:0.3389,NDCG@5:0.2280) [0.4 s] *
INFO:root:Epoch 4     loss=0.3861 [10.1 s]    dev=(HR@5:0.3491,NDCG@5:0.2385) [0.3 s] *
INFO:root:Epoch 5     loss=0.3667 [11.2 s]    dev=(HR@5:0.3620,NDCG@5:0.2480) [0.4 s] *
INFO:root:Epoch 6     loss=0.3456 [11.1 s]    dev=(HR@5:0.3802,NDCG@5:0.2657) [0.4 s] *
INFO:root:Epoch 7     loss=0.3262 [9.6 s]    dev=(HR@5:0.3915,NDCG@5:0.2727) [0.4 s] *
INFO:root:Epoch 8     loss=0.3061 [9.7 s]    dev=(HR@5:0.4026,NDCG@5:0.2843) [0.4 s] *
INFO:root:Epoch 9     loss=0.2893 [10.7 s]    dev=(HR@5:0.4068,NDCG@5:0.2892) [0.4 s] *
INFO:root:Epoch 10    loss=0.2788 [10.5 s]    dev=(HR@5:0.4119,NDCG@5:0.2951) [0.4 s] *
INFO:root:Epoch 11    loss=0.2670 [11.2 s]    dev=(HR@5:0.4143,NDCG@5:0.2977) [0.4 s] *
INFO:root:Epoch 12    loss=0.2584 [11.2 s]    dev=(HR@5:0.4180,NDCG@5:0.3028) [0.4 s] *
INFO:root:Epoch 13    loss=0.2531 [11.3 s]    dev=(HR@5:0.4258,NDCG@5:0.3086) [0.4 s] *
INFO:root:Epoch 14    loss=0.2473 [9.7 s]    dev=(HR@5:0.4239,NDCG@5:0.3081) [0.4 s]
INFO:root:Epoch 15    loss=0.2436 [10.8 s]    dev=(HR@5:0.4245,NDCG@5:0.3064) [0.4 s]
INFO:root:Epoch 16    loss=0.2406 [11.2 s]    dev=(HR@5:0.4260,NDCG@5:0.3106) [0.4 s] *
INFO:root:Epoch 17    loss=0.2363 [11.1 s]    dev=(HR@5:0.4244,NDCG@5:0.3095) [0.4 s]
INFO:root:Epoch 18    loss=0.2319 [11.2 s]    dev=(HR@5:0.4308,NDCG@5:0.3136) [0.4 s] *
INFO:root:Epoch 19    loss=0.2284 [11.1 s]    dev=(HR@5:0.4288,NDCG@5:0.3152) [0.4 s] *
INFO:root:Epoch 20    loss=0.2270 [11.2 s]    dev=(HR@5:0.4315,NDCG@5:0.3171) [0.4 s] *
INFO:root:Epoch 21    loss=0.2222 [10.9 s]    dev=(HR@5:0.4314,NDCG@5:0.3167) [0.4 s]
INFO:root:Epoch 22    loss=0.2202 [10.5 s]    dev=(HR@5:0.4317,NDCG@5:0.3172) [0.4 s] *
INFO:root:Epoch 23    loss=0.2211 [11.3 s]    dev=(HR@5:0.4302,NDCG@5:0.3173) [0.4 s] *
INFO:root:Epoch 24    loss=0.2206 [11.1 s]    dev=(HR@5:0.4353,NDCG@5:0.3199) [0.4 s] *
INFO:root:Epoch 25    loss=0.2169 [10.8 s]    dev=(HR@5:0.4304,NDCG@5:0.3165) [0.4 s]
INFO:root:Epoch 26    loss=0.2165 [11.1 s]    dev=(HR@5:0.4334,NDCG@5:0.3199) [0.4 s]
INFO:root:Epoch 27    loss=0.2154 [10.2 s]    dev=(HR@5:0.4348,NDCG@5:0.3201) [0.4 s] *
INFO:root:Epoch 28    loss=0.2155 [10.9 s]    dev=(HR@5:0.4363,NDCG@5:0.3221) [0.4 s] *
INFO:root:Epoch 29    loss=0.2129 [10.8 s]    dev=(HR@5:0.4312,NDCG@5:0.3169) [0.4 s]
INFO:root:Epoch 30    loss=0.2122 [11.3 s]    dev=(HR@5:0.4347,NDCG@5:0.3201) [0.4 s]
INFO:root:Epoch 31    loss=0.2113 [11.2 s]    dev=(HR@5:0.4378,NDCG@5:0.3216) [0.4 s]
INFO:root:Epoch 32    loss=0.2117 [10.6 s]    dev=(HR@5:0.4363,NDCG@5:0.3209) [0.4 s]
INFO:root:Epoch 33    loss=0.2100 [9.5 s]    dev=(HR@5:0.4363,NDCG@5:0.3226) [0.4 s] *
INFO:root:Epoch 34    loss=0.2090 [11.5 s]    dev=(HR@5:0.4364,NDCG@5:0.3206) [0.4 s]
INFO:root:Epoch 35    loss=0.2093 [10.9 s]    dev=(HR@5:0.4336,NDCG@5:0.3190) [0.3 s]
INFO:root:Epoch 36    loss=0.2072 [10.7 s]    dev=(HR@5:0.4366,NDCG@5:0.3219) [0.4 s]
INFO:root:Epoch 37    loss=0.2079 [10.1 s]    dev=(HR@5:0.4383,NDCG@5:0.3222) [0.4 s]
INFO:root:Epoch 38    loss=0.2075 [11.1 s]    dev=(HR@5:0.4380,NDCG@5:0.3220) [0.4 s]
INFO:root:Epoch 39    loss=0.2079 [11.1 s]    dev=(HR@5:0.4364,NDCG@5:0.3198) [0.4 s]
INFO:root:Epoch 40    loss=0.2060 [10.4 s]    dev=(HR@5:0.4351,NDCG@5:0.3202) [0.4 s]
INFO:root:Epoch 41    loss=0.2066 [11.1 s]    dev=(HR@5:0.4338,NDCG@5:0.3182) [0.4 s]
INFO:root:Epoch 42    loss=0.2065 [11.1 s]    dev=(HR@5:0.4398,NDCG@5:0.3210) [0.4 s]
INFO:root:Epoch 43    loss=0.2058 [10.7 s]    dev=(HR@5:0.4429,NDCG@5:0.3261) [0.4 s] *
INFO:root:Epoch 44    loss=0.2069 [11.0 s]    dev=(HR@5:0.4368,NDCG@5:0.3200) [0.4 s]
INFO:root:Epoch 45    loss=0.2033 [11.3 s]    dev=(HR@5:0.4400,NDCG@5:0.3252) [0.4 s]
INFO:root:Epoch 46    loss=0.2049 [11.1 s]    dev=(HR@5:0.4335,NDCG@5:0.3183) [0.3 s]
INFO:root:Epoch 47    loss=0.2055 [10.3 s]    dev=(HR@5:0.4350,NDCG@5:0.3194) [0.4 s]
INFO:root:Epoch 48    loss=0.2037 [11.1 s]    dev=(HR@5:0.4362,NDCG@5:0.3198) [0.4 s]
INFO:root:Epoch 49    loss=0.2024 [11.1 s]    dev=(HR@5:0.4390,NDCG@5:0.3223) [0.4 s]
INFO:root:Epoch 50    loss=0.2034 [10.8 s]    dev=(HR@5:0.4355,NDCG@5:0.3210) [0.4 s]
INFO:root:Epoch 51    loss=0.2025 [11.0 s]    dev=(HR@5:0.4412,NDCG@5:0.3246) [0.4 s]
INFO:root:Epoch 52    loss=0.2036 [11.4 s]    dev=(HR@5:0.4383,NDCG@5:0.3215) [0.4 s]
INFO:root:Epoch 53    loss=0.2022 [10.4 s]    dev=(HR@5:0.4378,NDCG@5:0.3215) [0.4 s]
INFO:root:Epoch 54    loss=0.2007 [10.9 s]    dev=(HR@5:0.4420,NDCG@5:0.3223) [0.4 s]
INFO:root:Epoch 55    loss=0.2008 [10.7 s]    dev=(HR@5:0.4402,NDCG@5:0.3222) [0.4 s]
INFO:root:Epoch 56    loss=0.2006 [10.8 s]    dev=(HR@5:0.4420,NDCG@5:0.3254) [0.4 s]
INFO:root:Epoch 57    loss=0.2012 [11.2 s]    dev=(HR@5:0.4426,NDCG@5:0.3275) [0.4 s] *
INFO:root:Epoch 58    loss=0.2018 [11.0 s]    dev=(HR@5:0.4429,NDCG@5:0.3266) [0.3 s]
INFO:root:Epoch 59    loss=0.2004 [9.3 s]    dev=(HR@5:0.4391,NDCG@5:0.3238) [0.4 s]
INFO:root:Epoch 60    loss=0.2009 [11.1 s]    dev=(HR@5:0.4397,NDCG@5:0.3246) [0.4 s]
INFO:root:Epoch 61    loss=0.2003 [11.1 s]    dev=(HR@5:0.4438,NDCG@5:0.3270) [0.4 s]
INFO:root:Epoch 62    loss=0.1997 [11.3 s]    dev=(HR@5:0.4456,NDCG@5:0.3276) [0.4 s] *
INFO:root:Epoch 63    loss=0.2018 [11.3 s]    dev=(HR@5:0.4434,NDCG@5:0.3280) [0.4 s] *
INFO:root:Epoch 64    loss=0.1997 [11.2 s]    dev=(HR@5:0.4409,NDCG@5:0.3231) [0.4 s]
INFO:root:Epoch 65    loss=0.1998 [11.1 s]    dev=(HR@5:0.4393,NDCG@5:0.3229) [0.4 s]
INFO:root:Epoch 66    loss=0.1983 [11.0 s]    dev=(HR@5:0.4413,NDCG@5:0.3231) [0.3 s]
INFO:root:Epoch 67    loss=0.1984 [11.2 s]    dev=(HR@5:0.4393,NDCG@5:0.3211) [0.4 s]
INFO:root:Epoch 68    loss=0.1970 [11.0 s]    dev=(HR@5:0.4432,NDCG@5:0.3234) [0.4 s]
INFO:root:Epoch 69    loss=0.1987 [10.9 s]    dev=(HR@5:0.4408,NDCG@5:0.3237) [0.4 s]
INFO:root:Epoch 70    loss=0.1982 [10.6 s]    dev=(HR@5:0.4387,NDCG@5:0.3230) [0.4 s]
INFO:root:Epoch 71    loss=0.1973 [11.2 s]    dev=(HR@5:0.4419,NDCG@5:0.3250) [0.4 s]
INFO:root:Epoch 72    loss=0.1972 [10.9 s]    dev=(HR@5:0.4398,NDCG@5:0.3237) [0.4 s]
INFO:root:Epoch 73    loss=0.1978 [11.0 s]    dev=(HR@5:0.4413,NDCG@5:0.3242) [0.3 s]
INFO:root:Epoch 74    loss=0.1981 [11.0 s]    dev=(HR@5:0.4390,NDCG@5:0.3210) [0.4 s]
INFO:root:Epoch 75    loss=0.1991 [11.2 s]    dev=(HR@5:0.4394,NDCG@5:0.3222) [0.4 s]
INFO:root:Epoch 76    loss=0.1975 [11.0 s]    dev=(HR@5:0.4389,NDCG@5:0.3225) [0.4 s]
INFO:root:Epoch 77    loss=0.1967 [10.6 s]    dev=(HR@5:0.4421,NDCG@5:0.3264) [0.4 s]
INFO:root:Epoch 78    loss=0.1967 [10.7 s]    dev=(HR@5:0.4415,NDCG@5:0.3223) [0.4 s]
INFO:root:Epoch 79    loss=0.1979 [11.2 s]    dev=(HR@5:0.4442,NDCG@5:0.3265) [0.4 s]
INFO:root:Epoch 80    loss=0.1961 [11.3 s]    dev=(HR@5:0.4383,NDCG@5:0.3223) [0.4 s]
INFO:root:Epoch 81    loss=0.1974 [11.1 s]    dev=(HR@5:0.4363,NDCG@5:0.3188) [0.4 s]
INFO:root:Epoch 82    loss=0.1979 [11.6 s]    dev=(HR@5:0.4384,NDCG@5:0.3203) [0.4 s]
INFO:root:Epoch 83    loss=0.1954 [11.1 s]    dev=(HR@5:0.4406,NDCG@5:0.3225) [0.4 s]
INFO:root:Early stop at 83 based on dev result.
INFO:root:
Best Iter(dev)=   63	 dev=(HR@5:0.4434,NDCG@5:0.3280) [935.6 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.3945,NDCG@5:0.2844,HR@10:0.5015,NDCG@10:0.3190,HR@20:0.6226,NDCG@20:0.3495,HR@50:0.8377,NDCG@50:0.3921)
INFO:root:
--------------------------------------------- END: 2024-12-22 16:19:50 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-22 20:20:07 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [12.1 s]    dev=(HR@5:0.2509,NDCG@5:0.1669) [0.4 s] *
INFO:root:Epoch 2     loss=0.4330 [10.9 s]    dev=(HR@5:0.3201,NDCG@5:0.2167) [0.4 s] *
INFO:root:Epoch 3     loss=0.4005 [11.0 s]    dev=(HR@5:0.3385,NDCG@5:0.2281) [0.4 s] *
INFO:root:Epoch 4     loss=0.3848 [10.9 s]    dev=(HR@5:0.3532,NDCG@5:0.2426) [0.4 s] *
INFO:root:Epoch 5     loss=0.3649 [11.0 s]    dev=(HR@5:0.3675,NDCG@5:0.2535) [0.4 s] *
INFO:root:Epoch 6     loss=0.3429 [11.1 s]    dev=(HR@5:0.3832,NDCG@5:0.2697) [0.4 s] *
INFO:root:Epoch 7     loss=0.3261 [11.0 s]    dev=(HR@5:0.3899,NDCG@5:0.2732) [0.4 s] *
INFO:root:Epoch 8     loss=0.3089 [11.0 s]    dev=(HR@5:0.3950,NDCG@5:0.2813) [0.4 s] *
INFO:root:Epoch 9     loss=0.2925 [10.5 s]    dev=(HR@5:0.4015,NDCG@5:0.2875) [0.4 s] *
INFO:root:Epoch 10    loss=0.2807 [10.8 s]    dev=(HR@5:0.4048,NDCG@5:0.2927) [0.4 s] *
INFO:root:Epoch 11    loss=0.2680 [11.1 s]    dev=(HR@5:0.4127,NDCG@5:0.2982) [0.4 s] *
INFO:root:Epoch 12    loss=0.2583 [11.3 s]    dev=(HR@5:0.4126,NDCG@5:0.3008) [0.4 s] *
INFO:root:Epoch 13    loss=0.2522 [11.0 s]    dev=(HR@5:0.4196,NDCG@5:0.3065) [0.4 s] *
INFO:root:Epoch 14    loss=0.2454 [10.9 s]    dev=(HR@5:0.4191,NDCG@5:0.3061) [0.4 s]
INFO:root:Epoch 15    loss=0.2404 [11.2 s]    dev=(HR@5:0.4213,NDCG@5:0.3059) [0.4 s]
INFO:root:Epoch 16    loss=0.2360 [11.0 s]    dev=(HR@5:0.4222,NDCG@5:0.3089) [0.4 s] *
INFO:root:Epoch 17    loss=0.2322 [11.0 s]    dev=(HR@5:0.4223,NDCG@5:0.3075) [0.4 s]
INFO:root:Epoch 18    loss=0.2282 [11.1 s]    dev=(HR@5:0.4261,NDCG@5:0.3114) [0.4 s] *
INFO:root:Epoch 19    loss=0.2243 [11.1 s]    dev=(HR@5:0.4258,NDCG@5:0.3147) [0.4 s] *
INFO:root:Epoch 20    loss=0.2229 [10.9 s]    dev=(HR@5:0.4289,NDCG@5:0.3149) [0.4 s] *
INFO:root:Epoch 21    loss=0.2179 [10.8 s]    dev=(HR@5:0.4306,NDCG@5:0.3171) [0.4 s] *
INFO:root:Epoch 22    loss=0.2165 [11.0 s]    dev=(HR@5:0.4265,NDCG@5:0.3134) [0.4 s]
INFO:root:Epoch 23    loss=0.2159 [10.9 s]    dev=(HR@5:0.4272,NDCG@5:0.3152) [0.4 s]
INFO:root:Epoch 24    loss=0.2147 [10.9 s]    dev=(HR@5:0.4304,NDCG@5:0.3173) [0.4 s] *
INFO:root:Epoch 25    loss=0.2129 [11.0 s]    dev=(HR@5:0.4304,NDCG@5:0.3176) [0.4 s] *
INFO:root:Epoch 26    loss=0.2125 [11.3 s]    dev=(HR@5:0.4307,NDCG@5:0.3179) [0.4 s] *
INFO:root:Epoch 27    loss=0.2111 [11.3 s]    dev=(HR@5:0.4356,NDCG@5:0.3222) [0.4 s] *
INFO:root:Epoch 28    loss=0.2096 [11.1 s]    dev=(HR@5:0.4348,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 29    loss=0.2087 [11.1 s]    dev=(HR@5:0.4335,NDCG@5:0.3200) [0.4 s]
INFO:root:Epoch 30    loss=0.2076 [11.1 s]    dev=(HR@5:0.4341,NDCG@5:0.3221) [0.4 s]
INFO:root:Epoch 31    loss=0.2065 [10.8 s]    dev=(HR@5:0.4331,NDCG@5:0.3197) [0.4 s]
INFO:root:Epoch 32    loss=0.2071 [11.0 s]    dev=(HR@5:0.4333,NDCG@5:0.3203) [0.4 s]
INFO:root:Epoch 33    loss=0.2059 [11.0 s]    dev=(HR@5:0.4338,NDCG@5:0.3206) [0.4 s]
INFO:root:Epoch 34    loss=0.2042 [10.9 s]    dev=(HR@5:0.4340,NDCG@5:0.3197) [0.4 s]
INFO:root:Epoch 35    loss=0.2058 [10.9 s]    dev=(HR@5:0.4302,NDCG@5:0.3181) [0.4 s]
INFO:root:Epoch 36    loss=0.2024 [10.9 s]    dev=(HR@5:0.4351,NDCG@5:0.3200) [0.4 s]
INFO:root:Epoch 37    loss=0.2040 [11.2 s]    dev=(HR@5:0.4386,NDCG@5:0.3240) [0.4 s] *
INFO:root:Epoch 38    loss=0.2035 [11.2 s]    dev=(HR@5:0.4349,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 39    loss=0.2033 [11.1 s]    dev=(HR@5:0.4348,NDCG@5:0.3196) [0.4 s]
INFO:root:Epoch 40    loss=0.2016 [11.1 s]    dev=(HR@5:0.4300,NDCG@5:0.3185) [0.4 s]
INFO:root:Epoch 41    loss=0.2029 [10.9 s]    dev=(HR@5:0.4334,NDCG@5:0.3204) [0.4 s]
INFO:root:Epoch 42    loss=0.2029 [11.0 s]    dev=(HR@5:0.4408,NDCG@5:0.3234) [0.4 s]
INFO:root:Epoch 43    loss=0.2013 [11.3 s]    dev=(HR@5:0.4408,NDCG@5:0.3261) [0.4 s] *
INFO:root:Epoch 44    loss=0.2032 [11.0 s]    dev=(HR@5:0.4385,NDCG@5:0.3229) [0.4 s]
INFO:root:Epoch 45    loss=0.1987 [10.8 s]    dev=(HR@5:0.4422,NDCG@5:0.3282) [0.4 s] *
INFO:root:Epoch 46    loss=0.2009 [10.9 s]    dev=(HR@5:0.4374,NDCG@5:0.3232) [0.4 s]
INFO:root:Epoch 47    loss=0.2020 [11.0 s]    dev=(HR@5:0.4374,NDCG@5:0.3222) [0.4 s]
INFO:root:Epoch 48    loss=0.1992 [10.9 s]    dev=(HR@5:0.4321,NDCG@5:0.3200) [0.4 s]
INFO:root:Epoch 49    loss=0.1989 [9.4 s]    dev=(HR@5:0.4387,NDCG@5:0.3230) [0.4 s]
INFO:root:Epoch 50    loss=0.1996 [11.0 s]    dev=(HR@5:0.4367,NDCG@5:0.3235) [0.4 s]
INFO:root:Epoch 51    loss=0.1987 [10.8 s]    dev=(HR@5:0.4390,NDCG@5:0.3264) [0.4 s]
INFO:root:Epoch 52    loss=0.1987 [11.3 s]    dev=(HR@5:0.4362,NDCG@5:0.3229) [0.4 s]
INFO:root:Epoch 53    loss=0.1978 [11.1 s]    dev=(HR@5:0.4385,NDCG@5:0.3235) [0.4 s]
INFO:root:Epoch 54    loss=0.1958 [11.1 s]    dev=(HR@5:0.4406,NDCG@5:0.3250) [0.4 s]
INFO:root:Epoch 55    loss=0.1969 [10.1 s]    dev=(HR@5:0.4395,NDCG@5:0.3247) [0.4 s]
INFO:root:Epoch 56    loss=0.1961 [11.0 s]    dev=(HR@5:0.4368,NDCG@5:0.3241) [0.4 s]
INFO:root:Epoch 57    loss=0.1959 [11.3 s]    dev=(HR@5:0.4408,NDCG@5:0.3267) [0.4 s]
INFO:root:Epoch 58    loss=0.1972 [10.8 s]    dev=(HR@5:0.4421,NDCG@5:0.3259) [0.4 s]
INFO:root:Epoch 59    loss=0.1957 [11.0 s]    dev=(HR@5:0.4354,NDCG@5:0.3218) [0.4 s]
INFO:root:Epoch 60    loss=0.1966 [11.0 s]    dev=(HR@5:0.4389,NDCG@5:0.3268) [0.4 s]
INFO:root:Epoch 61    loss=0.1960 [11.4 s]    dev=(HR@5:0.4380,NDCG@5:0.3250) [0.4 s]
INFO:root:Epoch 62    loss=0.1950 [11.1 s]    dev=(HR@5:0.4430,NDCG@5:0.3266) [0.4 s]
INFO:root:Epoch 63    loss=0.1964 [11.2 s]    dev=(HR@5:0.4437,NDCG@5:0.3283) [0.4 s] *
INFO:root:Epoch 64    loss=0.1954 [11.2 s]    dev=(HR@5:0.4408,NDCG@5:0.3251) [0.4 s]
INFO:root:Epoch 65    loss=0.1956 [11.4 s]    dev=(HR@5:0.4355,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 66    loss=0.1941 [10.8 s]    dev=(HR@5:0.4404,NDCG@5:0.3247) [0.4 s]
INFO:root:Epoch 67    loss=0.1945 [11.1 s]    dev=(HR@5:0.4394,NDCG@5:0.3240) [0.4 s]
INFO:root:Epoch 68    loss=0.1933 [10.9 s]    dev=(HR@5:0.4387,NDCG@5:0.3240) [0.4 s]
INFO:root:Epoch 69    loss=0.1937 [11.4 s]    dev=(HR@5:0.4376,NDCG@5:0.3235) [0.4 s]
INFO:root:Epoch 70    loss=0.1943 [10.6 s]    dev=(HR@5:0.4385,NDCG@5:0.3247) [0.4 s]
INFO:root:Epoch 71    loss=0.1933 [11.2 s]    dev=(HR@5:0.4378,NDCG@5:0.3253) [0.4 s]
INFO:root:Epoch 72    loss=0.1920 [11.0 s]    dev=(HR@5:0.4415,NDCG@5:0.3245) [0.4 s]
INFO:root:Epoch 73    loss=0.1942 [10.3 s]    dev=(HR@5:0.4372,NDCG@5:0.3220) [0.4 s]
INFO:root:Epoch 74    loss=0.1937 [11.3 s]    dev=(HR@5:0.4352,NDCG@5:0.3200) [0.4 s]
INFO:root:Epoch 75    loss=0.1946 [11.3 s]    dev=(HR@5:0.4375,NDCG@5:0.3242) [0.4 s]
INFO:root:Epoch 76    loss=0.1932 [11.1 s]    dev=(HR@5:0.4355,NDCG@5:0.3216) [0.3 s]
INFO:root:Epoch 77    loss=0.1925 [11.1 s]    dev=(HR@5:0.4379,NDCG@5:0.3241) [0.4 s]
INFO:root:Epoch 78    loss=0.1925 [11.1 s]    dev=(HR@5:0.4387,NDCG@5:0.3245) [0.4 s]
INFO:root:Epoch 79    loss=0.1929 [11.2 s]    dev=(HR@5:0.4364,NDCG@5:0.3228) [0.4 s]
INFO:root:Epoch 80    loss=0.1911 [10.6 s]    dev=(HR@5:0.4353,NDCG@5:0.3212) [0.4 s]
INFO:root:Epoch 81    loss=0.1925 [10.4 s]    dev=(HR@5:0.4345,NDCG@5:0.3203) [0.4 s]
INFO:root:Epoch 82    loss=0.1937 [11.0 s]    dev=(HR@5:0.4387,NDCG@5:0.3239) [0.4 s]
INFO:root:Epoch 83    loss=0.1919 [10.7 s]    dev=(HR@5:0.4391,NDCG@5:0.3236) [0.4 s]
INFO:root:Early stop at 83 based on dev result.
INFO:root:
Best Iter(dev)=   63	 dev=(HR@5:0.4437,NDCG@5:0.3283) [944.8 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.3890,NDCG@5:0.2809,HR@10:0.4962,NDCG@10:0.3156,HR@20:0.6154,NDCG@20:0.3455,HR@50:0.8228,NDCG@50:0.3866)
INFO:root:
--------------------------------------------- END: 2024-12-22 20:35:55 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-22 20:57:43 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [12.4 s]    dev=(HR@5:0.2511,NDCG@5:0.1670) [0.4 s] *
INFO:root:Epoch 2     loss=0.4324 [11.0 s]    dev=(HR@5:0.3202,NDCG@5:0.2172) [0.4 s] *
INFO:root:Epoch 3     loss=0.4001 [10.9 s]    dev=(HR@5:0.3388,NDCG@5:0.2287) [0.4 s] *
INFO:root:Epoch 4     loss=0.3847 [11.0 s]    dev=(HR@5:0.3533,NDCG@5:0.2419) [0.4 s] *
INFO:root:Epoch 5     loss=0.3655 [11.3 s]    dev=(HR@5:0.3652,NDCG@5:0.2502) [0.4 s] *
INFO:root:Epoch 6     loss=0.3447 [11.2 s]    dev=(HR@5:0.3800,NDCG@5:0.2667) [0.4 s] *
INFO:root:Epoch 7     loss=0.3272 [10.5 s]    dev=(HR@5:0.3874,NDCG@5:0.2709) [0.4 s] *
INFO:root:Epoch 8     loss=0.3091 [10.9 s]    dev=(HR@5:0.3976,NDCG@5:0.2809) [0.4 s] *
INFO:root:Epoch 9     loss=0.2916 [10.9 s]    dev=(HR@5:0.4022,NDCG@5:0.2859) [0.4 s] *
INFO:root:Epoch 10    loss=0.2806 [11.2 s]    dev=(HR@5:0.4079,NDCG@5:0.2920) [0.4 s] *
INFO:root:Epoch 11    loss=0.2680 [11.2 s]    dev=(HR@5:0.4131,NDCG@5:0.2955) [0.4 s] *
INFO:root:Epoch 12    loss=0.2582 [12.1 s]    dev=(HR@5:0.4141,NDCG@5:0.2984) [0.4 s] *
INFO:root:Epoch 13    loss=0.2523 [11.3 s]    dev=(HR@5:0.4207,NDCG@5:0.3045) [0.4 s] *
INFO:root:Epoch 14    loss=0.2456 [11.3 s]    dev=(HR@5:0.4221,NDCG@5:0.3046) [0.4 s] *
INFO:root:Epoch 15    loss=0.2403 [10.9 s]    dev=(HR@5:0.4210,NDCG@5:0.3046) [0.4 s]
INFO:root:Epoch 16    loss=0.2370 [10.9 s]    dev=(HR@5:0.4201,NDCG@5:0.3066) [0.4 s] *
INFO:root:Epoch 17    loss=0.2331 [11.0 s]    dev=(HR@5:0.4197,NDCG@5:0.3041) [0.4 s]
INFO:root:Epoch 18    loss=0.2276 [10.9 s]    dev=(HR@5:0.4234,NDCG@5:0.3084) [0.4 s] *
INFO:root:Epoch 19    loss=0.2244 [10.9 s]    dev=(HR@5:0.4232,NDCG@5:0.3100) [0.4 s] *
INFO:root:Epoch 20    loss=0.2228 [10.7 s]    dev=(HR@5:0.4242,NDCG@5:0.3122) [0.4 s] *
INFO:root:Epoch 21    loss=0.2184 [10.8 s]    dev=(HR@5:0.4301,NDCG@5:0.3132) [0.4 s] *
INFO:root:Epoch 22    loss=0.2167 [10.9 s]    dev=(HR@5:0.4297,NDCG@5:0.3132) [0.4 s] *
INFO:root:Epoch 23    loss=0.2167 [10.6 s]    dev=(HR@5:0.4263,NDCG@5:0.3122) [0.4 s]
INFO:root:Epoch 24    loss=0.2158 [11.1 s]    dev=(HR@5:0.4307,NDCG@5:0.3151) [0.4 s] *
INFO:root:Epoch 25    loss=0.2125 [11.0 s]    dev=(HR@5:0.4242,NDCG@5:0.3109) [0.4 s]
INFO:root:Epoch 26    loss=0.2125 [10.5 s]    dev=(HR@5:0.4301,NDCG@5:0.3157) [0.4 s] *
INFO:root:Epoch 27    loss=0.2114 [10.6 s]    dev=(HR@5:0.4310,NDCG@5:0.3160) [0.4 s] *
INFO:root:Epoch 28    loss=0.2113 [11.0 s]    dev=(HR@5:0.4343,NDCG@5:0.3186) [0.4 s] *
INFO:root:Epoch 29    loss=0.2093 [10.8 s]    dev=(HR@5:0.4304,NDCG@5:0.3148) [0.4 s]
INFO:root:Epoch 30    loss=0.2083 [11.1 s]    dev=(HR@5:0.4325,NDCG@5:0.3174) [0.4 s]
INFO:root:Epoch 31    loss=0.2076 [9.2 s]    dev=(HR@5:0.4329,NDCG@5:0.3168) [0.4 s]
INFO:root:Epoch 32    loss=0.2079 [10.7 s]    dev=(HR@5:0.4333,NDCG@5:0.3177) [0.4 s]
INFO:root:Epoch 33    loss=0.2068 [10.7 s]    dev=(HR@5:0.4309,NDCG@5:0.3164) [0.4 s]
INFO:root:Epoch 34    loss=0.2049 [11.0 s]    dev=(HR@5:0.4338,NDCG@5:0.3175) [0.4 s]
INFO:root:Epoch 35    loss=0.2067 [11.2 s]    dev=(HR@5:0.4306,NDCG@5:0.3150) [0.4 s]
INFO:root:Epoch 36    loss=0.2042 [10.8 s]    dev=(HR@5:0.4343,NDCG@5:0.3169) [0.4 s]
INFO:root:Epoch 37    loss=0.2053 [11.0 s]    dev=(HR@5:0.4384,NDCG@5:0.3197) [0.4 s] *
INFO:root:Epoch 38    loss=0.2048 [10.3 s]    dev=(HR@5:0.4364,NDCG@5:0.3186) [0.4 s]
INFO:root:Epoch 39    loss=0.2043 [10.8 s]    dev=(HR@5:0.4343,NDCG@5:0.3164) [0.4 s]
INFO:root:Epoch 40    loss=0.2034 [11.1 s]    dev=(HR@5:0.4355,NDCG@5:0.3187) [0.4 s]
INFO:root:Epoch 41    loss=0.2044 [11.2 s]    dev=(HR@5:0.4327,NDCG@5:0.3165) [0.4 s]
INFO:root:Epoch 42    loss=0.2045 [11.0 s]    dev=(HR@5:0.4358,NDCG@5:0.3170) [0.4 s]
INFO:root:Epoch 43    loss=0.2032 [10.9 s]    dev=(HR@5:0.4391,NDCG@5:0.3224) [0.4 s] *
INFO:root:Epoch 44    loss=0.2053 [10.9 s]    dev=(HR@5:0.4359,NDCG@5:0.3193) [0.4 s]
INFO:root:Epoch 45    loss=0.2006 [10.5 s]    dev=(HR@5:0.4396,NDCG@5:0.3255) [0.4 s] *
INFO:root:Epoch 46    loss=0.2026 [10.6 s]    dev=(HR@5:0.4351,NDCG@5:0.3191) [0.4 s]
INFO:root:Epoch 47    loss=0.2034 [11.3 s]    dev=(HR@5:0.4355,NDCG@5:0.3177) [0.4 s]
INFO:root:Epoch 48    loss=0.2006 [11.0 s]    dev=(HR@5:0.4305,NDCG@5:0.3144) [0.4 s]
INFO:root:Epoch 49    loss=0.2000 [11.1 s]    dev=(HR@5:0.4357,NDCG@5:0.3209) [0.4 s]
INFO:root:Epoch 50    loss=0.2014 [10.9 s]    dev=(HR@5:0.4339,NDCG@5:0.3200) [0.4 s]
INFO:root:Epoch 51    loss=0.2005 [11.1 s]    dev=(HR@5:0.4375,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 52    loss=0.2005 [11.2 s]    dev=(HR@5:0.4338,NDCG@5:0.3164) [0.4 s]
INFO:root:Epoch 53    loss=0.1998 [11.4 s]    dev=(HR@5:0.4360,NDCG@5:0.3185) [0.4 s]
INFO:root:Epoch 54    loss=0.1980 [11.2 s]    dev=(HR@5:0.4399,NDCG@5:0.3203) [0.4 s]
INFO:root:Epoch 55    loss=0.1984 [11.1 s]    dev=(HR@5:0.4367,NDCG@5:0.3193) [0.4 s]
INFO:root:Epoch 56    loss=0.1979 [11.1 s]    dev=(HR@5:0.4367,NDCG@5:0.3205) [0.4 s]
INFO:root:Epoch 57    loss=0.1986 [10.4 s]    dev=(HR@5:0.4404,NDCG@5:0.3243) [0.4 s]
INFO:root:Epoch 58    loss=0.1988 [11.1 s]    dev=(HR@5:0.4397,NDCG@5:0.3227) [0.4 s]
INFO:root:Epoch 59    loss=0.1975 [9.5 s]    dev=(HR@5:0.4396,NDCG@5:0.3222) [0.4 s]
INFO:root:Epoch 60    loss=0.1984 [10.4 s]    dev=(HR@5:0.4380,NDCG@5:0.3216) [0.4 s]
INFO:root:Epoch 61    loss=0.1977 [11.1 s]    dev=(HR@5:0.4383,NDCG@5:0.3231) [0.3 s]
INFO:root:Epoch 62    loss=0.1966 [11.0 s]    dev=(HR@5:0.4415,NDCG@5:0.3232) [0.4 s]
INFO:root:Epoch 63    loss=0.1979 [11.1 s]    dev=(HR@5:0.4406,NDCG@5:0.3236) [0.4 s]
INFO:root:Epoch 64    loss=0.1973 [10.6 s]    dev=(HR@5:0.4413,NDCG@5:0.3228) [0.4 s]
INFO:root:Epoch 65    loss=0.1976 [10.7 s]    dev=(HR@5:0.4380,NDCG@5:0.3199) [0.4 s]
INFO:root:Early stop at 65 based on dev result.
INFO:root:
Best Iter(dev)=   45	 dev=(HR@5:0.4396,NDCG@5:0.3255) [734.9 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.3859,NDCG@5:0.2762,HR@10:0.4922,NDCG@10:0.3106,HR@20:0.6171,NDCG@20:0.3421,HR@50:0.8222,NDCG@50:0.3827)
INFO:root:
--------------------------------------------- END: 2024-12-22 21:10:01 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-22 21:41:58 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [12.0 s]    dev=(HR@5:0.2509,NDCG@5:0.1671) [0.4 s] *
INFO:root:Epoch 2     loss=0.4324 [11.3 s]    dev=(HR@5:0.3201,NDCG@5:0.2173) [0.4 s] *
INFO:root:Epoch 3     loss=0.4002 [11.3 s]    dev=(HR@5:0.3391,NDCG@5:0.2282) [0.4 s] *
INFO:root:Epoch 4     loss=0.3851 [10.7 s]    dev=(HR@5:0.3526,NDCG@5:0.2411) [0.4 s] *
INFO:root:Epoch 5     loss=0.3660 [11.3 s]    dev=(HR@5:0.3642,NDCG@5:0.2496) [0.4 s] *
INFO:root:Epoch 6     loss=0.3457 [11.1 s]    dev=(HR@5:0.3810,NDCG@5:0.2662) [0.4 s] *
INFO:root:Epoch 7     loss=0.3279 [10.7 s]    dev=(HR@5:0.3870,NDCG@5:0.2704) [0.4 s] *
INFO:root:Epoch 8     loss=0.3092 [11.1 s]    dev=(HR@5:0.3991,NDCG@5:0.2819) [0.4 s] *
INFO:root:Epoch 9     loss=0.2917 [11.3 s]    dev=(HR@5:0.4065,NDCG@5:0.2885) [0.4 s] *
INFO:root:Epoch 10    loss=0.2807 [11.2 s]    dev=(HR@5:0.4104,NDCG@5:0.2932) [0.4 s] *
INFO:root:Epoch 11    loss=0.2683 [10.9 s]    dev=(HR@5:0.4147,NDCG@5:0.2973) [0.4 s] *
INFO:root:Epoch 12    loss=0.2593 [9.9 s]    dev=(HR@5:0.4180,NDCG@5:0.3026) [0.4 s] *
INFO:root:Epoch 13    loss=0.2534 [11.3 s]    dev=(HR@5:0.4257,NDCG@5:0.3084) [0.4 s] *
INFO:root:Epoch 14    loss=0.2471 [11.0 s]    dev=(HR@5:0.4263,NDCG@5:0.3081) [0.4 s]
INFO:root:Epoch 15    loss=0.2431 [11.0 s]    dev=(HR@5:0.4269,NDCG@5:0.3087) [0.5 s] *
INFO:root:Epoch 16    loss=0.2402 [10.9 s]    dev=(HR@5:0.4263,NDCG@5:0.3101) [0.4 s] *
INFO:root:Epoch 17    loss=0.2358 [11.0 s]    dev=(HR@5:0.4244,NDCG@5:0.3095) [0.4 s]
INFO:root:Epoch 18    loss=0.2310 [11.3 s]    dev=(HR@5:0.4290,NDCG@5:0.3132) [0.4 s] *
INFO:root:Epoch 19    loss=0.2276 [10.9 s]    dev=(HR@5:0.4289,NDCG@5:0.3162) [0.4 s] *
INFO:root:Epoch 20    loss=0.2260 [10.9 s]    dev=(HR@5:0.4306,NDCG@5:0.3172) [0.4 s] *
INFO:root:Epoch 21    loss=0.2215 [11.1 s]    dev=(HR@5:0.4332,NDCG@5:0.3174) [0.4 s] *
INFO:root:Epoch 22    loss=0.2194 [11.0 s]    dev=(HR@5:0.4305,NDCG@5:0.3162) [0.4 s]
INFO:root:Epoch 23    loss=0.2197 [11.2 s]    dev=(HR@5:0.4294,NDCG@5:0.3173) [0.4 s]
INFO:root:Epoch 24    loss=0.2193 [10.9 s]    dev=(HR@5:0.4348,NDCG@5:0.3192) [0.4 s] *
INFO:root:Epoch 25    loss=0.2162 [11.0 s]    dev=(HR@5:0.4313,NDCG@5:0.3175) [0.4 s]
INFO:root:Epoch 26    loss=0.2158 [11.1 s]    dev=(HR@5:0.4347,NDCG@5:0.3201) [0.3 s] *
INFO:root:Epoch 27    loss=0.2144 [10.8 s]    dev=(HR@5:0.4329,NDCG@5:0.3193) [0.4 s]
INFO:root:Epoch 28    loss=0.2149 [11.2 s]    dev=(HR@5:0.4316,NDCG@5:0.3194) [0.4 s]
INFO:root:Epoch 29    loss=0.2120 [11.0 s]    dev=(HR@5:0.4300,NDCG@5:0.3170) [0.4 s]
INFO:root:Epoch 30    loss=0.2113 [11.1 s]    dev=(HR@5:0.4308,NDCG@5:0.3173) [0.4 s]
INFO:root:Epoch 31    loss=0.2102 [11.0 s]    dev=(HR@5:0.4336,NDCG@5:0.3188) [0.4 s]
INFO:root:Epoch 32    loss=0.2110 [10.9 s]    dev=(HR@5:0.4338,NDCG@5:0.3193) [0.4 s]
INFO:root:Epoch 33    loss=0.2092 [10.6 s]    dev=(HR@5:0.4333,NDCG@5:0.3210) [0.4 s] *
INFO:root:Epoch 34    loss=0.2080 [11.1 s]    dev=(HR@5:0.4348,NDCG@5:0.3196) [0.4 s]
INFO:root:Epoch 35    loss=0.2088 [10.7 s]    dev=(HR@5:0.4340,NDCG@5:0.3180) [0.4 s]
INFO:root:Epoch 36    loss=0.2063 [10.8 s]    dev=(HR@5:0.4321,NDCG@5:0.3197) [0.4 s]
INFO:root:Epoch 37    loss=0.2070 [10.8 s]    dev=(HR@5:0.4337,NDCG@5:0.3192) [0.4 s]
INFO:root:Epoch 38    loss=0.2064 [10.9 s]    dev=(HR@5:0.4366,NDCG@5:0.3206) [0.4 s]
INFO:root:Epoch 39    loss=0.2067 [10.7 s]    dev=(HR@5:0.4320,NDCG@5:0.3187) [0.4 s]
INFO:root:Epoch 40    loss=0.2054 [10.7 s]    dev=(HR@5:0.4301,NDCG@5:0.3177) [0.4 s]
INFO:root:Epoch 41    loss=0.2060 [11.2 s]    dev=(HR@5:0.4299,NDCG@5:0.3162) [0.4 s]
INFO:root:Epoch 42    loss=0.2057 [11.1 s]    dev=(HR@5:0.4353,NDCG@5:0.3190) [0.4 s]
INFO:root:Epoch 43    loss=0.2044 [10.9 s]    dev=(HR@5:0.4395,NDCG@5:0.3241) [0.4 s] *
INFO:root:Epoch 44    loss=0.2058 [10.9 s]    dev=(HR@5:0.4321,NDCG@5:0.3173) [0.4 s]
INFO:root:Epoch 45    loss=0.2023 [10.7 s]    dev=(HR@5:0.4398,NDCG@5:0.3248) [0.4 s] *
INFO:root:Epoch 46    loss=0.2035 [10.8 s]    dev=(HR@5:0.4304,NDCG@5:0.3158) [0.4 s]
INFO:root:Epoch 47    loss=0.2039 [11.0 s]    dev=(HR@5:0.4345,NDCG@5:0.3182) [0.4 s]
INFO:root:Epoch 48    loss=0.2021 [10.3 s]    dev=(HR@5:0.4310,NDCG@5:0.3158) [0.4 s]
INFO:root:Epoch 49    loss=0.2013 [10.3 s]    dev=(HR@5:0.4388,NDCG@5:0.3219) [0.4 s]
INFO:root:Epoch 50    loss=0.2029 [10.4 s]    dev=(HR@5:0.4355,NDCG@5:0.3198) [0.4 s]
INFO:root:Epoch 51    loss=0.2006 [11.0 s]    dev=(HR@5:0.4387,NDCG@5:0.3230) [0.4 s]
INFO:root:Epoch 52    loss=0.2018 [10.9 s]    dev=(HR@5:0.4378,NDCG@5:0.3202) [0.4 s]
INFO:root:Epoch 53    loss=0.2008 [11.2 s]    dev=(HR@5:0.4355,NDCG@5:0.3194) [0.4 s]
INFO:root:Epoch 54    loss=0.1992 [11.1 s]    dev=(HR@5:0.4370,NDCG@5:0.3193) [0.4 s]
INFO:root:Epoch 55    loss=0.1990 [10.8 s]    dev=(HR@5:0.4378,NDCG@5:0.3213) [0.3 s]
INFO:root:Epoch 56    loss=0.1992 [11.0 s]    dev=(HR@5:0.4382,NDCG@5:0.3228) [0.4 s]
INFO:root:Epoch 57    loss=0.1993 [11.1 s]    dev=(HR@5:0.4406,NDCG@5:0.3253) [0.4 s] *
INFO:root:Epoch 58    loss=0.2004 [11.3 s]    dev=(HR@5:0.4377,NDCG@5:0.3235) [0.4 s]
INFO:root:Epoch 59    loss=0.1986 [11.0 s]    dev=(HR@5:0.4363,NDCG@5:0.3215) [0.4 s]
INFO:root:Epoch 60    loss=0.1993 [11.1 s]    dev=(HR@5:0.4381,NDCG@5:0.3231) [0.4 s]
INFO:root:Epoch 61    loss=0.1981 [10.9 s]    dev=(HR@5:0.4383,NDCG@5:0.3233) [0.4 s]
INFO:root:Epoch 62    loss=0.1986 [11.1 s]    dev=(HR@5:0.4398,NDCG@5:0.3249) [0.4 s]
INFO:root:Epoch 63    loss=0.1995 [10.7 s]    dev=(HR@5:0.4403,NDCG@5:0.3256) [0.4 s] *
INFO:root:Epoch 64    loss=0.1977 [10.1 s]    dev=(HR@5:0.4398,NDCG@5:0.3229) [0.4 s]
INFO:root:Epoch 65    loss=0.1979 [11.0 s]    dev=(HR@5:0.4370,NDCG@5:0.3220) [0.4 s]
INFO:root:Epoch 66    loss=0.1964 [11.2 s]    dev=(HR@5:0.4380,NDCG@5:0.3221) [0.4 s]
INFO:root:Epoch 67    loss=0.1969 [10.9 s]    dev=(HR@5:0.4381,NDCG@5:0.3209) [0.4 s]
INFO:root:Epoch 68    loss=0.1954 [9.5 s]    dev=(HR@5:0.4421,NDCG@5:0.3230) [0.4 s]
INFO:root:Epoch 69    loss=0.1970 [10.9 s]    dev=(HR@5:0.4385,NDCG@5:0.3230) [0.4 s]
INFO:root:Epoch 70    loss=0.1961 [10.1 s]    dev=(HR@5:0.4387,NDCG@5:0.3226) [0.4 s]
INFO:root:Epoch 71    loss=0.1959 [11.0 s]    dev=(HR@5:0.4404,NDCG@5:0.3252) [0.4 s]
INFO:root:Epoch 72    loss=0.1954 [10.5 s]    dev=(HR@5:0.4357,NDCG@5:0.3232) [0.4 s]
INFO:root:Epoch 73    loss=0.1963 [10.1 s]    dev=(HR@5:0.4399,NDCG@5:0.3236) [0.4 s]
INFO:root:Epoch 74    loss=0.1963 [10.4 s]    dev=(HR@5:0.4372,NDCG@5:0.3214) [0.3 s]
INFO:root:Epoch 75    loss=0.1977 [10.8 s]    dev=(HR@5:0.4369,NDCG@5:0.3222) [0.4 s]
INFO:root:Epoch 76    loss=0.1960 [10.2 s]    dev=(HR@5:0.4376,NDCG@5:0.3224) [0.4 s]
INFO:root:Epoch 77    loss=0.1950 [10.9 s]    dev=(HR@5:0.4394,NDCG@5:0.3242) [0.4 s]
INFO:root:Epoch 78    loss=0.1951 [10.4 s]    dev=(HR@5:0.4373,NDCG@5:0.3214) [0.4 s]
INFO:root:Epoch 79    loss=0.1955 [10.6 s]    dev=(HR@5:0.4403,NDCG@5:0.3251) [0.4 s]
INFO:root:Epoch 80    loss=0.1940 [11.0 s]    dev=(HR@5:0.4386,NDCG@5:0.3222) [0.4 s]
INFO:root:Epoch 81    loss=0.1947 [11.2 s]    dev=(HR@5:0.4348,NDCG@5:0.3176) [0.4 s]
INFO:root:Epoch 82    loss=0.1959 [11.2 s]    dev=(HR@5:0.4343,NDCG@5:0.3204) [0.4 s]
INFO:root:Epoch 83    loss=0.1936 [11.2 s]    dev=(HR@5:0.4382,NDCG@5:0.3234) [0.4 s]
INFO:root:Early stop at 83 based on dev result.
INFO:root:
Best Iter(dev)=   63	 dev=(HR@5:0.4403,NDCG@5:0.3256) [934.8 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.3913,NDCG@5:0.2810,HR@10:0.4971,NDCG@10:0.3152,HR@20:0.6188,NDCG@20:0.3459,HR@50:0.8294,NDCG@50:0.3876)
INFO:root:
--------------------------------------------- END: 2024-12-22 21:57:36 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-22 22:31:31 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5165 [12.0 s]    dev=(HR@5:0.2512,NDCG@5:0.1672) [0.3 s] *
INFO:root:Epoch 2     loss=0.4324 [10.9 s]    dev=(HR@5:0.3194,NDCG@5:0.2170) [0.4 s] *
INFO:root:Epoch 3     loss=0.4003 [10.3 s]    dev=(HR@5:0.3389,NDCG@5:0.2280) [0.4 s] *
INFO:root:Epoch 4     loss=0.3861 [11.3 s]    dev=(HR@5:0.3491,NDCG@5:0.2385) [0.4 s] *
INFO:root:Epoch 5     loss=0.3667 [11.1 s]    dev=(HR@5:0.3620,NDCG@5:0.2480) [0.4 s] *
INFO:root:Epoch 6     loss=0.3456 [10.0 s]    dev=(HR@5:0.3802,NDCG@5:0.2657) [0.4 s] *
INFO:root:Epoch 7     loss=0.3262 [11.0 s]    dev=(HR@5:0.3915,NDCG@5:0.2727) [0.4 s] *
INFO:root:Epoch 8     loss=0.3061 [11.0 s]    dev=(HR@5:0.4026,NDCG@5:0.2843) [0.4 s] *
INFO:root:Epoch 9     loss=0.2893 [11.2 s]    dev=(HR@5:0.4068,NDCG@5:0.2892) [0.4 s] *
INFO:root:Epoch 10    loss=0.2788 [11.1 s]    dev=(HR@5:0.4119,NDCG@5:0.2951) [0.4 s] *
INFO:root:Epoch 11    loss=0.2670 [11.4 s]    dev=(HR@5:0.4143,NDCG@5:0.2977) [0.4 s] *
INFO:root:Epoch 12    loss=0.2584 [10.8 s]    dev=(HR@5:0.4180,NDCG@5:0.3028) [0.4 s] *
INFO:root:Epoch 13    loss=0.2531 [11.0 s]    dev=(HR@5:0.4258,NDCG@5:0.3086) [0.4 s] *
INFO:root:Epoch 14    loss=0.2473 [11.2 s]    dev=(HR@5:0.4239,NDCG@5:0.3081) [0.4 s]
INFO:root:Epoch 15    loss=0.2436 [11.0 s]    dev=(HR@5:0.4245,NDCG@5:0.3064) [0.4 s]
INFO:root:Epoch 16    loss=0.2406 [10.6 s]    dev=(HR@5:0.4260,NDCG@5:0.3106) [0.4 s] *
INFO:root:Epoch 17    loss=0.2363 [11.5 s]    dev=(HR@5:0.4244,NDCG@5:0.3095) [0.4 s]
INFO:root:Epoch 18    loss=0.2319 [10.8 s]    dev=(HR@5:0.4308,NDCG@5:0.3136) [0.4 s] *
INFO:root:Epoch 19    loss=0.2284 [11.3 s]    dev=(HR@5:0.4288,NDCG@5:0.3152) [0.4 s] *
INFO:root:Epoch 20    loss=0.2270 [10.9 s]    dev=(HR@5:0.4315,NDCG@5:0.3171) [0.4 s] *
INFO:root:Epoch 21    loss=0.2222 [10.9 s]    dev=(HR@5:0.4314,NDCG@5:0.3167) [0.4 s]
INFO:root:Epoch 22    loss=0.2202 [11.2 s]    dev=(HR@5:0.4317,NDCG@5:0.3172) [0.4 s] *
INFO:root:Epoch 23    loss=0.2211 [11.1 s]    dev=(HR@5:0.4302,NDCG@5:0.3173) [0.4 s] *
INFO:root:Epoch 24    loss=0.2206 [10.0 s]    dev=(HR@5:0.4353,NDCG@5:0.3199) [0.4 s] *
INFO:root:Epoch 25    loss=0.2169 [11.3 s]    dev=(HR@5:0.4304,NDCG@5:0.3165) [0.4 s]
INFO:root:Epoch 26    loss=0.2165 [11.0 s]    dev=(HR@5:0.4334,NDCG@5:0.3199) [0.4 s]
INFO:root:Epoch 27    loss=0.2154 [11.0 s]    dev=(HR@5:0.4348,NDCG@5:0.3201) [0.4 s] *
INFO:root:Epoch 28    loss=0.2155 [11.1 s]    dev=(HR@5:0.4363,NDCG@5:0.3221) [0.4 s] *
INFO:root:Epoch 29    loss=0.2129 [11.0 s]    dev=(HR@5:0.4312,NDCG@5:0.3169) [0.4 s]
INFO:root:Epoch 30    loss=0.2122 [10.9 s]    dev=(HR@5:0.4347,NDCG@5:0.3201) [0.4 s]
INFO:root:Epoch 31    loss=0.2113 [11.0 s]    dev=(HR@5:0.4378,NDCG@5:0.3216) [0.4 s]
INFO:root:Epoch 32    loss=0.2117 [11.2 s]    dev=(HR@5:0.4363,NDCG@5:0.3209) [0.4 s]
INFO:root:Epoch 33    loss=0.2100 [11.1 s]    dev=(HR@5:0.4363,NDCG@5:0.3226) [0.4 s] *
INFO:root:Epoch 34    loss=0.2090 [11.1 s]    dev=(HR@5:0.4364,NDCG@5:0.3206) [0.4 s]
INFO:root:Epoch 35    loss=0.2093 [11.1 s]    dev=(HR@5:0.4336,NDCG@5:0.3190) [0.4 s]
INFO:root:Epoch 36    loss=0.2072 [10.6 s]    dev=(HR@5:0.4366,NDCG@5:0.3219) [0.4 s]
INFO:root:Epoch 37    loss=0.2079 [11.1 s]    dev=(HR@5:0.4383,NDCG@5:0.3222) [0.4 s]
INFO:root:Epoch 38    loss=0.2075 [11.0 s]    dev=(HR@5:0.4380,NDCG@5:0.3220) [0.4 s]
INFO:root:Epoch 39    loss=0.2079 [10.9 s]    dev=(HR@5:0.4364,NDCG@5:0.3198) [0.4 s]
INFO:root:Epoch 40    loss=0.2060 [9.8 s]    dev=(HR@5:0.4351,NDCG@5:0.3202) [0.4 s]
INFO:root:Epoch 41    loss=0.2066 [10.8 s]    dev=(HR@5:0.4338,NDCG@5:0.3182) [0.4 s]
INFO:root:Epoch 42    loss=0.2065 [10.9 s]    dev=(HR@5:0.4398,NDCG@5:0.3210) [0.4 s]
INFO:root:Epoch 43    loss=0.2058 [10.0 s]    dev=(HR@5:0.4429,NDCG@5:0.3261) [0.3 s] *
INFO:root:Epoch 44    loss=0.2069 [10.8 s]    dev=(HR@5:0.4368,NDCG@5:0.3200) [0.4 s]
INFO:root:Epoch 45    loss=0.2033 [10.7 s]    dev=(HR@5:0.4400,NDCG@5:0.3252) [0.4 s]
INFO:root:Epoch 46    loss=0.2049 [11.1 s]    dev=(HR@5:0.4335,NDCG@5:0.3183) [0.4 s]
INFO:root:Epoch 47    loss=0.2055 [11.4 s]    dev=(HR@5:0.4350,NDCG@5:0.3194) [0.4 s]
INFO:root:Epoch 48    loss=0.2037 [11.3 s]    dev=(HR@5:0.4362,NDCG@5:0.3198) [0.4 s]
INFO:root:Epoch 49    loss=0.2024 [10.9 s]    dev=(HR@5:0.4390,NDCG@5:0.3223) [0.4 s]
INFO:root:Epoch 50    loss=0.2034 [11.0 s]    dev=(HR@5:0.4355,NDCG@5:0.3210) [0.4 s]
INFO:root:Epoch 51    loss=0.2025 [11.1 s]    dev=(HR@5:0.4412,NDCG@5:0.3246) [0.4 s]
INFO:root:Epoch 52    loss=0.2036 [10.9 s]    dev=(HR@5:0.4383,NDCG@5:0.3215) [0.4 s]
INFO:root:Epoch 53    loss=0.2022 [10.7 s]    dev=(HR@5:0.4378,NDCG@5:0.3215) [0.4 s]
INFO:root:Epoch 54    loss=0.2007 [11.1 s]    dev=(HR@5:0.4420,NDCG@5:0.3223) [0.4 s]
INFO:root:Epoch 55    loss=0.2008 [11.0 s]    dev=(HR@5:0.4402,NDCG@5:0.3222) [0.4 s]
INFO:root:Epoch 56    loss=0.2006 [11.2 s]    dev=(HR@5:0.4420,NDCG@5:0.3254) [0.4 s]
INFO:root:Epoch 57    loss=0.2012 [11.1 s]    dev=(HR@5:0.4426,NDCG@5:0.3275) [0.4 s] *
INFO:root:Epoch 58    loss=0.2018 [11.5 s]    dev=(HR@5:0.4429,NDCG@5:0.3266) [0.4 s]
INFO:root:Epoch 59    loss=0.2004 [11.2 s]    dev=(HR@5:0.4391,NDCG@5:0.3238) [0.4 s]
INFO:root:Epoch 60    loss=0.2009 [10.9 s]    dev=(HR@5:0.4397,NDCG@5:0.3246) [0.4 s]
INFO:root:Epoch 61    loss=0.2003 [11.4 s]    dev=(HR@5:0.4438,NDCG@5:0.3270) [0.4 s]
INFO:root:Epoch 62    loss=0.1997 [11.2 s]    dev=(HR@5:0.4456,NDCG@5:0.3276) [0.3 s] *
INFO:root:Epoch 63    loss=0.2018 [10.9 s]    dev=(HR@5:0.4434,NDCG@5:0.3280) [0.4 s] *
INFO:root:Epoch 64    loss=0.1997 [11.2 s]    dev=(HR@5:0.4409,NDCG@5:0.3231) [0.4 s]
INFO:root:Epoch 65    loss=0.1998 [11.3 s]    dev=(HR@5:0.4393,NDCG@5:0.3229) [0.4 s]
INFO:root:Epoch 66    loss=0.1983 [11.2 s]    dev=(HR@5:0.4413,NDCG@5:0.3231) [0.4 s]
INFO:root:Epoch 67    loss=0.1984 [11.1 s]    dev=(HR@5:0.4393,NDCG@5:0.3211) [0.4 s]
INFO:root:Epoch 68    loss=0.1970 [11.1 s]    dev=(HR@5:0.4432,NDCG@5:0.3234) [0.4 s]
INFO:root:Epoch 69    loss=0.1987 [11.0 s]    dev=(HR@5:0.4408,NDCG@5:0.3237) [0.4 s]
INFO:root:Epoch 70    loss=0.1982 [11.0 s]    dev=(HR@5:0.4387,NDCG@5:0.3230) [0.4 s]
INFO:root:Epoch 71    loss=0.1973 [11.2 s]    dev=(HR@5:0.4419,NDCG@5:0.3250) [0.4 s]
INFO:root:Epoch 72    loss=0.1972 [10.0 s]    dev=(HR@5:0.4398,NDCG@5:0.3237) [0.4 s]
INFO:root:Epoch 73    loss=0.1978 [11.4 s]    dev=(HR@5:0.4413,NDCG@5:0.3242) [0.4 s]
INFO:root:Epoch 74    loss=0.1981 [10.5 s]    dev=(HR@5:0.4390,NDCG@5:0.3210) [0.4 s]
INFO:root:Epoch 75    loss=0.1991 [11.1 s]    dev=(HR@5:0.4394,NDCG@5:0.3222) [0.4 s]
INFO:root:Epoch 76    loss=0.1975 [11.1 s]    dev=(HR@5:0.4389,NDCG@5:0.3225) [0.4 s]
INFO:root:Epoch 77    loss=0.1967 [10.7 s]    dev=(HR@5:0.4421,NDCG@5:0.3264) [0.4 s]
INFO:root:Epoch 78    loss=0.1967 [10.5 s]    dev=(HR@5:0.4415,NDCG@5:0.3223) [0.4 s]
INFO:root:Epoch 79    loss=0.1979 [11.2 s]    dev=(HR@5:0.4442,NDCG@5:0.3265) [0.4 s]
INFO:root:Epoch 80    loss=0.1961 [10.6 s]    dev=(HR@5:0.4383,NDCG@5:0.3223) [0.4 s]
INFO:root:Epoch 81    loss=0.1974 [11.0 s]    dev=(HR@5:0.4363,NDCG@5:0.3188) [0.4 s]
INFO:root:Epoch 82    loss=0.1979 [11.1 s]    dev=(HR@5:0.4384,NDCG@5:0.3203) [0.4 s]
INFO:root:Epoch 83    loss=0.1954 [11.3 s]    dev=(HR@5:0.4406,NDCG@5:0.3225) [0.4 s]
INFO:root:Early stop at 83 based on dev result.
INFO:root:
Best Iter(dev)=   63	 dev=(HR@5:0.4434,NDCG@5:0.3280) [943.6 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.3945,NDCG@5:0.2844,HR@10:0.5015,NDCG@10:0.3190,HR@20:0.6226,NDCG@20:0.3495,HR@50:0.8377,NDCG@50:0.3921)
INFO:root:
--------------------------------------------- END: 2024-12-22 22:47:17 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-22 23:22:30 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.1                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5165 [12.6 s]    dev=(HR@5:0.2515,NDCG@5:0.1672) [0.4 s] *
INFO:root:Epoch 2     loss=0.4324 [11.3 s]    dev=(HR@5:0.3198,NDCG@5:0.2172) [0.4 s] *
INFO:root:Epoch 3     loss=0.4003 [11.6 s]    dev=(HR@5:0.3389,NDCG@5:0.2281) [0.4 s] *
INFO:root:Epoch 4     loss=0.3862 [11.1 s]    dev=(HR@5:0.3495,NDCG@5:0.2390) [0.4 s] *
INFO:root:Epoch 5     loss=0.3673 [9.5 s]    dev=(HR@5:0.3613,NDCG@5:0.2481) [0.4 s] *
INFO:root:Epoch 6     loss=0.3452 [10.7 s]    dev=(HR@5:0.3806,NDCG@5:0.2670) [0.4 s] *
INFO:root:Epoch 7     loss=0.3252 [11.5 s]    dev=(HR@5:0.3910,NDCG@5:0.2740) [0.4 s] *
INFO:root:Epoch 8     loss=0.3050 [11.5 s]    dev=(HR@5:0.4022,NDCG@5:0.2857) [0.4 s] *
INFO:root:Epoch 9     loss=0.2880 [11.5 s]    dev=(HR@5:0.4088,NDCG@5:0.2916) [0.4 s] *
INFO:root:Epoch 10    loss=0.2779 [11.9 s]    dev=(HR@5:0.4107,NDCG@5:0.2954) [0.4 s] *
INFO:root:Epoch 11    loss=0.2663 [11.4 s]    dev=(HR@5:0.4141,NDCG@5:0.2986) [0.4 s] *
INFO:root:Epoch 12    loss=0.2579 [11.8 s]    dev=(HR@5:0.4174,NDCG@5:0.3031) [0.4 s] *
INFO:root:Epoch 13    loss=0.2528 [11.6 s]    dev=(HR@5:0.4240,NDCG@5:0.3073) [0.4 s] *
INFO:root:Epoch 14    loss=0.2472 [11.4 s]    dev=(HR@5:0.4236,NDCG@5:0.3070) [0.4 s]
INFO:root:Epoch 15    loss=0.2437 [11.2 s]    dev=(HR@5:0.4233,NDCG@5:0.3063) [0.4 s]
INFO:root:Epoch 16    loss=0.2410 [11.1 s]    dev=(HR@5:0.4259,NDCG@5:0.3111) [0.4 s] *
INFO:root:Epoch 17    loss=0.2368 [11.2 s]    dev=(HR@5:0.4203,NDCG@5:0.3079) [0.4 s]
INFO:root:Epoch 18    loss=0.2327 [11.5 s]    dev=(HR@5:0.4291,NDCG@5:0.3127) [0.4 s] *
INFO:root:Epoch 19    loss=0.2295 [11.7 s]    dev=(HR@5:0.4265,NDCG@5:0.3142) [0.4 s] *
INFO:root:Epoch 20    loss=0.2283 [11.6 s]    dev=(HR@5:0.4308,NDCG@5:0.3164) [0.4 s] *
INFO:root:Epoch 21    loss=0.2235 [11.5 s]    dev=(HR@5:0.4306,NDCG@5:0.3153) [0.4 s]
INFO:root:Epoch 22    loss=0.2220 [11.8 s]    dev=(HR@5:0.4284,NDCG@5:0.3157) [0.4 s]
INFO:root:Epoch 23    loss=0.2226 [11.9 s]    dev=(HR@5:0.4304,NDCG@5:0.3178) [0.4 s] *
INFO:root:Epoch 24    loss=0.2221 [11.8 s]    dev=(HR@5:0.4349,NDCG@5:0.3194) [0.4 s] *
INFO:root:Epoch 25    loss=0.2185 [11.6 s]    dev=(HR@5:0.4295,NDCG@5:0.3159) [0.4 s]
INFO:root:Epoch 26    loss=0.2179 [10.0 s]    dev=(HR@5:0.4309,NDCG@5:0.3183) [0.4 s]
INFO:root:Epoch 27    loss=0.2165 [11.5 s]    dev=(HR@5:0.4312,NDCG@5:0.3191) [0.4 s]
INFO:root:Epoch 28    loss=0.2168 [10.9 s]    dev=(HR@5:0.4341,NDCG@5:0.3212) [0.4 s] *
INFO:root:Epoch 29    loss=0.2139 [11.5 s]    dev=(HR@5:0.4340,NDCG@5:0.3188) [0.4 s]
INFO:root:Epoch 30    loss=0.2129 [11.2 s]    dev=(HR@5:0.4323,NDCG@5:0.3189) [0.4 s]
INFO:root:Epoch 31    loss=0.2123 [11.7 s]    dev=(HR@5:0.4364,NDCG@5:0.3215) [0.4 s] *
INFO:root:Epoch 32    loss=0.2123 [10.4 s]    dev=(HR@5:0.4350,NDCG@5:0.3194) [0.4 s]
INFO:root:Epoch 33    loss=0.2107 [11.6 s]    dev=(HR@5:0.4370,NDCG@5:0.3222) [0.4 s] *
INFO:root:Epoch 34    loss=0.2091 [10.4 s]    dev=(HR@5:0.4336,NDCG@5:0.3190) [0.4 s]
INFO:root:Epoch 35    loss=0.2095 [11.4 s]    dev=(HR@5:0.4346,NDCG@5:0.3191) [0.4 s]
INFO:root:Epoch 36    loss=0.2073 [11.5 s]    dev=(HR@5:0.4348,NDCG@5:0.3204) [0.4 s]
INFO:root:Epoch 37    loss=0.2078 [11.2 s]    dev=(HR@5:0.4359,NDCG@5:0.3209) [0.4 s]
INFO:root:Epoch 38    loss=0.2075 [11.1 s]    dev=(HR@5:0.4393,NDCG@5:0.3233) [0.4 s] *
INFO:root:Epoch 39    loss=0.2077 [11.1 s]    dev=(HR@5:0.4385,NDCG@5:0.3201) [0.4 s]
INFO:root:Epoch 40    loss=0.2058 [11.3 s]    dev=(HR@5:0.4362,NDCG@5:0.3207) [0.4 s]
INFO:root:Epoch 41    loss=0.2059 [9.4 s]    dev=(HR@5:0.4344,NDCG@5:0.3179) [0.4 s]
INFO:root:Epoch 42    loss=0.2057 [10.2 s]    dev=(HR@5:0.4398,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 43    loss=0.2045 [10.0 s]    dev=(HR@5:0.4410,NDCG@5:0.3252) [0.4 s] *
INFO:root:Epoch 44    loss=0.2063 [10.3 s]    dev=(HR@5:0.4374,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 45    loss=0.2024 [10.2 s]    dev=(HR@5:0.4410,NDCG@5:0.3258) [0.4 s] *
INFO:root:Epoch 46    loss=0.2040 [11.1 s]    dev=(HR@5:0.4323,NDCG@5:0.3187) [0.4 s]
INFO:root:Epoch 47    loss=0.2039 [11.0 s]    dev=(HR@5:0.4382,NDCG@5:0.3214) [0.4 s]
INFO:root:Epoch 48    loss=0.2020 [11.3 s]    dev=(HR@5:0.4365,NDCG@5:0.3201) [0.4 s]
INFO:root:Epoch 49    loss=0.2015 [11.3 s]    dev=(HR@5:0.4372,NDCG@5:0.3221) [0.4 s]
INFO:root:Epoch 50    loss=0.2025 [11.3 s]    dev=(HR@5:0.4348,NDCG@5:0.3204) [0.4 s]
INFO:root:Epoch 51    loss=0.2010 [11.1 s]    dev=(HR@5:0.4389,NDCG@5:0.3235) [0.4 s]
INFO:root:Epoch 52    loss=0.2020 [11.1 s]    dev=(HR@5:0.4363,NDCG@5:0.3214) [0.4 s]
INFO:root:Epoch 53    loss=0.2012 [10.8 s]    dev=(HR@5:0.4380,NDCG@5:0.3220) [0.4 s]
INFO:root:Epoch 54    loss=0.1990 [10.9 s]    dev=(HR@5:0.4408,NDCG@5:0.3234) [0.4 s]
INFO:root:Epoch 55    loss=0.1990 [10.9 s]    dev=(HR@5:0.4369,NDCG@5:0.3222) [0.4 s]
INFO:root:Epoch 56    loss=0.1990 [11.3 s]    dev=(HR@5:0.4388,NDCG@5:0.3242) [0.4 s]
INFO:root:Epoch 57    loss=0.1994 [10.9 s]    dev=(HR@5:0.4407,NDCG@5:0.3257) [0.4 s]
INFO:root:Epoch 58    loss=0.2002 [10.9 s]    dev=(HR@5:0.4404,NDCG@5:0.3252) [0.4 s]
INFO:root:Epoch 59    loss=0.1986 [10.9 s]    dev=(HR@5:0.4406,NDCG@5:0.3252) [0.4 s]
INFO:root:Epoch 60    loss=0.1996 [11.2 s]    dev=(HR@5:0.4394,NDCG@5:0.3235) [0.4 s]
INFO:root:Epoch 61    loss=0.1983 [11.0 s]    dev=(HR@5:0.4441,NDCG@5:0.3276) [0.4 s] *
INFO:root:Epoch 62    loss=0.1983 [11.0 s]    dev=(HR@5:0.4456,NDCG@5:0.3288) [0.4 s] *
INFO:root:Epoch 63    loss=0.2006 [11.3 s]    dev=(HR@5:0.4459,NDCG@5:0.3290) [0.4 s] *
INFO:root:Epoch 64    loss=0.1980 [11.2 s]    dev=(HR@5:0.4398,NDCG@5:0.3236) [0.4 s]
INFO:root:Epoch 65    loss=0.1979 [11.0 s]    dev=(HR@5:0.4380,NDCG@5:0.3216) [0.4 s]
INFO:root:Epoch 66    loss=0.1972 [11.1 s]    dev=(HR@5:0.4412,NDCG@5:0.3235) [0.4 s]
INFO:root:Epoch 67    loss=0.1972 [10.9 s]    dev=(HR@5:0.4372,NDCG@5:0.3210) [0.4 s]
INFO:root:Epoch 68    loss=0.1957 [11.3 s]    dev=(HR@5:0.4421,NDCG@5:0.3248) [0.4 s]
INFO:root:Epoch 69    loss=0.1976 [11.3 s]    dev=(HR@5:0.4411,NDCG@5:0.3251) [0.4 s]
INFO:root:Epoch 70    loss=0.1971 [11.4 s]    dev=(HR@5:0.4405,NDCG@5:0.3236) [0.4 s]
INFO:root:Epoch 71    loss=0.1961 [11.3 s]    dev=(HR@5:0.4432,NDCG@5:0.3260) [0.4 s]
INFO:root:Epoch 72    loss=0.1960 [10.9 s]    dev=(HR@5:0.4411,NDCG@5:0.3244) [0.4 s]
INFO:root:Epoch 73    loss=0.1966 [10.7 s]    dev=(HR@5:0.4402,NDCG@5:0.3244) [0.4 s]
INFO:root:Epoch 74    loss=0.1962 [10.9 s]    dev=(HR@5:0.4400,NDCG@5:0.3222) [0.4 s]
INFO:root:Epoch 75    loss=0.1976 [11.2 s]    dev=(HR@5:0.4373,NDCG@5:0.3217) [0.4 s]
INFO:root:Epoch 76    loss=0.1962 [10.8 s]    dev=(HR@5:0.4397,NDCG@5:0.3232) [0.4 s]
INFO:root:Epoch 77    loss=0.1958 [11.2 s]    dev=(HR@5:0.4424,NDCG@5:0.3267) [0.4 s]
INFO:root:Epoch 78    loss=0.1955 [11.0 s]    dev=(HR@5:0.4430,NDCG@5:0.3244) [0.4 s]
INFO:root:Epoch 79    loss=0.1961 [11.1 s]    dev=(HR@5:0.4423,NDCG@5:0.3244) [0.4 s]
INFO:root:Epoch 80    loss=0.1941 [11.2 s]    dev=(HR@5:0.4400,NDCG@5:0.3227) [0.4 s]
INFO:root:Epoch 81    loss=0.1961 [11.3 s]    dev=(HR@5:0.4380,NDCG@5:0.3189) [0.4 s]
INFO:root:Epoch 82    loss=0.1957 [10.9 s]    dev=(HR@5:0.4361,NDCG@5:0.3219) [0.4 s]
INFO:root:Epoch 83    loss=0.1936 [10.9 s]    dev=(HR@5:0.4376,NDCG@5:0.3212) [0.4 s]
INFO:root:Early stop at 83 based on dev result.
INFO:root:
Best Iter(dev)=   63	 dev=(HR@5:0.4459,NDCG@5:0.3290) [957.0 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.3925,NDCG@5:0.2828,HR@10:0.5003,NDCG@10:0.3176,HR@20:0.6205,NDCG@20:0.3478,HR@50:0.8340,NDCG@50:0.3901)
INFO:root:
--------------------------------------------- END: 2024-12-22 23:38:30 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 00:09:08 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [13.3 s]    dev=(HR@5:0.2505,NDCG@5:0.1666) [0.4 s] *
INFO:root:Epoch 2     loss=0.4330 [11.6 s]    dev=(HR@5:0.3193,NDCG@5:0.2162) [0.5 s] *
INFO:root:Epoch 3     loss=0.3979 [11.5 s]    dev=(HR@5:0.3460,NDCG@5:0.2338) [0.4 s] *
INFO:root:Epoch 4     loss=0.3767 [11.3 s]    dev=(HR@5:0.3678,NDCG@5:0.2543) [0.4 s] *
INFO:root:Epoch 5     loss=0.3512 [10.9 s]    dev=(HR@5:0.3849,NDCG@5:0.2688) [0.4 s] *
INFO:root:Epoch 6     loss=0.3256 [10.4 s]    dev=(HR@5:0.3979,NDCG@5:0.2816) [0.4 s] *
INFO:root:Epoch 7     loss=0.3064 [10.7 s]    dev=(HR@5:0.4025,NDCG@5:0.2860) [0.4 s] *
INFO:root:Epoch 8     loss=0.2901 [10.5 s]    dev=(HR@5:0.4073,NDCG@5:0.2918) [0.4 s] *
INFO:root:Epoch 9     loss=0.2766 [11.2 s]    dev=(HR@5:0.4084,NDCG@5:0.2936) [0.4 s] *
INFO:root:Epoch 10    loss=0.2677 [11.3 s]    dev=(HR@5:0.4109,NDCG@5:0.2964) [0.4 s] *
INFO:root:Epoch 11    loss=0.2577 [11.1 s]    dev=(HR@5:0.4157,NDCG@5:0.2998) [0.4 s] *
INFO:root:Epoch 12    loss=0.2504 [10.3 s]    dev=(HR@5:0.4150,NDCG@5:0.3007) [0.4 s] *
INFO:root:Epoch 13    loss=0.2478 [10.4 s]    dev=(HR@5:0.4186,NDCG@5:0.3049) [0.4 s] *
INFO:root:Epoch 14    loss=0.2415 [10.6 s]    dev=(HR@5:0.4214,NDCG@5:0.3050) [0.4 s] *
INFO:root:Epoch 15    loss=0.2395 [10.3 s]    dev=(HR@5:0.4207,NDCG@5:0.3043) [0.4 s]
INFO:root:Epoch 16    loss=0.2366 [10.5 s]    dev=(HR@5:0.4211,NDCG@5:0.3062) [0.4 s] *
INFO:root:Epoch 17    loss=0.2334 [11.3 s]    dev=(HR@5:0.4184,NDCG@5:0.3029) [0.4 s]
INFO:root:Epoch 18    loss=0.2299 [11.3 s]    dev=(HR@5:0.4213,NDCG@5:0.3069) [0.4 s] *
INFO:root:Epoch 19    loss=0.2267 [11.1 s]    dev=(HR@5:0.4227,NDCG@5:0.3083) [0.4 s] *
INFO:root:Epoch 20    loss=0.2249 [11.3 s]    dev=(HR@5:0.4269,NDCG@5:0.3113) [0.4 s] *
INFO:root:Epoch 21    loss=0.2211 [11.3 s]    dev=(HR@5:0.4265,NDCG@5:0.3116) [0.4 s] *
INFO:root:Epoch 22    loss=0.2195 [11.3 s]    dev=(HR@5:0.4286,NDCG@5:0.3139) [0.4 s] *
INFO:root:Epoch 23    loss=0.2195 [11.2 s]    dev=(HR@5:0.4278,NDCG@5:0.3137) [0.4 s]
INFO:root:Epoch 24    loss=0.2183 [11.2 s]    dev=(HR@5:0.4322,NDCG@5:0.3159) [0.4 s] *
INFO:root:Epoch 25    loss=0.2157 [11.2 s]    dev=(HR@5:0.4316,NDCG@5:0.3150) [0.4 s]
INFO:root:Epoch 26    loss=0.2153 [11.3 s]    dev=(HR@5:0.4318,NDCG@5:0.3179) [0.4 s] *
INFO:root:Epoch 27    loss=0.2147 [10.1 s]    dev=(HR@5:0.4329,NDCG@5:0.3186) [0.4 s] *
INFO:root:Epoch 28    loss=0.2146 [11.2 s]    dev=(HR@5:0.4327,NDCG@5:0.3191) [0.4 s] *
INFO:root:Epoch 29    loss=0.2115 [11.0 s]    dev=(HR@5:0.4341,NDCG@5:0.3184) [0.4 s]
INFO:root:Epoch 30    loss=0.2113 [9.6 s]    dev=(HR@5:0.4323,NDCG@5:0.3178) [0.4 s]
INFO:root:Epoch 31    loss=0.2086 [10.2 s]    dev=(HR@5:0.4371,NDCG@5:0.3214) [0.3 s] *
INFO:root:Epoch 32    loss=0.2095 [11.2 s]    dev=(HR@5:0.4296,NDCG@5:0.3154) [0.4 s]
INFO:root:Epoch 33    loss=0.2086 [10.7 s]    dev=(HR@5:0.4351,NDCG@5:0.3195) [0.4 s]
INFO:root:Epoch 34    loss=0.2077 [11.3 s]    dev=(HR@5:0.4364,NDCG@5:0.3204) [0.4 s]
INFO:root:Epoch 35    loss=0.2082 [10.2 s]    dev=(HR@5:0.4348,NDCG@5:0.3177) [0.4 s]
INFO:root:Epoch 36    loss=0.2059 [11.3 s]    dev=(HR@5:0.4389,NDCG@5:0.3201) [0.4 s]
INFO:root:Epoch 37    loss=0.2064 [10.5 s]    dev=(HR@5:0.4366,NDCG@5:0.3200) [0.4 s]
INFO:root:Epoch 38    loss=0.2052 [10.5 s]    dev=(HR@5:0.4369,NDCG@5:0.3205) [0.4 s]
INFO:root:Epoch 39    loss=0.2062 [11.1 s]    dev=(HR@5:0.4344,NDCG@5:0.3160) [0.4 s]
INFO:root:Epoch 40    loss=0.2045 [11.3 s]    dev=(HR@5:0.4351,NDCG@5:0.3177) [0.4 s]
INFO:root:Epoch 41    loss=0.2053 [11.3 s]    dev=(HR@5:0.4361,NDCG@5:0.3191) [0.4 s]
INFO:root:Epoch 42    loss=0.2056 [11.3 s]    dev=(HR@5:0.4373,NDCG@5:0.3189) [0.4 s]
INFO:root:Epoch 43    loss=0.2029 [11.3 s]    dev=(HR@5:0.4378,NDCG@5:0.3224) [0.4 s] *
INFO:root:Epoch 44    loss=0.2038 [10.6 s]    dev=(HR@5:0.4351,NDCG@5:0.3180) [0.4 s]
INFO:root:Epoch 45    loss=0.2009 [11.2 s]    dev=(HR@5:0.4412,NDCG@5:0.3255) [0.4 s] *
INFO:root:Epoch 46    loss=0.2019 [11.2 s]    dev=(HR@5:0.4357,NDCG@5:0.3186) [0.4 s]
INFO:root:Epoch 47    loss=0.2022 [11.1 s]    dev=(HR@5:0.4367,NDCG@5:0.3186) [0.4 s]
INFO:root:Epoch 48    loss=0.2007 [11.3 s]    dev=(HR@5:0.4319,NDCG@5:0.3156) [0.4 s]
INFO:root:Epoch 49    loss=0.1997 [11.3 s]    dev=(HR@5:0.4417,NDCG@5:0.3222) [0.4 s]
INFO:root:Epoch 50    loss=0.2014 [11.3 s]    dev=(HR@5:0.4363,NDCG@5:0.3209) [0.4 s]
INFO:root:Epoch 51    loss=0.1993 [11.3 s]    dev=(HR@5:0.4379,NDCG@5:0.3197) [0.4 s]
INFO:root:Epoch 52    loss=0.2003 [11.3 s]    dev=(HR@5:0.4375,NDCG@5:0.3193) [0.4 s]
INFO:root:Epoch 53    loss=0.2001 [11.4 s]    dev=(HR@5:0.4383,NDCG@5:0.3214) [0.4 s]
INFO:root:Epoch 54    loss=0.1972 [10.1 s]    dev=(HR@5:0.4420,NDCG@5:0.3254) [0.4 s]
INFO:root:Epoch 55    loss=0.1975 [11.2 s]    dev=(HR@5:0.4417,NDCG@5:0.3230) [0.4 s]
INFO:root:Epoch 56    loss=0.1976 [11.6 s]    dev=(HR@5:0.4411,NDCG@5:0.3253) [0.4 s]
INFO:root:Epoch 57    loss=0.1978 [11.2 s]    dev=(HR@5:0.4387,NDCG@5:0.3236) [0.4 s]
INFO:root:Epoch 58    loss=0.1986 [11.3 s]    dev=(HR@5:0.4390,NDCG@5:0.3234) [0.4 s]
INFO:root:Epoch 59    loss=0.1975 [11.5 s]    dev=(HR@5:0.4396,NDCG@5:0.3234) [0.4 s]
INFO:root:Epoch 60    loss=0.1972 [11.1 s]    dev=(HR@5:0.4368,NDCG@5:0.3230) [0.4 s]
INFO:root:Epoch 61    loss=0.1968 [11.3 s]    dev=(HR@5:0.4417,NDCG@5:0.3251) [0.4 s]
INFO:root:Epoch 62    loss=0.1962 [10.9 s]    dev=(HR@5:0.4437,NDCG@5:0.3254) [0.4 s]
INFO:root:Epoch 63    loss=0.1968 [11.3 s]    dev=(HR@5:0.4418,NDCG@5:0.3245) [0.4 s]
INFO:root:Epoch 64    loss=0.1954 [11.5 s]    dev=(HR@5:0.4399,NDCG@5:0.3215) [0.4 s]
INFO:root:Epoch 65    loss=0.1964 [11.2 s]    dev=(HR@5:0.4372,NDCG@5:0.3209) [0.4 s]
INFO:root:Early stop at 65 based on dev result.
INFO:root:
Best Iter(dev)=   45	 dev=(HR@5:0.4412,NDCG@5:0.3255) [744.0 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.3975,NDCG@5:0.2832,HR@10:0.5013,NDCG@10:0.3167,HR@20:0.6216,NDCG@20:0.3470,HR@50:0.8266,NDCG@50:0.3876)
INFO:root:
--------------------------------------------- END: 2024-12-23 00:21:35 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 00:57:44 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [12.1 s]    dev=(HR@5:0.2525,NDCG@5:0.1680) [0.4 s] *
INFO:root:Epoch 2     loss=0.4304 [11.4 s]    dev=(HR@5:0.3234,NDCG@5:0.2200) [0.4 s] *
INFO:root:Epoch 3     loss=0.3932 [11.0 s]    dev=(HR@5:0.3539,NDCG@5:0.2408) [0.4 s] *
INFO:root:Epoch 4     loss=0.3709 [11.3 s]    dev=(HR@5:0.3700,NDCG@5:0.2553) [0.4 s] *
INFO:root:Epoch 5     loss=0.3475 [11.1 s]    dev=(HR@5:0.3855,NDCG@5:0.2682) [0.4 s] *
INFO:root:Epoch 6     loss=0.3237 [11.8 s]    dev=(HR@5:0.4005,NDCG@5:0.2822) [0.4 s] *
INFO:root:Epoch 7     loss=0.3047 [11.2 s]    dev=(HR@5:0.4054,NDCG@5:0.2877) [0.4 s] *
INFO:root:Epoch 8     loss=0.2894 [11.0 s]    dev=(HR@5:0.4115,NDCG@5:0.2945) [0.4 s] *
INFO:root:Epoch 9     loss=0.2755 [11.3 s]    dev=(HR@5:0.4144,NDCG@5:0.2960) [0.4 s] *
INFO:root:Epoch 10    loss=0.2678 [11.1 s]    dev=(HR@5:0.4165,NDCG@5:0.2993) [0.4 s] *
INFO:root:Epoch 11    loss=0.2584 [10.9 s]    dev=(HR@5:0.4225,NDCG@5:0.3030) [0.4 s] *
INFO:root:Epoch 12    loss=0.2517 [11.4 s]    dev=(HR@5:0.4224,NDCG@5:0.3041) [0.4 s] *
INFO:root:Epoch 13    loss=0.2489 [11.1 s]    dev=(HR@5:0.4278,NDCG@5:0.3098) [0.4 s] *
INFO:root:Epoch 14    loss=0.2433 [11.1 s]    dev=(HR@5:0.4301,NDCG@5:0.3099) [0.4 s] *
INFO:root:Epoch 15    loss=0.2413 [10.8 s]    dev=(HR@5:0.4245,NDCG@5:0.3077) [0.4 s]
INFO:root:Epoch 16    loss=0.2390 [11.2 s]    dev=(HR@5:0.4277,NDCG@5:0.3106) [0.4 s] *
INFO:root:Epoch 17    loss=0.2358 [11.0 s]    dev=(HR@5:0.4264,NDCG@5:0.3076) [0.4 s]
INFO:root:Epoch 18    loss=0.2313 [11.0 s]    dev=(HR@5:0.4314,NDCG@5:0.3133) [0.4 s] *
INFO:root:Epoch 19    loss=0.2304 [11.2 s]    dev=(HR@5:0.4305,NDCG@5:0.3139) [0.4 s] *
INFO:root:Epoch 20    loss=0.2277 [11.2 s]    dev=(HR@5:0.4326,NDCG@5:0.3159) [0.4 s] *
INFO:root:Epoch 21    loss=0.2246 [10.8 s]    dev=(HR@5:0.4327,NDCG@5:0.3144) [0.4 s]
INFO:root:Epoch 22    loss=0.2232 [10.9 s]    dev=(HR@5:0.4353,NDCG@5:0.3171) [0.4 s] *
INFO:root:Epoch 23    loss=0.2246 [10.8 s]    dev=(HR@5:0.4331,NDCG@5:0.3172) [0.4 s] *
INFO:root:Epoch 24    loss=0.2231 [11.0 s]    dev=(HR@5:0.4391,NDCG@5:0.3184) [0.4 s] *
INFO:root:Epoch 25    loss=0.2199 [10.9 s]    dev=(HR@5:0.4356,NDCG@5:0.3183) [0.4 s]
INFO:root:Epoch 26    loss=0.2204 [11.1 s]    dev=(HR@5:0.4406,NDCG@5:0.3202) [0.4 s] *
INFO:root:Epoch 27    loss=0.2199 [11.0 s]    dev=(HR@5:0.4404,NDCG@5:0.3208) [0.4 s] *
INFO:root:Epoch 28    loss=0.2202 [11.4 s]    dev=(HR@5:0.4434,NDCG@5:0.3221) [0.4 s] *
INFO:root:Epoch 29    loss=0.2174 [10.9 s]    dev=(HR@5:0.4339,NDCG@5:0.3169) [0.4 s]
INFO:root:Epoch 30    loss=0.2173 [11.3 s]    dev=(HR@5:0.4353,NDCG@5:0.3171) [0.4 s]
INFO:root:Epoch 31    loss=0.2164 [11.0 s]    dev=(HR@5:0.4416,NDCG@5:0.3228) [0.4 s] *
INFO:root:Epoch 32    loss=0.2162 [10.8 s]    dev=(HR@5:0.4406,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 33    loss=0.2161 [10.7 s]    dev=(HR@5:0.4386,NDCG@5:0.3201) [0.4 s]
INFO:root:Epoch 34    loss=0.2150 [10.7 s]    dev=(HR@5:0.4369,NDCG@5:0.3180) [0.4 s]
INFO:root:Epoch 35    loss=0.2151 [11.1 s]    dev=(HR@5:0.4353,NDCG@5:0.3163) [0.4 s]
INFO:root:Epoch 36    loss=0.2125 [10.0 s]    dev=(HR@5:0.4383,NDCG@5:0.3182) [0.4 s]
INFO:root:Epoch 37    loss=0.2132 [11.0 s]    dev=(HR@5:0.4380,NDCG@5:0.3184) [0.4 s]
INFO:root:Epoch 38    loss=0.2132 [11.0 s]    dev=(HR@5:0.4356,NDCG@5:0.3161) [0.4 s]
INFO:root:Epoch 39    loss=0.2134 [11.0 s]    dev=(HR@5:0.4368,NDCG@5:0.3163) [0.4 s]
INFO:root:Epoch 40    loss=0.2125 [11.2 s]    dev=(HR@5:0.4351,NDCG@5:0.3162) [0.4 s]
INFO:root:Epoch 41    loss=0.2126 [11.0 s]    dev=(HR@5:0.4313,NDCG@5:0.3116) [0.4 s]
INFO:root:Epoch 42    loss=0.2124 [11.0 s]    dev=(HR@5:0.4408,NDCG@5:0.3195) [0.4 s]
INFO:root:Epoch 43    loss=0.2108 [11.3 s]    dev=(HR@5:0.4402,NDCG@5:0.3201) [0.4 s]
INFO:root:Epoch 44    loss=0.2114 [11.0 s]    dev=(HR@5:0.4382,NDCG@5:0.3165) [0.4 s]
INFO:root:Epoch 45    loss=0.2081 [10.4 s]    dev=(HR@5:0.4395,NDCG@5:0.3193) [0.4 s]
INFO:root:Epoch 46    loss=0.2095 [10.3 s]    dev=(HR@5:0.4398,NDCG@5:0.3189) [0.4 s]
INFO:root:Epoch 47    loss=0.2094 [10.8 s]    dev=(HR@5:0.4393,NDCG@5:0.3193) [0.4 s]
INFO:root:Epoch 48    loss=0.2093 [10.1 s]    dev=(HR@5:0.4354,NDCG@5:0.3155) [0.3 s]
INFO:root:Epoch 49    loss=0.2077 [10.3 s]    dev=(HR@5:0.4419,NDCG@5:0.3213) [0.3 s]
INFO:root:Epoch 50    loss=0.2092 [11.0 s]    dev=(HR@5:0.4364,NDCG@5:0.3194) [0.4 s]
INFO:root:Epoch 51    loss=0.2088 [11.1 s]    dev=(HR@5:0.4403,NDCG@5:0.3205) [0.4 s]
INFO:root:Early stop at 51 based on dev result.
INFO:root:
Best Iter(dev)=   31	 dev=(HR@5:0.4416,NDCG@5:0.3228) [580.8 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.3965,NDCG@5:0.2797,HR@10:0.5062,NDCG@10:0.3153,HR@20:0.6309,NDCG@20:0.3467,HR@50:0.8386,NDCG@50:0.3879)
INFO:root:
--------------------------------------------- END: 2024-12-23 01:07:28 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 01:26:13 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5164 [12.4 s]    dev=(HR@5:0.2540,NDCG@5:0.1694) [0.4 s] *
INFO:root:Epoch 2     loss=0.4293 [11.2 s]    dev=(HR@5:0.3253,NDCG@5:0.2217) [0.4 s] *
INFO:root:Epoch 3     loss=0.3933 [11.1 s]    dev=(HR@5:0.3526,NDCG@5:0.2408) [0.4 s] *
INFO:root:Epoch 4     loss=0.3722 [11.1 s]    dev=(HR@5:0.3691,NDCG@5:0.2552) [0.4 s] *
INFO:root:Epoch 5     loss=0.3471 [11.1 s]    dev=(HR@5:0.3896,NDCG@5:0.2718) [0.4 s] *
INFO:root:Epoch 6     loss=0.3218 [11.1 s]    dev=(HR@5:0.4037,NDCG@5:0.2856) [0.4 s] *
INFO:root:Epoch 7     loss=0.3029 [11.1 s]    dev=(HR@5:0.4135,NDCG@5:0.2929) [0.4 s] *
INFO:root:Epoch 8     loss=0.2877 [11.1 s]    dev=(HR@5:0.4171,NDCG@5:0.2993) [0.4 s] *
INFO:root:Epoch 9     loss=0.2736 [11.1 s]    dev=(HR@5:0.4200,NDCG@5:0.3027) [0.4 s] *
INFO:root:Epoch 10    loss=0.2652 [11.4 s]    dev=(HR@5:0.4234,NDCG@5:0.3054) [0.4 s] *
INFO:root:Epoch 11    loss=0.2562 [10.9 s]    dev=(HR@5:0.4274,NDCG@5:0.3081) [0.4 s] *
INFO:root:Epoch 12    loss=0.2493 [11.3 s]    dev=(HR@5:0.4278,NDCG@5:0.3098) [0.4 s] *
INFO:root:Epoch 13    loss=0.2465 [10.6 s]    dev=(HR@5:0.4338,NDCG@5:0.3149) [0.4 s] *
INFO:root:Epoch 14    loss=0.2411 [10.2 s]    dev=(HR@5:0.4333,NDCG@5:0.3143) [0.4 s]
INFO:root:Epoch 15    loss=0.2390 [10.7 s]    dev=(HR@5:0.4347,NDCG@5:0.3137) [0.4 s]
INFO:root:Epoch 16    loss=0.2371 [10.7 s]    dev=(HR@5:0.4330,NDCG@5:0.3151) [0.4 s] *
INFO:root:Epoch 17    loss=0.2344 [10.4 s]    dev=(HR@5:0.4299,NDCG@5:0.3117) [0.4 s]
INFO:root:Epoch 18    loss=0.2299 [11.0 s]    dev=(HR@5:0.4359,NDCG@5:0.3170) [0.4 s] *
INFO:root:Epoch 19    loss=0.2293 [11.0 s]    dev=(HR@5:0.4342,NDCG@5:0.3172) [0.4 s] *
INFO:root:Epoch 20    loss=0.2264 [10.4 s]    dev=(HR@5:0.4385,NDCG@5:0.3189) [0.4 s] *
INFO:root:Epoch 21    loss=0.2236 [10.4 s]    dev=(HR@5:0.4380,NDCG@5:0.3183) [0.4 s]
INFO:root:Epoch 22    loss=0.2226 [10.4 s]    dev=(HR@5:0.4388,NDCG@5:0.3196) [0.4 s] *
INFO:root:Epoch 23    loss=0.2239 [10.5 s]    dev=(HR@5:0.4352,NDCG@5:0.3201) [0.4 s] *
INFO:root:Epoch 24    loss=0.2227 [10.8 s]    dev=(HR@5:0.4412,NDCG@5:0.3202) [0.4 s] *
INFO:root:Epoch 25    loss=0.2197 [10.8 s]    dev=(HR@5:0.4408,NDCG@5:0.3215) [0.4 s] *
INFO:root:Epoch 26    loss=0.2202 [10.4 s]    dev=(HR@5:0.4427,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 27    loss=0.2200 [10.4 s]    dev=(HR@5:0.4430,NDCG@5:0.3228) [0.4 s] *
INFO:root:Epoch 28    loss=0.2199 [10.5 s]    dev=(HR@5:0.4442,NDCG@5:0.3247) [0.4 s] *
INFO:root:Epoch 29    loss=0.2175 [10.5 s]    dev=(HR@5:0.4406,NDCG@5:0.3202) [0.3 s]
INFO:root:Epoch 30    loss=0.2171 [10.9 s]    dev=(HR@5:0.4372,NDCG@5:0.3201) [0.4 s]
INFO:root:Epoch 31    loss=0.2168 [11.1 s]    dev=(HR@5:0.4455,NDCG@5:0.3260) [0.4 s] *
INFO:root:Epoch 32    loss=0.2169 [11.0 s]    dev=(HR@5:0.4429,NDCG@5:0.3225) [0.4 s]
INFO:root:Epoch 33    loss=0.2168 [11.1 s]    dev=(HR@5:0.4415,NDCG@5:0.3231) [0.4 s]
INFO:root:Epoch 34    loss=0.2162 [11.1 s]    dev=(HR@5:0.4406,NDCG@5:0.3219) [0.4 s]
INFO:root:Epoch 35    loss=0.2163 [10.5 s]    dev=(HR@5:0.4406,NDCG@5:0.3190) [0.4 s]
INFO:root:Epoch 36    loss=0.2137 [11.0 s]    dev=(HR@5:0.4374,NDCG@5:0.3192) [0.4 s]
INFO:root:Epoch 37    loss=0.2143 [10.9 s]    dev=(HR@5:0.4406,NDCG@5:0.3199) [0.4 s]
INFO:root:Epoch 38    loss=0.2151 [11.0 s]    dev=(HR@5:0.4393,NDCG@5:0.3202) [0.4 s]
INFO:root:Epoch 39    loss=0.2148 [10.7 s]    dev=(HR@5:0.4378,NDCG@5:0.3180) [0.4 s]
INFO:root:Epoch 40    loss=0.2146 [11.3 s]    dev=(HR@5:0.4336,NDCG@5:0.3166) [0.4 s]
INFO:root:Epoch 41    loss=0.2147 [10.9 s]    dev=(HR@5:0.4353,NDCG@5:0.3164) [0.4 s]
INFO:root:Epoch 42    loss=0.2144 [11.3 s]    dev=(HR@5:0.4436,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 43    loss=0.2128 [11.1 s]    dev=(HR@5:0.4442,NDCG@5:0.3218) [0.4 s]
INFO:root:Epoch 44    loss=0.2128 [11.3 s]    dev=(HR@5:0.4392,NDCG@5:0.3189) [0.4 s]
INFO:root:Epoch 45    loss=0.2096 [11.4 s]    dev=(HR@5:0.4398,NDCG@5:0.3206) [0.4 s]
INFO:root:Epoch 46    loss=0.2109 [11.0 s]    dev=(HR@5:0.4433,NDCG@5:0.3211) [0.4 s]
INFO:root:Epoch 47    loss=0.2103 [11.2 s]    dev=(HR@5:0.4412,NDCG@5:0.3198) [0.4 s]
INFO:root:Epoch 48    loss=0.2100 [11.3 s]    dev=(HR@5:0.4381,NDCG@5:0.3178) [0.4 s]
INFO:root:Epoch 49    loss=0.2091 [11.2 s]    dev=(HR@5:0.4433,NDCG@5:0.3220) [0.4 s]
INFO:root:Epoch 50    loss=0.2104 [10.8 s]    dev=(HR@5:0.4403,NDCG@5:0.3220) [0.4 s]
INFO:root:Epoch 51    loss=0.2091 [10.3 s]    dev=(HR@5:0.4415,NDCG@5:0.3230) [0.4 s]
INFO:root:Early stop at 51 based on dev result.
INFO:root:
Best Iter(dev)=   31	 dev=(HR@5:0.4455,NDCG@5:0.3260) [577.0 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.4007,NDCG@5:0.2829,HR@10:0.5086,NDCG@10:0.3179,HR@20:0.6330,NDCG@20:0.3492,HR@50:0.8435,NDCG@50:0.3910)
INFO:root:
--------------------------------------------- END: 2024-12-23 01:35:53 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 01:55:08 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5165 [11.2 s]    dev=(HR@5:0.2533,NDCG@5:0.1689) [0.4 s] *
INFO:root:Epoch 2     loss=0.4298 [10.8 s]    dev=(HR@5:0.3242,NDCG@5:0.2209) [0.4 s] *
INFO:root:Epoch 3     loss=0.3942 [12.0 s]    dev=(HR@5:0.3486,NDCG@5:0.2380) [0.4 s] *
INFO:root:Epoch 4     loss=0.3735 [11.0 s]    dev=(HR@5:0.3682,NDCG@5:0.2557) [0.4 s] *
INFO:root:Epoch 5     loss=0.3482 [11.6 s]    dev=(HR@5:0.3892,NDCG@5:0.2719) [0.4 s] *
INFO:root:Epoch 6     loss=0.3226 [11.6 s]    dev=(HR@5:0.4064,NDCG@5:0.2867) [0.4 s] *
INFO:root:Epoch 7     loss=0.3040 [11.8 s]    dev=(HR@5:0.4124,NDCG@5:0.2920) [0.4 s] *
INFO:root:Epoch 8     loss=0.2896 [11.6 s]    dev=(HR@5:0.4167,NDCG@5:0.2991) [0.4 s] *
INFO:root:Epoch 9     loss=0.2758 [11.8 s]    dev=(HR@5:0.4205,NDCG@5:0.3024) [0.4 s] *
INFO:root:Epoch 10    loss=0.2673 [11.8 s]    dev=(HR@5:0.4231,NDCG@5:0.3053) [0.4 s] *
INFO:root:Epoch 11    loss=0.2580 [11.7 s]    dev=(HR@5:0.4274,NDCG@5:0.3086) [0.4 s] *
INFO:root:Epoch 12    loss=0.2508 [11.7 s]    dev=(HR@5:0.4291,NDCG@5:0.3105) [0.4 s] *
INFO:root:Epoch 13    loss=0.2474 [11.7 s]    dev=(HR@5:0.4353,NDCG@5:0.3157) [0.4 s] *
INFO:root:Epoch 14    loss=0.2423 [11.2 s]    dev=(HR@5:0.4336,NDCG@5:0.3138) [0.4 s]
INFO:root:Epoch 15    loss=0.2396 [11.3 s]    dev=(HR@5:0.4325,NDCG@5:0.3128) [0.4 s]
INFO:root:Epoch 16    loss=0.2378 [11.4 s]    dev=(HR@5:0.4325,NDCG@5:0.3156) [0.4 s]
INFO:root:Epoch 17    loss=0.2349 [11.6 s]    dev=(HR@5:0.4297,NDCG@5:0.3122) [0.4 s]
INFO:root:Epoch 18    loss=0.2305 [11.8 s]    dev=(HR@5:0.4360,NDCG@5:0.3178) [0.4 s] *
INFO:root:Epoch 19    loss=0.2298 [11.8 s]    dev=(HR@5:0.4350,NDCG@5:0.3177) [0.4 s]
INFO:root:Epoch 20    loss=0.2269 [11.8 s]    dev=(HR@5:0.4391,NDCG@5:0.3196) [0.4 s] *
INFO:root:Epoch 21    loss=0.2239 [11.6 s]    dev=(HR@5:0.4378,NDCG@5:0.3186) [0.4 s]
INFO:root:Epoch 22    loss=0.2232 [11.6 s]    dev=(HR@5:0.4390,NDCG@5:0.3202) [0.4 s] *
INFO:root:Epoch 23    loss=0.2240 [10.2 s]    dev=(HR@5:0.4356,NDCG@5:0.3192) [0.4 s]
INFO:root:Epoch 24    loss=0.2234 [10.4 s]    dev=(HR@5:0.4409,NDCG@5:0.3206) [0.4 s] *
INFO:root:Epoch 25    loss=0.2200 [11.6 s]    dev=(HR@5:0.4410,NDCG@5:0.3218) [0.4 s] *
INFO:root:Epoch 26    loss=0.2203 [11.8 s]    dev=(HR@5:0.4408,NDCG@5:0.3207) [0.4 s]
INFO:root:Epoch 27    loss=0.2205 [10.2 s]    dev=(HR@5:0.4438,NDCG@5:0.3236) [0.4 s] *
INFO:root:Epoch 28    loss=0.2200 [10.2 s]    dev=(HR@5:0.4452,NDCG@5:0.3257) [0.4 s] *
INFO:root:Epoch 29    loss=0.2175 [10.8 s]    dev=(HR@5:0.4391,NDCG@5:0.3210) [0.4 s]
INFO:root:Epoch 30    loss=0.2174 [10.0 s]    dev=(HR@5:0.4404,NDCG@5:0.3224) [0.4 s]
INFO:root:Epoch 31    loss=0.2168 [10.2 s]    dev=(HR@5:0.4444,NDCG@5:0.3260) [0.4 s] *
INFO:root:Epoch 32    loss=0.2169 [11.2 s]    dev=(HR@5:0.4400,NDCG@5:0.3209) [0.4 s]
INFO:root:Epoch 33    loss=0.2167 [11.8 s]    dev=(HR@5:0.4397,NDCG@5:0.3227) [0.4 s]
INFO:root:Epoch 34    loss=0.2162 [11.4 s]    dev=(HR@5:0.4412,NDCG@5:0.3226) [0.4 s]
INFO:root:Epoch 35    loss=0.2161 [11.5 s]    dev=(HR@5:0.4411,NDCG@5:0.3206) [0.4 s]
INFO:root:Epoch 36    loss=0.2133 [11.9 s]    dev=(HR@5:0.4406,NDCG@5:0.3206) [0.4 s]
INFO:root:Epoch 37    loss=0.2141 [11.8 s]    dev=(HR@5:0.4410,NDCG@5:0.3192) [0.4 s]
INFO:root:Epoch 38    loss=0.2150 [11.9 s]    dev=(HR@5:0.4398,NDCG@5:0.3207) [0.4 s]
INFO:root:Epoch 39    loss=0.2146 [12.0 s]    dev=(HR@5:0.4380,NDCG@5:0.3187) [0.4 s]
INFO:root:Epoch 40    loss=0.2140 [11.8 s]    dev=(HR@5:0.4338,NDCG@5:0.3171) [0.4 s]
INFO:root:Epoch 41    loss=0.2145 [11.9 s]    dev=(HR@5:0.4357,NDCG@5:0.3166) [0.4 s]
INFO:root:Epoch 42    loss=0.2139 [11.2 s]    dev=(HR@5:0.4421,NDCG@5:0.3215) [0.4 s]
INFO:root:Epoch 43    loss=0.2120 [10.0 s]    dev=(HR@5:0.4424,NDCG@5:0.3211) [0.4 s]
INFO:root:Epoch 44    loss=0.2123 [9.6 s]    dev=(HR@5:0.4400,NDCG@5:0.3183) [0.4 s]
INFO:root:Epoch 45    loss=0.2089 [10.3 s]    dev=(HR@5:0.4398,NDCG@5:0.3211) [0.4 s]
INFO:root:Epoch 46    loss=0.2101 [11.9 s]    dev=(HR@5:0.4389,NDCG@5:0.3195) [0.4 s]
INFO:root:Epoch 47    loss=0.2094 [11.1 s]    dev=(HR@5:0.4393,NDCG@5:0.3181) [0.4 s]
INFO:root:Epoch 48    loss=0.2093 [11.8 s]    dev=(HR@5:0.4348,NDCG@5:0.3159) [0.4 s]
INFO:root:Epoch 49    loss=0.2080 [11.0 s]    dev=(HR@5:0.4414,NDCG@5:0.3216) [0.4 s]
INFO:root:Epoch 50    loss=0.2097 [10.6 s]    dev=(HR@5:0.4378,NDCG@5:0.3207) [0.4 s]
INFO:root:Epoch 51    loss=0.2083 [10.7 s]    dev=(HR@5:0.4430,NDCG@5:0.3224) [0.4 s]
INFO:root:Early stop at 51 based on dev result.
INFO:root:
Best Iter(dev)=   31	 dev=(HR@5:0.4444,NDCG@5:0.3260) [594.9 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.3977,NDCG@5:0.2817,HR@10:0.5071,NDCG@10:0.3171,HR@20:0.6279,NDCG@20:0.3475,HR@50:0.8409,NDCG@50:0.3898)
INFO:root:
--------------------------------------------- END: 2024-12-23 02:05:06 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 02:25:30 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.3                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5166 [12.1 s]    dev=(HR@5:0.2528,NDCG@5:0.1683) [0.4 s] *
INFO:root:Epoch 2     loss=0.4305 [11.3 s]    dev=(HR@5:0.3235,NDCG@5:0.2193) [0.4 s] *
INFO:root:Epoch 3     loss=0.3952 [11.2 s]    dev=(HR@5:0.3459,NDCG@5:0.2354) [0.4 s] *
INFO:root:Epoch 4     loss=0.3744 [11.1 s]    dev=(HR@5:0.3671,NDCG@5:0.2544) [0.4 s] *
INFO:root:Epoch 5     loss=0.3484 [11.3 s]    dev=(HR@5:0.3908,NDCG@5:0.2729) [0.4 s] *
INFO:root:Epoch 6     loss=0.3207 [11.2 s]    dev=(HR@5:0.4113,NDCG@5:0.2938) [0.4 s] *
INFO:root:Epoch 7     loss=0.2995 [11.0 s]    dev=(HR@5:0.4189,NDCG@5:0.3008) [0.4 s] *
INFO:root:Epoch 8     loss=0.2836 [11.0 s]    dev=(HR@5:0.4259,NDCG@5:0.3067) [0.4 s] *
INFO:root:Epoch 9     loss=0.2695 [11.0 s]    dev=(HR@5:0.4295,NDCG@5:0.3112) [0.4 s] *
INFO:root:Epoch 10    loss=0.2607 [11.1 s]    dev=(HR@5:0.4316,NDCG@5:0.3132) [0.4 s] *
INFO:root:Epoch 11    loss=0.2512 [10.8 s]    dev=(HR@5:0.4323,NDCG@5:0.3138) [0.4 s] *
INFO:root:Epoch 12    loss=0.2439 [11.1 s]    dev=(HR@5:0.4358,NDCG@5:0.3174) [0.4 s] *
INFO:root:Epoch 13    loss=0.2408 [10.8 s]    dev=(HR@5:0.4410,NDCG@5:0.3219) [0.4 s] *
INFO:root:Epoch 14    loss=0.2360 [11.0 s]    dev=(HR@5:0.4405,NDCG@5:0.3205) [0.4 s]
INFO:root:Epoch 15    loss=0.2331 [11.2 s]    dev=(HR@5:0.4357,NDCG@5:0.3167) [0.4 s]
INFO:root:Epoch 16    loss=0.2311 [10.9 s]    dev=(HR@5:0.4377,NDCG@5:0.3210) [0.4 s]
INFO:root:Epoch 17    loss=0.2278 [11.4 s]    dev=(HR@5:0.4316,NDCG@5:0.3164) [0.4 s]
INFO:root:Epoch 18    loss=0.2236 [11.1 s]    dev=(HR@5:0.4409,NDCG@5:0.3226) [0.4 s] *
INFO:root:Epoch 19    loss=0.2227 [11.0 s]    dev=(HR@5:0.4364,NDCG@5:0.3203) [0.4 s]
INFO:root:Epoch 20    loss=0.2200 [10.9 s]    dev=(HR@5:0.4416,NDCG@5:0.3228) [0.4 s] *
INFO:root:Epoch 21    loss=0.2167 [11.3 s]    dev=(HR@5:0.4393,NDCG@5:0.3228) [0.4 s]
INFO:root:Epoch 22    loss=0.2164 [11.0 s]    dev=(HR@5:0.4401,NDCG@5:0.3236) [0.4 s] *
INFO:root:Epoch 23    loss=0.2165 [11.4 s]    dev=(HR@5:0.4389,NDCG@5:0.3227) [0.4 s]
INFO:root:Epoch 24    loss=0.2161 [11.3 s]    dev=(HR@5:0.4417,NDCG@5:0.3231) [0.4 s]
INFO:root:Epoch 25    loss=0.2137 [11.1 s]    dev=(HR@5:0.4387,NDCG@5:0.3224) [0.4 s]
INFO:root:Epoch 26    loss=0.2131 [11.0 s]    dev=(HR@5:0.4420,NDCG@5:0.3242) [0.4 s] *
INFO:root:Epoch 27    loss=0.2138 [10.8 s]    dev=(HR@5:0.4444,NDCG@5:0.3264) [0.4 s] *
INFO:root:Epoch 28    loss=0.2125 [10.7 s]    dev=(HR@5:0.4447,NDCG@5:0.3273) [0.4 s] *
INFO:root:Epoch 29    loss=0.2100 [10.7 s]    dev=(HR@5:0.4406,NDCG@5:0.3238) [0.3 s]
INFO:root:Epoch 30    loss=0.2101 [10.5 s]    dev=(HR@5:0.4422,NDCG@5:0.3259) [0.4 s]
INFO:root:Epoch 31    loss=0.2090 [10.8 s]    dev=(HR@5:0.4421,NDCG@5:0.3267) [0.4 s]
INFO:root:Epoch 32    loss=0.2092 [11.1 s]    dev=(HR@5:0.4424,NDCG@5:0.3259) [0.4 s]
INFO:root:Epoch 33    loss=0.2084 [11.2 s]    dev=(HR@5:0.4420,NDCG@5:0.3257) [0.4 s]
INFO:root:Epoch 34    loss=0.2074 [11.1 s]    dev=(HR@5:0.4419,NDCG@5:0.3258) [0.4 s]
INFO:root:Epoch 35    loss=0.2071 [11.0 s]    dev=(HR@5:0.4395,NDCG@5:0.3226) [0.4 s]
INFO:root:Epoch 36    loss=0.2041 [11.1 s]    dev=(HR@5:0.4401,NDCG@5:0.3245) [0.4 s]
INFO:root:Epoch 37    loss=0.2056 [11.0 s]    dev=(HR@5:0.4415,NDCG@5:0.3246) [0.4 s]
INFO:root:Epoch 38    loss=0.2050 [11.0 s]    dev=(HR@5:0.4413,NDCG@5:0.3251) [0.4 s]
INFO:root:Epoch 39    loss=0.2044 [11.2 s]    dev=(HR@5:0.4423,NDCG@5:0.3227) [0.4 s]
INFO:root:Epoch 40    loss=0.2037 [11.1 s]    dev=(HR@5:0.4392,NDCG@5:0.3214) [0.4 s]
INFO:root:Epoch 41    loss=0.2040 [10.9 s]    dev=(HR@5:0.4353,NDCG@5:0.3193) [0.4 s]
INFO:root:Epoch 42    loss=0.2037 [10.8 s]    dev=(HR@5:0.4435,NDCG@5:0.3247) [0.4 s]
INFO:root:Epoch 43    loss=0.2019 [10.7 s]    dev=(HR@5:0.4456,NDCG@5:0.3266) [0.4 s]
INFO:root:Epoch 44    loss=0.2027 [11.2 s]    dev=(HR@5:0.4378,NDCG@5:0.3204) [0.4 s]
INFO:root:Epoch 45    loss=0.1996 [11.0 s]    dev=(HR@5:0.4434,NDCG@5:0.3252) [0.4 s]
INFO:root:Epoch 46    loss=0.2015 [11.3 s]    dev=(HR@5:0.4425,NDCG@5:0.3244) [0.4 s]
INFO:root:Epoch 47    loss=0.2004 [11.0 s]    dev=(HR@5:0.4425,NDCG@5:0.3245) [0.4 s]
INFO:root:Epoch 48    loss=0.2000 [11.1 s]    dev=(HR@5:0.4410,NDCG@5:0.3222) [0.4 s]
INFO:root:Early stop at 48 based on dev result.
INFO:root:
Best Iter(dev)=   28	 dev=(HR@5:0.4447,NDCG@5:0.3273) [549.2 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.3975,NDCG@5:0.2844,HR@10:0.5073,NDCG@10:0.3199,HR@20:0.6312,NDCG@20:0.3512,HR@50:0.8360,NDCG@50:0.3916)
INFO:root:
--------------------------------------------- END: 2024-12-23 02:34:42 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 02:54:31 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5159 [12.3 s]    dev=(HR@5:0.2508,NDCG@5:0.1669) [0.4 s] *
INFO:root:Epoch 2     loss=0.4328 [11.0 s]    dev=(HR@5:0.3184,NDCG@5:0.2150) [0.4 s] *
INFO:root:Epoch 3     loss=0.3979 [11.4 s]    dev=(HR@5:0.3431,NDCG@5:0.2301) [0.4 s] *
INFO:root:Epoch 4     loss=0.3764 [11.3 s]    dev=(HR@5:0.3637,NDCG@5:0.2493) [0.4 s] *
INFO:root:Epoch 5     loss=0.3515 [10.7 s]    dev=(HR@5:0.3776,NDCG@5:0.2629) [0.4 s] *
INFO:root:Epoch 6     loss=0.3278 [11.2 s]    dev=(HR@5:0.3920,NDCG@5:0.2772) [0.4 s] *
INFO:root:Epoch 7     loss=0.3083 [11.2 s]    dev=(HR@5:0.3943,NDCG@5:0.2821) [0.4 s] *
INFO:root:Epoch 8     loss=0.2916 [11.1 s]    dev=(HR@5:0.4026,NDCG@5:0.2894) [0.4 s] *
INFO:root:Epoch 9     loss=0.2761 [11.4 s]    dev=(HR@5:0.4033,NDCG@5:0.2938) [0.4 s] *
INFO:root:Epoch 10    loss=0.2648 [11.0 s]    dev=(HR@5:0.4080,NDCG@5:0.2966) [0.4 s] *
INFO:root:Epoch 11    loss=0.2540 [10.8 s]    dev=(HR@5:0.4210,NDCG@5:0.3048) [0.4 s] *
INFO:root:Epoch 12    loss=0.2446 [11.1 s]    dev=(HR@5:0.4212,NDCG@5:0.3060) [0.4 s] *
INFO:root:Epoch 13    loss=0.2407 [11.3 s]    dev=(HR@5:0.4277,NDCG@5:0.3119) [0.4 s] *
INFO:root:Epoch 14    loss=0.2340 [10.8 s]    dev=(HR@5:0.4271,NDCG@5:0.3107) [0.4 s]
INFO:root:Epoch 15    loss=0.2315 [11.0 s]    dev=(HR@5:0.4289,NDCG@5:0.3104) [0.4 s]
INFO:root:Epoch 16    loss=0.2278 [11.2 s]    dev=(HR@5:0.4282,NDCG@5:0.3123) [0.4 s] *
INFO:root:Epoch 17    loss=0.2247 [11.0 s]    dev=(HR@5:0.4244,NDCG@5:0.3086) [0.4 s]
INFO:root:Epoch 18    loss=0.2204 [11.0 s]    dev=(HR@5:0.4292,NDCG@5:0.3139) [0.4 s] *
INFO:root:Epoch 19    loss=0.2184 [10.8 s]    dev=(HR@5:0.4306,NDCG@5:0.3142) [0.4 s] *
INFO:root:Epoch 20    loss=0.2164 [10.4 s]    dev=(HR@5:0.4328,NDCG@5:0.3169) [0.4 s] *
INFO:root:Epoch 21    loss=0.2123 [10.8 s]    dev=(HR@5:0.4355,NDCG@5:0.3176) [0.4 s] *
INFO:root:Epoch 22    loss=0.2110 [10.9 s]    dev=(HR@5:0.4340,NDCG@5:0.3183) [0.4 s] *
INFO:root:Epoch 23    loss=0.2113 [11.0 s]    dev=(HR@5:0.4295,NDCG@5:0.3151) [0.4 s]
INFO:root:Epoch 24    loss=0.2100 [11.0 s]    dev=(HR@5:0.4361,NDCG@5:0.3191) [0.4 s] *
INFO:root:Epoch 25    loss=0.2078 [10.9 s]    dev=(HR@5:0.4309,NDCG@5:0.3148) [0.4 s]
INFO:root:Epoch 26    loss=0.2077 [10.9 s]    dev=(HR@5:0.4331,NDCG@5:0.3171) [0.3 s]
INFO:root:Epoch 27    loss=0.2068 [10.9 s]    dev=(HR@5:0.4368,NDCG@5:0.3189) [0.4 s]
INFO:root:Epoch 28    loss=0.2068 [10.9 s]    dev=(HR@5:0.4408,NDCG@5:0.3230) [0.4 s] *
INFO:root:Epoch 29    loss=0.2044 [11.0 s]    dev=(HR@5:0.4374,NDCG@5:0.3208) [0.4 s]
INFO:root:Epoch 30    loss=0.2042 [11.0 s]    dev=(HR@5:0.4330,NDCG@5:0.3186) [0.4 s]
INFO:root:Epoch 31    loss=0.2021 [11.0 s]    dev=(HR@5:0.4404,NDCG@5:0.3231) [0.4 s] *
INFO:root:Epoch 32    loss=0.2030 [11.0 s]    dev=(HR@5:0.4392,NDCG@5:0.3210) [0.4 s]
INFO:root:Epoch 33    loss=0.2025 [10.9 s]    dev=(HR@5:0.4410,NDCG@5:0.3235) [0.4 s] *
INFO:root:Epoch 34    loss=0.2011 [9.9 s]    dev=(HR@5:0.4417,NDCG@5:0.3226) [0.4 s]
INFO:root:Epoch 35    loss=0.2016 [11.1 s]    dev=(HR@5:0.4411,NDCG@5:0.3211) [0.4 s]
INFO:root:Epoch 36    loss=0.2001 [11.1 s]    dev=(HR@5:0.4412,NDCG@5:0.3198) [0.4 s]
INFO:root:Epoch 37    loss=0.2000 [11.0 s]    dev=(HR@5:0.4418,NDCG@5:0.3220) [0.4 s]
INFO:root:Epoch 38    loss=0.2000 [11.0 s]    dev=(HR@5:0.4426,NDCG@5:0.3221) [0.4 s]
INFO:root:Epoch 39    loss=0.2000 [10.9 s]    dev=(HR@5:0.4357,NDCG@5:0.3163) [0.4 s]
INFO:root:Epoch 40    loss=0.1994 [11.2 s]    dev=(HR@5:0.4422,NDCG@5:0.3224) [0.4 s]
INFO:root:Epoch 41    loss=0.2002 [11.0 s]    dev=(HR@5:0.4366,NDCG@5:0.3176) [0.4 s]
INFO:root:Epoch 42    loss=0.1998 [11.0 s]    dev=(HR@5:0.4438,NDCG@5:0.3225) [0.4 s]
INFO:root:Epoch 43    loss=0.1974 [11.0 s]    dev=(HR@5:0.4426,NDCG@5:0.3239) [0.4 s] *
INFO:root:Epoch 44    loss=0.1998 [10.4 s]    dev=(HR@5:0.4393,NDCG@5:0.3226) [0.4 s]
INFO:root:Epoch 45    loss=0.1958 [9.9 s]    dev=(HR@5:0.4436,NDCG@5:0.3259) [0.4 s] *
INFO:root:Epoch 46    loss=0.1971 [10.8 s]    dev=(HR@5:0.4438,NDCG@5:0.3236) [0.4 s]
INFO:root:Epoch 47    loss=0.1975 [11.2 s]    dev=(HR@5:0.4434,NDCG@5:0.3251) [0.4 s]
INFO:root:Epoch 48    loss=0.1958 [11.0 s]    dev=(HR@5:0.4423,NDCG@5:0.3219) [0.4 s]
INFO:root:Epoch 49    loss=0.1954 [10.8 s]    dev=(HR@5:0.4489,NDCG@5:0.3277) [0.4 s] *
INFO:root:Epoch 50    loss=0.1963 [11.1 s]    dev=(HR@5:0.4395,NDCG@5:0.3216) [0.4 s]
INFO:root:Epoch 51    loss=0.1950 [11.0 s]    dev=(HR@5:0.4457,NDCG@5:0.3253) [0.4 s]
INFO:root:Epoch 52    loss=0.1956 [11.0 s]    dev=(HR@5:0.4425,NDCG@5:0.3223) [0.4 s]
INFO:root:Epoch 53    loss=0.1953 [11.1 s]    dev=(HR@5:0.4454,NDCG@5:0.3251) [0.4 s]
INFO:root:Epoch 54    loss=0.1932 [10.9 s]    dev=(HR@5:0.4459,NDCG@5:0.3257) [0.4 s]
INFO:root:Epoch 55    loss=0.1930 [11.3 s]    dev=(HR@5:0.4442,NDCG@5:0.3243) [0.4 s]
INFO:root:Epoch 56    loss=0.1929 [11.3 s]    dev=(HR@5:0.4473,NDCG@5:0.3262) [0.4 s]
INFO:root:Epoch 57    loss=0.1937 [11.3 s]    dev=(HR@5:0.4465,NDCG@5:0.3275) [0.4 s]
INFO:root:Epoch 58    loss=0.1946 [11.0 s]    dev=(HR@5:0.4462,NDCG@5:0.3282) [0.4 s] *
INFO:root:Epoch 59    loss=0.1935 [10.9 s]    dev=(HR@5:0.4436,NDCG@5:0.3251) [0.4 s]
INFO:root:Epoch 60    loss=0.1933 [10.8 s]    dev=(HR@5:0.4438,NDCG@5:0.3264) [0.4 s]
INFO:root:Epoch 61    loss=0.1931 [11.1 s]    dev=(HR@5:0.4517,NDCG@5:0.3298) [0.4 s] *
INFO:root:Epoch 62    loss=0.1924 [11.1 s]    dev=(HR@5:0.4470,NDCG@5:0.3275) [0.4 s]
INFO:root:Epoch 63    loss=0.1931 [11.0 s]    dev=(HR@5:0.4484,NDCG@5:0.3277) [0.4 s]
INFO:root:Epoch 64    loss=0.1920 [10.9 s]    dev=(HR@5:0.4449,NDCG@5:0.3252) [0.4 s]
INFO:root:Epoch 65    loss=0.1927 [10.8 s]    dev=(HR@5:0.4449,NDCG@5:0.3256) [0.4 s]
INFO:root:Epoch 66    loss=0.1914 [10.9 s]    dev=(HR@5:0.4470,NDCG@5:0.3250) [0.3 s]
INFO:root:Epoch 67    loss=0.1923 [10.6 s]    dev=(HR@5:0.4491,NDCG@5:0.3272) [0.4 s]
INFO:root:Epoch 68    loss=0.1902 [11.1 s]    dev=(HR@5:0.4479,NDCG@5:0.3285) [0.4 s]
INFO:root:Epoch 69    loss=0.1925 [11.0 s]    dev=(HR@5:0.4451,NDCG@5:0.3257) [0.4 s]
INFO:root:Epoch 70    loss=0.1909 [11.1 s]    dev=(HR@5:0.4494,NDCG@5:0.3289) [0.4 s]
INFO:root:Epoch 71    loss=0.1906 [11.1 s]    dev=(HR@5:0.4457,NDCG@5:0.3279) [0.4 s]
INFO:root:Epoch 72    loss=0.1902 [11.2 s]    dev=(HR@5:0.4458,NDCG@5:0.3276) [0.4 s]
INFO:root:Epoch 73    loss=0.1908 [11.2 s]    dev=(HR@5:0.4464,NDCG@5:0.3266) [0.4 s]
INFO:root:Epoch 74    loss=0.1918 [11.1 s]    dev=(HR@5:0.4464,NDCG@5:0.3264) [0.4 s]
INFO:root:Epoch 75    loss=0.1923 [11.2 s]    dev=(HR@5:0.4444,NDCG@5:0.3255) [0.4 s]
INFO:root:Epoch 76    loss=0.1916 [11.2 s]    dev=(HR@5:0.4488,NDCG@5:0.3291) [0.4 s]
INFO:root:Epoch 77    loss=0.1901 [11.1 s]    dev=(HR@5:0.4485,NDCG@5:0.3280) [0.4 s]
INFO:root:Epoch 78    loss=0.1900 [10.9 s]    dev=(HR@5:0.4470,NDCG@5:0.3271) [0.4 s]
INFO:root:Epoch 79    loss=0.1906 [11.2 s]    dev=(HR@5:0.4515,NDCG@5:0.3288) [0.3 s]
INFO:root:Epoch 80    loss=0.1890 [10.9 s]    dev=(HR@5:0.4485,NDCG@5:0.3267) [0.3 s]
INFO:root:Epoch 81    loss=0.1892 [11.3 s]    dev=(HR@5:0.4435,NDCG@5:0.3229) [0.4 s]
INFO:root:Early stop at 81 based on dev result.
INFO:root:
Best Iter(dev)=   61	 dev=(HR@5:0.4517,NDCG@5:0.3298) [922.1 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.4009,NDCG@5:0.2850,HR@10:0.5096,NDCG@10:0.3202,HR@20:0.6271,NDCG@20:0.3499,HR@50:0.8324,NDCG@50:0.3906)
INFO:root:
--------------------------------------------- END: 2024-12-23 03:09:56 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 03:45:59 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5162 [11.1 s]    dev=(HR@5:0.2519,NDCG@5:0.1679) [0.4 s] *
INFO:root:Epoch 2     loss=0.4301 [10.9 s]    dev=(HR@5:0.3231,NDCG@5:0.2192) [0.4 s] *
INFO:root:Epoch 3     loss=0.3929 [10.9 s]    dev=(HR@5:0.3502,NDCG@5:0.2378) [0.4 s] *
INFO:root:Epoch 4     loss=0.3697 [10.9 s]    dev=(HR@5:0.3685,NDCG@5:0.2541) [0.4 s] *
INFO:root:Epoch 5     loss=0.3450 [11.2 s]    dev=(HR@5:0.3858,NDCG@5:0.2691) [0.4 s] *
INFO:root:Epoch 6     loss=0.3211 [11.1 s]    dev=(HR@5:0.4022,NDCG@5:0.2829) [0.4 s] *
INFO:root:Epoch 7     loss=0.3030 [10.9 s]    dev=(HR@5:0.4071,NDCG@5:0.2871) [0.4 s] *
INFO:root:Epoch 8     loss=0.2889 [11.1 s]    dev=(HR@5:0.4121,NDCG@5:0.2942) [0.4 s] *
INFO:root:Epoch 9     loss=0.2758 [10.8 s]    dev=(HR@5:0.4146,NDCG@5:0.2971) [0.4 s] *
INFO:root:Epoch 10    loss=0.2679 [10.9 s]    dev=(HR@5:0.4169,NDCG@5:0.3001) [0.4 s] *
INFO:root:Epoch 11    loss=0.2592 [11.0 s]    dev=(HR@5:0.4205,NDCG@5:0.3033) [0.4 s] *
INFO:root:Epoch 12    loss=0.2525 [10.6 s]    dev=(HR@5:0.4230,NDCG@5:0.3062) [0.4 s] *
INFO:root:Epoch 13    loss=0.2487 [10.9 s]    dev=(HR@5:0.4257,NDCG@5:0.3085) [0.4 s] *
INFO:root:Epoch 14    loss=0.2447 [11.2 s]    dev=(HR@5:0.4264,NDCG@5:0.3074) [0.4 s]
INFO:root:Epoch 15    loss=0.2426 [11.1 s]    dev=(HR@5:0.4211,NDCG@5:0.3057) [0.4 s]
INFO:root:Epoch 16    loss=0.2411 [11.2 s]    dev=(HR@5:0.4267,NDCG@5:0.3088) [0.4 s] *
INFO:root:Epoch 17    loss=0.2372 [11.0 s]    dev=(HR@5:0.4259,NDCG@5:0.3067) [0.4 s]
INFO:root:Epoch 18    loss=0.2328 [10.9 s]    dev=(HR@5:0.4263,NDCG@5:0.3087) [0.4 s]
INFO:root:Epoch 19    loss=0.2318 [11.0 s]    dev=(HR@5:0.4284,NDCG@5:0.3113) [0.4 s] *
INFO:root:Epoch 20    loss=0.2293 [10.8 s]    dev=(HR@5:0.4299,NDCG@5:0.3140) [0.4 s] *
INFO:root:Epoch 21    loss=0.2252 [10.9 s]    dev=(HR@5:0.4318,NDCG@5:0.3143) [0.4 s] *
INFO:root:Epoch 22    loss=0.2245 [10.9 s]    dev=(HR@5:0.4323,NDCG@5:0.3134) [0.4 s]
INFO:root:Epoch 23    loss=0.2257 [11.1 s]    dev=(HR@5:0.4271,NDCG@5:0.3108) [0.4 s]
INFO:root:Epoch 24    loss=0.2241 [10.4 s]    dev=(HR@5:0.4306,NDCG@5:0.3121) [0.4 s]
INFO:root:Epoch 25    loss=0.2207 [10.9 s]    dev=(HR@5:0.4270,NDCG@5:0.3112) [0.4 s]
INFO:root:Epoch 26    loss=0.2210 [11.0 s]    dev=(HR@5:0.4333,NDCG@5:0.3141) [0.4 s]
INFO:root:Epoch 27    loss=0.2204 [10.9 s]    dev=(HR@5:0.4292,NDCG@5:0.3113) [0.4 s]
INFO:root:Epoch 28    loss=0.2203 [9.9 s]    dev=(HR@5:0.4345,NDCG@5:0.3161) [0.4 s] *
INFO:root:Epoch 29    loss=0.2182 [11.2 s]    dev=(HR@5:0.4292,NDCG@5:0.3122) [0.4 s]
INFO:root:Epoch 30    loss=0.2171 [10.9 s]    dev=(HR@5:0.4312,NDCG@5:0.3139) [0.4 s]
INFO:root:Epoch 31    loss=0.2174 [10.9 s]    dev=(HR@5:0.4338,NDCG@5:0.3170) [0.4 s] *
INFO:root:Epoch 32    loss=0.2176 [11.0 s]    dev=(HR@5:0.4317,NDCG@5:0.3140) [0.4 s]
INFO:root:Epoch 33    loss=0.2155 [10.9 s]    dev=(HR@5:0.4310,NDCG@5:0.3161) [0.4 s]
INFO:root:Epoch 34    loss=0.2152 [11.1 s]    dev=(HR@5:0.4308,NDCG@5:0.3147) [0.4 s]
INFO:root:Epoch 35    loss=0.2159 [11.1 s]    dev=(HR@5:0.4278,NDCG@5:0.3113) [0.4 s]
INFO:root:Epoch 36    loss=0.2136 [11.2 s]    dev=(HR@5:0.4289,NDCG@5:0.3114) [0.4 s]
INFO:root:Epoch 37    loss=0.2141 [11.1 s]    dev=(HR@5:0.4293,NDCG@5:0.3115) [0.4 s]
INFO:root:Epoch 38    loss=0.2142 [10.9 s]    dev=(HR@5:0.4312,NDCG@5:0.3131) [0.4 s]
INFO:root:Epoch 39    loss=0.2141 [10.1 s]    dev=(HR@5:0.4261,NDCG@5:0.3076) [0.4 s]
INFO:root:Epoch 40    loss=0.2132 [11.0 s]    dev=(HR@5:0.4280,NDCG@5:0.3123) [0.4 s]
INFO:root:Epoch 41    loss=0.2140 [10.9 s]    dev=(HR@5:0.4279,NDCG@5:0.3113) [0.4 s]
INFO:root:Epoch 42    loss=0.2134 [11.1 s]    dev=(HR@5:0.4307,NDCG@5:0.3118) [0.4 s]
INFO:root:Epoch 43    loss=0.2113 [11.1 s]    dev=(HR@5:0.4334,NDCG@5:0.3156) [0.4 s]
INFO:root:Epoch 44    loss=0.2132 [10.8 s]    dev=(HR@5:0.4286,NDCG@5:0.3121) [0.4 s]
INFO:root:Epoch 45    loss=0.2085 [11.2 s]    dev=(HR@5:0.4332,NDCG@5:0.3159) [0.4 s]
INFO:root:Epoch 46    loss=0.2110 [11.2 s]    dev=(HR@5:0.4273,NDCG@5:0.3094) [0.4 s]
INFO:root:Epoch 47    loss=0.2111 [11.4 s]    dev=(HR@5:0.4292,NDCG@5:0.3116) [0.4 s]
INFO:root:Epoch 48    loss=0.2104 [11.0 s]    dev=(HR@5:0.4296,NDCG@5:0.3110) [0.4 s]
INFO:root:Epoch 49    loss=0.2091 [10.8 s]    dev=(HR@5:0.4337,NDCG@5:0.3142) [0.4 s]
INFO:root:Epoch 50    loss=0.2097 [10.9 s]    dev=(HR@5:0.4277,NDCG@5:0.3140) [0.4 s]
INFO:root:Epoch 51    loss=0.2100 [11.3 s]    dev=(HR@5:0.4310,NDCG@5:0.3148) [0.4 s]
INFO:root:Early stop at 51 based on dev result.
INFO:root:
Best Iter(dev)=   31	 dev=(HR@5:0.4338,NDCG@5:0.3170) [578.1 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.3855,NDCG@5:0.2739,HR@10:0.4908,NDCG@10:0.3080,HR@20:0.6140,NDCG@20:0.3391,HR@50:0.8266,NDCG@50:0.3812)
INFO:root:
--------------------------------------------- END: 2024-12-23 03:55:40 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 04:20:46 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5163 [12.4 s]    dev=(HR@5:0.2527,NDCG@5:0.1687) [0.4 s] *
INFO:root:Epoch 2     loss=0.4292 [11.5 s]    dev=(HR@5:0.3267,NDCG@5:0.2214) [0.4 s] *
INFO:root:Epoch 3     loss=0.3913 [11.7 s]    dev=(HR@5:0.3549,NDCG@5:0.2418) [0.4 s] *
INFO:root:Epoch 4     loss=0.3664 [11.6 s]    dev=(HR@5:0.3782,NDCG@5:0.2635) [0.4 s] *
INFO:root:Epoch 5     loss=0.3399 [11.6 s]    dev=(HR@5:0.3987,NDCG@5:0.2810) [0.4 s] *
INFO:root:Epoch 6     loss=0.3144 [11.2 s]    dev=(HR@5:0.4148,NDCG@5:0.2969) [0.4 s] *
INFO:root:Epoch 7     loss=0.2962 [11.8 s]    dev=(HR@5:0.4197,NDCG@5:0.2994) [0.4 s] *
INFO:root:Epoch 8     loss=0.2821 [11.8 s]    dev=(HR@5:0.4250,NDCG@5:0.3065) [0.4 s] *
INFO:root:Epoch 9     loss=0.2696 [11.8 s]    dev=(HR@5:0.4247,NDCG@5:0.3081) [0.4 s] *
INFO:root:Epoch 10    loss=0.2616 [11.5 s]    dev=(HR@5:0.4263,NDCG@5:0.3093) [0.4 s] *
INFO:root:Epoch 11    loss=0.2531 [11.3 s]    dev=(HR@5:0.4308,NDCG@5:0.3121) [0.4 s] *
INFO:root:Epoch 12    loss=0.2464 [11.7 s]    dev=(HR@5:0.4307,NDCG@5:0.3128) [0.4 s] *
INFO:root:Epoch 13    loss=0.2428 [10.7 s]    dev=(HR@5:0.4355,NDCG@5:0.3170) [0.4 s] *
INFO:root:Epoch 14    loss=0.2381 [11.7 s]    dev=(HR@5:0.4395,NDCG@5:0.3181) [0.4 s] *
INFO:root:Epoch 15    loss=0.2344 [11.8 s]    dev=(HR@5:0.4381,NDCG@5:0.3170) [0.4 s]
INFO:root:Epoch 16    loss=0.2321 [11.2 s]    dev=(HR@5:0.4402,NDCG@5:0.3189) [0.4 s] *
INFO:root:Epoch 17    loss=0.2275 [11.7 s]    dev=(HR@5:0.4370,NDCG@5:0.3169) [0.4 s]
INFO:root:Epoch 18    loss=0.2233 [9.7 s]    dev=(HR@5:0.4398,NDCG@5:0.3209) [0.4 s] *
INFO:root:Epoch 19    loss=0.2211 [11.7 s]    dev=(HR@5:0.4402,NDCG@5:0.3213) [0.4 s] *
INFO:root:Epoch 20    loss=0.2175 [11.5 s]    dev=(HR@5:0.4422,NDCG@5:0.3239) [0.4 s] *
INFO:root:Epoch 21    loss=0.2144 [10.6 s]    dev=(HR@5:0.4406,NDCG@5:0.3205) [0.4 s]
INFO:root:Epoch 22    loss=0.2134 [11.4 s]    dev=(HR@5:0.4438,NDCG@5:0.3238) [0.4 s]
INFO:root:Epoch 23    loss=0.2136 [11.9 s]    dev=(HR@5:0.4428,NDCG@5:0.3243) [0.3 s] *
INFO:root:Epoch 24    loss=0.2132 [11.6 s]    dev=(HR@5:0.4434,NDCG@5:0.3227) [0.4 s]
INFO:root:Epoch 25    loss=0.2098 [11.6 s]    dev=(HR@5:0.4413,NDCG@5:0.3226) [0.4 s]
INFO:root:Epoch 26    loss=0.2098 [11.6 s]    dev=(HR@5:0.4474,NDCG@5:0.3257) [0.4 s] *
INFO:root:Epoch 27    loss=0.2099 [11.5 s]    dev=(HR@5:0.4434,NDCG@5:0.3240) [0.4 s]
INFO:root:Epoch 28    loss=0.2100 [11.0 s]    dev=(HR@5:0.4481,NDCG@5:0.3280) [0.4 s] *
INFO:root:Epoch 29    loss=0.2074 [11.8 s]    dev=(HR@5:0.4450,NDCG@5:0.3253) [0.4 s]
INFO:root:Epoch 30    loss=0.2060 [11.8 s]    dev=(HR@5:0.4406,NDCG@5:0.3223) [0.4 s]
INFO:root:Epoch 31    loss=0.2057 [11.7 s]    dev=(HR@5:0.4470,NDCG@5:0.3274) [0.4 s]
INFO:root:Epoch 32    loss=0.2056 [11.9 s]    dev=(HR@5:0.4440,NDCG@5:0.3246) [0.4 s]
INFO:root:Epoch 33    loss=0.2054 [11.9 s]    dev=(HR@5:0.4443,NDCG@5:0.3263) [0.4 s]
INFO:root:Epoch 34    loss=0.2040 [12.0 s]    dev=(HR@5:0.4438,NDCG@5:0.3248) [0.4 s]
INFO:root:Epoch 35    loss=0.2051 [11.7 s]    dev=(HR@5:0.4408,NDCG@5:0.3226) [0.4 s]
INFO:root:Epoch 36    loss=0.2026 [11.9 s]    dev=(HR@5:0.4409,NDCG@5:0.3220) [0.4 s]
INFO:root:Epoch 37    loss=0.2036 [11.5 s]    dev=(HR@5:0.4402,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 38    loss=0.2026 [10.0 s]    dev=(HR@5:0.4442,NDCG@5:0.3238) [0.4 s]
INFO:root:Epoch 39    loss=0.2037 [11.6 s]    dev=(HR@5:0.4387,NDCG@5:0.3195) [0.4 s]
INFO:root:Epoch 40    loss=0.2022 [11.0 s]    dev=(HR@5:0.4389,NDCG@5:0.3203) [0.4 s]
INFO:root:Epoch 41    loss=0.2030 [11.7 s]    dev=(HR@5:0.4398,NDCG@5:0.3217) [0.4 s]
INFO:root:Epoch 42    loss=0.2025 [11.5 s]    dev=(HR@5:0.4451,NDCG@5:0.3242) [0.4 s]
INFO:root:Epoch 43    loss=0.2009 [11.3 s]    dev=(HR@5:0.4456,NDCG@5:0.3268) [0.4 s]
INFO:root:Epoch 44    loss=0.2024 [11.9 s]    dev=(HR@5:0.4407,NDCG@5:0.3237) [0.4 s]
INFO:root:Epoch 45    loss=0.1988 [11.5 s]    dev=(HR@5:0.4475,NDCG@5:0.3284) [0.4 s] *
INFO:root:Epoch 46    loss=0.2006 [11.5 s]    dev=(HR@5:0.4390,NDCG@5:0.3212) [0.4 s]
INFO:root:Epoch 47    loss=0.2005 [11.8 s]    dev=(HR@5:0.4391,NDCG@5:0.3216) [0.4 s]
INFO:root:Epoch 48    loss=0.2000 [11.7 s]    dev=(HR@5:0.4371,NDCG@5:0.3194) [0.4 s]
INFO:root:Epoch 49    loss=0.1986 [11.7 s]    dev=(HR@5:0.4496,NDCG@5:0.3283) [0.4 s]
INFO:root:Epoch 50    loss=0.2005 [11.7 s]    dev=(HR@5:0.4405,NDCG@5:0.3237) [0.4 s]
INFO:root:Epoch 51    loss=0.1990 [10.6 s]    dev=(HR@5:0.4457,NDCG@5:0.3278) [0.4 s]
INFO:root:Epoch 52    loss=0.1997 [11.7 s]    dev=(HR@5:0.4429,NDCG@5:0.3238) [0.4 s]
INFO:root:Epoch 53    loss=0.1997 [10.1 s]    dev=(HR@5:0.4409,NDCG@5:0.3239) [0.4 s]
INFO:root:Epoch 54    loss=0.1981 [10.3 s]    dev=(HR@5:0.4413,NDCG@5:0.3239) [0.4 s]
INFO:root:Epoch 55    loss=0.1979 [9.9 s]    dev=(HR@5:0.4419,NDCG@5:0.3231) [0.4 s]
INFO:root:Epoch 56    loss=0.1978 [10.9 s]    dev=(HR@5:0.4438,NDCG@5:0.3252) [0.4 s]
INFO:root:Epoch 57    loss=0.1987 [11.5 s]    dev=(HR@5:0.4427,NDCG@5:0.3239) [0.4 s]
INFO:root:Epoch 58    loss=0.1981 [11.3 s]    dev=(HR@5:0.4454,NDCG@5:0.3260) [0.4 s]
INFO:root:Epoch 59    loss=0.1986 [11.6 s]    dev=(HR@5:0.4438,NDCG@5:0.3258) [0.4 s]
INFO:root:Epoch 60    loss=0.1977 [11.9 s]    dev=(HR@5:0.4410,NDCG@5:0.3241) [0.4 s]
INFO:root:Epoch 61    loss=0.1986 [11.9 s]    dev=(HR@5:0.4414,NDCG@5:0.3251) [0.4 s]
INFO:root:Epoch 62    loss=0.1977 [11.6 s]    dev=(HR@5:0.4427,NDCG@5:0.3257) [0.4 s]
INFO:root:Epoch 63    loss=0.1988 [11.6 s]    dev=(HR@5:0.4444,NDCG@5:0.3249) [0.4 s]
INFO:root:Epoch 64    loss=0.1972 [11.5 s]    dev=(HR@5:0.4428,NDCG@5:0.3219) [0.4 s]
INFO:root:Epoch 65    loss=0.1985 [10.9 s]    dev=(HR@5:0.4414,NDCG@5:0.3220) [0.4 s]
INFO:root:Early stop at 65 based on dev result.
INFO:root:
Best Iter(dev)=   45	 dev=(HR@5:0.4475,NDCG@5:0.3284) [769.1 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.4038,NDCG@5:0.2871,HR@10:0.5140,NDCG@10:0.3227,HR@20:0.6356,NDCG@20:0.3533,HR@50:0.8397,NDCG@50:0.3937)
INFO:root:
--------------------------------------------- END: 2024-12-23 04:33:38 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 04:53:16 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5166 [12.1 s]    dev=(HR@5:0.2530,NDCG@5:0.1691) [0.4 s] *
INFO:root:Epoch 2     loss=0.4285 [11.3 s]    dev=(HR@5:0.3293,NDCG@5:0.2236) [0.4 s] *
INFO:root:Epoch 3     loss=0.3894 [11.0 s]    dev=(HR@5:0.3601,NDCG@5:0.2465) [0.4 s] *
INFO:root:Epoch 4     loss=0.3629 [10.3 s]    dev=(HR@5:0.3857,NDCG@5:0.2689) [0.4 s] *
INFO:root:Epoch 5     loss=0.3358 [10.9 s]    dev=(HR@5:0.4052,NDCG@5:0.2863) [0.4 s] *
INFO:root:Epoch 6     loss=0.3106 [11.0 s]    dev=(HR@5:0.4201,NDCG@5:0.3025) [0.4 s] *
INFO:root:Epoch 7     loss=0.2922 [10.8 s]    dev=(HR@5:0.4240,NDCG@5:0.3047) [0.4 s] *
INFO:root:Epoch 8     loss=0.2777 [11.1 s]    dev=(HR@5:0.4316,NDCG@5:0.3124) [0.4 s] *
INFO:root:Epoch 9     loss=0.2643 [11.1 s]    dev=(HR@5:0.4340,NDCG@5:0.3151) [0.4 s] *
INFO:root:Epoch 10    loss=0.2557 [11.0 s]    dev=(HR@5:0.4357,NDCG@5:0.3165) [0.4 s] *
INFO:root:Epoch 11    loss=0.2470 [10.1 s]    dev=(HR@5:0.4389,NDCG@5:0.3182) [0.4 s] *
INFO:root:Epoch 12    loss=0.2397 [11.1 s]    dev=(HR@5:0.4386,NDCG@5:0.3193) [0.4 s] *
INFO:root:Epoch 13    loss=0.2361 [11.1 s]    dev=(HR@5:0.4427,NDCG@5:0.3231) [0.4 s] *
INFO:root:Epoch 14    loss=0.2317 [10.6 s]    dev=(HR@5:0.4425,NDCG@5:0.3226) [0.4 s]
INFO:root:Epoch 15    loss=0.2291 [10.4 s]    dev=(HR@5:0.4397,NDCG@5:0.3202) [0.4 s]
INFO:root:Epoch 16    loss=0.2273 [10.4 s]    dev=(HR@5:0.4408,NDCG@5:0.3211) [0.4 s]
INFO:root:Epoch 17    loss=0.2242 [10.9 s]    dev=(HR@5:0.4394,NDCG@5:0.3186) [0.4 s]
INFO:root:Epoch 18    loss=0.2202 [10.9 s]    dev=(HR@5:0.4441,NDCG@5:0.3244) [0.4 s] *
INFO:root:Epoch 19    loss=0.2193 [11.1 s]    dev=(HR@5:0.4401,NDCG@5:0.3223) [0.4 s]
INFO:root:Epoch 20    loss=0.2162 [10.9 s]    dev=(HR@5:0.4415,NDCG@5:0.3244) [0.4 s]
INFO:root:Epoch 21    loss=0.2125 [10.9 s]    dev=(HR@5:0.4425,NDCG@5:0.3242) [0.4 s]
INFO:root:Epoch 22    loss=0.2124 [10.3 s]    dev=(HR@5:0.4429,NDCG@5:0.3239) [0.4 s]
INFO:root:Epoch 23    loss=0.2129 [10.8 s]    dev=(HR@5:0.4436,NDCG@5:0.3255) [0.4 s] *
INFO:root:Epoch 24    loss=0.2130 [10.9 s]    dev=(HR@5:0.4432,NDCG@5:0.3225) [0.4 s]
INFO:root:Epoch 25    loss=0.2094 [10.8 s]    dev=(HR@5:0.4417,NDCG@5:0.3227) [0.4 s]
INFO:root:Epoch 26    loss=0.2096 [10.9 s]    dev=(HR@5:0.4426,NDCG@5:0.3235) [0.4 s]
INFO:root:Epoch 27    loss=0.2100 [10.9 s]    dev=(HR@5:0.4435,NDCG@5:0.3240) [0.4 s]
INFO:root:Epoch 28    loss=0.2096 [11.1 s]    dev=(HR@5:0.4449,NDCG@5:0.3271) [0.4 s] *
INFO:root:Epoch 29    loss=0.2083 [11.3 s]    dev=(HR@5:0.4434,NDCG@5:0.3255) [0.4 s]
INFO:root:Epoch 30    loss=0.2071 [10.9 s]    dev=(HR@5:0.4410,NDCG@5:0.3233) [0.4 s]
INFO:root:Epoch 31    loss=0.2065 [10.9 s]    dev=(HR@5:0.4435,NDCG@5:0.3260) [0.4 s]
INFO:root:Epoch 32    loss=0.2066 [10.9 s]    dev=(HR@5:0.4389,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 33    loss=0.2068 [10.6 s]    dev=(HR@5:0.4427,NDCG@5:0.3266) [0.4 s]
INFO:root:Epoch 34    loss=0.2060 [10.7 s]    dev=(HR@5:0.4433,NDCG@5:0.3259) [0.4 s]
INFO:root:Epoch 35    loss=0.2068 [10.9 s]    dev=(HR@5:0.4415,NDCG@5:0.3240) [0.4 s]
INFO:root:Epoch 36    loss=0.2039 [11.2 s]    dev=(HR@5:0.4432,NDCG@5:0.3246) [0.4 s]
INFO:root:Epoch 37    loss=0.2047 [10.9 s]    dev=(HR@5:0.4410,NDCG@5:0.3233) [0.4 s]
INFO:root:Epoch 38    loss=0.2054 [10.8 s]    dev=(HR@5:0.4431,NDCG@5:0.3257) [0.4 s]
INFO:root:Epoch 39    loss=0.2055 [10.9 s]    dev=(HR@5:0.4376,NDCG@5:0.3204) [0.4 s]
INFO:root:Epoch 40    loss=0.2047 [10.9 s]    dev=(HR@5:0.4379,NDCG@5:0.3209) [0.4 s]
INFO:root:Epoch 41    loss=0.2058 [10.4 s]    dev=(HR@5:0.4413,NDCG@5:0.3234) [0.4 s]
INFO:root:Epoch 42    loss=0.2043 [10.2 s]    dev=(HR@5:0.4430,NDCG@5:0.3236) [0.4 s]
INFO:root:Epoch 43    loss=0.2035 [10.0 s]    dev=(HR@5:0.4474,NDCG@5:0.3279) [0.4 s] *
INFO:root:Epoch 44    loss=0.2044 [9.9 s]    dev=(HR@5:0.4410,NDCG@5:0.3233) [0.4 s]
INFO:root:Epoch 45    loss=0.2018 [10.8 s]    dev=(HR@5:0.4410,NDCG@5:0.3274) [0.4 s]
INFO:root:Epoch 46    loss=0.2034 [10.8 s]    dev=(HR@5:0.4372,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 47    loss=0.2029 [10.3 s]    dev=(HR@5:0.4410,NDCG@5:0.3242) [0.4 s]
INFO:root:Epoch 48    loss=0.2026 [11.0 s]    dev=(HR@5:0.4397,NDCG@5:0.3219) [0.4 s]
INFO:root:Epoch 49    loss=0.2017 [10.9 s]    dev=(HR@5:0.4443,NDCG@5:0.3272) [0.4 s]
INFO:root:Epoch 50    loss=0.2036 [11.0 s]    dev=(HR@5:0.4411,NDCG@5:0.3249) [0.4 s]
INFO:root:Epoch 51    loss=0.2016 [11.1 s]    dev=(HR@5:0.4430,NDCG@5:0.3270) [0.4 s]
INFO:root:Epoch 52    loss=0.2021 [10.7 s]    dev=(HR@5:0.4404,NDCG@5:0.3248) [0.4 s]
INFO:root:Epoch 53    loss=0.2018 [11.1 s]    dev=(HR@5:0.4407,NDCG@5:0.3248) [0.4 s]
INFO:root:Epoch 54    loss=0.2002 [11.0 s]    dev=(HR@5:0.4410,NDCG@5:0.3254) [0.4 s]
INFO:root:Epoch 55    loss=0.2004 [11.0 s]    dev=(HR@5:0.4454,NDCG@5:0.3263) [0.4 s]
INFO:root:Epoch 56    loss=0.1998 [11.2 s]    dev=(HR@5:0.4448,NDCG@5:0.3274) [0.4 s]
INFO:root:Epoch 57    loss=0.2010 [10.9 s]    dev=(HR@5:0.4456,NDCG@5:0.3278) [0.4 s]
INFO:root:Epoch 58    loss=0.2006 [11.0 s]    dev=(HR@5:0.4467,NDCG@5:0.3300) [0.4 s] *
INFO:root:Epoch 59    loss=0.2005 [11.1 s]    dev=(HR@5:0.4442,NDCG@5:0.3278) [0.4 s]
INFO:root:Epoch 60    loss=0.1998 [11.0 s]    dev=(HR@5:0.4436,NDCG@5:0.3267) [0.4 s]
INFO:root:Epoch 61    loss=0.2005 [11.0 s]    dev=(HR@5:0.4451,NDCG@5:0.3285) [0.3 s]
INFO:root:Epoch 62    loss=0.1994 [10.9 s]    dev=(HR@5:0.4429,NDCG@5:0.3266) [0.4 s]
INFO:root:Epoch 63    loss=0.2002 [10.6 s]    dev=(HR@5:0.4455,NDCG@5:0.3267) [0.4 s]
INFO:root:Epoch 64    loss=0.1980 [11.0 s]    dev=(HR@5:0.4422,NDCG@5:0.3234) [0.4 s]
INFO:root:Epoch 65    loss=0.1994 [10.9 s]    dev=(HR@5:0.4413,NDCG@5:0.3242) [0.4 s]
INFO:root:Epoch 66    loss=0.1980 [11.0 s]    dev=(HR@5:0.4425,NDCG@5:0.3251) [0.4 s]
INFO:root:Epoch 67    loss=0.1980 [11.1 s]    dev=(HR@5:0.4421,NDCG@5:0.3236) [0.4 s]
INFO:root:Epoch 68    loss=0.1960 [11.1 s]    dev=(HR@5:0.4433,NDCG@5:0.3251) [0.4 s]
INFO:root:Epoch 69    loss=0.1984 [11.2 s]    dev=(HR@5:0.4421,NDCG@5:0.3239) [0.4 s]
INFO:root:Epoch 70    loss=0.1977 [11.0 s]    dev=(HR@5:0.4421,NDCG@5:0.3245) [0.4 s]
INFO:root:Epoch 71    loss=0.1976 [10.9 s]    dev=(HR@5:0.4393,NDCG@5:0.3235) [0.4 s]
INFO:root:Epoch 72    loss=0.1967 [11.2 s]    dev=(HR@5:0.4381,NDCG@5:0.3224) [0.4 s]
INFO:root:Epoch 73    loss=0.1980 [11.2 s]    dev=(HR@5:0.4382,NDCG@5:0.3205) [0.4 s]
INFO:root:Epoch 74    loss=0.1981 [10.9 s]    dev=(HR@5:0.4419,NDCG@5:0.3231) [0.4 s]
INFO:root:Epoch 75    loss=0.1993 [10.9 s]    dev=(HR@5:0.4427,NDCG@5:0.3266) [0.4 s]
INFO:root:Epoch 76    loss=0.1975 [11.0 s]    dev=(HR@5:0.4428,NDCG@5:0.3241) [0.4 s]
INFO:root:Epoch 77    loss=0.1964 [11.0 s]    dev=(HR@5:0.4410,NDCG@5:0.3232) [0.4 s]
INFO:root:Epoch 78    loss=0.1967 [10.9 s]    dev=(HR@5:0.4430,NDCG@5:0.3236) [0.4 s]
INFO:root:Early stop at 78 based on dev result.
INFO:root:
Best Iter(dev)=   58	 dev=(HR@5:0.4467,NDCG@5:0.3300) [878.4 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.4031,NDCG@5:0.2870,HR@10:0.5128,NDCG@10:0.3226,HR@20:0.6339,NDCG@20:0.3530,HR@50:0.8364,NDCG@50:0.3931)
INFO:root:
--------------------------------------------- END: 2024-12-23 05:07:58 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 05:26:34 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.5                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5165 [13.0 s]    dev=(HR@5:0.2564,NDCG@5:0.1714) [0.4 s] *
INFO:root:Epoch 2     loss=0.4264 [11.4 s]    dev=(HR@5:0.3337,NDCG@5:0.2277) [0.4 s] *
INFO:root:Epoch 3     loss=0.3877 [11.3 s]    dev=(HR@5:0.3646,NDCG@5:0.2505) [0.4 s] *
INFO:root:Epoch 4     loss=0.3634 [11.2 s]    dev=(HR@5:0.3847,NDCG@5:0.2673) [0.4 s] *
INFO:root:Epoch 5     loss=0.3399 [11.3 s]    dev=(HR@5:0.4013,NDCG@5:0.2831) [0.4 s] *
INFO:root:Epoch 6     loss=0.3154 [11.2 s]    dev=(HR@5:0.4175,NDCG@5:0.3010) [0.4 s] *
INFO:root:Epoch 7     loss=0.2960 [11.2 s]    dev=(HR@5:0.4230,NDCG@5:0.3047) [0.4 s] *
INFO:root:Epoch 8     loss=0.2815 [11.2 s]    dev=(HR@5:0.4283,NDCG@5:0.3099) [0.4 s] *
INFO:root:Epoch 9     loss=0.2677 [11.2 s]    dev=(HR@5:0.4333,NDCG@5:0.3140) [0.4 s] *
INFO:root:Epoch 10    loss=0.2594 [11.2 s]    dev=(HR@5:0.4344,NDCG@5:0.3148) [0.4 s] *
INFO:root:Epoch 11    loss=0.2507 [11.2 s]    dev=(HR@5:0.4352,NDCG@5:0.3163) [0.4 s] *
INFO:root:Epoch 12    loss=0.2427 [11.2 s]    dev=(HR@5:0.4386,NDCG@5:0.3190) [0.4 s] *
INFO:root:Epoch 13    loss=0.2394 [10.6 s]    dev=(HR@5:0.4424,NDCG@5:0.3231) [0.4 s] *
INFO:root:Epoch 14    loss=0.2338 [11.4 s]    dev=(HR@5:0.4439,NDCG@5:0.3231) [0.4 s] *
INFO:root:Epoch 15    loss=0.2310 [11.5 s]    dev=(HR@5:0.4402,NDCG@5:0.3218) [0.4 s]
INFO:root:Epoch 16    loss=0.2294 [11.1 s]    dev=(HR@5:0.4421,NDCG@5:0.3231) [0.4 s] *
INFO:root:Epoch 17    loss=0.2249 [11.3 s]    dev=(HR@5:0.4330,NDCG@5:0.3175) [0.4 s]
INFO:root:Epoch 18    loss=0.2210 [10.5 s]    dev=(HR@5:0.4419,NDCG@5:0.3251) [0.4 s] *
INFO:root:Epoch 19    loss=0.2196 [11.0 s]    dev=(HR@5:0.4404,NDCG@5:0.3239) [0.4 s]
INFO:root:Epoch 20    loss=0.2168 [10.0 s]    dev=(HR@5:0.4438,NDCG@5:0.3254) [0.4 s] *
INFO:root:Epoch 21    loss=0.2129 [10.8 s]    dev=(HR@5:0.4415,NDCG@5:0.3245) [0.4 s]
INFO:root:Epoch 22    loss=0.2131 [11.1 s]    dev=(HR@5:0.4430,NDCG@5:0.3268) [0.4 s] *
INFO:root:Epoch 23    loss=0.2131 [11.2 s]    dev=(HR@5:0.4391,NDCG@5:0.3241) [0.4 s]
INFO:root:Epoch 24    loss=0.2123 [10.8 s]    dev=(HR@5:0.4416,NDCG@5:0.3239) [0.4 s]
INFO:root:Epoch 25    loss=0.2091 [11.3 s]    dev=(HR@5:0.4396,NDCG@5:0.3228) [0.4 s]
INFO:root:Epoch 26    loss=0.2098 [11.2 s]    dev=(HR@5:0.4430,NDCG@5:0.3248) [0.4 s]
INFO:root:Epoch 27    loss=0.2098 [10.6 s]    dev=(HR@5:0.4432,NDCG@5:0.3259) [0.4 s]
INFO:root:Epoch 28    loss=0.2091 [11.2 s]    dev=(HR@5:0.4466,NDCG@5:0.3289) [0.4 s] *
INFO:root:Epoch 29    loss=0.2072 [11.4 s]    dev=(HR@5:0.4463,NDCG@5:0.3277) [0.4 s]
INFO:root:Epoch 30    loss=0.2061 [11.2 s]    dev=(HR@5:0.4420,NDCG@5:0.3240) [0.4 s]
INFO:root:Epoch 31    loss=0.2058 [10.1 s]    dev=(HR@5:0.4460,NDCG@5:0.3288) [0.4 s]
INFO:root:Epoch 32    loss=0.2057 [10.8 s]    dev=(HR@5:0.4444,NDCG@5:0.3265) [0.4 s]
INFO:root:Epoch 33    loss=0.2060 [10.8 s]    dev=(HR@5:0.4449,NDCG@5:0.3275) [0.4 s]
INFO:root:Epoch 34    loss=0.2049 [11.2 s]    dev=(HR@5:0.4493,NDCG@5:0.3309) [0.4 s] *
INFO:root:Epoch 35    loss=0.2054 [11.2 s]    dev=(HR@5:0.4403,NDCG@5:0.3240) [0.4 s]
INFO:root:Epoch 36    loss=0.2033 [10.2 s]    dev=(HR@5:0.4399,NDCG@5:0.3232) [0.4 s]
INFO:root:Epoch 37    loss=0.2037 [9.7 s]    dev=(HR@5:0.4428,NDCG@5:0.3250) [0.4 s]
INFO:root:Epoch 38    loss=0.2043 [10.7 s]    dev=(HR@5:0.4436,NDCG@5:0.3260) [0.4 s]
INFO:root:Epoch 39    loss=0.2041 [10.6 s]    dev=(HR@5:0.4381,NDCG@5:0.3211) [0.4 s]
INFO:root:Epoch 40    loss=0.2033 [10.7 s]    dev=(HR@5:0.4422,NDCG@5:0.3234) [0.4 s]
INFO:root:Epoch 41    loss=0.2036 [11.2 s]    dev=(HR@5:0.4374,NDCG@5:0.3201) [0.4 s]
INFO:root:Epoch 42    loss=0.2029 [11.3 s]    dev=(HR@5:0.4460,NDCG@5:0.3249) [0.4 s]
INFO:root:Epoch 43    loss=0.2016 [11.3 s]    dev=(HR@5:0.4458,NDCG@5:0.3275) [0.4 s]
INFO:root:Epoch 44    loss=0.2029 [11.3 s]    dev=(HR@5:0.4391,NDCG@5:0.3205) [0.4 s]
INFO:root:Epoch 45    loss=0.2000 [11.2 s]    dev=(HR@5:0.4447,NDCG@5:0.3273) [0.4 s]
INFO:root:Epoch 46    loss=0.2016 [11.2 s]    dev=(HR@5:0.4419,NDCG@5:0.3244) [0.4 s]
INFO:root:Epoch 47    loss=0.2019 [11.2 s]    dev=(HR@5:0.4442,NDCG@5:0.3252) [0.4 s]
INFO:root:Epoch 48    loss=0.2012 [11.2 s]    dev=(HR@5:0.4406,NDCG@5:0.3209) [0.4 s]
INFO:root:Epoch 49    loss=0.2008 [11.2 s]    dev=(HR@5:0.4472,NDCG@5:0.3273) [0.4 s]
INFO:root:Epoch 50    loss=0.2017 [11.3 s]    dev=(HR@5:0.4434,NDCG@5:0.3246) [0.4 s]
INFO:root:Epoch 51    loss=0.2004 [11.3 s]    dev=(HR@5:0.4460,NDCG@5:0.3273) [0.4 s]
INFO:root:Epoch 52    loss=0.2004 [11.3 s]    dev=(HR@5:0.4440,NDCG@5:0.3246) [0.4 s]
INFO:root:Epoch 53    loss=0.2007 [11.3 s]    dev=(HR@5:0.4404,NDCG@5:0.3245) [0.4 s]
INFO:root:Epoch 54    loss=0.1979 [11.2 s]    dev=(HR@5:0.4441,NDCG@5:0.3247) [0.4 s]
INFO:root:Early stop at 54 based on dev result.
INFO:root:
Best Iter(dev)=   34	 dev=(HR@5:0.4493,NDCG@5:0.3309) [619.2 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.3969,NDCG@5:0.2831,HR@10:0.5075,NDCG@10:0.3188,HR@20:0.6328,NDCG@20:0.3503,HR@50:0.8388,NDCG@50:0.3912)
INFO:root:
--------------------------------------------- END: 2024-12-23 05:36:56 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 05:55:37 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5151 [12.2 s]    dev=(HR@5:0.2524,NDCG@5:0.1682) [0.4 s] *
INFO:root:Epoch 2     loss=0.4308 [9.9 s]    dev=(HR@5:0.3208,NDCG@5:0.2168) [0.4 s] *
INFO:root:Epoch 3     loss=0.3963 [11.0 s]    dev=(HR@5:0.3465,NDCG@5:0.2333) [0.4 s] *
INFO:root:Epoch 4     loss=0.3744 [10.9 s]    dev=(HR@5:0.3639,NDCG@5:0.2507) [0.4 s] *
INFO:root:Epoch 5     loss=0.3514 [11.0 s]    dev=(HR@5:0.3791,NDCG@5:0.2660) [0.4 s] *
INFO:root:Epoch 6     loss=0.3289 [10.9 s]    dev=(HR@5:0.3951,NDCG@5:0.2809) [0.4 s] *
INFO:root:Epoch 7     loss=0.3105 [10.9 s]    dev=(HR@5:0.3979,NDCG@5:0.2853) [0.4 s] *
INFO:root:Epoch 8     loss=0.2957 [11.0 s]    dev=(HR@5:0.4041,NDCG@5:0.2910) [0.4 s] *
INFO:root:Epoch 9     loss=0.2807 [10.8 s]    dev=(HR@5:0.4067,NDCG@5:0.2947) [0.4 s] *
INFO:root:Epoch 10    loss=0.2708 [11.2 s]    dev=(HR@5:0.4113,NDCG@5:0.2973) [0.4 s] *
INFO:root:Epoch 11    loss=0.2609 [11.1 s]    dev=(HR@5:0.4168,NDCG@5:0.3007) [0.4 s] *
INFO:root:Epoch 12    loss=0.2522 [10.8 s]    dev=(HR@5:0.4218,NDCG@5:0.3063) [0.4 s] *
INFO:root:Epoch 13    loss=0.2484 [11.0 s]    dev=(HR@5:0.4223,NDCG@5:0.3075) [0.4 s] *
INFO:root:Epoch 14    loss=0.2436 [11.1 s]    dev=(HR@5:0.4198,NDCG@5:0.3046) [0.4 s]
INFO:root:Epoch 15    loss=0.2405 [11.0 s]    dev=(HR@5:0.4235,NDCG@5:0.3063) [0.4 s]
INFO:root:Epoch 16    loss=0.2376 [11.1 s]    dev=(HR@5:0.4239,NDCG@5:0.3073) [0.4 s]
INFO:root:Epoch 17    loss=0.2342 [11.1 s]    dev=(HR@5:0.4223,NDCG@5:0.3070) [0.4 s]
INFO:root:Epoch 18    loss=0.2297 [11.0 s]    dev=(HR@5:0.4261,NDCG@5:0.3084) [0.4 s] *
INFO:root:Epoch 19    loss=0.2275 [10.9 s]    dev=(HR@5:0.4267,NDCG@5:0.3114) [0.4 s] *
INFO:root:Epoch 20    loss=0.2257 [11.0 s]    dev=(HR@5:0.4323,NDCG@5:0.3137) [0.4 s] *
INFO:root:Epoch 21    loss=0.2217 [10.3 s]    dev=(HR@5:0.4317,NDCG@5:0.3122) [0.4 s]
INFO:root:Epoch 22    loss=0.2213 [11.4 s]    dev=(HR@5:0.4274,NDCG@5:0.3109) [0.4 s]
INFO:root:Epoch 23    loss=0.2215 [9.7 s]    dev=(HR@5:0.4269,NDCG@5:0.3115) [0.4 s]
INFO:root:Epoch 24    loss=0.2204 [10.8 s]    dev=(HR@5:0.4361,NDCG@5:0.3157) [0.4 s] *
INFO:root:Epoch 25    loss=0.2170 [10.8 s]    dev=(HR@5:0.4311,NDCG@5:0.3132) [0.4 s]
INFO:root:Epoch 26    loss=0.2176 [10.7 s]    dev=(HR@5:0.4357,NDCG@5:0.3172) [0.4 s] *
INFO:root:Epoch 27    loss=0.2169 [11.3 s]    dev=(HR@5:0.4312,NDCG@5:0.3138) [0.4 s]
INFO:root:Epoch 28    loss=0.2170 [11.0 s]    dev=(HR@5:0.4372,NDCG@5:0.3183) [0.4 s] *
INFO:root:Epoch 29    loss=0.2138 [11.0 s]    dev=(HR@5:0.4325,NDCG@5:0.3148) [0.4 s]
INFO:root:Epoch 30    loss=0.2136 [11.2 s]    dev=(HR@5:0.4299,NDCG@5:0.3148) [0.4 s]
INFO:root:Epoch 31    loss=0.2124 [11.1 s]    dev=(HR@5:0.4367,NDCG@5:0.3193) [0.4 s] *
INFO:root:Epoch 32    loss=0.2140 [11.0 s]    dev=(HR@5:0.4332,NDCG@5:0.3151) [0.4 s]
INFO:root:Epoch 33    loss=0.2127 [10.9 s]    dev=(HR@5:0.4325,NDCG@5:0.3161) [0.4 s]
INFO:root:Epoch 34    loss=0.2122 [10.7 s]    dev=(HR@5:0.4325,NDCG@5:0.3150) [0.4 s]
INFO:root:Epoch 35    loss=0.2120 [9.0 s]    dev=(HR@5:0.4325,NDCG@5:0.3128) [0.4 s]
INFO:root:Epoch 36    loss=0.2104 [11.2 s]    dev=(HR@5:0.4358,NDCG@5:0.3165) [0.4 s]
INFO:root:Epoch 37    loss=0.2107 [10.9 s]    dev=(HR@5:0.4331,NDCG@5:0.3149) [0.4 s]
INFO:root:Epoch 38    loss=0.2103 [11.0 s]    dev=(HR@5:0.4376,NDCG@5:0.3177) [0.4 s]
INFO:root:Epoch 39    loss=0.2112 [11.1 s]    dev=(HR@5:0.4284,NDCG@5:0.3104) [0.4 s]
INFO:root:Epoch 40    loss=0.2102 [10.8 s]    dev=(HR@5:0.4312,NDCG@5:0.3146) [0.4 s]
INFO:root:Epoch 41    loss=0.2115 [11.1 s]    dev=(HR@5:0.4327,NDCG@5:0.3148) [0.4 s]
INFO:root:Epoch 42    loss=0.2114 [10.8 s]    dev=(HR@5:0.4359,NDCG@5:0.3168) [0.4 s]
INFO:root:Epoch 43    loss=0.2089 [10.8 s]    dev=(HR@5:0.4356,NDCG@5:0.3190) [0.4 s]
INFO:root:Epoch 44    loss=0.2106 [11.2 s]    dev=(HR@5:0.4321,NDCG@5:0.3140) [0.4 s]
INFO:root:Epoch 45    loss=0.2070 [10.9 s]    dev=(HR@5:0.4355,NDCG@5:0.3199) [0.4 s] *
INFO:root:Epoch 46    loss=0.2084 [11.1 s]    dev=(HR@5:0.4315,NDCG@5:0.3150) [0.4 s]
INFO:root:Epoch 47    loss=0.2088 [11.1 s]    dev=(HR@5:0.4342,NDCG@5:0.3156) [0.4 s]
INFO:root:Epoch 48    loss=0.2084 [10.9 s]    dev=(HR@5:0.4344,NDCG@5:0.3154) [0.4 s]
INFO:root:Epoch 49    loss=0.2065 [10.9 s]    dev=(HR@5:0.4360,NDCG@5:0.3185) [0.4 s]
INFO:root:Epoch 50    loss=0.2076 [10.9 s]    dev=(HR@5:0.4333,NDCG@5:0.3172) [0.4 s]
INFO:root:Epoch 51    loss=0.2065 [10.9 s]    dev=(HR@5:0.4396,NDCG@5:0.3196) [0.4 s]
INFO:root:Epoch 52    loss=0.2070 [10.8 s]    dev=(HR@5:0.4363,NDCG@5:0.3182) [0.4 s]
INFO:root:Epoch 53    loss=0.2061 [11.0 s]    dev=(HR@5:0.4342,NDCG@5:0.3172) [0.4 s]
INFO:root:Epoch 54    loss=0.2052 [11.1 s]    dev=(HR@5:0.4357,NDCG@5:0.3173) [0.4 s]
INFO:root:Epoch 55    loss=0.2054 [11.0 s]    dev=(HR@5:0.4380,NDCG@5:0.3185) [0.4 s]
INFO:root:Epoch 56    loss=0.2048 [10.5 s]    dev=(HR@5:0.4399,NDCG@5:0.3212) [0.4 s] *
INFO:root:Epoch 57    loss=0.2052 [10.8 s]    dev=(HR@5:0.4378,NDCG@5:0.3185) [0.4 s]
INFO:root:Epoch 58    loss=0.2061 [10.5 s]    dev=(HR@5:0.4386,NDCG@5:0.3226) [0.4 s] *
INFO:root:Epoch 59    loss=0.2056 [11.1 s]    dev=(HR@5:0.4363,NDCG@5:0.3186) [0.4 s]
INFO:root:Epoch 60    loss=0.2053 [11.3 s]    dev=(HR@5:0.4384,NDCG@5:0.3193) [0.4 s]
INFO:root:Epoch 61    loss=0.2050 [10.9 s]    dev=(HR@5:0.4438,NDCG@5:0.3244) [0.4 s] *
INFO:root:Epoch 62    loss=0.2036 [11.0 s]    dev=(HR@5:0.4407,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 63    loss=0.2055 [10.8 s]    dev=(HR@5:0.4387,NDCG@5:0.3194) [0.4 s]
INFO:root:Epoch 64    loss=0.2036 [10.9 s]    dev=(HR@5:0.4368,NDCG@5:0.3182) [0.4 s]
INFO:root:Epoch 65    loss=0.2042 [11.0 s]    dev=(HR@5:0.4319,NDCG@5:0.3152) [0.4 s]
INFO:root:Epoch 66    loss=0.2031 [10.8 s]    dev=(HR@5:0.4374,NDCG@5:0.3176) [0.4 s]
INFO:root:Epoch 67    loss=0.2035 [10.1 s]    dev=(HR@5:0.4368,NDCG@5:0.3197) [0.4 s]
INFO:root:Epoch 68    loss=0.2017 [10.5 s]    dev=(HR@5:0.4389,NDCG@5:0.3199) [0.4 s]
INFO:root:Epoch 69    loss=0.2037 [10.4 s]    dev=(HR@5:0.4344,NDCG@5:0.3168) [0.4 s]
INFO:root:Epoch 70    loss=0.2031 [10.9 s]    dev=(HR@5:0.4366,NDCG@5:0.3187) [0.4 s]
INFO:root:Epoch 71    loss=0.2024 [11.0 s]    dev=(HR@5:0.4346,NDCG@5:0.3175) [0.4 s]
INFO:root:Epoch 72    loss=0.2006 [10.6 s]    dev=(HR@5:0.4362,NDCG@5:0.3187) [0.4 s]
INFO:root:Epoch 73    loss=0.2021 [11.1 s]    dev=(HR@5:0.4349,NDCG@5:0.3162) [0.4 s]
INFO:root:Epoch 74    loss=0.2020 [10.5 s]    dev=(HR@5:0.4356,NDCG@5:0.3169) [0.4 s]
INFO:root:Epoch 75    loss=0.2038 [9.2 s]    dev=(HR@5:0.4353,NDCG@5:0.3182) [0.4 s]
INFO:root:Epoch 76    loss=0.2024 [11.0 s]    dev=(HR@5:0.4381,NDCG@5:0.3197) [0.4 s]
INFO:root:Epoch 77    loss=0.2016 [11.4 s]    dev=(HR@5:0.4359,NDCG@5:0.3172) [0.4 s]
INFO:root:Epoch 78    loss=0.2021 [11.4 s]    dev=(HR@5:0.4370,NDCG@5:0.3168) [0.4 s]
INFO:root:Epoch 79    loss=0.2022 [10.9 s]    dev=(HR@5:0.4418,NDCG@5:0.3222) [0.4 s]
INFO:root:Epoch 80    loss=0.2004 [9.7 s]    dev=(HR@5:0.4387,NDCG@5:0.3195) [0.4 s]
INFO:root:Epoch 81    loss=0.2006 [10.7 s]    dev=(HR@5:0.4370,NDCG@5:0.3177) [0.4 s]
INFO:root:Early stop at 81 based on dev result.
INFO:root:
Best Iter(dev)=   61	 dev=(HR@5:0.4438,NDCG@5:0.3244) [910.1 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.3907,NDCG@5:0.2777,HR@10:0.5032,NDCG@10:0.3142,HR@20:0.6205,NDCG@20:0.3437,HR@50:0.8294,NDCG@50:0.3851)
INFO:root:
--------------------------------------------- END: 2024-12-23 06:10:49 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 06:36:44 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5150 [12.5 s]    dev=(HR@5:0.2556,NDCG@5:0.1710) [0.4 s] *
INFO:root:Epoch 2     loss=0.4260 [11.4 s]    dev=(HR@5:0.3293,NDCG@5:0.2238) [0.4 s] *
INFO:root:Epoch 3     loss=0.3887 [11.0 s]    dev=(HR@5:0.3569,NDCG@5:0.2426) [0.4 s] *
INFO:root:Epoch 4     loss=0.3650 [10.9 s]    dev=(HR@5:0.3780,NDCG@5:0.2620) [0.4 s] *
INFO:root:Epoch 5     loss=0.3406 [10.6 s]    dev=(HR@5:0.3964,NDCG@5:0.2794) [0.4 s] *
INFO:root:Epoch 6     loss=0.3165 [11.1 s]    dev=(HR@5:0.4107,NDCG@5:0.2935) [0.4 s] *
INFO:root:Epoch 7     loss=0.2994 [10.8 s]    dev=(HR@5:0.4158,NDCG@5:0.2967) [0.4 s] *
INFO:root:Epoch 8     loss=0.2854 [11.2 s]    dev=(HR@5:0.4212,NDCG@5:0.3037) [0.4 s] *
INFO:root:Epoch 9     loss=0.2721 [11.1 s]    dev=(HR@5:0.4256,NDCG@5:0.3061) [0.4 s] *
INFO:root:Epoch 10    loss=0.2633 [11.1 s]    dev=(HR@5:0.4267,NDCG@5:0.3073) [0.4 s] *
INFO:root:Epoch 11    loss=0.2528 [11.3 s]    dev=(HR@5:0.4312,NDCG@5:0.3121) [0.4 s] *
INFO:root:Epoch 12    loss=0.2457 [11.1 s]    dev=(HR@5:0.4319,NDCG@5:0.3139) [0.4 s] *
INFO:root:Epoch 13    loss=0.2411 [11.0 s]    dev=(HR@5:0.4386,NDCG@5:0.3181) [0.4 s] *
INFO:root:Epoch 14    loss=0.2369 [11.1 s]    dev=(HR@5:0.4372,NDCG@5:0.3168) [0.4 s]
INFO:root:Epoch 15    loss=0.2329 [11.2 s]    dev=(HR@5:0.4371,NDCG@5:0.3171) [0.4 s]
INFO:root:Epoch 16    loss=0.2297 [11.1 s]    dev=(HR@5:0.4376,NDCG@5:0.3188) [0.4 s] *
INFO:root:Epoch 17    loss=0.2259 [11.2 s]    dev=(HR@5:0.4375,NDCG@5:0.3178) [0.4 s]
INFO:root:Epoch 18    loss=0.2212 [11.0 s]    dev=(HR@5:0.4385,NDCG@5:0.3181) [0.4 s]
INFO:root:Epoch 19    loss=0.2187 [11.3 s]    dev=(HR@5:0.4398,NDCG@5:0.3205) [0.4 s] *
INFO:root:Epoch 20    loss=0.2162 [11.0 s]    dev=(HR@5:0.4439,NDCG@5:0.3245) [0.4 s] *
INFO:root:Epoch 21    loss=0.2121 [10.7 s]    dev=(HR@5:0.4433,NDCG@5:0.3231) [0.4 s]
INFO:root:Epoch 22    loss=0.2109 [11.0 s]    dev=(HR@5:0.4419,NDCG@5:0.3238) [0.4 s]
INFO:root:Epoch 23    loss=0.2117 [11.0 s]    dev=(HR@5:0.4431,NDCG@5:0.3257) [0.4 s] *
INFO:root:Epoch 24    loss=0.2110 [11.0 s]    dev=(HR@5:0.4449,NDCG@5:0.3258) [0.4 s] *
INFO:root:Epoch 25    loss=0.2062 [10.9 s]    dev=(HR@5:0.4409,NDCG@5:0.3211) [0.4 s]
INFO:root:Epoch 26    loss=0.2072 [10.5 s]    dev=(HR@5:0.4453,NDCG@5:0.3250) [0.4 s]
INFO:root:Epoch 27    loss=0.2070 [11.1 s]    dev=(HR@5:0.4416,NDCG@5:0.3241) [0.4 s]
INFO:root:Epoch 28    loss=0.2061 [11.4 s]    dev=(HR@5:0.4468,NDCG@5:0.3274) [0.4 s] *
INFO:root:Epoch 29    loss=0.2047 [10.9 s]    dev=(HR@5:0.4423,NDCG@5:0.3235) [0.4 s]
INFO:root:Epoch 30    loss=0.2041 [10.9 s]    dev=(HR@5:0.4419,NDCG@5:0.3249) [0.4 s]
INFO:root:Epoch 31    loss=0.2021 [10.5 s]    dev=(HR@5:0.4444,NDCG@5:0.3275) [0.4 s] *
INFO:root:Epoch 32    loss=0.2034 [10.9 s]    dev=(HR@5:0.4443,NDCG@5:0.3251) [0.4 s]
INFO:root:Epoch 33    loss=0.2026 [11.0 s]    dev=(HR@5:0.4436,NDCG@5:0.3276) [0.4 s] *
INFO:root:Epoch 34    loss=0.2015 [10.9 s]    dev=(HR@5:0.4436,NDCG@5:0.3257) [0.4 s]
INFO:root:Epoch 35    loss=0.2026 [11.2 s]    dev=(HR@5:0.4335,NDCG@5:0.3178) [0.4 s]
INFO:root:Epoch 36    loss=0.1993 [11.3 s]    dev=(HR@5:0.4413,NDCG@5:0.3219) [0.4 s]
INFO:root:Epoch 37    loss=0.2012 [11.3 s]    dev=(HR@5:0.4457,NDCG@5:0.3258) [0.4 s]
INFO:root:Epoch 38    loss=0.2000 [10.8 s]    dev=(HR@5:0.4384,NDCG@5:0.3195) [0.4 s]
INFO:root:Epoch 39    loss=0.2006 [11.0 s]    dev=(HR@5:0.4406,NDCG@5:0.3210) [0.4 s]
INFO:root:Epoch 40    loss=0.1992 [11.2 s]    dev=(HR@5:0.4432,NDCG@5:0.3247) [0.4 s]
INFO:root:Epoch 41    loss=0.2007 [11.0 s]    dev=(HR@5:0.4424,NDCG@5:0.3224) [0.4 s]
INFO:root:Epoch 42    loss=0.2003 [11.1 s]    dev=(HR@5:0.4459,NDCG@5:0.3258) [0.4 s]
INFO:root:Epoch 43    loss=0.1985 [11.1 s]    dev=(HR@5:0.4478,NDCG@5:0.3292) [0.4 s] *
INFO:root:Epoch 44    loss=0.1998 [11.0 s]    dev=(HR@5:0.4415,NDCG@5:0.3235) [0.4 s]
INFO:root:Epoch 45    loss=0.1966 [10.9 s]    dev=(HR@5:0.4437,NDCG@5:0.3260) [0.4 s]
INFO:root:Epoch 46    loss=0.1990 [11.2 s]    dev=(HR@5:0.4425,NDCG@5:0.3239) [0.4 s]
INFO:root:Epoch 47    loss=0.1982 [11.1 s]    dev=(HR@5:0.4468,NDCG@5:0.3266) [0.4 s]
INFO:root:Epoch 48    loss=0.1983 [11.1 s]    dev=(HR@5:0.4453,NDCG@5:0.3252) [0.4 s]
INFO:root:Epoch 49    loss=0.1965 [11.0 s]    dev=(HR@5:0.4506,NDCG@5:0.3307) [0.4 s] *
INFO:root:Epoch 50    loss=0.1989 [11.0 s]    dev=(HR@5:0.4405,NDCG@5:0.3244) [0.4 s]
INFO:root:Epoch 51    loss=0.1969 [11.0 s]    dev=(HR@5:0.4455,NDCG@5:0.3265) [0.4 s]
INFO:root:Epoch 52    loss=0.1973 [11.0 s]    dev=(HR@5:0.4479,NDCG@5:0.3280) [0.4 s]
INFO:root:Epoch 53    loss=0.1974 [11.1 s]    dev=(HR@5:0.4465,NDCG@5:0.3269) [0.4 s]
INFO:root:Epoch 54    loss=0.1963 [11.1 s]    dev=(HR@5:0.4464,NDCG@5:0.3255) [0.4 s]
INFO:root:Epoch 55    loss=0.1959 [10.9 s]    dev=(HR@5:0.4444,NDCG@5:0.3242) [0.4 s]
INFO:root:Epoch 56    loss=0.1958 [10.9 s]    dev=(HR@5:0.4470,NDCG@5:0.3283) [0.4 s]
INFO:root:Epoch 57    loss=0.1966 [10.9 s]    dev=(HR@5:0.4470,NDCG@5:0.3306) [0.4 s]
INFO:root:Epoch 58    loss=0.1976 [10.9 s]    dev=(HR@5:0.4509,NDCG@5:0.3317) [0.4 s] *
INFO:root:Epoch 59    loss=0.1964 [10.7 s]    dev=(HR@5:0.4459,NDCG@5:0.3273) [0.4 s]
INFO:root:Epoch 60    loss=0.1966 [11.2 s]    dev=(HR@5:0.4474,NDCG@5:0.3302) [0.4 s]
INFO:root:Epoch 61    loss=0.1967 [11.5 s]    dev=(HR@5:0.4478,NDCG@5:0.3309) [0.4 s]
INFO:root:Epoch 62    loss=0.1964 [10.9 s]    dev=(HR@5:0.4518,NDCG@5:0.3308) [0.4 s]
INFO:root:Epoch 63    loss=0.1977 [10.8 s]    dev=(HR@5:0.4513,NDCG@5:0.3304) [0.4 s]
INFO:root:Epoch 64    loss=0.1952 [10.5 s]    dev=(HR@5:0.4446,NDCG@5:0.3264) [0.4 s]
INFO:root:Epoch 65    loss=0.1967 [11.2 s]    dev=(HR@5:0.4464,NDCG@5:0.3264) [0.4 s]
INFO:root:Epoch 66    loss=0.1948 [10.2 s]    dev=(HR@5:0.4459,NDCG@5:0.3268) [0.4 s]
INFO:root:Epoch 67    loss=0.1956 [10.4 s]    dev=(HR@5:0.4453,NDCG@5:0.3265) [0.4 s]
INFO:root:Epoch 68    loss=0.1940 [11.0 s]    dev=(HR@5:0.4472,NDCG@5:0.3277) [0.4 s]
INFO:root:Epoch 69    loss=0.1959 [10.9 s]    dev=(HR@5:0.4483,NDCG@5:0.3283) [0.4 s]
INFO:root:Epoch 70    loss=0.1949 [11.1 s]    dev=(HR@5:0.4465,NDCG@5:0.3274) [0.4 s]
INFO:root:Epoch 71    loss=0.1947 [10.9 s]    dev=(HR@5:0.4476,NDCG@5:0.3294) [0.4 s]
INFO:root:Epoch 72    loss=0.1941 [11.0 s]    dev=(HR@5:0.4483,NDCG@5:0.3276) [0.4 s]
INFO:root:Epoch 73    loss=0.1944 [11.0 s]    dev=(HR@5:0.4444,NDCG@5:0.3246) [0.4 s]
INFO:root:Epoch 74    loss=0.1959 [10.9 s]    dev=(HR@5:0.4434,NDCG@5:0.3230) [0.4 s]
INFO:root:Epoch 75    loss=0.1963 [11.0 s]    dev=(HR@5:0.4526,NDCG@5:0.3320) [0.4 s] *
INFO:root:Epoch 76    loss=0.1949 [9.8 s]    dev=(HR@5:0.4512,NDCG@5:0.3304) [0.4 s]
INFO:root:Epoch 77    loss=0.1945 [10.1 s]    dev=(HR@5:0.4470,NDCG@5:0.3267) [0.4 s]
INFO:root:Epoch 78    loss=0.1948 [10.8 s]    dev=(HR@5:0.4530,NDCG@5:0.3296) [0.4 s]
INFO:root:Epoch 79    loss=0.1959 [10.9 s]    dev=(HR@5:0.4529,NDCG@5:0.3305) [0.4 s]
INFO:root:Epoch 80    loss=0.1936 [11.1 s]    dev=(HR@5:0.4484,NDCG@5:0.3281) [0.4 s]
INFO:root:Epoch 81    loss=0.1935 [11.0 s]    dev=(HR@5:0.4432,NDCG@5:0.3228) [0.4 s]
INFO:root:Epoch 82    loss=0.1949 [11.1 s]    dev=(HR@5:0.4470,NDCG@5:0.3276) [0.4 s]
INFO:root:Epoch 83    loss=0.1933 [10.9 s]    dev=(HR@5:0.4517,NDCG@5:0.3305) [0.4 s]
INFO:root:Epoch 84    loss=0.1924 [10.6 s]    dev=(HR@5:0.4485,NDCG@5:0.3285) [0.4 s]
INFO:root:Epoch 85    loss=0.1947 [10.7 s]    dev=(HR@5:0.4511,NDCG@5:0.3297) [0.4 s]
INFO:root:Epoch 86    loss=0.1942 [10.7 s]    dev=(HR@5:0.4473,NDCG@5:0.3284) [0.4 s]
INFO:root:Epoch 87    loss=0.1942 [10.8 s]    dev=(HR@5:0.4499,NDCG@5:0.3286) [0.4 s]
INFO:root:Epoch 88    loss=0.1933 [10.7 s]    dev=(HR@5:0.4496,NDCG@5:0.3288) [0.4 s]
INFO:root:Epoch 89    loss=0.1924 [10.9 s]    dev=(HR@5:0.4485,NDCG@5:0.3290) [0.4 s]
INFO:root:Epoch 90    loss=0.1922 [10.9 s]    dev=(HR@5:0.4547,NDCG@5:0.3320) [0.4 s] *
INFO:root:Epoch 91    loss=0.1927 [11.0 s]    dev=(HR@5:0.4536,NDCG@5:0.3312) [0.4 s]
INFO:root:Epoch 92    loss=0.1912 [11.0 s]    dev=(HR@5:0.4514,NDCG@5:0.3288) [0.4 s]
INFO:root:Epoch 93    loss=0.1929 [10.9 s]    dev=(HR@5:0.4512,NDCG@5:0.3291) [0.4 s]
INFO:root:Epoch 94    loss=0.1932 [11.1 s]    dev=(HR@5:0.4506,NDCG@5:0.3289) [0.4 s]
INFO:root:Epoch 95    loss=0.1925 [11.3 s]    dev=(HR@5:0.4489,NDCG@5:0.3289) [0.4 s]
INFO:root:Epoch 96    loss=0.1912 [11.0 s]    dev=(HR@5:0.4461,NDCG@5:0.3271) [0.4 s]
INFO:root:Epoch 97    loss=0.1920 [11.1 s]    dev=(HR@5:0.4460,NDCG@5:0.3249) [0.4 s]
INFO:root:Epoch 98    loss=0.1909 [10.9 s]    dev=(HR@5:0.4479,NDCG@5:0.3252) [0.4 s]
INFO:root:Epoch 99    loss=0.1929 [11.1 s]    dev=(HR@5:0.4493,NDCG@5:0.3289) [0.4 s]
INFO:root:Epoch 100   loss=0.1909 [10.9 s]    dev=(HR@5:0.4529,NDCG@5:0.3316) [0.4 s]
INFO:root:Epoch 101   loss=0.1923 [10.9 s]    dev=(HR@5:0.4491,NDCG@5:0.3270) [0.4 s]
INFO:root:Epoch 102   loss=0.1926 [11.0 s]    dev=(HR@5:0.4541,NDCG@5:0.3319) [0.4 s]
INFO:root:Epoch 103   loss=0.1919 [11.0 s]    dev=(HR@5:0.4427,NDCG@5:0.3235) [0.4 s]
INFO:root:Epoch 104   loss=0.1910 [11.0 s]    dev=(HR@5:0.4438,NDCG@5:0.3253) [0.4 s]
INFO:root:Epoch 105   loss=0.1903 [11.1 s]    dev=(HR@5:0.4487,NDCG@5:0.3286) [0.4 s]
INFO:root:Epoch 106   loss=0.1913 [11.0 s]    dev=(HR@5:0.4459,NDCG@5:0.3264) [0.4 s]
INFO:root:Epoch 107   loss=0.1916 [11.0 s]    dev=(HR@5:0.4451,NDCG@5:0.3247) [0.4 s]
INFO:root:Epoch 108   loss=0.1916 [11.0 s]    dev=(HR@5:0.4485,NDCG@5:0.3290) [0.4 s]
INFO:root:Epoch 109   loss=0.1906 [11.1 s]    dev=(HR@5:0.4497,NDCG@5:0.3292) [0.4 s]
INFO:root:Epoch 110   loss=0.1894 [11.3 s]    dev=(HR@5:0.4503,NDCG@5:0.3286) [0.4 s]
INFO:root:Early stop at 110 based on dev result.
INFO:root:
Best Iter(dev)=   90	 dev=(HR@5:0.4547,NDCG@5:0.3320) [1249.9 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.4037,NDCG@5:0.2863,HR@10:0.5152,NDCG@10:0.3223,HR@20:0.6393,NDCG@20:0.3536,HR@50:0.8405,NDCG@50:0.3934)
INFO:root:
--------------------------------------------- END: 2024-12-23 06:57:37 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 07:25:05 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5153 [12.5 s]    dev=(HR@5:0.2565,NDCG@5:0.1718) [0.4 s] *
INFO:root:Epoch 2     loss=0.4250 [10.9 s]    dev=(HR@5:0.3328,NDCG@5:0.2261) [0.4 s] *
INFO:root:Epoch 3     loss=0.3865 [11.1 s]    dev=(HR@5:0.3634,NDCG@5:0.2480) [0.4 s] *
INFO:root:Epoch 4     loss=0.3609 [11.2 s]    dev=(HR@5:0.3857,NDCG@5:0.2689) [0.4 s] *
INFO:root:Epoch 5     loss=0.3360 [11.0 s]    dev=(HR@5:0.4019,NDCG@5:0.2853) [0.4 s] *
INFO:root:Epoch 6     loss=0.3121 [11.0 s]    dev=(HR@5:0.4183,NDCG@5:0.2984) [0.4 s] *
INFO:root:Epoch 7     loss=0.2943 [10.9 s]    dev=(HR@5:0.4213,NDCG@5:0.3004) [0.4 s] *
INFO:root:Epoch 8     loss=0.2798 [11.0 s]    dev=(HR@5:0.4263,NDCG@5:0.3081) [0.4 s] *
INFO:root:Epoch 9     loss=0.2663 [11.1 s]    dev=(HR@5:0.4309,NDCG@5:0.3124) [0.4 s] *
INFO:root:Epoch 10    loss=0.2561 [11.2 s]    dev=(HR@5:0.4356,NDCG@5:0.3167) [0.4 s] *
INFO:root:Epoch 11    loss=0.2463 [11.0 s]    dev=(HR@5:0.4388,NDCG@5:0.3185) [0.4 s] *
INFO:root:Epoch 12    loss=0.2380 [11.1 s]    dev=(HR@5:0.4390,NDCG@5:0.3203) [0.4 s] *
INFO:root:Epoch 13    loss=0.2334 [11.2 s]    dev=(HR@5:0.4441,NDCG@5:0.3242) [0.4 s] *
INFO:root:Epoch 14    loss=0.2294 [11.2 s]    dev=(HR@5:0.4451,NDCG@5:0.3249) [0.4 s] *
INFO:root:Epoch 15    loss=0.2257 [11.2 s]    dev=(HR@5:0.4437,NDCG@5:0.3237) [0.4 s]
INFO:root:Epoch 16    loss=0.2220 [11.0 s]    dev=(HR@5:0.4460,NDCG@5:0.3263) [0.4 s] *
INFO:root:Epoch 17    loss=0.2183 [11.1 s]    dev=(HR@5:0.4436,NDCG@5:0.3237) [0.4 s]
INFO:root:Epoch 18    loss=0.2139 [10.6 s]    dev=(HR@5:0.4484,NDCG@5:0.3291) [0.4 s] *
INFO:root:Epoch 19    loss=0.2117 [11.1 s]    dev=(HR@5:0.4461,NDCG@5:0.3277) [0.4 s]
INFO:root:Epoch 20    loss=0.2086 [11.2 s]    dev=(HR@5:0.4515,NDCG@5:0.3315) [0.4 s] *
INFO:root:Epoch 21    loss=0.2054 [11.2 s]    dev=(HR@5:0.4528,NDCG@5:0.3312) [0.4 s]
INFO:root:Epoch 22    loss=0.2048 [10.9 s]    dev=(HR@5:0.4500,NDCG@5:0.3308) [0.4 s]
INFO:root:Epoch 23    loss=0.2054 [10.8 s]    dev=(HR@5:0.4468,NDCG@5:0.3305) [0.4 s]
INFO:root:Epoch 24    loss=0.2045 [11.1 s]    dev=(HR@5:0.4488,NDCG@5:0.3292) [0.4 s]
INFO:root:Epoch 25    loss=0.2005 [11.3 s]    dev=(HR@5:0.4482,NDCG@5:0.3271) [0.4 s]
INFO:root:Epoch 26    loss=0.2009 [11.2 s]    dev=(HR@5:0.4509,NDCG@5:0.3299) [0.4 s]
INFO:root:Epoch 27    loss=0.2002 [11.3 s]    dev=(HR@5:0.4507,NDCG@5:0.3307) [0.4 s]
INFO:root:Epoch 28    loss=0.2003 [11.3 s]    dev=(HR@5:0.4543,NDCG@5:0.3347) [0.4 s] *
INFO:root:Epoch 29    loss=0.1986 [11.1 s]    dev=(HR@5:0.4511,NDCG@5:0.3309) [0.4 s]
INFO:root:Epoch 30    loss=0.1979 [11.3 s]    dev=(HR@5:0.4515,NDCG@5:0.3318) [0.4 s]
INFO:root:Epoch 31    loss=0.1972 [11.3 s]    dev=(HR@5:0.4509,NDCG@5:0.3328) [0.4 s]
INFO:root:Epoch 32    loss=0.1966 [11.1 s]    dev=(HR@5:0.4511,NDCG@5:0.3321) [0.4 s]
INFO:root:Epoch 33    loss=0.1971 [11.0 s]    dev=(HR@5:0.4518,NDCG@5:0.3329) [0.4 s]
INFO:root:Epoch 34    loss=0.1964 [10.7 s]    dev=(HR@5:0.4487,NDCG@5:0.3286) [0.4 s]
INFO:root:Epoch 35    loss=0.1970 [11.1 s]    dev=(HR@5:0.4485,NDCG@5:0.3282) [0.4 s]
INFO:root:Epoch 36    loss=0.1943 [11.3 s]    dev=(HR@5:0.4515,NDCG@5:0.3301) [0.4 s]
INFO:root:Epoch 37    loss=0.1956 [11.0 s]    dev=(HR@5:0.4485,NDCG@5:0.3293) [0.4 s]
INFO:root:Epoch 38    loss=0.1953 [11.1 s]    dev=(HR@5:0.4491,NDCG@5:0.3293) [0.4 s]
INFO:root:Epoch 39    loss=0.1957 [10.9 s]    dev=(HR@5:0.4471,NDCG@5:0.3271) [0.4 s]
INFO:root:Epoch 40    loss=0.1949 [10.4 s]    dev=(HR@5:0.4478,NDCG@5:0.3293) [0.4 s]
INFO:root:Epoch 41    loss=0.1950 [11.0 s]    dev=(HR@5:0.4510,NDCG@5:0.3290) [0.4 s]
INFO:root:Epoch 42    loss=0.1949 [11.0 s]    dev=(HR@5:0.4528,NDCG@5:0.3319) [0.4 s]
INFO:root:Epoch 43    loss=0.1935 [11.0 s]    dev=(HR@5:0.4531,NDCG@5:0.3331) [0.4 s]
INFO:root:Epoch 44    loss=0.1943 [11.0 s]    dev=(HR@5:0.4492,NDCG@5:0.3294) [0.4 s]
INFO:root:Epoch 45    loss=0.1926 [11.0 s]    dev=(HR@5:0.4513,NDCG@5:0.3337) [0.4 s]
INFO:root:Epoch 46    loss=0.1932 [10.9 s]    dev=(HR@5:0.4474,NDCG@5:0.3298) [0.4 s]
INFO:root:Epoch 47    loss=0.1934 [11.0 s]    dev=(HR@5:0.4501,NDCG@5:0.3290) [0.4 s]
INFO:root:Epoch 48    loss=0.1930 [10.9 s]    dev=(HR@5:0.4498,NDCG@5:0.3296) [0.4 s]
INFO:root:Early stop at 48 based on dev result.
INFO:root:
Best Iter(dev)=   28	 dev=(HR@5:0.4543,NDCG@5:0.3347) [550.1 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.4002,NDCG@5:0.2871,HR@10:0.5115,NDCG@10:0.3231,HR@20:0.6325,NDCG@20:0.3536,HR@50:0.8354,NDCG@50:0.3937)
INFO:root:
--------------------------------------------- END: 2024-12-23 07:34:18 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 07:54:30 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5154 [11.9 s]    dev=(HR@5:0.2590,NDCG@5:0.1737) [0.4 s] *
INFO:root:Epoch 2     loss=0.4238 [10.8 s]    dev=(HR@5:0.3362,NDCG@5:0.2286) [0.4 s] *
INFO:root:Epoch 3     loss=0.3858 [11.1 s]    dev=(HR@5:0.3639,NDCG@5:0.2494) [0.4 s] *
INFO:root:Epoch 4     loss=0.3601 [11.0 s]    dev=(HR@5:0.3872,NDCG@5:0.2709) [0.4 s] *
INFO:root:Epoch 5     loss=0.3352 [11.2 s]    dev=(HR@5:0.4031,NDCG@5:0.2866) [0.4 s] *
INFO:root:Epoch 6     loss=0.3116 [11.1 s]    dev=(HR@5:0.4191,NDCG@5:0.3002) [0.4 s] *
INFO:root:Epoch 7     loss=0.2938 [11.1 s]    dev=(HR@5:0.4245,NDCG@5:0.3045) [0.4 s] *
INFO:root:Epoch 8     loss=0.2786 [11.1 s]    dev=(HR@5:0.4301,NDCG@5:0.3124) [0.4 s] *
INFO:root:Epoch 9     loss=0.2646 [11.1 s]    dev=(HR@5:0.4359,NDCG@5:0.3175) [0.4 s] *
INFO:root:Epoch 10    loss=0.2549 [11.3 s]    dev=(HR@5:0.4400,NDCG@5:0.3210) [0.4 s] *
INFO:root:Epoch 11    loss=0.2443 [11.2 s]    dev=(HR@5:0.4427,NDCG@5:0.3228) [0.4 s] *
INFO:root:Epoch 12    loss=0.2359 [10.4 s]    dev=(HR@5:0.4457,NDCG@5:0.3255) [0.4 s] *
INFO:root:Epoch 13    loss=0.2315 [10.4 s]    dev=(HR@5:0.4488,NDCG@5:0.3294) [0.4 s] *
INFO:root:Epoch 14    loss=0.2266 [10.7 s]    dev=(HR@5:0.4490,NDCG@5:0.3300) [0.4 s] *
INFO:root:Epoch 15    loss=0.2231 [11.1 s]    dev=(HR@5:0.4481,NDCG@5:0.3283) [0.4 s]
INFO:root:Epoch 16    loss=0.2203 [10.9 s]    dev=(HR@5:0.4497,NDCG@5:0.3296) [0.4 s]
INFO:root:Epoch 17    loss=0.2168 [10.4 s]    dev=(HR@5:0.4496,NDCG@5:0.3297) [0.4 s]
INFO:root:Epoch 18    loss=0.2129 [10.5 s]    dev=(HR@5:0.4510,NDCG@5:0.3316) [0.4 s] *
INFO:root:Epoch 19    loss=0.2111 [11.1 s]    dev=(HR@5:0.4482,NDCG@5:0.3290) [0.4 s]
INFO:root:Epoch 20    loss=0.2087 [11.1 s]    dev=(HR@5:0.4492,NDCG@5:0.3320) [0.4 s] *
INFO:root:Epoch 21    loss=0.2055 [11.1 s]    dev=(HR@5:0.4524,NDCG@5:0.3324) [0.4 s] *
INFO:root:Epoch 22    loss=0.2054 [11.1 s]    dev=(HR@5:0.4478,NDCG@5:0.3304) [0.4 s]
INFO:root:Epoch 23    loss=0.2060 [11.0 s]    dev=(HR@5:0.4488,NDCG@5:0.3309) [0.4 s]
INFO:root:Epoch 24    loss=0.2055 [10.9 s]    dev=(HR@5:0.4492,NDCG@5:0.3303) [0.4 s]
INFO:root:Epoch 25    loss=0.2011 [11.0 s]    dev=(HR@5:0.4451,NDCG@5:0.3277) [0.4 s]
INFO:root:Epoch 26    loss=0.2024 [10.8 s]    dev=(HR@5:0.4504,NDCG@5:0.3316) [0.4 s]
INFO:root:Epoch 27    loss=0.2024 [10.9 s]    dev=(HR@5:0.4509,NDCG@5:0.3325) [0.4 s] *
INFO:root:Epoch 28    loss=0.2020 [10.3 s]    dev=(HR@5:0.4528,NDCG@5:0.3347) [0.3 s] *
INFO:root:Epoch 29    loss=0.2006 [9.9 s]    dev=(HR@5:0.4496,NDCG@5:0.3315) [0.3 s]
INFO:root:Epoch 30    loss=0.2007 [11.0 s]    dev=(HR@5:0.4533,NDCG@5:0.3342) [0.4 s]
INFO:root:Epoch 31    loss=0.1986 [11.0 s]    dev=(HR@5:0.4519,NDCG@5:0.3348) [0.4 s] *
INFO:root:Epoch 32    loss=0.1992 [11.1 s]    dev=(HR@5:0.4523,NDCG@5:0.3319) [0.4 s]
INFO:root:Epoch 33    loss=0.1999 [11.0 s]    dev=(HR@5:0.4570,NDCG@5:0.3380) [0.4 s] *
INFO:root:Epoch 34    loss=0.1994 [11.0 s]    dev=(HR@5:0.4521,NDCG@5:0.3346) [0.4 s]
INFO:root:Epoch 35    loss=0.1988 [11.2 s]    dev=(HR@5:0.4524,NDCG@5:0.3340) [0.4 s]
INFO:root:Epoch 36    loss=0.1975 [11.0 s]    dev=(HR@5:0.4537,NDCG@5:0.3324) [0.4 s]
INFO:root:Epoch 37    loss=0.1980 [11.3 s]    dev=(HR@5:0.4539,NDCG@5:0.3335) [0.4 s]
INFO:root:Epoch 38    loss=0.1983 [10.7 s]    dev=(HR@5:0.4517,NDCG@5:0.3318) [0.4 s]
INFO:root:Epoch 39    loss=0.1982 [11.0 s]    dev=(HR@5:0.4460,NDCG@5:0.3277) [0.4 s]
INFO:root:Epoch 40    loss=0.1973 [11.0 s]    dev=(HR@5:0.4477,NDCG@5:0.3304) [0.4 s]
INFO:root:Epoch 41    loss=0.1980 [11.3 s]    dev=(HR@5:0.4513,NDCG@5:0.3319) [0.4 s]
INFO:root:Epoch 42    loss=0.1974 [11.3 s]    dev=(HR@5:0.4509,NDCG@5:0.3307) [0.4 s]
INFO:root:Epoch 43    loss=0.1961 [11.2 s]    dev=(HR@5:0.4551,NDCG@5:0.3357) [0.4 s]
INFO:root:Epoch 44    loss=0.1974 [11.3 s]    dev=(HR@5:0.4526,NDCG@5:0.3329) [0.3 s]
INFO:root:Epoch 45    loss=0.1948 [11.3 s]    dev=(HR@5:0.4539,NDCG@5:0.3359) [0.4 s]
INFO:root:Epoch 46    loss=0.1955 [10.9 s]    dev=(HR@5:0.4512,NDCG@5:0.3327) [0.4 s]
INFO:root:Epoch 47    loss=0.1959 [11.3 s]    dev=(HR@5:0.4524,NDCG@5:0.3318) [0.4 s]
INFO:root:Epoch 48    loss=0.1958 [11.2 s]    dev=(HR@5:0.4494,NDCG@5:0.3303) [0.4 s]
INFO:root:Epoch 49    loss=0.1940 [10.6 s]    dev=(HR@5:0.4533,NDCG@5:0.3330) [0.4 s]
INFO:root:Epoch 50    loss=0.1969 [10.8 s]    dev=(HR@5:0.4502,NDCG@5:0.3315) [0.4 s]
INFO:root:Epoch 51    loss=0.1945 [10.9 s]    dev=(HR@5:0.4507,NDCG@5:0.3313) [0.4 s]
INFO:root:Epoch 52    loss=0.1960 [11.2 s]    dev=(HR@5:0.4516,NDCG@5:0.3306) [0.4 s]
INFO:root:Epoch 53    loss=0.1947 [11.0 s]    dev=(HR@5:0.4487,NDCG@5:0.3295) [0.4 s]
INFO:root:Early stop at 53 based on dev result.
INFO:root:
Best Iter(dev)=   33	 dev=(HR@5:0.4570,NDCG@5:0.3380) [601.6 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.4058,NDCG@5:0.2920,HR@10:0.5130,NDCG@10:0.3268,HR@20:0.6344,NDCG@20:0.3574,HR@50:0.8369,NDCG@50:0.3975)
INFO:root:
--------------------------------------------- END: 2024-12-23 08:04:34 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 08:25:15 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.7                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5157 [12.5 s]    dev=(HR@5:0.2599,NDCG@5:0.1741) [0.4 s] *
INFO:root:Epoch 2     loss=0.4238 [11.4 s]    dev=(HR@5:0.3376,NDCG@5:0.2299) [0.4 s] *
INFO:root:Epoch 3     loss=0.3850 [11.4 s]    dev=(HR@5:0.3680,NDCG@5:0.2541) [0.4 s] *
INFO:root:Epoch 4     loss=0.3585 [11.3 s]    dev=(HR@5:0.3919,NDCG@5:0.2744) [0.4 s] *
INFO:root:Epoch 5     loss=0.3332 [11.3 s]    dev=(HR@5:0.4068,NDCG@5:0.2892) [0.4 s] *
INFO:root:Epoch 6     loss=0.3099 [10.9 s]    dev=(HR@5:0.4231,NDCG@5:0.3036) [0.4 s] *
INFO:root:Epoch 7     loss=0.2925 [11.3 s]    dev=(HR@5:0.4263,NDCG@5:0.3070) [0.4 s] *
INFO:root:Epoch 8     loss=0.2766 [10.9 s]    dev=(HR@5:0.4329,NDCG@5:0.3147) [0.4 s] *
INFO:root:Epoch 9     loss=0.2629 [11.1 s]    dev=(HR@5:0.4367,NDCG@5:0.3187) [0.4 s] *
INFO:root:Epoch 10    loss=0.2533 [9.9 s]    dev=(HR@5:0.4371,NDCG@5:0.3204) [0.4 s] *
INFO:root:Epoch 11    loss=0.2430 [10.2 s]    dev=(HR@5:0.4422,NDCG@5:0.3233) [0.4 s] *
INFO:root:Epoch 12    loss=0.2349 [10.3 s]    dev=(HR@5:0.4426,NDCG@5:0.3229) [0.4 s]
INFO:root:Epoch 13    loss=0.2310 [11.0 s]    dev=(HR@5:0.4487,NDCG@5:0.3294) [0.4 s] *
INFO:root:Epoch 14    loss=0.2266 [11.3 s]    dev=(HR@5:0.4471,NDCG@5:0.3282) [0.4 s]
INFO:root:Epoch 15    loss=0.2233 [11.3 s]    dev=(HR@5:0.4443,NDCG@5:0.3259) [0.4 s]
INFO:root:Epoch 16    loss=0.2209 [11.5 s]    dev=(HR@5:0.4453,NDCG@5:0.3283) [0.4 s]
INFO:root:Epoch 17    loss=0.2172 [11.4 s]    dev=(HR@5:0.4468,NDCG@5:0.3272) [0.4 s]
INFO:root:Epoch 18    loss=0.2137 [11.3 s]    dev=(HR@5:0.4515,NDCG@5:0.3318) [0.4 s] *
INFO:root:Epoch 19    loss=0.2120 [11.3 s]    dev=(HR@5:0.4497,NDCG@5:0.3301) [0.4 s]
INFO:root:Epoch 20    loss=0.2097 [11.1 s]    dev=(HR@5:0.4485,NDCG@5:0.3314) [0.4 s]
INFO:root:Epoch 21    loss=0.2065 [11.2 s]    dev=(HR@5:0.4509,NDCG@5:0.3315) [0.4 s]
INFO:root:Epoch 22    loss=0.2071 [11.6 s]    dev=(HR@5:0.4488,NDCG@5:0.3300) [0.4 s]
INFO:root:Epoch 23    loss=0.2071 [11.3 s]    dev=(HR@5:0.4488,NDCG@5:0.3311) [0.3 s]
INFO:root:Epoch 24    loss=0.2060 [11.4 s]    dev=(HR@5:0.4492,NDCG@5:0.3300) [0.4 s]
INFO:root:Epoch 25    loss=0.2028 [10.9 s]    dev=(HR@5:0.4472,NDCG@5:0.3291) [0.4 s]
INFO:root:Epoch 26    loss=0.2037 [11.3 s]    dev=(HR@5:0.4479,NDCG@5:0.3317) [0.4 s]
INFO:root:Epoch 27    loss=0.2029 [11.0 s]    dev=(HR@5:0.4527,NDCG@5:0.3334) [0.4 s] *
INFO:root:Epoch 28    loss=0.2029 [11.2 s]    dev=(HR@5:0.4537,NDCG@5:0.3358) [0.4 s] *
INFO:root:Epoch 29    loss=0.2009 [11.3 s]    dev=(HR@5:0.4514,NDCG@5:0.3339) [0.4 s]
INFO:root:Epoch 30    loss=0.2017 [11.3 s]    dev=(HR@5:0.4534,NDCG@5:0.3345) [0.4 s]
INFO:root:Epoch 31    loss=0.1993 [11.4 s]    dev=(HR@5:0.4530,NDCG@5:0.3350) [0.4 s]
INFO:root:Epoch 32    loss=0.2003 [11.4 s]    dev=(HR@5:0.4520,NDCG@5:0.3322) [0.4 s]
INFO:root:Epoch 33    loss=0.2006 [11.3 s]    dev=(HR@5:0.4554,NDCG@5:0.3375) [0.4 s] *
INFO:root:Epoch 34    loss=0.2003 [11.3 s]    dev=(HR@5:0.4546,NDCG@5:0.3355) [0.4 s]
INFO:root:Epoch 35    loss=0.1998 [11.3 s]    dev=(HR@5:0.4514,NDCG@5:0.3332) [0.4 s]
INFO:root:Epoch 36    loss=0.1981 [11.4 s]    dev=(HR@5:0.4521,NDCG@5:0.3325) [0.4 s]
INFO:root:Epoch 37    loss=0.1993 [11.3 s]    dev=(HR@5:0.4533,NDCG@5:0.3341) [0.4 s]
INFO:root:Epoch 38    loss=0.1997 [11.2 s]    dev=(HR@5:0.4534,NDCG@5:0.3339) [0.4 s]
INFO:root:Epoch 39    loss=0.1991 [11.4 s]    dev=(HR@5:0.4482,NDCG@5:0.3288) [0.4 s]
INFO:root:Epoch 40    loss=0.1989 [11.1 s]    dev=(HR@5:0.4470,NDCG@5:0.3314) [0.4 s]
INFO:root:Epoch 41    loss=0.1993 [11.4 s]    dev=(HR@5:0.4518,NDCG@5:0.3320) [0.4 s]
INFO:root:Epoch 42    loss=0.1985 [10.9 s]    dev=(HR@5:0.4533,NDCG@5:0.3338) [0.4 s]
INFO:root:Epoch 43    loss=0.1968 [11.3 s]    dev=(HR@5:0.4520,NDCG@5:0.3344) [0.4 s]
INFO:root:Epoch 44    loss=0.1981 [11.3 s]    dev=(HR@5:0.4507,NDCG@5:0.3318) [0.4 s]
INFO:root:Epoch 45    loss=0.1957 [10.9 s]    dev=(HR@5:0.4543,NDCG@5:0.3365) [0.4 s]
INFO:root:Epoch 46    loss=0.1967 [9.9 s]    dev=(HR@5:0.4521,NDCG@5:0.3333) [0.4 s]
INFO:root:Epoch 47    loss=0.1967 [11.5 s]    dev=(HR@5:0.4527,NDCG@5:0.3321) [0.4 s]
INFO:root:Epoch 48    loss=0.1955 [10.5 s]    dev=(HR@5:0.4483,NDCG@5:0.3305) [0.4 s]
INFO:root:Epoch 49    loss=0.1946 [10.4 s]    dev=(HR@5:0.4535,NDCG@5:0.3353) [0.4 s]
INFO:root:Epoch 50    loss=0.1968 [11.2 s]    dev=(HR@5:0.4513,NDCG@5:0.3331) [0.4 s]
INFO:root:Epoch 51    loss=0.1952 [11.3 s]    dev=(HR@5:0.4530,NDCG@5:0.3342) [0.4 s]
INFO:root:Epoch 52    loss=0.1952 [11.3 s]    dev=(HR@5:0.4506,NDCG@5:0.3322) [0.4 s]
INFO:root:Epoch 53    loss=0.1949 [11.3 s]    dev=(HR@5:0.4499,NDCG@5:0.3326) [0.4 s]
INFO:root:Early stop at 53 based on dev result.
INFO:root:
Best Iter(dev)=   33	 dev=(HR@5:0.4554,NDCG@5:0.3375) [611.8 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.4051,NDCG@5:0.2914,HR@10:0.5096,NDCG@10:0.3252,HR@20:0.6295,NDCG@20:0.3554,HR@50:0.8358,NDCG@50:0.3963)
INFO:root:
--------------------------------------------- END: 2024-12-23 08:35:30 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 08:58:19 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 1                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5142 [12.2 s]    dev=(HR@5:0.2517,NDCG@5:0.1674) [0.4 s] *
INFO:root:Epoch 2     loss=0.4311 [10.5 s]    dev=(HR@5:0.3166,NDCG@5:0.2139) [0.4 s] *
INFO:root:Epoch 3     loss=0.3979 [11.0 s]    dev=(HR@5:0.3398,NDCG@5:0.2284) [0.4 s] *
INFO:root:Epoch 4     loss=0.3764 [10.6 s]    dev=(HR@5:0.3571,NDCG@5:0.2440) [0.4 s] *
INFO:root:Epoch 5     loss=0.3528 [11.2 s]    dev=(HR@5:0.3725,NDCG@5:0.2580) [0.4 s] *
INFO:root:Epoch 6     loss=0.3291 [10.8 s]    dev=(HR@5:0.3947,NDCG@5:0.2795) [0.4 s] *
INFO:root:Epoch 7     loss=0.3110 [11.1 s]    dev=(HR@5:0.3968,NDCG@5:0.2806) [0.4 s] *
INFO:root:Epoch 8     loss=0.2985 [10.5 s]    dev=(HR@5:0.4007,NDCG@5:0.2862) [0.4 s] *
INFO:root:Epoch 9     loss=0.2853 [11.0 s]    dev=(HR@5:0.4010,NDCG@5:0.2864) [0.4 s] *
INFO:root:Epoch 10    loss=0.2778 [10.2 s]    dev=(HR@5:0.4056,NDCG@5:0.2902) [0.4 s] *
INFO:root:Epoch 11    loss=0.2692 [11.2 s]    dev=(HR@5:0.4088,NDCG@5:0.2913) [0.4 s] *
INFO:root:Epoch 12    loss=0.2616 [11.0 s]    dev=(HR@5:0.4120,NDCG@5:0.2966) [0.4 s] *
INFO:root:Epoch 13    loss=0.2574 [11.1 s]    dev=(HR@5:0.4177,NDCG@5:0.3004) [0.4 s] *
INFO:root:Epoch 14    loss=0.2526 [10.9 s]    dev=(HR@5:0.4178,NDCG@5:0.2992) [0.3 s]
INFO:root:Epoch 15    loss=0.2493 [10.9 s]    dev=(HR@5:0.4141,NDCG@5:0.2979) [0.4 s]
INFO:root:Epoch 16    loss=0.2465 [11.4 s]    dev=(HR@5:0.4183,NDCG@5:0.3020) [0.4 s] *
INFO:root:Epoch 17    loss=0.2427 [11.1 s]    dev=(HR@5:0.4135,NDCG@5:0.2979) [0.4 s]
INFO:root:Epoch 18    loss=0.2387 [11.3 s]    dev=(HR@5:0.4127,NDCG@5:0.2984) [0.4 s]
INFO:root:Epoch 19    loss=0.2348 [11.2 s]    dev=(HR@5:0.4205,NDCG@5:0.3048) [0.4 s] *
INFO:root:Epoch 20    loss=0.2326 [11.1 s]    dev=(HR@5:0.4254,NDCG@5:0.3081) [0.4 s] *
INFO:root:Epoch 21    loss=0.2274 [10.6 s]    dev=(HR@5:0.4277,NDCG@5:0.3095) [0.4 s] *
INFO:root:Epoch 22    loss=0.2261 [11.4 s]    dev=(HR@5:0.4263,NDCG@5:0.3089) [0.4 s]
INFO:root:Epoch 23    loss=0.2262 [11.1 s]    dev=(HR@5:0.4192,NDCG@5:0.3059) [0.4 s]
INFO:root:Epoch 24    loss=0.2243 [10.2 s]    dev=(HR@5:0.4320,NDCG@5:0.3128) [0.4 s] *
INFO:root:Epoch 25    loss=0.2208 [10.6 s]    dev=(HR@5:0.4293,NDCG@5:0.3108) [0.4 s]
INFO:root:Epoch 26    loss=0.2212 [10.9 s]    dev=(HR@5:0.4323,NDCG@5:0.3138) [0.4 s] *
INFO:root:Epoch 27    loss=0.2196 [11.2 s]    dev=(HR@5:0.4297,NDCG@5:0.3121) [0.4 s]
INFO:root:Epoch 28    loss=0.2201 [11.1 s]    dev=(HR@5:0.4336,NDCG@5:0.3153) [0.4 s] *
INFO:root:Epoch 29    loss=0.2171 [11.1 s]    dev=(HR@5:0.4301,NDCG@5:0.3132) [0.4 s]
INFO:root:Epoch 30    loss=0.2167 [11.2 s]    dev=(HR@5:0.4312,NDCG@5:0.3156) [0.4 s] *
INFO:root:Epoch 31    loss=0.2146 [11.1 s]    dev=(HR@5:0.4337,NDCG@5:0.3167) [0.4 s] *
INFO:root:Epoch 32    loss=0.2162 [11.5 s]    dev=(HR@5:0.4314,NDCG@5:0.3137) [0.4 s]
INFO:root:Epoch 33    loss=0.2152 [11.1 s]    dev=(HR@5:0.4372,NDCG@5:0.3178) [0.4 s] *
INFO:root:Epoch 34    loss=0.2140 [11.0 s]    dev=(HR@5:0.4380,NDCG@5:0.3180) [0.4 s] *
INFO:root:Epoch 35    loss=0.2140 [11.2 s]    dev=(HR@5:0.4325,NDCG@5:0.3142) [0.4 s]
INFO:root:Epoch 36    loss=0.2117 [10.1 s]    dev=(HR@5:0.4289,NDCG@5:0.3113) [0.4 s]
INFO:root:Epoch 37    loss=0.2122 [10.2 s]    dev=(HR@5:0.4332,NDCG@5:0.3161) [0.4 s]
INFO:root:Epoch 38    loss=0.2122 [9.9 s]    dev=(HR@5:0.4351,NDCG@5:0.3155) [0.4 s]
INFO:root:Epoch 39    loss=0.2122 [11.2 s]    dev=(HR@5:0.4284,NDCG@5:0.3109) [0.4 s]
INFO:root:Epoch 40    loss=0.2117 [11.3 s]    dev=(HR@5:0.4342,NDCG@5:0.3154) [0.4 s]
INFO:root:Epoch 41    loss=0.2118 [10.8 s]    dev=(HR@5:0.4320,NDCG@5:0.3131) [0.4 s]
INFO:root:Epoch 42    loss=0.2117 [11.1 s]    dev=(HR@5:0.4344,NDCG@5:0.3168) [0.4 s]
INFO:root:Epoch 43    loss=0.2103 [9.0 s]    dev=(HR@5:0.4389,NDCG@5:0.3205) [0.4 s] *
INFO:root:Epoch 44    loss=0.2116 [10.7 s]    dev=(HR@5:0.4372,NDCG@5:0.3164) [0.4 s]
INFO:root:Epoch 45    loss=0.2082 [11.2 s]    dev=(HR@5:0.4384,NDCG@5:0.3193) [0.4 s]
INFO:root:Epoch 46    loss=0.2093 [11.0 s]    dev=(HR@5:0.4290,NDCG@5:0.3119) [0.4 s]
INFO:root:Epoch 47    loss=0.2104 [11.0 s]    dev=(HR@5:0.4355,NDCG@5:0.3158) [0.4 s]
INFO:root:Epoch 48    loss=0.2096 [11.2 s]    dev=(HR@5:0.4394,NDCG@5:0.3181) [0.4 s]
INFO:root:Epoch 49    loss=0.2073 [10.9 s]    dev=(HR@5:0.4406,NDCG@5:0.3202) [0.4 s]
INFO:root:Epoch 50    loss=0.2087 [11.2 s]    dev=(HR@5:0.4352,NDCG@5:0.3189) [0.4 s]
INFO:root:Epoch 51    loss=0.2081 [11.1 s]    dev=(HR@5:0.4372,NDCG@5:0.3183) [0.4 s]
INFO:root:Epoch 52    loss=0.2072 [11.0 s]    dev=(HR@5:0.4378,NDCG@5:0.3179) [0.4 s]
INFO:root:Epoch 53    loss=0.2080 [11.1 s]    dev=(HR@5:0.4358,NDCG@5:0.3165) [0.4 s]
INFO:root:Epoch 54    loss=0.2056 [11.1 s]    dev=(HR@5:0.4378,NDCG@5:0.3189) [0.4 s]
INFO:root:Epoch 55    loss=0.2066 [10.4 s]    dev=(HR@5:0.4383,NDCG@5:0.3187) [0.4 s]
INFO:root:Epoch 56    loss=0.2059 [11.2 s]    dev=(HR@5:0.4445,NDCG@5:0.3243) [0.4 s] *
INFO:root:Epoch 57    loss=0.2068 [11.2 s]    dev=(HR@5:0.4408,NDCG@5:0.3223) [0.4 s]
INFO:root:Epoch 58    loss=0.2075 [11.1 s]    dev=(HR@5:0.4431,NDCG@5:0.3241) [0.4 s]
INFO:root:Epoch 59    loss=0.2058 [10.7 s]    dev=(HR@5:0.4410,NDCG@5:0.3217) [0.4 s]
INFO:root:Epoch 60    loss=0.2067 [11.0 s]    dev=(HR@5:0.4391,NDCG@5:0.3201) [0.4 s]
INFO:root:Epoch 61    loss=0.2057 [11.0 s]    dev=(HR@5:0.4444,NDCG@5:0.3253) [0.4 s] *
INFO:root:Epoch 62    loss=0.2052 [10.8 s]    dev=(HR@5:0.4415,NDCG@5:0.3218) [0.4 s]
INFO:root:Epoch 63    loss=0.2071 [11.3 s]    dev=(HR@5:0.4434,NDCG@5:0.3235) [0.4 s]
INFO:root:Epoch 64    loss=0.2042 [11.3 s]    dev=(HR@5:0.4406,NDCG@5:0.3210) [0.4 s]
INFO:root:Epoch 65    loss=0.2056 [11.2 s]    dev=(HR@5:0.4402,NDCG@5:0.3207) [0.4 s]
INFO:root:Epoch 66    loss=0.2043 [11.1 s]    dev=(HR@5:0.4385,NDCG@5:0.3184) [0.4 s]
INFO:root:Epoch 67    loss=0.2044 [11.1 s]    dev=(HR@5:0.4408,NDCG@5:0.3214) [0.4 s]
INFO:root:Epoch 68    loss=0.2028 [11.1 s]    dev=(HR@5:0.4388,NDCG@5:0.3215) [0.4 s]
INFO:root:Epoch 69    loss=0.2049 [11.0 s]    dev=(HR@5:0.4365,NDCG@5:0.3183) [0.4 s]
INFO:root:Epoch 70    loss=0.2041 [11.0 s]    dev=(HR@5:0.4351,NDCG@5:0.3194) [0.4 s]
INFO:root:Epoch 71    loss=0.2026 [11.0 s]    dev=(HR@5:0.4361,NDCG@5:0.3179) [0.4 s]
INFO:root:Epoch 72    loss=0.2025 [11.1 s]    dev=(HR@5:0.4376,NDCG@5:0.3189) [0.4 s]
INFO:root:Epoch 73    loss=0.2033 [11.0 s]    dev=(HR@5:0.4367,NDCG@5:0.3183) [0.4 s]
INFO:root:Epoch 74    loss=0.2027 [11.3 s]    dev=(HR@5:0.4349,NDCG@5:0.3157) [0.4 s]
INFO:root:Epoch 75    loss=0.2048 [11.2 s]    dev=(HR@5:0.4396,NDCG@5:0.3188) [0.4 s]
INFO:root:Epoch 76    loss=0.2028 [11.2 s]    dev=(HR@5:0.4445,NDCG@5:0.3236) [0.4 s]
INFO:root:Epoch 77    loss=0.2020 [11.1 s]    dev=(HR@5:0.4395,NDCG@5:0.3206) [0.4 s]
INFO:root:Epoch 78    loss=0.2020 [11.8 s]    dev=(HR@5:0.4415,NDCG@5:0.3187) [0.4 s]
INFO:root:Epoch 79    loss=0.2025 [11.2 s]    dev=(HR@5:0.4417,NDCG@5:0.3211) [0.4 s]
INFO:root:Epoch 80    loss=0.2001 [11.0 s]    dev=(HR@5:0.4421,NDCG@5:0.3208) [0.4 s]
INFO:root:Epoch 81    loss=0.2007 [11.1 s]    dev=(HR@5:0.4368,NDCG@5:0.3161) [0.4 s]
INFO:root:Early stop at 81 based on dev result.
INFO:root:
Best Iter(dev)=   61	 dev=(HR@5:0.4444,NDCG@5:0.3253) [921.7 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.3917,NDCG@5:0.2791,HR@10:0.5047,NDCG@10:0.3158,HR@20:0.6271,NDCG@20:0.3467,HR@50:0.8340,NDCG@50:0.3877)
INFO:root:
--------------------------------------------- END: 2024-12-23 09:13:43 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 09:44:05 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 3                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5140 [12.3 s]    dev=(HR@5:0.2617,NDCG@5:0.1753) [0.4 s] *
INFO:root:Epoch 2     loss=0.4228 [10.9 s]    dev=(HR@5:0.3347,NDCG@5:0.2285) [0.4 s] *
INFO:root:Epoch 3     loss=0.3866 [11.0 s]    dev=(HR@5:0.3635,NDCG@5:0.2492) [0.4 s] *
INFO:root:Epoch 4     loss=0.3630 [10.9 s]    dev=(HR@5:0.3822,NDCG@5:0.2660) [0.4 s] *
INFO:root:Epoch 5     loss=0.3378 [10.2 s]    dev=(HR@5:0.4006,NDCG@5:0.2811) [0.4 s] *
INFO:root:Epoch 6     loss=0.3132 [10.7 s]    dev=(HR@5:0.4116,NDCG@5:0.2924) [0.4 s] *
INFO:root:Epoch 7     loss=0.2958 [11.1 s]    dev=(HR@5:0.4156,NDCG@5:0.2953) [0.4 s] *
INFO:root:Epoch 8     loss=0.2825 [11.0 s]    dev=(HR@5:0.4203,NDCG@5:0.3027) [0.4 s] *
INFO:root:Epoch 9     loss=0.2696 [11.0 s]    dev=(HR@5:0.4216,NDCG@5:0.3037) [0.4 s] *
INFO:root:Epoch 10    loss=0.2613 [11.2 s]    dev=(HR@5:0.4231,NDCG@5:0.3058) [0.4 s] *
INFO:root:Epoch 11    loss=0.2526 [11.3 s]    dev=(HR@5:0.4305,NDCG@5:0.3113) [0.4 s] *
INFO:root:Epoch 12    loss=0.2451 [10.7 s]    dev=(HR@5:0.4335,NDCG@5:0.3129) [0.4 s] *
INFO:root:Epoch 13    loss=0.2401 [11.0 s]    dev=(HR@5:0.4402,NDCG@5:0.3181) [0.4 s] *
INFO:root:Epoch 14    loss=0.2356 [11.0 s]    dev=(HR@5:0.4404,NDCG@5:0.3176) [0.4 s]
INFO:root:Epoch 15    loss=0.2320 [11.0 s]    dev=(HR@5:0.4377,NDCG@5:0.3182) [0.4 s] *
INFO:root:Epoch 16    loss=0.2292 [11.1 s]    dev=(HR@5:0.4393,NDCG@5:0.3190) [0.4 s] *
INFO:root:Epoch 17    loss=0.2255 [11.3 s]    dev=(HR@5:0.4398,NDCG@5:0.3185) [0.4 s]
INFO:root:Epoch 18    loss=0.2208 [11.2 s]    dev=(HR@5:0.4395,NDCG@5:0.3203) [0.4 s] *
INFO:root:Epoch 19    loss=0.2191 [11.0 s]    dev=(HR@5:0.4397,NDCG@5:0.3194) [0.4 s]
INFO:root:Epoch 20    loss=0.2175 [10.7 s]    dev=(HR@5:0.4421,NDCG@5:0.3229) [0.4 s] *
INFO:root:Epoch 21    loss=0.2134 [11.2 s]    dev=(HR@5:0.4432,NDCG@5:0.3217) [0.4 s]
INFO:root:Epoch 22    loss=0.2128 [10.9 s]    dev=(HR@5:0.4405,NDCG@5:0.3206) [0.4 s]
INFO:root:Epoch 23    loss=0.2135 [10.6 s]    dev=(HR@5:0.4416,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 24    loss=0.2132 [10.9 s]    dev=(HR@5:0.4445,NDCG@5:0.3217) [0.4 s]
INFO:root:Epoch 25    loss=0.2097 [10.7 s]    dev=(HR@5:0.4386,NDCG@5:0.3186) [0.4 s]
INFO:root:Epoch 26    loss=0.2101 [9.8 s]    dev=(HR@5:0.4400,NDCG@5:0.3190) [0.4 s]
INFO:root:Epoch 27    loss=0.2092 [11.0 s]    dev=(HR@5:0.4392,NDCG@5:0.3187) [0.4 s]
INFO:root:Epoch 28    loss=0.2095 [10.8 s]    dev=(HR@5:0.4427,NDCG@5:0.3244) [0.4 s] *
INFO:root:Epoch 29    loss=0.2078 [10.5 s]    dev=(HR@5:0.4425,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 30    loss=0.2067 [10.8 s]    dev=(HR@5:0.4410,NDCG@5:0.3215) [0.4 s]
INFO:root:Epoch 31    loss=0.2066 [11.0 s]    dev=(HR@5:0.4408,NDCG@5:0.3231) [0.4 s]
INFO:root:Epoch 32    loss=0.2067 [10.4 s]    dev=(HR@5:0.4406,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 33    loss=0.2073 [10.9 s]    dev=(HR@5:0.4423,NDCG@5:0.3244) [0.4 s] *
INFO:root:Epoch 34    loss=0.2059 [10.9 s]    dev=(HR@5:0.4431,NDCG@5:0.3237) [0.4 s]
INFO:root:Epoch 35    loss=0.2067 [11.2 s]    dev=(HR@5:0.4379,NDCG@5:0.3183) [0.4 s]
INFO:root:Epoch 36    loss=0.2053 [10.7 s]    dev=(HR@5:0.4407,NDCG@5:0.3208) [0.4 s]
INFO:root:Epoch 37    loss=0.2060 [10.5 s]    dev=(HR@5:0.4381,NDCG@5:0.3192) [0.4 s]
INFO:root:Epoch 38    loss=0.2058 [10.7 s]    dev=(HR@5:0.4409,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 39    loss=0.2064 [11.1 s]    dev=(HR@5:0.4342,NDCG@5:0.3154) [0.4 s]
INFO:root:Epoch 40    loss=0.2056 [10.6 s]    dev=(HR@5:0.4398,NDCG@5:0.3193) [0.4 s]
INFO:root:Epoch 41    loss=0.2062 [10.4 s]    dev=(HR@5:0.4392,NDCG@5:0.3199) [0.4 s]
INFO:root:Epoch 42    loss=0.2059 [10.4 s]    dev=(HR@5:0.4440,NDCG@5:0.3223) [0.4 s]
INFO:root:Epoch 43    loss=0.2047 [10.7 s]    dev=(HR@5:0.4434,NDCG@5:0.3240) [0.4 s]
INFO:root:Epoch 44    loss=0.2057 [11.4 s]    dev=(HR@5:0.4385,NDCG@5:0.3200) [0.4 s]
INFO:root:Epoch 45    loss=0.2030 [11.3 s]    dev=(HR@5:0.4445,NDCG@5:0.3244) [0.4 s]
INFO:root:Epoch 46    loss=0.2045 [11.0 s]    dev=(HR@5:0.4374,NDCG@5:0.3176) [0.4 s]
INFO:root:Epoch 47    loss=0.2043 [10.6 s]    dev=(HR@5:0.4375,NDCG@5:0.3185) [0.4 s]
INFO:root:Epoch 48    loss=0.2043 [11.1 s]    dev=(HR@5:0.4398,NDCG@5:0.3203) [0.4 s]
INFO:root:Epoch 49    loss=0.2023 [11.3 s]    dev=(HR@5:0.4401,NDCG@5:0.3220) [0.4 s]
INFO:root:Epoch 50    loss=0.2047 [11.1 s]    dev=(HR@5:0.4412,NDCG@5:0.3228) [0.4 s]
INFO:root:Epoch 51    loss=0.2026 [11.0 s]    dev=(HR@5:0.4388,NDCG@5:0.3213) [0.4 s]
INFO:root:Epoch 52    loss=0.2031 [11.0 s]    dev=(HR@5:0.4419,NDCG@5:0.3223) [0.4 s]
INFO:root:Epoch 53    loss=0.2036 [9.9 s]    dev=(HR@5:0.4374,NDCG@5:0.3198) [0.4 s]
INFO:root:Early stop at 53 based on dev result.
INFO:root:
Best Iter(dev)=   33	 dev=(HR@5:0.4423,NDCG@5:0.3244) [597.2 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.3974,NDCG@5:0.2807,HR@10:0.5055,NDCG@10:0.3155,HR@20:0.6281,NDCG@20:0.3464,HR@50:0.8335,NDCG@50:0.3871)
INFO:root:
--------------------------------------------- END: 2024-12-23 09:54:05 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 10:30:52 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 5                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5141 [12.6 s]    dev=(HR@5:0.2646,NDCG@5:0.1771) [0.4 s] *
INFO:root:Epoch 2     loss=0.4212 [10.9 s]    dev=(HR@5:0.3387,NDCG@5:0.2315) [0.4 s] *
INFO:root:Epoch 3     loss=0.3839 [11.4 s]    dev=(HR@5:0.3701,NDCG@5:0.2543) [0.4 s] *
INFO:root:Epoch 4     loss=0.3599 [11.3 s]    dev=(HR@5:0.3892,NDCG@5:0.2700) [0.4 s] *
INFO:root:Epoch 5     loss=0.3362 [11.2 s]    dev=(HR@5:0.4021,NDCG@5:0.2852) [0.4 s] *
INFO:root:Epoch 6     loss=0.3109 [11.1 s]    dev=(HR@5:0.4215,NDCG@5:0.3021) [0.4 s] *
INFO:root:Epoch 7     loss=0.2924 [11.0 s]    dev=(HR@5:0.4277,NDCG@5:0.3071) [0.4 s] *
INFO:root:Epoch 8     loss=0.2767 [11.0 s]    dev=(HR@5:0.4312,NDCG@5:0.3134) [0.4 s] *
INFO:root:Epoch 9     loss=0.2633 [10.6 s]    dev=(HR@5:0.4363,NDCG@5:0.3170) [0.4 s] *
INFO:root:Epoch 10    loss=0.2544 [11.4 s]    dev=(HR@5:0.4378,NDCG@5:0.3211) [0.4 s] *
INFO:root:Epoch 11    loss=0.2452 [11.4 s]    dev=(HR@5:0.4421,NDCG@5:0.3230) [0.4 s] *
INFO:root:Epoch 12    loss=0.2372 [11.4 s]    dev=(HR@5:0.4460,NDCG@5:0.3256) [0.4 s] *
INFO:root:Epoch 13    loss=0.2329 [10.9 s]    dev=(HR@5:0.4474,NDCG@5:0.3286) [0.4 s] *
INFO:root:Epoch 14    loss=0.2287 [11.1 s]    dev=(HR@5:0.4488,NDCG@5:0.3284) [0.4 s]
INFO:root:Epoch 15    loss=0.2254 [11.1 s]    dev=(HR@5:0.4457,NDCG@5:0.3272) [0.4 s]
INFO:root:Epoch 16    loss=0.2226 [10.9 s]    dev=(HR@5:0.4478,NDCG@5:0.3295) [0.4 s] *
INFO:root:Epoch 17    loss=0.2198 [11.4 s]    dev=(HR@5:0.4485,NDCG@5:0.3288) [0.4 s]
INFO:root:Epoch 18    loss=0.2151 [11.1 s]    dev=(HR@5:0.4494,NDCG@5:0.3296) [0.4 s] *
INFO:root:Epoch 19    loss=0.2140 [10.6 s]    dev=(HR@5:0.4503,NDCG@5:0.3321) [0.4 s] *
INFO:root:Epoch 20    loss=0.2108 [10.2 s]    dev=(HR@5:0.4493,NDCG@5:0.3308) [0.4 s]
INFO:root:Epoch 21    loss=0.2070 [11.1 s]    dev=(HR@5:0.4474,NDCG@5:0.3299) [0.4 s]
INFO:root:Epoch 22    loss=0.2075 [10.6 s]    dev=(HR@5:0.4461,NDCG@5:0.3305) [0.4 s]
INFO:root:Epoch 23    loss=0.2077 [10.9 s]    dev=(HR@5:0.4438,NDCG@5:0.3290) [0.4 s]
INFO:root:Epoch 24    loss=0.2064 [10.7 s]    dev=(HR@5:0.4485,NDCG@5:0.3300) [0.4 s]
INFO:root:Epoch 25    loss=0.2035 [10.5 s]    dev=(HR@5:0.4453,NDCG@5:0.3288) [0.4 s]
INFO:root:Epoch 26    loss=0.2042 [10.9 s]    dev=(HR@5:0.4468,NDCG@5:0.3294) [0.4 s]
INFO:root:Epoch 27    loss=0.2036 [10.3 s]    dev=(HR@5:0.4451,NDCG@5:0.3306) [0.4 s]
INFO:root:Epoch 28    loss=0.2027 [10.9 s]    dev=(HR@5:0.4486,NDCG@5:0.3324) [0.4 s] *
INFO:root:Epoch 29    loss=0.2009 [11.0 s]    dev=(HR@5:0.4476,NDCG@5:0.3312) [0.4 s]
INFO:root:Epoch 30    loss=0.2016 [11.1 s]    dev=(HR@5:0.4483,NDCG@5:0.3304) [0.4 s]
INFO:root:Epoch 31    loss=0.2004 [11.1 s]    dev=(HR@5:0.4518,NDCG@5:0.3350) [0.4 s] *
INFO:root:Epoch 32    loss=0.2010 [10.1 s]    dev=(HR@5:0.4461,NDCG@5:0.3293) [0.4 s]
INFO:root:Epoch 33    loss=0.2010 [11.2 s]    dev=(HR@5:0.4511,NDCG@5:0.3338) [0.4 s]
INFO:root:Epoch 34    loss=0.2004 [11.1 s]    dev=(HR@5:0.4492,NDCG@5:0.3320) [0.4 s]
INFO:root:Epoch 35    loss=0.2011 [11.1 s]    dev=(HR@5:0.4470,NDCG@5:0.3294) [0.4 s]
INFO:root:Epoch 36    loss=0.1985 [10.9 s]    dev=(HR@5:0.4460,NDCG@5:0.3282) [0.4 s]
INFO:root:Epoch 37    loss=0.1987 [10.0 s]    dev=(HR@5:0.4495,NDCG@5:0.3311) [0.4 s]
INFO:root:Epoch 38    loss=0.1995 [11.3 s]    dev=(HR@5:0.4502,NDCG@5:0.3315) [0.4 s]
INFO:root:Epoch 39    loss=0.1998 [11.3 s]    dev=(HR@5:0.4433,NDCG@5:0.3261) [0.4 s]
INFO:root:Epoch 40    loss=0.1988 [11.2 s]    dev=(HR@5:0.4436,NDCG@5:0.3276) [0.4 s]
INFO:root:Epoch 41    loss=0.2000 [11.1 s]    dev=(HR@5:0.4492,NDCG@5:0.3306) [0.4 s]
INFO:root:Epoch 42    loss=0.1986 [9.9 s]    dev=(HR@5:0.4504,NDCG@5:0.3298) [0.4 s]
INFO:root:Epoch 43    loss=0.1972 [11.1 s]    dev=(HR@5:0.4522,NDCG@5:0.3327) [0.4 s]
INFO:root:Epoch 44    loss=0.1990 [10.8 s]    dev=(HR@5:0.4489,NDCG@5:0.3294) [0.4 s]
INFO:root:Epoch 45    loss=0.1956 [11.2 s]    dev=(HR@5:0.4504,NDCG@5:0.3324) [0.4 s]
INFO:root:Epoch 46    loss=0.1971 [11.2 s]    dev=(HR@5:0.4480,NDCG@5:0.3296) [0.4 s]
INFO:root:Epoch 47    loss=0.1972 [11.2 s]    dev=(HR@5:0.4477,NDCG@5:0.3296) [0.4 s]
INFO:root:Epoch 48    loss=0.1974 [11.1 s]    dev=(HR@5:0.4474,NDCG@5:0.3286) [0.4 s]
INFO:root:Epoch 49    loss=0.1963 [11.0 s]    dev=(HR@5:0.4505,NDCG@5:0.3307) [0.4 s]
INFO:root:Epoch 50    loss=0.1978 [11.1 s]    dev=(HR@5:0.4470,NDCG@5:0.3297) [0.4 s]
INFO:root:Epoch 51    loss=0.1965 [11.3 s]    dev=(HR@5:0.4491,NDCG@5:0.3321) [0.4 s]
INFO:root:Early stop at 51 based on dev result.
INFO:root:
Best Iter(dev)=   31	 dev=(HR@5:0.4518,NDCG@5:0.3350) [580.6 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.4009,NDCG@5:0.2880,HR@10:0.5079,NDCG@10:0.3226,HR@20:0.6286,NDCG@20:0.3530,HR@50:0.8326,NDCG@50:0.3934)
INFO:root:
--------------------------------------------- END: 2024-12-23 10:40:35 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 11:00:36 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 7                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5143 [12.4 s]    dev=(HR@5:0.2597,NDCG@5:0.1742) [0.4 s] *
INFO:root:Epoch 2     loss=0.4232 [11.1 s]    dev=(HR@5:0.3359,NDCG@5:0.2284) [0.4 s] *
INFO:root:Epoch 3     loss=0.3858 [11.0 s]    dev=(HR@5:0.3646,NDCG@5:0.2490) [0.4 s] *
INFO:root:Epoch 4     loss=0.3597 [10.7 s]    dev=(HR@5:0.3885,NDCG@5:0.2710) [0.4 s] *
INFO:root:Epoch 5     loss=0.3335 [11.2 s]    dev=(HR@5:0.4051,NDCG@5:0.2876) [0.4 s] *
INFO:root:Epoch 6     loss=0.3095 [11.2 s]    dev=(HR@5:0.4196,NDCG@5:0.2999) [0.4 s] *
INFO:root:Epoch 7     loss=0.2934 [11.1 s]    dev=(HR@5:0.4219,NDCG@5:0.3022) [0.4 s] *
INFO:root:Epoch 8     loss=0.2803 [11.2 s]    dev=(HR@5:0.4292,NDCG@5:0.3097) [0.4 s] *
INFO:root:Epoch 9     loss=0.2675 [11.0 s]    dev=(HR@5:0.4300,NDCG@5:0.3104) [0.4 s] *
INFO:root:Epoch 10    loss=0.2593 [11.1 s]    dev=(HR@5:0.4316,NDCG@5:0.3137) [0.4 s] *
INFO:root:Epoch 11    loss=0.2502 [11.1 s]    dev=(HR@5:0.4364,NDCG@5:0.3155) [0.4 s] *
INFO:root:Epoch 12    loss=0.2426 [11.1 s]    dev=(HR@5:0.4402,NDCG@5:0.3202) [0.4 s] *
INFO:root:Epoch 13    loss=0.2390 [11.2 s]    dev=(HR@5:0.4420,NDCG@5:0.3237) [0.4 s] *
INFO:root:Epoch 14    loss=0.2350 [11.1 s]    dev=(HR@5:0.4427,NDCG@5:0.3220) [0.4 s]
INFO:root:Epoch 15    loss=0.2308 [11.0 s]    dev=(HR@5:0.4402,NDCG@5:0.3217) [0.4 s]
INFO:root:Epoch 16    loss=0.2289 [11.0 s]    dev=(HR@5:0.4416,NDCG@5:0.3218) [0.4 s]
INFO:root:Epoch 17    loss=0.2255 [11.2 s]    dev=(HR@5:0.4383,NDCG@5:0.3217) [0.4 s]
INFO:root:Epoch 18    loss=0.2207 [11.0 s]    dev=(HR@5:0.4448,NDCG@5:0.3239) [0.4 s] *
INFO:root:Epoch 19    loss=0.2199 [11.1 s]    dev=(HR@5:0.4418,NDCG@5:0.3241) [0.4 s] *
INFO:root:Epoch 20    loss=0.2161 [10.8 s]    dev=(HR@5:0.4443,NDCG@5:0.3276) [0.4 s] *
INFO:root:Epoch 21    loss=0.2138 [11.0 s]    dev=(HR@5:0.4427,NDCG@5:0.3261) [0.4 s]
INFO:root:Epoch 22    loss=0.2131 [11.1 s]    dev=(HR@5:0.4406,NDCG@5:0.3265) [0.4 s]
INFO:root:Epoch 23    loss=0.2139 [11.2 s]    dev=(HR@5:0.4418,NDCG@5:0.3275) [0.4 s]
INFO:root:Epoch 24    loss=0.2133 [11.2 s]    dev=(HR@5:0.4451,NDCG@5:0.3269) [0.4 s]
INFO:root:Epoch 25    loss=0.2094 [10.9 s]    dev=(HR@5:0.4438,NDCG@5:0.3262) [0.4 s]
INFO:root:Epoch 26    loss=0.2096 [10.5 s]    dev=(HR@5:0.4446,NDCG@5:0.3296) [0.4 s] *
INFO:root:Epoch 27    loss=0.2106 [11.0 s]    dev=(HR@5:0.4451,NDCG@5:0.3297) [0.4 s] *
INFO:root:Epoch 28    loss=0.2100 [11.0 s]    dev=(HR@5:0.4449,NDCG@5:0.3296) [0.4 s]
INFO:root:Epoch 29    loss=0.2081 [11.1 s]    dev=(HR@5:0.4442,NDCG@5:0.3290) [0.4 s]
INFO:root:Epoch 30    loss=0.2083 [11.1 s]    dev=(HR@5:0.4430,NDCG@5:0.3292) [0.4 s]
INFO:root:Epoch 31    loss=0.2062 [11.0 s]    dev=(HR@5:0.4449,NDCG@5:0.3315) [0.4 s] *
INFO:root:Epoch 32    loss=0.2075 [11.0 s]    dev=(HR@5:0.4458,NDCG@5:0.3287) [0.4 s]
INFO:root:Epoch 33    loss=0.2071 [11.1 s]    dev=(HR@5:0.4447,NDCG@5:0.3306) [0.4 s]
INFO:root:Epoch 34    loss=0.2070 [10.8 s]    dev=(HR@5:0.4447,NDCG@5:0.3300) [0.4 s]
INFO:root:Epoch 35    loss=0.2073 [11.1 s]    dev=(HR@5:0.4434,NDCG@5:0.3281) [0.4 s]
INFO:root:Epoch 36    loss=0.2052 [11.2 s]    dev=(HR@5:0.4416,NDCG@5:0.3254) [0.4 s]
INFO:root:Epoch 37    loss=0.2052 [11.1 s]    dev=(HR@5:0.4463,NDCG@5:0.3293) [0.4 s]
INFO:root:Epoch 38    loss=0.2059 [11.4 s]    dev=(HR@5:0.4446,NDCG@5:0.3293) [0.4 s]
INFO:root:Epoch 39    loss=0.2060 [10.8 s]    dev=(HR@5:0.4370,NDCG@5:0.3234) [0.4 s]
INFO:root:Epoch 40    loss=0.2050 [10.7 s]    dev=(HR@5:0.4417,NDCG@5:0.3260) [0.4 s]
INFO:root:Epoch 41    loss=0.2056 [11.0 s]    dev=(HR@5:0.4435,NDCG@5:0.3267) [0.4 s]
INFO:root:Epoch 42    loss=0.2051 [11.1 s]    dev=(HR@5:0.4443,NDCG@5:0.3260) [0.4 s]
INFO:root:Epoch 43    loss=0.2035 [10.9 s]    dev=(HR@5:0.4467,NDCG@5:0.3291) [0.4 s]
INFO:root:Epoch 44    loss=0.2050 [11.2 s]    dev=(HR@5:0.4440,NDCG@5:0.3278) [0.4 s]
INFO:root:Epoch 45    loss=0.2030 [10.6 s]    dev=(HR@5:0.4483,NDCG@5:0.3330) [0.4 s] *
INFO:root:Epoch 46    loss=0.2039 [11.0 s]    dev=(HR@5:0.4439,NDCG@5:0.3280) [0.4 s]
INFO:root:Epoch 47    loss=0.2041 [11.0 s]    dev=(HR@5:0.4465,NDCG@5:0.3279) [0.3 s]
INFO:root:Epoch 48    loss=0.2037 [10.5 s]    dev=(HR@5:0.4453,NDCG@5:0.3288) [0.4 s]
INFO:root:Epoch 49    loss=0.2020 [9.8 s]    dev=(HR@5:0.4489,NDCG@5:0.3318) [0.4 s]
INFO:root:Epoch 50    loss=0.2038 [11.0 s]    dev=(HR@5:0.4451,NDCG@5:0.3269) [0.4 s]
INFO:root:Epoch 51    loss=0.2023 [11.0 s]    dev=(HR@5:0.4451,NDCG@5:0.3291) [0.4 s]
INFO:root:Epoch 52    loss=0.2028 [11.1 s]    dev=(HR@5:0.4435,NDCG@5:0.3272) [0.4 s]
INFO:root:Epoch 53    loss=0.2028 [11.1 s]    dev=(HR@5:0.4410,NDCG@5:0.3250) [0.4 s]
INFO:root:Epoch 54    loss=0.2012 [11.2 s]    dev=(HR@5:0.4427,NDCG@5:0.3258) [0.4 s]
INFO:root:Epoch 55    loss=0.2011 [11.1 s]    dev=(HR@5:0.4455,NDCG@5:0.3286) [0.4 s]
INFO:root:Epoch 56    loss=0.2016 [11.1 s]    dev=(HR@5:0.4460,NDCG@5:0.3290) [0.4 s]
INFO:root:Epoch 57    loss=0.2021 [11.0 s]    dev=(HR@5:0.4436,NDCG@5:0.3288) [0.4 s]
INFO:root:Epoch 58    loss=0.2027 [10.7 s]    dev=(HR@5:0.4471,NDCG@5:0.3308) [0.4 s]
INFO:root:Epoch 59    loss=0.2019 [11.5 s]    dev=(HR@5:0.4457,NDCG@5:0.3295) [0.4 s]
INFO:root:Epoch 60    loss=0.2019 [10.9 s]    dev=(HR@5:0.4472,NDCG@5:0.3308) [0.4 s]
INFO:root:Epoch 61    loss=0.2018 [11.0 s]    dev=(HR@5:0.4472,NDCG@5:0.3299) [0.4 s]
INFO:root:Epoch 62    loss=0.2009 [11.2 s]    dev=(HR@5:0.4469,NDCG@5:0.3283) [0.4 s]
INFO:root:Epoch 63    loss=0.2024 [10.0 s]    dev=(HR@5:0.4503,NDCG@5:0.3312) [0.4 s]
INFO:root:Epoch 64    loss=0.1996 [10.2 s]    dev=(HR@5:0.4452,NDCG@5:0.3278) [0.4 s]
INFO:root:Epoch 65    loss=0.2012 [10.6 s]    dev=(HR@5:0.4410,NDCG@5:0.3249) [0.4 s]
INFO:root:Early stop at 65 based on dev result.
INFO:root:
Best Iter(dev)=   45	 dev=(HR@5:0.4483,NDCG@5:0.3330) [739.4 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.3993,NDCG@5:0.2883,HR@10:0.5060,NDCG@10:0.3229,HR@20:0.6318,NDCG@20:0.3546,HR@50:0.8340,NDCG@50:0.3947)
INFO:root:
--------------------------------------------- END: 2024-12-23 11:12:58 ---------------------------------------------
INFO:root:Namespace(model_name='BSARec')
INFO:root:--------------------------------------------- BEGIN: 2024-12-23 11:35:49 ---------------------------------------------
INFO:root:
=====================================================
 Arguments                    | Values               
=====================================================
 alpha                        | 0.9                 
 attention_probs_dropout_prob | 0.1                 
 batch_size                   | 256                 
 c                            | 9                   
 dataset                      | Grocery_and_Gourm...
 dropout                      | 0                   
 early_stop                   | 10                  
 emb_size                     | 64                  
 epoch                        | 200                 
 eval_batch_size              | 256                 
 gpu                          | 0                   
 hidden_dropout_prob          | 0.1                 
 hidden_size                  | 64                  
 history_max                  | 50                  
 l2                           | 0.001               
 lr                           | 0.0005              
 num_heads                    | 1                   
 num_layers                   | 2                   
 num_neg                      | 1                   
 num_workers                  | 0                   
 optimizer                    | Adam                
 random_seed                  | 0                   
 test_all                     | 0                   
 topk                         | 5,10,20,50          
=====================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/Grocery_and_Gourmet_Food/SeqReader.pkl
INFO:root:#params: 661312
INFO:root:BSARec(
  (i_embeddings): Embedding(8714, 64)
  (p_embeddings): Embedding(51, 64)
  (transformer_block): ModuleList(
    (0): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): BSARecBlock(
      (layer): BSARecLayer(
        (filter_layer): FrequencyLayer(
          (out_dropout): Dropout(p=0, inplace=False)
          (LayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (attention_layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (feed_forward): FeedForward(
        (dense_1): Linear(in_features=64, out_features=256, bias=True)
        (dense_2): Linear(in_features=256, out_features=64, bias=True)
        (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5146 [11.9 s]    dev=(HR@5:0.2589,NDCG@5:0.1734) [0.4 s] *
INFO:root:Epoch 2     loss=0.4243 [11.9 s]    dev=(HR@5:0.3325,NDCG@5:0.2258) [0.4 s] *
INFO:root:Epoch 3     loss=0.3870 [11.2 s]    dev=(HR@5:0.3617,NDCG@5:0.2471) [0.4 s] *
INFO:root:Epoch 4     loss=0.3608 [11.6 s]    dev=(HR@5:0.3884,NDCG@5:0.2698) [0.4 s] *
INFO:root:Epoch 5     loss=0.3339 [11.6 s]    dev=(HR@5:0.4047,NDCG@5:0.2876) [0.4 s] *
INFO:root:Epoch 6     loss=0.3088 [11.6 s]    dev=(HR@5:0.4194,NDCG@5:0.3010) [0.4 s] *
INFO:root:Epoch 7     loss=0.2917 [11.6 s]    dev=(HR@5:0.4250,NDCG@5:0.3044) [0.4 s] *
INFO:root:Epoch 8     loss=0.2774 [11.8 s]    dev=(HR@5:0.4295,NDCG@5:0.3106) [0.4 s] *
INFO:root:Epoch 9     loss=0.2643 [11.8 s]    dev=(HR@5:0.4340,NDCG@5:0.3142) [0.4 s] *
INFO:root:Epoch 10    loss=0.2555 [11.5 s]    dev=(HR@5:0.4377,NDCG@5:0.3185) [0.3 s] *
INFO:root:Epoch 11    loss=0.2457 [9.8 s]    dev=(HR@5:0.4393,NDCG@5:0.3190) [0.3 s] *
INFO:root:Epoch 12    loss=0.2375 [11.2 s]    dev=(HR@5:0.4442,NDCG@5:0.3246) [0.3 s] *
INFO:root:Epoch 13    loss=0.2335 [10.9 s]    dev=(HR@5:0.4472,NDCG@5:0.3282) [0.4 s] *
INFO:root:Epoch 14    loss=0.2290 [11.7 s]    dev=(HR@5:0.4451,NDCG@5:0.3256) [0.4 s]
INFO:root:Epoch 15    loss=0.2247 [10.5 s]    dev=(HR@5:0.4453,NDCG@5:0.3264) [0.4 s]
INFO:root:Epoch 16    loss=0.2216 [11.1 s]    dev=(HR@5:0.4444,NDCG@5:0.3279) [0.4 s]
INFO:root:Epoch 17    loss=0.2179 [11.1 s]    dev=(HR@5:0.4486,NDCG@5:0.3302) [0.4 s] *
INFO:root:Epoch 18    loss=0.2134 [11.3 s]    dev=(HR@5:0.4513,NDCG@5:0.3312) [0.4 s] *
INFO:root:Epoch 19    loss=0.2120 [11.1 s]    dev=(HR@5:0.4484,NDCG@5:0.3307) [0.4 s]
INFO:root:Epoch 20    loss=0.2091 [11.2 s]    dev=(HR@5:0.4484,NDCG@5:0.3323) [0.4 s] *
INFO:root:Epoch 21    loss=0.2059 [11.0 s]    dev=(HR@5:0.4489,NDCG@5:0.3317) [0.4 s]
INFO:root:Epoch 22    loss=0.2048 [11.2 s]    dev=(HR@5:0.4483,NDCG@5:0.3326) [0.4 s] *
INFO:root:Epoch 23    loss=0.2061 [11.0 s]    dev=(HR@5:0.4498,NDCG@5:0.3331) [0.4 s] *
INFO:root:Epoch 24    loss=0.2045 [11.2 s]    dev=(HR@5:0.4481,NDCG@5:0.3315) [0.4 s]
INFO:root:Epoch 25    loss=0.2012 [10.9 s]    dev=(HR@5:0.4488,NDCG@5:0.3316) [0.4 s]
INFO:root:Epoch 26    loss=0.2011 [11.0 s]    dev=(HR@5:0.4459,NDCG@5:0.3320) [0.4 s]
INFO:root:Epoch 27    loss=0.2012 [11.0 s]    dev=(HR@5:0.4507,NDCG@5:0.3343) [0.4 s] *
INFO:root:Epoch 28    loss=0.2014 [11.0 s]    dev=(HR@5:0.4506,NDCG@5:0.3342) [0.3 s]
INFO:root:Epoch 29    loss=0.1994 [11.1 s]    dev=(HR@5:0.4494,NDCG@5:0.3340) [0.4 s]
INFO:root:Epoch 30    loss=0.1995 [11.1 s]    dev=(HR@5:0.4527,NDCG@5:0.3350) [0.4 s] *
INFO:root:Epoch 31    loss=0.1969 [10.9 s]    dev=(HR@5:0.4502,NDCG@5:0.3354) [0.4 s] *
INFO:root:Epoch 32    loss=0.1979 [10.9 s]    dev=(HR@5:0.4506,NDCG@5:0.3340) [0.4 s]
INFO:root:Epoch 33    loss=0.1983 [10.9 s]    dev=(HR@5:0.4508,NDCG@5:0.3358) [0.4 s] *
INFO:root:Epoch 34    loss=0.1971 [11.1 s]    dev=(HR@5:0.4486,NDCG@5:0.3339) [0.4 s]
INFO:root:Epoch 35    loss=0.1972 [10.8 s]    dev=(HR@5:0.4503,NDCG@5:0.3346) [0.4 s]
INFO:root:Epoch 36    loss=0.1955 [11.1 s]    dev=(HR@5:0.4496,NDCG@5:0.3327) [0.3 s]
INFO:root:Epoch 37    loss=0.1961 [10.4 s]    dev=(HR@5:0.4551,NDCG@5:0.3359) [0.4 s] *
INFO:root:Epoch 38    loss=0.1964 [11.0 s]    dev=(HR@5:0.4546,NDCG@5:0.3352) [0.4 s]
INFO:root:Epoch 39    loss=0.1959 [10.9 s]    dev=(HR@5:0.4474,NDCG@5:0.3307) [0.4 s]
INFO:root:Epoch 40    loss=0.1956 [11.2 s]    dev=(HR@5:0.4479,NDCG@5:0.3315) [0.4 s]
INFO:root:Epoch 41    loss=0.1965 [11.1 s]    dev=(HR@5:0.4507,NDCG@5:0.3336) [0.4 s]
INFO:root:Epoch 42    loss=0.1961 [11.4 s]    dev=(HR@5:0.4549,NDCG@5:0.3338) [0.4 s]
INFO:root:Epoch 43    loss=0.1940 [11.0 s]    dev=(HR@5:0.4530,NDCG@5:0.3355) [0.4 s]
INFO:root:Epoch 44    loss=0.1954 [11.0 s]    dev=(HR@5:0.4501,NDCG@5:0.3331) [0.4 s]
INFO:root:Epoch 45    loss=0.1927 [11.0 s]    dev=(HR@5:0.4534,NDCG@5:0.3365) [0.4 s] *
INFO:root:Epoch 46    loss=0.1941 [10.5 s]    dev=(HR@5:0.4495,NDCG@5:0.3345) [0.4 s]
INFO:root:Epoch 47    loss=0.1946 [11.0 s]    dev=(HR@5:0.4494,NDCG@5:0.3323) [0.4 s]
INFO:root:Epoch 48    loss=0.1930 [10.9 s]    dev=(HR@5:0.4541,NDCG@5:0.3359) [0.4 s]
INFO:root:Epoch 49    loss=0.1928 [11.1 s]    dev=(HR@5:0.4530,NDCG@5:0.3369) [0.4 s] *
INFO:root:Epoch 50    loss=0.1946 [11.0 s]    dev=(HR@5:0.4512,NDCG@5:0.3350) [0.4 s]
INFO:root:Epoch 51    loss=0.1923 [11.3 s]    dev=(HR@5:0.4519,NDCG@5:0.3342) [0.4 s]
INFO:root:Epoch 52    loss=0.1928 [11.1 s]    dev=(HR@5:0.4500,NDCG@5:0.3342) [0.4 s]
INFO:root:Epoch 53    loss=0.1928 [11.2 s]    dev=(HR@5:0.4468,NDCG@5:0.3314) [0.4 s]
INFO:root:Epoch 54    loss=0.1909 [10.5 s]    dev=(HR@5:0.4541,NDCG@5:0.3349) [0.4 s]
INFO:root:Epoch 55    loss=0.1918 [10.9 s]    dev=(HR@5:0.4501,NDCG@5:0.3346) [0.4 s]
INFO:root:Epoch 56    loss=0.1921 [11.2 s]    dev=(HR@5:0.4542,NDCG@5:0.3358) [0.4 s]
INFO:root:Epoch 57    loss=0.1920 [11.1 s]    dev=(HR@5:0.4536,NDCG@5:0.3358) [0.4 s]
INFO:root:Epoch 58    loss=0.1934 [11.0 s]    dev=(HR@5:0.4506,NDCG@5:0.3360) [0.4 s]
INFO:root:Epoch 59    loss=0.1922 [11.0 s]    dev=(HR@5:0.4508,NDCG@5:0.3336) [0.4 s]
INFO:root:Epoch 60    loss=0.1929 [11.0 s]    dev=(HR@5:0.4540,NDCG@5:0.3368) [0.4 s]
INFO:root:Epoch 61    loss=0.1925 [10.8 s]    dev=(HR@5:0.4517,NDCG@5:0.3353) [0.4 s]
INFO:root:Epoch 62    loss=0.1911 [10.9 s]    dev=(HR@5:0.4542,NDCG@5:0.3352) [0.4 s]
INFO:root:Epoch 63    loss=0.1931 [10.3 s]    dev=(HR@5:0.4534,NDCG@5:0.3365) [0.4 s]
INFO:root:Epoch 64    loss=0.1907 [10.9 s]    dev=(HR@5:0.4529,NDCG@5:0.3352) [0.4 s]
INFO:root:Epoch 65    loss=0.1920 [11.2 s]    dev=(HR@5:0.4515,NDCG@5:0.3349) [0.4 s]
INFO:root:Epoch 66    loss=0.1896 [11.1 s]    dev=(HR@5:0.4524,NDCG@5:0.3344) [0.4 s]
INFO:root:Epoch 67    loss=0.1902 [11.0 s]    dev=(HR@5:0.4528,NDCG@5:0.3348) [0.4 s]
INFO:root:Epoch 68    loss=0.1893 [11.0 s]    dev=(HR@5:0.4537,NDCG@5:0.3359) [0.4 s]
INFO:root:Epoch 69    loss=0.1906 [11.0 s]    dev=(HR@5:0.4547,NDCG@5:0.3355) [0.4 s]
INFO:root:Early stop at 69 based on dev result.
INFO:root:
Best Iter(dev)=   49	 dev=(HR@5:0.4530,NDCG@5:0.3369) [790.8 s] 
INFO:root:Load model from ../model/BSARec/BSARec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=0.001__emb_size=64__num_layers=2__num_heads=1.pt
INFO:root:
Test After Training: (HR@5:0.4069,NDCG@5:0.2968,HR@10:0.5152,NDCG@10:0.3319,HR@20:0.6345,NDCG@20:0.3620,HR@50:0.8375,NDCG@50:0.4022)
INFO:root:
--------------------------------------------- END: 2024-12-23 11:49:02 ---------------------------------------------
